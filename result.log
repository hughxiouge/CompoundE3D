2023-03-16 15:16:49,143 INFO     Model: CompoundE3D_Complete_Mix_T_H
2023-03-16 15:16:49,144 INFO     Dataset: ogbl-wikikg2
2023-03-16 15:16:49,144 INFO     #entity: 2500604
2023-03-16 15:16:49,144 INFO     #relation: 535
2023-03-16 15:16:49,144 INFO     #train: 16109182
2023-03-16 15:16:49,144 INFO     #valid: 429456
2023-03-16 15:16:49,144 INFO     #test: 598543
2023-03-16 15:16:49,144 INFO     relation type all
log/ogbl-wikikg2/CompoundE3D_Complete_Mix_T_H/300-8.0/1679004971.601762/train.log
relation type all

  0%|          | 0/16109182 [00:00<?, ?it/s]
  0%|          | 19140/16109182 [00:00<01:24, 191392.88it/s]
  0%|          | 39131/16109182 [00:00<01:21, 196398.30it/s]
  0%|          | 65354/16109182 [00:00<01:10, 226429.31it/s]
  1%|          | 87997/16109182 [00:00<01:19, 202249.29it/s]
  1%|          | 112335/16109182 [00:00<01:26, 185637.95it/s]
  1%|          | 137382/16109182 [00:00<01:18, 204526.61it/s]
  1%|          | 164663/16109182 [00:00<01:10, 224594.87it/s]
  1%|          | 187774/16109182 [00:00<01:24, 187997.42it/s]
  1%|▏         | 215619/16109182 [00:01<01:15, 211476.44it/s]
  1%|▏         | 238140/16109182 [00:01<01:30, 175451.19it/s]
  2%|▏         | 264042/16109182 [00:01<01:21, 195471.53it/s]
  2%|▏         | 289707/16109182 [00:01<01:14, 211068.04it/s]
  2%|▏         | 316907/16109182 [00:01<01:09, 227330.57it/s]
  2%|▏         | 340946/16109182 [00:01<01:30, 173451.44it/s]
  2%|▏         | 365377/16109182 [00:01<01:23, 189643.12it/s]
  2%|▏         | 390975/16109182 [00:01<01:16, 205968.85it/s]
  3%|▎         | 416885/16109182 [00:02<01:11, 219787.71it/s]
  3%|▎         | 440520/16109182 [00:02<01:38, 158684.13it/s]
  3%|▎         | 465508/16109182 [00:02<01:27, 178287.93it/s]
  3%|▎         | 491606/16109182 [00:02<01:18, 197714.46it/s]
  3%|▎         | 517701/16109182 [00:02<01:12, 213602.82it/s]
  3%|▎         | 544222/16109182 [00:02<01:08, 227009.39it/s]
  4%|▎         | 568962/16109182 [00:02<01:40, 154482.83it/s]
  4%|▎         | 590849/16109182 [00:03<01:32, 167757.60it/s]
  4%|▍         | 617351/16109182 [00:03<01:21, 189887.11it/s]
  4%|▍         | 643789/16109182 [00:03<01:14, 208159.36it/s]
  4%|▍         | 669922/16109182 [00:03<01:09, 221954.68it/s]
  4%|▍         | 695959/16109182 [00:03<01:06, 232340.36it/s]
  4%|▍         | 720763/16109182 [00:03<01:06, 232870.84it/s]
  5%|▍         | 746928/16109182 [00:03<01:46, 144349.36it/s]
  5%|▍         | 772027/16109182 [00:04<01:32, 165046.38it/s]
  5%|▍         | 797092/16109182 [00:04<01:23, 183628.27it/s]
  5%|▌         | 822503/16109182 [00:04<01:16, 200310.18it/s]
  5%|▌         | 848308/16109182 [00:04<01:11, 214899.09it/s]
  5%|▌         | 874026/16109182 [00:04<01:07, 226104.95it/s]
  6%|▌         | 899386/16109182 [00:04<01:05, 233654.96it/s]
  6%|▌         | 924791/16109182 [00:04<01:03, 239401.94it/s]
  6%|▌         | 950240/16109182 [00:04<01:02, 243729.26it/s]
  6%|▌         | 975346/16109182 [00:05<01:55, 130947.31it/s]
  6%|▌         | 999971/16109182 [00:05<01:39, 151838.14it/s]
  6%|▋         | 1024977/16109182 [00:05<01:27, 172032.51it/s]
  7%|▋         | 1050677/16109182 [00:05<01:18, 191322.80it/s]
  7%|▋         | 1076364/16109182 [00:05<01:12, 207374.44it/s]
  7%|▋         | 1101831/16109182 [00:05<01:08, 219629.64it/s]
  7%|▋         | 1127554/16109182 [00:05<01:05, 229782.75it/s]
  7%|▋         | 1153105/16109182 [00:05<01:03, 236945.91it/s]
  7%|▋         | 1178540/16109182 [00:05<01:01, 241897.40it/s]
  7%|▋         | 1204096/16109182 [00:06<01:00, 245843.28it/s]
  8%|▊         | 1229371/16109182 [00:06<01:03, 232808.82it/s]
  8%|▊         | 1255475/16109182 [00:06<01:01, 240759.03it/s]
  8%|▊         | 1280037/16109182 [00:06<02:06, 117056.27it/s]
  8%|▊         | 1305050/16109182 [00:06<01:46, 139062.72it/s]
  8%|▊         | 1330545/16109182 [00:06<01:31, 161207.94it/s]
  8%|▊         | 1355890/16109182 [00:07<01:21, 180988.27it/s]
  9%|▊         | 1381121/16109182 [00:07<01:14, 197711.86it/s]
  9%|▊         | 1406345/16109182 [00:07<01:09, 211392.48it/s]
  9%|▉         | 1432010/16109182 [00:07<01:05, 223331.44it/s]
  9%|▉         | 1456627/16109182 [00:07<01:07, 217402.07it/s]
  9%|▉         | 1482139/16109182 [00:07<01:04, 227591.81it/s]
  9%|▉         | 1507798/16109182 [00:07<01:01, 235666.54it/s]
 10%|▉         | 1533098/16109182 [00:07<01:00, 240598.72it/s]
 10%|▉         | 1558414/16109182 [00:07<00:59, 244226.18it/s]
 10%|▉         | 1584033/16109182 [00:07<00:58, 247719.64it/s]
 10%|▉         | 1609704/16109182 [00:08<00:57, 250363.21it/s]
 10%|█         | 1634993/16109182 [00:08<02:20, 102775.40it/s]
 10%|█         | 1659415/16109182 [00:08<01:56, 123652.12it/s]
 10%|█         | 1684267/16109182 [00:08<01:39, 145395.35it/s]
 11%|█         | 1709378/16109182 [00:08<01:26, 166452.89it/s]
 11%|█         | 1734639/16109182 [00:09<01:17, 185538.59it/s]
 11%|█         | 1759522/16109182 [00:09<01:11, 200752.19it/s]
 11%|█         | 1784632/16109182 [00:09<01:07, 213621.64it/s]
 11%|█         | 1809795/16109182 [00:09<01:03, 223786.10it/s]
 11%|█▏        | 1834402/16109182 [00:09<01:02, 229945.47it/s]
 12%|█▏        | 1858981/16109182 [00:09<01:01, 233512.91it/s]
 12%|█▏        | 1883893/16109182 [00:09<00:59, 237951.86it/s]
 12%|█▏        | 1908852/16109182 [00:09<00:58, 241333.55it/s]
 12%|█▏        | 1933562/16109182 [00:09<00:58, 242648.35it/s]
 12%|█▏        | 1958858/16109182 [00:09<00:57, 245688.29it/s]
 12%|█▏        | 1983716/16109182 [00:10<00:57, 245526.01it/s]
 12%|█▏        | 2008471/16109182 [00:10<00:57, 244478.54it/s]
 13%|█▎        | 2033330/16109182 [00:10<00:57, 245694.41it/s]
 13%|█▎        | 2058322/16109182 [00:10<00:56, 246948.88it/s]
 13%|█▎        | 2083173/16109182 [00:10<00:56, 247408.45it/s]
 13%|█▎        | 2107965/16109182 [00:11<02:42, 86354.95it/s] 
 13%|█▎        | 2132382/16109182 [00:11<02:10, 106802.07it/s]
 13%|█▎        | 2156840/16109182 [00:11<01:48, 128320.22it/s]
 14%|█▎        | 2181663/16109182 [00:11<01:32, 150192.65it/s]
 14%|█▎        | 2206572/16109182 [00:11<01:21, 170635.06it/s]
 14%|█▍        | 2231001/16109182 [00:11<01:14, 187425.45it/s]
 14%|█▍        | 2255382/16109182 [00:11<01:08, 201274.78it/s]
 14%|█▍        | 2279753/16109182 [00:11<01:05, 212295.69it/s]
 14%|█▍        | 2304803/16109182 [00:11<01:02, 222634.03it/s]
 14%|█▍        | 2329292/16109182 [00:12<01:00, 228837.94it/s]
 15%|█▍        | 2353835/16109182 [00:12<00:58, 233562.37it/s]
 15%|█▍        | 2378644/16109182 [00:12<00:57, 237762.50it/s]
 15%|█▍        | 2403176/16109182 [00:12<00:58, 236133.41it/s]
 15%|█▌        | 2427320/16109182 [00:12<00:57, 237216.96it/s]
 15%|█▌        | 2451852/16109182 [00:12<00:57, 239592.82it/s]
 15%|█▌        | 2476309/16109182 [00:12<00:56, 241061.18it/s]
 16%|█▌        | 2500882/16109182 [00:12<00:56, 242443.29it/s]
 16%|█▌        | 2525300/16109182 [00:12<00:55, 242957.64it/s]
 16%|█▌        | 2550100/16109182 [00:12<00:55, 244460.23it/s]
 16%|█▌        | 2574613/16109182 [00:13<01:03, 212034.90it/s]
 16%|█▌        | 2599474/16109182 [00:13<01:00, 221911.53it/s]
 16%|█▋        | 2624139/16109182 [00:13<00:58, 228796.83it/s]
 16%|█▋        | 2649163/16109182 [00:13<00:57, 234896.08it/s]
 17%|█▋        | 2673703/16109182 [00:13<00:56, 237928.83it/s]
 17%|█▋        | 2698523/16109182 [00:13<00:55, 240927.52it/s]
 17%|█▋        | 2722829/16109182 [00:14<03:03, 72937.50it/s] 
 17%|█▋        | 2746499/16109182 [00:14<02:26, 91396.05it/s]
 17%|█▋        | 2770634/16109182 [00:14<01:58, 112192.73it/s]
 17%|█▋        | 2795098/16109182 [00:14<01:39, 134094.27it/s]
 18%|█▊        | 2819669/16109182 [00:14<01:25, 155422.02it/s]
 18%|█▊        | 2844978/16109182 [00:15<01:15, 176364.42it/s]
 18%|█▊        | 2869879/16109182 [00:15<01:08, 193397.93it/s]
 18%|█▊        | 2894217/16109182 [00:15<01:04, 205936.43it/s]
 18%|█▊        | 2918906/16109182 [00:15<01:00, 216740.56it/s]
 18%|█▊        | 2943421/16109182 [00:15<00:58, 224515.72it/s]
 18%|█▊        | 2967750/16109182 [00:15<00:57, 229416.48it/s]
 19%|█▊        | 2992037/16109182 [00:15<01:05, 201359.53it/s]
 19%|█▊        | 3016420/16109182 [00:15<01:01, 212436.75it/s]
 19%|█▉        | 3041083/16109182 [00:15<00:58, 221717.84it/s]
 19%|█▉        | 3065910/16109182 [00:15<00:56, 229136.10it/s]
 19%|█▉        | 3090637/16109182 [00:16<00:55, 234306.56it/s]
 19%|█▉        | 3115058/16109182 [00:16<00:54, 237172.02it/s]
 19%|█▉        | 3140030/16109182 [00:16<00:53, 240840.48it/s]
 20%|█▉        | 3164397/16109182 [00:16<00:53, 241493.39it/s]
 20%|█▉        | 3189422/16109182 [00:16<00:52, 244084.73it/s]
 20%|█▉        | 3214412/16109182 [00:16<00:52, 245811.84it/s]
 20%|██        | 3239095/16109182 [00:16<00:52, 245411.27it/s]
 20%|██        | 3264060/16109182 [00:16<00:52, 246671.30it/s]
 20%|██        | 3288778/16109182 [00:16<00:51, 246691.03it/s]
 21%|██        | 3313483/16109182 [00:16<00:51, 246706.97it/s]
 21%|██        | 3338520/16109182 [00:17<00:51, 247800.12it/s]
 21%|██        | 3363621/16109182 [00:17<00:51, 248758.99it/s]
 21%|██        | 3388583/16109182 [00:17<00:51, 249014.70it/s]
 21%|██        | 3413494/16109182 [00:17<00:51, 248575.12it/s]
 21%|██▏       | 3438358/16109182 [00:17<00:51, 247490.97it/s]
 21%|██▏       | 3463113/16109182 [00:17<00:51, 245922.21it/s]
 22%|██▏       | 3487711/16109182 [00:18<03:14, 64753.61it/s] 
 22%|██▏       | 3512182/16109182 [00:18<02:31, 82875.06it/s]
 22%|██▏       | 3536028/16109182 [00:18<02:02, 102441.65it/s]
 22%|██▏       | 3560233/16109182 [00:18<01:41, 123703.18it/s]
 22%|██▏       | 3584849/16109182 [00:19<01:26, 145584.40it/s]
 22%|██▏       | 3609254/16109182 [00:19<01:15, 165607.36it/s]
 23%|██▎       | 3633398/16109182 [00:19<01:08, 182677.17it/s]
 23%|██▎       | 3657474/16109182 [00:19<01:03, 196807.77it/s]
 23%|██▎       | 3682023/16109182 [00:19<00:59, 209363.32it/s]
 23%|██▎       | 3706338/16109182 [00:19<00:56, 218456.09it/s]
 23%|██▎       | 3730624/16109182 [00:19<00:54, 225232.20it/s]
 23%|██▎       | 3754999/16109182 [00:19<00:53, 230487.19it/s]
 23%|██▎       | 3779951/16109182 [00:19<00:52, 235978.74it/s]
 24%|██▎       | 3804626/16109182 [00:19<00:51, 239120.07it/s]
 24%|██▍       | 3829127/16109182 [00:20<00:51, 240781.99it/s]
 24%|██▍       | 3853690/16109182 [00:20<00:50, 242214.81it/s]
 24%|██▍       | 3878345/16109182 [00:20<00:50, 243500.86it/s]
 24%|██▍       | 3902902/16109182 [00:20<00:50, 243519.59it/s]
 24%|██▍       | 3927457/16109182 [00:20<00:49, 244121.94it/s]
 25%|██▍       | 3951971/16109182 [00:20<00:49, 243187.44it/s]
 25%|██▍       | 3976362/16109182 [00:20<00:50, 241829.19it/s]
 25%|██▍       | 4000739/16109182 [00:20<00:49, 242402.88it/s]
 25%|██▍       | 4025233/16109182 [00:20<00:49, 243157.08it/s]
 25%|██▌       | 4049575/16109182 [00:20<00:49, 243082.15it/s]
 25%|██▌       | 4073902/16109182 [00:21<00:49, 243073.58it/s]
 25%|██▌       | 4098271/16109182 [00:21<00:49, 243255.47it/s]
 26%|██▌       | 4122606/16109182 [00:21<00:49, 242660.04it/s]
 26%|██▌       | 4146977/16109182 [00:21<00:49, 242969.95it/s]
 26%|██▌       | 4171279/16109182 [00:21<00:49, 242925.71it/s]
 26%|██▌       | 4195575/16109182 [00:21<00:49, 242601.21it/s]
 26%|██▌       | 4219838/16109182 [00:21<00:49, 242200.22it/s]
 26%|██▋       | 4244399/16109182 [00:21<00:48, 243217.16it/s]
 26%|██▋       | 4268723/16109182 [00:21<00:48, 242533.23it/s]
 27%|██▋       | 4292978/16109182 [00:21<00:48, 242388.15it/s]
 27%|██▋       | 4317218/16109182 [00:22<00:48, 241345.45it/s]
 27%|██▋       | 4341922/16109182 [00:22<00:48, 243043.69it/s]
 27%|██▋       | 4366229/16109182 [00:22<00:48, 242437.14it/s]
 27%|██▋       | 4390475/16109182 [00:22<00:48, 241947.40it/s]
 27%|██▋       | 4414671/16109182 [00:22<00:48, 241751.70it/s]
 28%|██▊       | 4438847/16109182 [00:22<00:48, 241328.25it/s]
 28%|██▊       | 4462981/16109182 [00:23<03:37, 53567.79it/s] 
 28%|██▊       | 4487303/16109182 [00:23<02:46, 69984.79it/s]
 28%|██▊       | 4511773/16109182 [00:23<02:09, 89212.56it/s]
 28%|██▊       | 4535319/16109182 [00:24<01:46, 109080.89it/s]
 28%|██▊       | 4559895/16109182 [00:24<01:27, 131293.25it/s]
 28%|██▊       | 4583634/16109182 [00:24<01:16, 151282.44it/s]
 29%|██▊       | 4607463/16109182 [00:24<01:07, 169734.91it/s]
 29%|██▉       | 4631816/16109182 [00:24<01:01, 186893.49it/s]
 29%|██▉       | 4655770/16109182 [00:24<00:57, 200018.46it/s]
 29%|██▉       | 4679444/16109182 [00:24<00:54, 209247.35it/s]
 29%|██▉       | 4703500/16109182 [00:24<00:52, 217776.17it/s]
 29%|██▉       | 4727568/16109182 [00:24<00:50, 224189.54it/s]
 29%|██▉       | 4751777/16109182 [00:24<00:49, 229303.33it/s]
 30%|██▉       | 4776356/16109182 [00:25<00:48, 234080.60it/s]
 30%|██▉       | 4800855/16109182 [00:25<00:47, 237272.19it/s]
 30%|██▉       | 4825104/16109182 [00:25<00:47, 237475.47it/s]
 30%|███       | 4849217/16109182 [00:25<00:47, 236897.85it/s]
 30%|███       | 4873163/16109182 [00:25<00:47, 236788.31it/s]
 30%|███       | 4897021/16109182 [00:25<00:49, 228181.83it/s]
 31%|███       | 4920026/16109182 [00:25<00:48, 228378.73it/s]
 31%|███       | 4942996/16109182 [00:25<00:49, 227370.13it/s]
 31%|███       | 4966589/16109182 [00:25<00:48, 229873.65it/s]
 31%|███       | 4990228/16109182 [00:26<00:47, 231794.03it/s]
 31%|███       | 5013692/16109182 [00:26<00:47, 232633.40it/s]
 31%|███▏      | 5037345/16109182 [00:26<00:47, 233790.44it/s]
 31%|███▏      | 5061661/16109182 [00:26<00:46, 236583.10it/s]
 32%|███▏      | 5085340/16109182 [00:26<00:46, 236324.11it/s]
 32%|███▏      | 5109310/16109182 [00:26<00:46, 237327.72it/s]
 32%|███▏      | 5133054/16109182 [00:26<00:46, 236822.47it/s]
 32%|███▏      | 5156776/16109182 [00:26<00:46, 236935.47it/s]
 32%|███▏      | 5180705/16109182 [00:26<00:45, 237637.47it/s]
 32%|███▏      | 5204473/16109182 [00:26<00:45, 237493.24it/s]
 32%|███▏      | 5228446/16109182 [00:27<00:45, 238159.14it/s]
 33%|███▎      | 5252505/16109182 [00:27<00:45, 238885.73it/s]
 33%|███▎      | 5276396/16109182 [00:27<00:45, 238860.81it/s]
 33%|███▎      | 5300284/16109182 [00:27<00:45, 237959.05it/s]
 33%|███▎      | 5324082/16109182 [00:27<00:45, 236925.44it/s]
 33%|███▎      | 5347777/16109182 [00:27<00:45, 236831.23it/s]
 33%|███▎      | 5371675/16109182 [00:27<00:45, 237468.29it/s]
 33%|███▎      | 5395685/16109182 [00:27<00:44, 238250.89it/s]
 34%|███▎      | 5419610/16109182 [00:27<00:44, 238546.35it/s]
 34%|███▍      | 5443466/16109182 [00:27<00:44, 237815.35it/s]
 34%|███▍      | 5467249/16109182 [00:28<01:01, 173664.58it/s]
 34%|███▍      | 5491073/16109182 [00:28<00:56, 189018.49it/s]
 34%|███▍      | 5515051/16109182 [00:28<00:52, 201885.91it/s]
 34%|███▍      | 5539477/16109182 [00:28<00:49, 213149.79it/s]
 35%|███▍      | 5563506/16109182 [00:28<00:47, 220618.66it/s]
 35%|███▍      | 5588141/16109182 [00:28<00:46, 227878.34it/s]
 35%|███▍      | 5611971/16109182 [00:28<00:45, 230871.08it/s]
 35%|███▍      | 5635627/16109182 [00:28<00:45, 232521.81it/s]
 35%|███▌      | 5659264/16109182 [00:28<00:44, 232893.88it/s]
 35%|███▌      | 5682824/16109182 [00:29<00:44, 233324.45it/s]
 35%|███▌      | 5706346/16109182 [00:30<03:58, 43537.57it/s] 
 36%|███▌      | 5729755/16109182 [00:30<03:00, 57444.44it/s]
 36%|███▌      | 5753904/16109182 [00:30<02:18, 74821.16it/s]
 36%|███▌      | 5777621/16109182 [00:30<01:49, 94115.89it/s]
 36%|███▌      | 5801334/16109182 [00:31<01:29, 114872.28it/s]
 36%|███▌      | 5825114/16109182 [00:31<01:15, 135982.07it/s]
 36%|███▋      | 5848899/16109182 [00:31<01:05, 156049.36it/s]
 36%|███▋      | 5873006/16109182 [00:31<00:58, 174720.01it/s]
 37%|███▋      | 5896856/16109182 [00:31<00:53, 189950.34it/s]
 37%|███▋      | 5920684/16109182 [00:31<00:50, 202241.61it/s]
 37%|███▋      | 5944869/16109182 [00:31<00:47, 212796.96it/s]
 37%|███▋      | 5968934/16109182 [00:31<00:45, 220475.96it/s]
 37%|███▋      | 5992962/16109182 [00:31<00:44, 226070.87it/s]
 37%|███▋      | 6016947/16109182 [00:31<00:43, 230031.12it/s]
 38%|███▊      | 6041315/16109182 [00:32<00:43, 234003.03it/s]
 38%|███▊      | 6065375/16109182 [00:32<00:42, 235025.60it/s]
 38%|███▊      | 6089594/16109182 [00:32<00:42, 237135.20it/s]
 38%|███▊      | 6113636/16109182 [00:32<00:42, 237888.37it/s]
 38%|███▊      | 6137655/16109182 [00:32<00:41, 237826.11it/s]
 38%|███▊      | 6161599/16109182 [00:32<00:41, 237449.49it/s]
 38%|███▊      | 6185457/16109182 [00:32<00:57, 173028.64it/s]
 39%|███▊      | 6208921/16109182 [00:32<00:52, 187577.18it/s]
 39%|███▊      | 6233184/16109182 [00:32<00:49, 201462.59it/s]
 39%|███▉      | 6257041/16109182 [00:33<00:46, 211289.56it/s]
 39%|███▉      | 6281679/16109182 [00:33<00:44, 220920.47it/s]
 39%|███▉      | 6306290/16109182 [00:33<00:42, 228014.23it/s]
 39%|███▉      | 6330219/16109182 [00:33<00:42, 231246.31it/s]
 39%|███▉      | 6354690/16109182 [00:33<00:41, 235159.09it/s]
 40%|███▉      | 6379177/16109182 [00:33<00:40, 238007.26it/s]
 40%|███▉      | 6403484/16109182 [00:33<00:40, 239501.46it/s]
 40%|███▉      | 6427839/16109182 [00:33<00:40, 240699.90it/s]
 40%|████      | 6452056/16109182 [00:33<00:41, 233364.98it/s]
 40%|████      | 6476512/16109182 [00:33<00:40, 236624.60it/s]
 40%|████      | 6500657/16109182 [00:34<00:40, 238039.93it/s]
 41%|████      | 6525583/16109182 [00:34<00:39, 241186.37it/s]
 41%|████      | 6550188/16109182 [00:34<00:39, 242627.91it/s]
 41%|████      | 6574948/16109182 [00:34<00:39, 244106.19it/s]
 41%|████      | 6599391/16109182 [00:34<00:39, 243391.12it/s]
 41%|████      | 6624072/16109182 [00:34<00:38, 244406.98it/s]
 41%|████▏     | 6648530/16109182 [00:34<00:38, 243495.63it/s]
 41%|████▏     | 6672892/16109182 [00:34<00:38, 242098.52it/s]
 42%|████▏     | 6697517/16109182 [00:34<00:38, 243330.16it/s]
 42%|████▏     | 6721858/16109182 [00:34<00:38, 241978.68it/s]
 42%|████▏     | 6746063/16109182 [00:35<00:38, 241180.92it/s]
 42%|████▏     | 6770638/16109182 [00:35<00:38, 242539.11it/s]
 42%|████▏     | 6794897/16109182 [00:35<00:38, 242479.17it/s]
 42%|████▏     | 6819372/16109182 [00:35<00:38, 243154.73it/s]
 42%|████▏     | 6843690/16109182 [00:35<00:38, 242642.00it/s]
 43%|████▎     | 6867956/16109182 [00:35<00:38, 242008.22it/s]
 43%|████▎     | 6892159/16109182 [00:35<00:39, 233656.37it/s]
 43%|████▎     | 6915585/16109182 [00:35<00:39, 232842.72it/s]
 43%|████▎     | 6938911/16109182 [00:35<00:39, 232749.02it/s]
 43%|████▎     | 6962981/16109182 [00:35<00:38, 235093.58it/s]
 43%|████▎     | 6986842/16109182 [00:36<00:38, 236132.26it/s]
 44%|████▎     | 7011415/16109182 [00:36<00:38, 238984.45it/s]
 44%|████▎     | 7035596/16109182 [00:36<00:37, 239824.12it/s]
 44%|████▍     | 7059709/16109182 [00:36<00:37, 240211.82it/s]
 44%|████▍     | 7084237/16109182 [00:36<00:37, 241724.62it/s]
 44%|████▍     | 7108416/16109182 [00:36<00:37, 241270.81it/s]
 44%|████▍     | 7132548/16109182 [00:36<00:37, 240603.75it/s]
 44%|████▍     | 7156744/16109182 [00:36<00:37, 241005.84it/s]
 45%|████▍     | 7180847/16109182 [00:36<00:37, 240552.95it/s]
 45%|████▍     | 7205364/16109182 [00:36<00:36, 241798.64it/s]
 45%|████▍     | 7229930/16109182 [00:37<00:36, 242951.25it/s]
 45%|████▌     | 7254356/16109182 [00:37<00:36, 243338.69it/s]
 45%|████▌     | 7279154/16109182 [00:37<00:36, 244727.37it/s]
 45%|████▌     | 7303858/16109182 [00:37<00:35, 245414.44it/s]
 45%|████▌     | 7328401/16109182 [00:39<04:08, 35365.67it/s] 
 46%|████▌     | 7352230/16109182 [00:39<03:05, 47161.39it/s]
 46%|████▌     | 7376120/16109182 [00:39<02:21, 61862.65it/s]
 46%|████▌     | 7399875/16109182 [00:39<01:49, 79206.45it/s]
 46%|████▌     | 7423822/16109182 [00:39<01:27, 99014.45it/s]
 46%|████▌     | 7448018/16109182 [00:39<01:11, 120465.56it/s]
 46%|████▋     | 7472764/16109182 [00:40<01:00, 142884.07it/s]
 47%|████▋     | 7497283/16109182 [00:40<00:52, 163487.42it/s]
 47%|████▋     | 7521182/16109182 [00:40<00:47, 180355.85it/s]
 47%|████▋     | 7544996/16109182 [00:40<00:44, 194335.47it/s]
 47%|████▋     | 7569250/16109182 [00:40<00:41, 206714.88it/s]
 47%|████▋     | 7593194/16109182 [00:40<00:39, 215314.50it/s]
 47%|████▋     | 7617115/16109182 [00:40<00:38, 221780.07it/s]
 47%|████▋     | 7641019/16109182 [00:40<00:37, 226009.79it/s]
 48%|████▊     | 7665288/16109182 [00:40<00:36, 230803.10it/s]
 48%|████▊     | 7689250/16109182 [00:40<00:36, 232310.30it/s]
 48%|████▊     | 7713570/16109182 [00:41<00:35, 235495.82it/s]
 48%|████▊     | 7738078/16109182 [00:41<00:35, 238319.02it/s]
 48%|████▊     | 7762224/16109182 [00:41<00:34, 238893.44it/s]
 48%|████▊     | 7786614/16109182 [00:41<00:34, 240377.31it/s]
 48%|████▊     | 7810808/16109182 [00:41<00:34, 239767.07it/s]
 49%|████▊     | 7834894/16109182 [00:41<00:34, 239167.39it/s]
 49%|████▉     | 7859184/16109182 [00:41<00:34, 240276.27it/s]
 49%|████▉     | 7883267/16109182 [00:41<00:34, 239584.80it/s]
 49%|████▉     | 7907264/16109182 [00:41<00:34, 238918.02it/s]
 49%|████▉     | 7931183/16109182 [00:41<00:34, 238980.45it/s]
 49%|████▉     | 7955100/16109182 [00:42<00:34, 237850.66it/s]
 50%|████▉     | 7978900/16109182 [00:42<00:34, 235276.68it/s]
 50%|████▉     | 8002443/16109182 [00:42<00:34, 234488.94it/s]
 50%|████▉     | 8026125/16109182 [00:42<00:34, 235177.45it/s]
 50%|████▉     | 8049651/16109182 [00:42<00:34, 232014.11it/s]
 50%|█████     | 8073518/16109182 [00:42<00:34, 233977.74it/s]
 50%|█████     | 8097314/16109182 [00:42<00:34, 235157.83it/s]
 50%|█████     | 8120867/16109182 [00:42<00:33, 235266.71it/s]
 51%|█████     | 8144920/16109182 [00:42<00:33, 236834.64it/s]
 51%|█████     | 8168634/16109182 [00:42<00:33, 236924.12it/s]
 51%|█████     | 8192331/16109182 [00:43<00:33, 236736.26it/s]
 51%|█████     | 8216008/16109182 [00:43<00:33, 236021.25it/s]
 51%|█████     | 8239755/16109182 [00:43<00:33, 236451.92it/s]
 51%|█████▏    | 8263402/16109182 [00:43<00:33, 236288.17it/s]
 51%|█████▏    | 8287132/16109182 [00:43<00:33, 236588.53it/s]
 52%|█████▏    | 8310956/16109182 [00:43<00:32, 237078.47it/s]
 52%|█████▏    | 8334665/16109182 [00:43<00:32, 235852.99it/s]
 52%|█████▏    | 8358353/16109182 [00:43<00:32, 236155.41it/s]
 52%|█████▏    | 8381970/16109182 [00:43<00:32, 235717.32it/s]
 52%|█████▏    | 8405569/16109182 [00:44<00:32, 235795.21it/s]
 52%|█████▏    | 8429590/16109182 [00:44<00:32, 237113.73it/s]
 52%|█████▏    | 8453303/16109182 [00:44<00:32, 236275.15it/s]
 53%|█████▎    | 8476932/16109182 [00:44<00:32, 236221.75it/s]
 53%|█████▎    | 8500617/16109182 [00:44<00:32, 236407.75it/s]
 53%|█████▎    | 8524259/16109182 [00:44<00:32, 234891.29it/s]
 53%|█████▎    | 8547751/16109182 [00:44<00:32, 233226.29it/s]
 53%|█████▎    | 8571078/16109182 [00:44<00:32, 233122.21it/s]
 53%|█████▎    | 8594393/16109182 [00:44<00:32, 232476.85it/s]
 53%|█████▎    | 8617877/16109182 [00:44<00:32, 233177.98it/s]
 54%|█████▎    | 8641197/16109182 [00:45<00:32, 232885.04it/s]
 54%|█████▍    | 8664730/16109182 [00:45<00:31, 233613.19it/s]
 54%|█████▍    | 8688093/16109182 [00:45<00:31, 233245.85it/s]
 54%|█████▍    | 8711419/16109182 [00:45<00:31, 232531.61it/s]
 54%|█████▍    | 8734673/16109182 [00:45<00:31, 232042.09it/s]
 54%|█████▍    | 8758167/16109182 [00:45<00:31, 232903.76it/s]
 55%|█████▍    | 8782174/16109182 [00:45<00:31, 235042.46it/s]
 55%|█████▍    | 8805680/16109182 [00:45<00:32, 227308.56it/s]
 55%|█████▍    | 8828466/16109182 [00:45<00:32, 224616.24it/s]
 55%|█████▍    | 8851609/16109182 [00:45<00:32, 226603.95it/s]
 55%|█████▌    | 8874605/16109182 [00:46<00:31, 227588.19it/s]
 55%|█████▌    | 8897593/16109182 [00:46<00:31, 228262.79it/s]
 55%|█████▌    | 8920959/16109182 [00:46<00:31, 229864.87it/s]
 56%|█████▌    | 8944285/16109182 [00:46<00:31, 230873.46it/s]
 56%|█████▌    | 8967609/16109182 [00:46<00:30, 231578.95it/s]
 56%|█████▌    | 8991409/16109182 [00:46<00:30, 233495.53it/s]
 56%|█████▌    | 9014818/16109182 [00:46<00:30, 233671.21it/s]
 56%|█████▌    | 9038190/16109182 [00:46<00:30, 232890.58it/s]
 56%|█████▋    | 9061483/16109182 [00:46<00:30, 232211.91it/s]
 56%|█████▋    | 9084707/16109182 [00:46<00:30, 232217.23it/s]
 57%|█████▋    | 9108645/16109182 [00:47<00:29, 234356.29it/s]
 57%|█████▋    | 9132179/16109182 [00:47<00:29, 234646.79it/s]
 57%|█████▋    | 9155646/16109182 [00:47<00:29, 234340.53it/s]
 57%|█████▋    | 9179082/16109182 [00:47<00:29, 234072.75it/s]
 57%|█████▋    | 9202491/16109182 [00:47<00:29, 232281.72it/s]
 57%|█████▋    | 9225964/16109182 [00:47<00:29, 233007.36it/s]
 57%|█████▋    | 9249638/16109182 [00:47<00:29, 234117.58it/s]
 58%|█████▊    | 9273278/16109182 [00:47<00:29, 234795.67it/s]
 58%|█████▊    | 9296760/16109182 [00:47<00:29, 233708.26it/s]
 58%|█████▊    | 9320134/16109182 [00:47<00:29, 232708.84it/s]
 58%|█████▊    | 9343787/16109182 [00:48<00:28, 233845.65it/s]
 58%|█████▊    | 9367174/16109182 [00:48<00:28, 232990.54it/s]
 58%|█████▊    | 9390475/16109182 [00:50<04:05, 27369.86it/s] 
 58%|█████▊    | 9414058/16109182 [00:50<02:59, 37306.48it/s]
 59%|█████▊    | 9437760/16109182 [00:50<02:13, 50038.88it/s]
 59%|█████▊    | 9461894/16109182 [00:51<01:40, 66007.29it/s]
 59%|█████▉    | 9485379/16109182 [00:51<01:18, 83996.17it/s]
 59%|█████▉    | 9509309/16109182 [00:51<01:03, 104510.12it/s]
 59%|█████▉    | 9533021/16109182 [00:51<00:52, 125561.62it/s]
 59%|█████▉    | 9556495/16109182 [00:51<00:44, 145744.01it/s]
 59%|█████▉    | 9580626/16109182 [00:51<00:39, 165707.50it/s]
 60%|█████▉    | 9604646/16109182 [00:51<00:35, 182828.44it/s]
 60%|█████▉    | 9628232/16109182 [00:51<00:33, 195881.44it/s]
 60%|█████▉    | 9652034/16109182 [00:51<00:31, 206874.98it/s]
 60%|██████    | 9676251/16109182 [00:51<00:29, 216384.92it/s]
 60%|██████    | 9700322/16109182 [00:52<00:28, 223180.33it/s]
 60%|██████    | 9724209/16109182 [00:52<00:28, 226601.60it/s]
 61%|██████    | 9747981/16109182 [00:52<00:27, 229080.26it/s]
 61%|██████    | 9771675/16109182 [00:52<00:27, 230732.53it/s]
 61%|██████    | 9795303/16109182 [00:52<00:27, 227474.62it/s]
 61%|██████    | 9818752/16109182 [00:52<00:27, 229511.60it/s]
 61%|██████    | 9842797/16109182 [00:52<00:26, 232719.34it/s]
 61%|██████    | 9866525/16109182 [00:52<00:26, 234061.86it/s]
 61%|██████▏   | 9890289/16109182 [00:52<00:26, 235119.89it/s]
 62%|██████▏   | 9914245/16109182 [00:52<00:26, 236439.44it/s]
 62%|██████▏   | 9938332/16109182 [00:53<00:25, 237759.96it/s]
 62%|██████▏   | 9962161/16109182 [00:53<00:26, 236075.18it/s]
 62%|██████▏   | 9986352/16109182 [00:53<00:25, 237807.59it/s]
 62%|██████▏   | 10010310/16109182 [00:53<00:25, 238331.97it/s]
 62%|██████▏   | 10034164/16109182 [00:53<00:25, 236934.79it/s]
 62%|██████▏   | 10057974/16109182 [00:53<00:25, 237279.76it/s]
 63%|██████▎   | 10081851/16109182 [00:53<00:25, 237714.02it/s]
 63%|██████▎   | 10105631/16109182 [00:53<00:25, 237357.46it/s]
 63%|██████▎   | 10129724/16109182 [00:53<00:25, 238420.52it/s]
 63%|██████▎   | 10153571/16109182 [00:53<00:25, 237963.25it/s]
 63%|██████▎   | 10177371/16109182 [00:54<00:25, 236808.10it/s]
 63%|██████▎   | 10201211/16109182 [00:54<00:24, 237279.50it/s]
 63%|██████▎   | 10224942/16109182 [00:54<00:24, 236244.68it/s]
 64%|██████▎   | 10248869/16109182 [00:54<00:24, 237142.31it/s]
 64%|██████▍   | 10272586/16109182 [00:54<00:24, 236840.24it/s]
 64%|██████▍   | 10296272/16109182 [00:54<00:24, 234127.97it/s]
 64%|██████▍   | 10319692/16109182 [00:54<00:24, 233905.62it/s]
 64%|██████▍   | 10343088/16109182 [00:54<00:24, 233588.81it/s]
 64%|██████▍   | 10366737/16109182 [00:54<00:24, 234450.67it/s]
 64%|██████▍   | 10390238/16109182 [00:54<00:24, 234614.56it/s]
 65%|██████▍   | 10413702/16109182 [00:55<00:24, 233885.13it/s]
 65%|██████▍   | 10437513/16109182 [00:55<00:24, 235144.39it/s]
 65%|██████▍   | 10461425/16109182 [00:55<00:23, 236328.61it/s]
 65%|██████▌   | 10485060/16109182 [00:55<00:23, 235088.72it/s]
 65%|██████▌   | 10508572/16109182 [00:55<00:23, 234475.03it/s]
 65%|██████▌   | 10532336/16109182 [00:55<00:23, 235415.47it/s]
 66%|██████▌   | 10555880/16109182 [00:55<00:24, 226948.07it/s]
 66%|██████▌   | 10578639/16109182 [00:55<00:24, 224929.80it/s]
 66%|██████▌   | 10601957/16109182 [00:55<00:24, 227335.55it/s]
 66%|██████▌   | 10625427/16109182 [00:55<00:23, 229500.20it/s]
 66%|██████▌   | 10648973/16109182 [00:56<00:23, 231259.96it/s]
 66%|██████▋   | 10672515/16109182 [00:56<00:23, 232490.64it/s]
 66%|██████▋   | 10696414/16109182 [00:56<00:23, 234425.39it/s]
 67%|██████▋   | 10719933/16109182 [00:56<00:22, 234651.95it/s]
 67%|██████▋   | 10743408/16109182 [00:56<00:22, 234472.88it/s]
 67%|██████▋   | 10767123/16109182 [00:56<00:22, 235268.23it/s]
 67%|██████▋   | 10790776/16109182 [00:56<00:22, 235642.86it/s]
 67%|██████▋   | 10814644/16109182 [00:56<00:22, 236550.39it/s]
 67%|██████▋   | 10838302/16109182 [00:56<00:22, 235921.45it/s]
 67%|██████▋   | 10861953/16109182 [00:57<00:22, 236093.25it/s]
 68%|██████▊   | 10885564/16109182 [00:57<00:22, 235673.48it/s]
 68%|██████▊   | 10909377/16109182 [00:57<00:21, 236384.85it/s]
 68%|██████▊   | 10933017/16109182 [00:57<00:21, 235471.57it/s]
 68%|██████▊   | 10956898/16109182 [00:57<00:21, 236466.11it/s]
 68%|██████▊   | 10980546/16109182 [00:57<00:21, 236065.57it/s]
 68%|██████▊   | 11004154/16109182 [00:57<00:21, 235333.53it/s]
 68%|██████▊   | 11028121/16109182 [00:57<00:21, 236626.44it/s]
 69%|██████▊   | 11051785/16109182 [00:57<00:21, 236565.79it/s]
 69%|██████▉   | 11075443/16109182 [00:57<00:21, 236047.46it/s]
 69%|██████▉   | 11099452/16109182 [00:58<00:21, 237252.68it/s]
 69%|██████▉   | 11123179/16109182 [00:58<00:21, 236432.01it/s]
 69%|██████▉   | 11146824/16109182 [00:58<00:21, 235754.74it/s]
 69%|██████▉   | 11170401/16109182 [00:58<00:20, 235241.46it/s]
 69%|██████▉   | 11194239/16109182 [00:58<00:20, 236172.91it/s]
 70%|██████▉   | 11218175/16109182 [00:58<00:20, 237123.42it/s]
 70%|██████▉   | 11241889/16109182 [00:58<00:20, 236661.55it/s]
 70%|██████▉   | 11265556/16109182 [00:58<00:20, 236362.46it/s]
 70%|███████   | 11289562/16109182 [00:58<00:20, 237466.20it/s]
 70%|███████   | 11313310/16109182 [00:58<00:20, 236455.12it/s]
 70%|███████   | 11336957/16109182 [00:59<00:20, 235367.94it/s]
 71%|███████   | 11360965/16109182 [00:59<00:20, 236768.57it/s]
 71%|███████   | 11384644/16109182 [00:59<00:20, 235756.91it/s]
 71%|███████   | 11408227/16109182 [00:59<00:19, 235776.08it/s]
 71%|███████   | 11431879/16109182 [00:59<00:19, 235995.67it/s]
 71%|███████   | 11456108/16109182 [00:59<00:19, 237873.55it/s]
 71%|███████▏  | 11479897/16109182 [00:59<00:19, 237010.75it/s]
 71%|███████▏  | 11503620/16109182 [00:59<00:19, 237074.47it/s]
 72%|███████▏  | 11527329/16109182 [00:59<00:19, 236855.01it/s]
 72%|███████▏  | 11551016/16109182 [00:59<00:19, 236152.70it/s]
 72%|███████▏  | 11574633/16109182 [01:00<00:19, 236009.30it/s]
 72%|███████▏  | 11598235/16109182 [01:00<00:19, 233621.22it/s]
 72%|███████▏  | 11622052/16109182 [01:00<00:19, 234970.16it/s]
 72%|███████▏  | 11645554/16109182 [01:00<00:19, 234667.60it/s]
 72%|███████▏  | 11669025/16109182 [01:00<00:18, 234011.03it/s]
 73%|███████▎  | 11692429/16109182 [01:00<00:34, 127809.34it/s]
 73%|███████▎  | 11716164/16109182 [01:00<00:29, 148476.23it/s]
 73%|███████▎  | 11739889/16109182 [01:01<00:26, 167328.05it/s]
 73%|███████▎  | 11763837/16109182 [01:01<00:23, 184120.44it/s]
 73%|███████▎  | 11787757/16109182 [01:01<00:21, 197863.82it/s]
 73%|███████▎  | 11811232/16109182 [01:01<00:20, 207555.23it/s]
 73%|███████▎  | 11835312/16109182 [01:01<00:19, 216627.48it/s]
 74%|███████▎  | 11859186/16109182 [01:01<00:19, 222827.85it/s]
 74%|███████▍  | 11882930/16109182 [01:01<00:18, 227004.03it/s]
 74%|███████▍  | 11906571/16109182 [01:01<00:18, 229731.80it/s]
 74%|███████▍  | 11930932/16109182 [01:01<00:17, 233793.26it/s]
 74%|███████▍  | 11954718/16109182 [01:01<00:17, 234758.48it/s]
 74%|███████▍  | 11978766/16109182 [01:02<00:17, 236450.32it/s]
 75%|███████▍  | 12002614/16109182 [01:02<00:17, 236042.09it/s]
 75%|███████▍  | 12026360/16109182 [01:05<02:53, 23562.01it/s] 
 75%|███████▍  | 12049482/16109182 [01:05<02:06, 31993.01it/s]
 75%|███████▍  | 12073022/16109182 [01:05<01:33, 43143.93it/s]
 75%|███████▌  | 12097111/16109182 [01:05<01:09, 57505.63it/s]
 75%|███████▌  | 12118881/16109182 [01:05<00:54, 72563.59it/s]
 75%|███████▌  | 12141525/16109182 [01:05<00:43, 90780.25it/s]
 76%|███████▌  | 12164558/16109182 [01:05<00:35, 110967.02it/s]
 76%|███████▌  | 12188252/16109182 [01:05<00:29, 132540.33it/s]
 76%|███████▌  | 12212381/16109182 [01:06<00:25, 153915.99it/s]
 76%|███████▌  | 12236148/16109182 [01:06<00:22, 172276.82it/s]
 76%|███████▌  | 12259822/16109182 [01:06<00:20, 187649.88it/s]
 76%|███████▋  | 12283922/16109182 [01:06<00:19, 201205.32it/s]
 76%|███████▋  | 12307725/16109182 [01:06<00:18, 211010.74it/s]
 77%|███████▋  | 12331395/16109182 [01:06<00:17, 217943.28it/s]
 77%|███████▋  | 12355260/16109182 [01:06<00:16, 223786.96it/s]
 77%|███████▋  | 12378976/16109182 [01:06<00:16, 227607.17it/s]
 77%|███████▋  | 12402749/16109182 [01:06<00:16, 230550.01it/s]
 77%|███████▋  | 12426480/16109182 [01:06<00:15, 231508.96it/s]
 77%|███████▋  | 12450105/16109182 [01:07<00:15, 230139.98it/s]
 77%|███████▋  | 12473453/16109182 [01:07<00:15, 227874.34it/s]
 78%|███████▊  | 12497153/16109182 [01:07<00:15, 230542.80it/s]
 78%|███████▊  | 12520380/16109182 [01:07<00:15, 230941.37it/s]
 78%|███████▊  | 12543596/16109182 [01:07<00:15, 231062.22it/s]
 78%|███████▊  | 12567298/16109182 [01:07<00:15, 232830.66it/s]
 78%|███████▊  | 12590643/16109182 [01:07<00:15, 232046.38it/s]
 78%|███████▊  | 12614110/16109182 [01:07<00:15, 232825.74it/s]
 78%|███████▊  | 12637700/16109182 [01:07<00:14, 233732.03it/s]
 79%|███████▊  | 12661096/16109182 [01:07<00:14, 233084.40it/s]
 79%|███████▊  | 12684421/16109182 [01:08<00:14, 232763.59it/s]
 79%|███████▉  | 12708089/16109182 [01:08<00:14, 233929.67it/s]
 79%|███████▉  | 12731491/16109182 [01:08<00:14, 233623.43it/s]
 79%|███████▉  | 12755205/16109182 [01:08<00:14, 234671.08it/s]
 79%|███████▉  | 12778927/16109182 [01:08<00:14, 235429.40it/s]
 79%|███████▉  | 12802474/16109182 [01:08<00:14, 235327.69it/s]
 80%|███████▉  | 12826387/16109182 [01:08<00:13, 236462.23it/s]
 80%|███████▉  | 12850327/16109182 [01:08<00:13, 237339.16it/s]
 80%|███████▉  | 12874063/16109182 [01:08<00:13, 236862.31it/s]
 80%|████████  | 12898273/16109182 [01:08<00:13, 238428.94it/s]
 80%|████████  | 12922117/16109182 [01:09<00:13, 237715.95it/s]
 80%|████████  | 12945890/16109182 [01:09<00:13, 237620.42it/s]
 81%|████████  | 12969653/16109182 [01:09<00:13, 235832.63it/s]
 81%|████████  | 12993240/16109182 [01:09<00:24, 128446.37it/s]
 81%|████████  | 13017045/16109182 [01:09<00:20, 149068.85it/s]
 81%|████████  | 13039554/16109182 [01:09<00:18, 165170.99it/s]
 81%|████████  | 13063117/16109182 [01:09<00:16, 181539.76it/s]
 81%|████████  | 13086712/16109182 [01:10<00:15, 195095.50it/s]
 81%|████████▏ | 13110239/16109182 [01:10<00:14, 205640.47it/s]
 82%|████████▏ | 13134142/16109182 [01:10<00:13, 214744.78it/s]
 82%|████████▏ | 13157777/16109182 [01:10<00:13, 220793.79it/s]
 82%|████████▏ | 13181136/16109182 [01:10<00:13, 224450.35it/s]
 82%|████████▏ | 13205166/16109182 [01:10<00:12, 229044.90it/s]
 82%|████████▏ | 13229729/16109182 [01:10<00:12, 233900.17it/s]
 82%|████████▏ | 13253528/16109182 [01:10<00:12, 234687.90it/s]
 82%|████████▏ | 13277285/16109182 [01:10<00:12, 235309.03it/s]
 83%|████████▎ | 13301161/16109182 [01:10<00:11, 236331.46it/s]
 83%|████████▎ | 13325106/16109182 [01:11<00:11, 237251.75it/s]
 83%|████████▎ | 13348989/16109182 [01:11<00:11, 237718.78it/s]
 83%|████████▎ | 13372832/16109182 [01:11<00:11, 237103.83it/s]
 83%|████████▎ | 13396717/16109182 [01:11<00:11, 237621.84it/s]
 83%|████████▎ | 13421316/16109182 [01:11<00:11, 240121.64it/s]
 83%|████████▎ | 13445354/16109182 [01:11<00:11, 239721.79it/s]
 84%|████████▎ | 13469344/16109182 [01:11<00:11, 239149.82it/s]
 84%|████████▍ | 13493640/16109182 [01:11<00:10, 240276.60it/s]
 84%|████████▍ | 13517771/16109182 [01:11<00:10, 240581.18it/s]
 84%|████████▍ | 13541836/16109182 [01:11<00:10, 239380.93it/s]
 84%|████████▍ | 13565780/16109182 [01:12<00:10, 237977.76it/s]
 84%|████████▍ | 13589645/16109182 [01:12<00:10, 238175.59it/s]
 85%|████████▍ | 13613609/16109182 [01:12<00:10, 238610.42it/s]
 85%|████████▍ | 13637673/16109182 [01:12<00:10, 239215.54it/s]
 85%|████████▍ | 13662245/16109182 [01:12<00:10, 241159.22it/s]
 85%|████████▍ | 13686500/16109182 [01:12<00:10, 241572.64it/s]
 85%|████████▌ | 13710659/16109182 [01:12<00:09, 240878.64it/s]
 85%|████████▌ | 13735161/16109182 [01:12<00:09, 242114.87it/s]
 85%|████████▌ | 13759481/16109182 [01:12<00:09, 242437.38it/s]
 86%|████████▌ | 13783726/16109182 [01:12<00:09, 240454.42it/s]
 86%|████████▌ | 13808355/16109182 [01:13<00:09, 242189.36it/s]
 86%|████████▌ | 13832579/16109182 [01:13<00:09, 241743.53it/s]
 86%|████████▌ | 13856809/16109182 [01:13<00:09, 241906.83it/s]
 86%|████████▌ | 13881142/16109182 [01:13<00:09, 242328.82it/s]
 86%|████████▋ | 13905377/16109182 [01:13<00:09, 241713.76it/s]
 86%|████████▋ | 13929550/16109182 [01:13<00:09, 241207.00it/s]
 87%|████████▋ | 13953687/16109182 [01:13<00:08, 241251.65it/s]
 87%|████████▋ | 13977960/16109182 [01:13<00:08, 241690.92it/s]
 87%|████████▋ | 14002130/16109182 [01:13<00:08, 241382.15it/s]
 87%|████████▋ | 14026269/16109182 [01:13<00:08, 241027.82it/s]
 87%|████████▋ | 14050407/16109182 [01:14<00:08, 241130.69it/s]
 87%|████████▋ | 14074718/16109182 [01:14<00:08, 241719.67it/s]
 88%|████████▊ | 14098891/16109182 [01:14<00:08, 240698.60it/s]
 88%|████████▊ | 14123221/16109182 [01:14<00:08, 241473.48it/s]
 88%|████████▊ | 14147370/16109182 [01:14<00:08, 240021.50it/s]
 88%|████████▊ | 14171375/16109182 [01:14<00:08, 238993.21it/s]
 88%|████████▊ | 14195322/16109182 [01:14<00:08, 239133.57it/s]
 88%|████████▊ | 14219426/16109182 [01:14<00:07, 239699.90it/s]
 88%|████████▊ | 14243398/16109182 [01:14<00:07, 238986.89it/s]
 89%|████████▊ | 14268048/16109182 [01:14<00:07, 241227.36it/s]
 89%|████████▊ | 14292173/16109182 [01:15<00:07, 240938.24it/s]
 89%|████████▉ | 14316269/16109182 [01:15<00:07, 239571.27it/s]
 89%|████████▉ | 14340229/16109182 [01:15<00:07, 238155.86it/s]
 89%|████████▉ | 14364162/16109182 [01:15<00:07, 238501.79it/s]
 89%|████████▉ | 14388040/16109182 [01:15<00:07, 238582.28it/s]
 89%|████████▉ | 14412011/16109182 [01:15<00:07, 238917.37it/s]
 90%|████████▉ | 14435904/16109182 [01:15<00:07, 234900.10it/s]
 90%|████████▉ | 14459700/16109182 [01:15<00:06, 235801.89it/s]
 90%|████████▉ | 14484005/16109182 [01:15<00:06, 237951.60it/s]
 90%|█████████ | 14508358/16109182 [01:15<00:06, 239606.88it/s]
 90%|█████████ | 14532649/16109182 [01:16<00:06, 240590.18it/s]
 90%|█████████ | 14556715/16109182 [01:16<00:06, 239659.23it/s]
 91%|█████████ | 14580871/16109182 [01:16<00:06, 240223.51it/s]
 91%|█████████ | 14604898/16109182 [01:16<00:06, 239451.30it/s]
 91%|█████████ | 14628847/16109182 [01:16<00:06, 238761.02it/s]
 91%|█████████ | 14652726/16109182 [01:16<00:06, 238401.55it/s]
 91%|█████████ | 14676568/16109182 [01:16<00:06, 237753.92it/s]
 91%|█████████▏| 14700675/16109182 [01:16<00:05, 238741.46it/s]
 91%|█████████▏| 14724551/16109182 [01:16<00:05, 238206.28it/s]
 92%|█████████▏| 14748373/16109182 [01:16<00:05, 237181.49it/s]
 92%|█████████▏| 14772093/16109182 [01:17<00:05, 236362.12it/s]
 92%|█████████▏| 14796338/16109182 [01:17<00:05, 238173.42it/s]
 92%|█████████▏| 14820331/16109182 [01:17<00:05, 238693.76it/s]
 92%|█████████▏| 14844202/16109182 [01:17<00:05, 237196.06it/s]
 92%|█████████▏| 14867930/16109182 [01:17<00:05, 237217.94it/s]
 92%|█████████▏| 14891809/16109182 [01:17<00:05, 237685.20it/s]
 93%|█████████▎| 14915694/16109182 [01:17<00:05, 238029.99it/s]
 93%|█████████▎| 14940201/16109182 [01:17<00:04, 240134.92it/s]
 93%|█████████▎| 14964216/16109182 [01:17<00:04, 239752.41it/s]
 93%|█████████▎| 14988326/16109182 [01:17<00:04, 240151.21it/s]
 93%|█████████▎| 15012342/16109182 [01:18<00:04, 237687.33it/s]
 93%|█████████▎| 15036117/16109182 [01:18<00:04, 235397.23it/s]
 93%|█████████▎| 15059944/16109182 [01:18<00:04, 236246.40it/s]
 94%|█████████▎| 15083575/16109182 [01:18<00:04, 236100.52it/s]
 94%|█████████▍| 15107190/16109182 [01:18<00:04, 234194.28it/s]
 94%|█████████▍| 15130615/16109182 [01:18<00:04, 233908.07it/s]
 94%|█████████▍| 15154209/16109182 [01:18<00:04, 234511.05it/s]
 94%|█████████▍| 15178045/16109182 [01:18<00:03, 235654.11it/s]
 94%|█████████▍| 15201614/16109182 [01:18<00:03, 235054.91it/s]
 95%|█████████▍| 15225472/16109182 [01:18<00:03, 236103.89it/s]
 95%|█████████▍| 15249447/16109182 [01:19<00:03, 237191.16it/s]
 95%|█████████▍| 15273641/16109182 [01:19<00:03, 238608.17it/s]
 95%|█████████▍| 15297504/16109182 [01:19<00:03, 238069.92it/s]
 95%|█████████▌| 15321313/16109182 [01:19<00:03, 237066.47it/s]
 95%|█████████▌| 15345022/16109182 [01:19<00:03, 236222.80it/s]
 95%|█████████▌| 15368646/16109182 [01:19<00:03, 234400.72it/s]
 96%|█████████▌| 15392433/16109182 [01:19<00:03, 235427.10it/s]
 96%|█████████▌| 15415979/16109182 [01:19<00:02, 235408.71it/s]
 96%|█████████▌| 15439825/16109182 [01:19<00:02, 236317.07it/s]
 96%|█████████▌| 15463459/16109182 [01:23<00:34, 18491.64it/s] 
 96%|█████████▌| 15486746/16109182 [01:24<00:24, 25424.67it/s]
 96%|█████████▋| 15509508/16109182 [01:24<00:17, 34353.57it/s]
 96%|█████████▋| 15532545/16109182 [01:24<00:12, 45985.53it/s]
 97%|█████████▋| 15555911/16109182 [01:24<00:09, 60652.04it/s]
 97%|█████████▋| 15579708/16109182 [01:24<00:06, 78459.59it/s]
 97%|█████████▋| 15603203/16109182 [01:24<00:05, 98093.50it/s]
 97%|█████████▋| 15627185/16109182 [01:24<00:04, 119634.88it/s]
 97%|█████████▋| 15650796/16109182 [01:24<00:03, 140412.69it/s]
 97%|█████████▋| 15674809/16109182 [01:24<00:02, 160663.83it/s]
 97%|█████████▋| 15698482/16109182 [01:24<00:02, 177768.21it/s]
 98%|█████████▊| 15722460/16109182 [01:25<00:02, 192845.20it/s]
 98%|█████████▊| 15746425/16109182 [01:25<00:01, 204908.31it/s]
 98%|█████████▊| 15770174/16109182 [01:25<00:01, 213676.08it/s]
 98%|█████████▊| 15793922/16109182 [01:25<00:01, 219017.93it/s]
 98%|█████████▊| 15817657/16109182 [01:25<00:01, 224200.38it/s]
 98%|█████████▊| 15841299/16109182 [01:25<00:01, 227239.67it/s]
 98%|█████████▊| 15864890/16109182 [01:25<00:01, 225674.33it/s]
 99%|█████████▊| 15888066/16109182 [01:25<00:00, 225081.15it/s]
 99%|█████████▉| 15911000/16109182 [01:25<00:00, 225521.93it/s]
 99%|█████████▉| 15934030/16109182 [01:25<00:00, 226916.37it/s]
 99%|█████████▉| 15957531/16109182 [01:26<00:00, 229300.20it/s]
 99%|█████████▉| 15980720/16109182 [01:26<00:00, 230062.92it/s]
 99%|█████████▉| 16004091/16109182 [01:26<00:00, 231143.53it/s]
 99%|█████████▉| 16027455/16109182 [01:26<00:00, 231885.90it/s]
100%|█████████▉| 16050698/16109182 [01:26<00:00, 231624.53it/s]
100%|█████████▉| 16074483/16109182 [01:26<00:00, 233481.18it/s]
100%|█████████▉| 16098161/16109182 [01:26<00:00, 234464.44it/s]
100%|██████████| 16109182/16109182 [01:26<00:00, 185802.13it/s]
2023-03-16 15:18:18,741 INFO     Model Parameter Configuration:
2023-03-16 15:18:18,741 INFO     Parameter gamma: torch.Size([1]), require_grad = False
2023-03-16 15:18:18,741 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False
2023-03-16 15:18:18,741 INFO     Parameter entity_embedding: torch.Size([2500604, 300]), require_grad = True
2023-03-16 15:18:18,742 INFO     Parameter relation_embedding: torch.Size([535, 900]), require_grad = True
2023-03-16 15:18:32,878 INFO     Ramdomly Initializing CompoundE3D_Complete_Mix_T_H Model...
2023-03-16 15:18:32,879 INFO     Start Training...
2023-03-16 15:18:32,879 INFO     init_step = 0
2023-03-16 15:18:32,879 INFO     negative_sample_size = 125
2023-03-16 15:18:32,879 INFO     batch_size = 8192
2023-03-16 15:18:32,879 INFO     hidden_dim = 300
2023-03-16 15:18:32,879 INFO     gamma = 8.000000
2023-03-16 15:18:32,879 INFO     negative_adversarial_sampling = True
2023-03-16 15:18:32,879 INFO     learning_rate = 0.001000
2023-03-16 15:18:32,879 INFO     adversarial_temperature = 1.000000
2023-03-16 15:18:32,879 INFO     learning_rate = 0
2023-03-16 15:18:34,532 INFO     Train positive_sample_loss at step 0: 0.776890
2023-03-16 15:18:34,533 INFO     Train negative_sample_loss at step 0: 0.677355
2023-03-16 15:18:34,534 INFO     Train loss at step 0: 0.727122
2023-03-16 15:18:55,490 INFO     Train positive_sample_loss at step 100: 1.367731
2023-03-16 15:18:55,490 INFO     Train negative_sample_loss at step 100: 0.492249
2023-03-16 15:18:55,490 INFO     Train loss at step 100: 0.929990
2023-03-16 15:19:14,793 INFO     Train positive_sample_loss at step 200: 2.137084
2023-03-16 15:19:14,793 INFO     Train negative_sample_loss at step 200: 0.388124
2023-03-16 15:19:14,793 INFO     Train loss at step 200: 1.262604
2023-03-16 15:19:34,104 INFO     Train positive_sample_loss at step 300: 2.085486
2023-03-16 15:19:34,105 INFO     Train negative_sample_loss at step 300: 0.392865
2023-03-16 15:19:34,105 INFO     Train loss at step 300: 1.239176
2023-03-16 15:19:53,421 INFO     Train positive_sample_loss at step 400: 1.922183
2023-03-16 15:19:53,422 INFO     Train negative_sample_loss at step 400: 0.408382
2023-03-16 15:19:53,422 INFO     Train loss at step 400: 1.165283
2023-03-16 15:20:12,734 INFO     Train positive_sample_loss at step 500: 1.760830
2023-03-16 15:20:12,734 INFO     Train negative_sample_loss at step 500: 0.421803
2023-03-16 15:20:12,734 INFO     Train loss at step 500: 1.091317
2023-03-16 15:20:32,043 INFO     Train positive_sample_loss at step 600: 1.611494
2023-03-16 15:20:32,044 INFO     Train negative_sample_loss at step 600: 0.430738
2023-03-16 15:20:32,044 INFO     Train loss at step 600: 1.021116
2023-03-16 15:20:51,354 INFO     Train positive_sample_loss at step 700: 1.488507
2023-03-16 15:20:51,355 INFO     Train negative_sample_loss at step 700: 0.434756
2023-03-16 15:20:51,355 INFO     Train loss at step 700: 0.961632
2023-03-16 15:21:10,670 INFO     Train positive_sample_loss at step 800: 1.374403
2023-03-16 15:21:10,671 INFO     Train negative_sample_loss at step 800: 0.437017
2023-03-16 15:21:10,671 INFO     Train loss at step 800: 0.905710
2023-03-16 15:21:37,367 INFO     Train positive_sample_loss at step 900: 1.286885
2023-03-16 15:21:37,368 INFO     Train negative_sample_loss at step 900: 0.433954
2023-03-16 15:21:37,368 INFO     Train loss at step 900: 0.860419
2023-03-16 15:21:56,701 INFO     Train positive_sample_loss at step 1000: 1.205064
2023-03-16 15:21:56,702 INFO     Train negative_sample_loss at step 1000: 0.429899
2023-03-16 15:21:56,702 INFO     Train loss at step 1000: 0.817482
2023-03-16 15:22:16,024 INFO     Train positive_sample_loss at step 1100: 1.144562
2023-03-16 15:22:16,025 INFO     Train negative_sample_loss at step 1100: 0.423639
2023-03-16 15:22:16,025 INFO     Train loss at step 1100: 0.784101
2023-03-16 15:22:35,348 INFO     Train positive_sample_loss at step 1200: 1.087381
2023-03-16 15:22:35,348 INFO     Train negative_sample_loss at step 1200: 0.416398
2023-03-16 15:22:35,349 INFO     Train loss at step 1200: 0.751889
2023-03-16 15:22:54,673 INFO     Train positive_sample_loss at step 1300: 1.041035
2023-03-16 15:22:54,673 INFO     Train negative_sample_loss at step 1300: 0.407291
2023-03-16 15:22:54,673 INFO     Train loss at step 1300: 0.724163
2023-03-16 15:23:14,003 INFO     Train positive_sample_loss at step 1400: 0.995134
2023-03-16 15:23:14,004 INFO     Train negative_sample_loss at step 1400: 0.398751
2023-03-16 15:23:14,004 INFO     Train loss at step 1400: 0.696943
2023-03-16 15:23:33,334 INFO     Train positive_sample_loss at step 1500: 0.955930
2023-03-16 15:23:33,335 INFO     Train negative_sample_loss at step 1500: 0.389522
2023-03-16 15:23:33,335 INFO     Train loss at step 1500: 0.672726
2023-03-16 15:23:52,668 INFO     Train positive_sample_loss at step 1600: 0.925942
2023-03-16 15:23:52,668 INFO     Train negative_sample_loss at step 1600: 0.380643
2023-03-16 15:23:52,669 INFO     Train loss at step 1600: 0.653292
2023-03-16 15:24:11,999 INFO     Train positive_sample_loss at step 1700: 0.891222
2023-03-16 15:24:12,000 INFO     Train negative_sample_loss at step 1700: 0.370598
2023-03-16 15:24:12,000 INFO     Train loss at step 1700: 0.630910
2023-03-16 15:24:31,326 INFO     Train positive_sample_loss at step 1800: 0.864349
2023-03-16 15:24:31,327 INFO     Train negative_sample_loss at step 1800: 0.361431
2023-03-16 15:24:31,327 INFO     Train loss at step 1800: 0.612890
2023-03-16 15:24:50,659 INFO     Train positive_sample_loss at step 1900: 0.838701
2023-03-16 15:24:50,659 INFO     Train negative_sample_loss at step 1900: 0.351510
2023-03-16 15:24:50,660 INFO     Train loss at step 1900: 0.595105
2023-03-16 15:25:16,862 INFO     Train positive_sample_loss at step 2000: 0.813231
2023-03-16 15:25:16,863 INFO     Train negative_sample_loss at step 2000: 0.343190
2023-03-16 15:25:16,863 INFO     Train loss at step 2000: 0.578210
2023-03-16 15:25:36,201 INFO     Train positive_sample_loss at step 2100: 0.789457
2023-03-16 15:25:36,202 INFO     Train negative_sample_loss at step 2100: 0.334044
2023-03-16 15:25:36,202 INFO     Train loss at step 2100: 0.561751
2023-03-16 15:25:55,534 INFO     Train positive_sample_loss at step 2200: 0.768007
2023-03-16 15:25:55,535 INFO     Train negative_sample_loss at step 2200: 0.325815
2023-03-16 15:25:55,535 INFO     Train loss at step 2200: 0.546911
2023-03-16 15:26:14,871 INFO     Train positive_sample_loss at step 2300: 0.746890
2023-03-16 15:26:14,872 INFO     Train negative_sample_loss at step 2300: 0.316871
2023-03-16 15:26:14,872 INFO     Train loss at step 2300: 0.531881
2023-03-16 15:26:34,208 INFO     Train positive_sample_loss at step 2400: 0.728280
2023-03-16 15:26:34,209 INFO     Train negative_sample_loss at step 2400: 0.309017
2023-03-16 15:26:34,209 INFO     Train loss at step 2400: 0.518649
2023-03-16 15:26:53,546 INFO     Train positive_sample_loss at step 2500: 0.712983
2023-03-16 15:26:53,547 INFO     Train negative_sample_loss at step 2500: 0.300264
2023-03-16 15:26:53,547 INFO     Train loss at step 2500: 0.506623
2023-03-16 15:27:12,888 INFO     Train positive_sample_loss at step 2600: 0.693702
2023-03-16 15:27:12,888 INFO     Train negative_sample_loss at step 2600: 0.292943
2023-03-16 15:27:12,888 INFO     Train loss at step 2600: 0.493322
2023-03-16 15:27:32,230 INFO     Train positive_sample_loss at step 2700: 0.675543
2023-03-16 15:27:32,231 INFO     Train negative_sample_loss at step 2700: 0.285840
2023-03-16 15:27:32,231 INFO     Train loss at step 2700: 0.480692
2023-03-16 15:27:51,563 INFO     Train positive_sample_loss at step 2800: 0.660001
2023-03-16 15:27:51,564 INFO     Train negative_sample_loss at step 2800: 0.278372
2023-03-16 15:27:51,564 INFO     Train loss at step 2800: 0.469186
2023-03-16 15:28:10,906 INFO     Train positive_sample_loss at step 2900: 0.644781
2023-03-16 15:28:10,907 INFO     Train negative_sample_loss at step 2900: 0.271450
2023-03-16 15:28:10,907 INFO     Train loss at step 2900: 0.458116
2023-03-16 15:28:37,076 INFO     Train positive_sample_loss at step 3000: 0.629914
2023-03-16 15:28:37,076 INFO     Train negative_sample_loss at step 3000: 0.264682
2023-03-16 15:28:37,076 INFO     Train loss at step 3000: 0.447298
2023-03-16 15:28:56,414 INFO     Train positive_sample_loss at step 3100: 0.615585
2023-03-16 15:28:56,415 INFO     Train negative_sample_loss at step 3100: 0.257685
2023-03-16 15:28:56,415 INFO     Train loss at step 3100: 0.436635
2023-03-16 15:29:15,752 INFO     Train positive_sample_loss at step 3200: 0.601915
2023-03-16 15:29:15,752 INFO     Train negative_sample_loss at step 3200: 0.252032
2023-03-16 15:29:15,752 INFO     Train loss at step 3200: 0.426974
2023-03-16 15:29:35,083 INFO     Train positive_sample_loss at step 3300: 0.588319
2023-03-16 15:29:35,084 INFO     Train negative_sample_loss at step 3300: 0.245702
2023-03-16 15:29:35,084 INFO     Train loss at step 3300: 0.417011
2023-03-16 15:29:54,425 INFO     Train positive_sample_loss at step 3400: 0.574727
2023-03-16 15:29:54,425 INFO     Train negative_sample_loss at step 3400: 0.239608
2023-03-16 15:29:54,426 INFO     Train loss at step 3400: 0.407167
2023-03-16 15:30:13,764 INFO     Train positive_sample_loss at step 3500: 0.561610
2023-03-16 15:30:13,764 INFO     Train negative_sample_loss at step 3500: 0.234877
2023-03-16 15:30:13,764 INFO     Train loss at step 3500: 0.398243
2023-03-16 15:30:33,106 INFO     Train positive_sample_loss at step 3600: 0.550343
2023-03-16 15:30:33,107 INFO     Train negative_sample_loss at step 3600: 0.229471
2023-03-16 15:30:33,107 INFO     Train loss at step 3600: 0.389907
2023-03-16 15:30:52,448 INFO     Train positive_sample_loss at step 3700: 0.536316
2023-03-16 15:30:52,448 INFO     Train negative_sample_loss at step 3700: 0.224378
2023-03-16 15:30:52,448 INFO     Train loss at step 3700: 0.380347
2023-03-16 15:31:11,783 INFO     Train positive_sample_loss at step 3800: 0.526723
2023-03-16 15:31:11,783 INFO     Train negative_sample_loss at step 3800: 0.219577
2023-03-16 15:31:11,783 INFO     Train loss at step 3800: 0.373150
2023-03-16 15:31:31,117 INFO     Train positive_sample_loss at step 3900: 0.515724
2023-03-16 15:31:31,117 INFO     Train negative_sample_loss at step 3900: 0.215379
2023-03-16 15:31:31,117 INFO     Train loss at step 3900: 0.365552
2023-03-16 15:31:56,208 INFO     Train positive_sample_loss at step 4000: 0.409500
2023-03-16 15:31:56,209 INFO     Train negative_sample_loss at step 4000: 0.204240
2023-03-16 15:31:56,209 INFO     Train loss at step 4000: 0.306870
2023-03-16 15:32:15,523 INFO     Train positive_sample_loss at step 4100: 0.363154
2023-03-16 15:32:15,524 INFO     Train negative_sample_loss at step 4100: 0.188683
2023-03-16 15:32:15,524 INFO     Train loss at step 4100: 0.275919
2023-03-16 15:32:34,829 INFO     Train positive_sample_loss at step 4200: 0.364850
2023-03-16 15:32:34,829 INFO     Train negative_sample_loss at step 4200: 0.180877
2023-03-16 15:32:34,830 INFO     Train loss at step 4200: 0.272864
2023-03-16 15:32:54,141 INFO     Train positive_sample_loss at step 4300: 0.367749
2023-03-16 15:32:54,142 INFO     Train negative_sample_loss at step 4300: 0.176099
2023-03-16 15:32:54,142 INFO     Train loss at step 4300: 0.271924
2023-03-16 15:33:13,442 INFO     Train positive_sample_loss at step 4400: 0.369177
2023-03-16 15:33:13,443 INFO     Train negative_sample_loss at step 4400: 0.171207
2023-03-16 15:33:13,443 INFO     Train loss at step 4400: 0.270192
2023-03-16 15:33:32,759 INFO     Train positive_sample_loss at step 4500: 0.370553
2023-03-16 15:33:32,759 INFO     Train negative_sample_loss at step 4500: 0.168300
2023-03-16 15:33:32,759 INFO     Train loss at step 4500: 0.269426
2023-03-16 15:33:52,084 INFO     Train positive_sample_loss at step 4600: 0.370733
2023-03-16 15:33:52,084 INFO     Train negative_sample_loss at step 4600: 0.165187
2023-03-16 15:33:52,085 INFO     Train loss at step 4600: 0.267960
2023-03-16 15:34:11,404 INFO     Train positive_sample_loss at step 4700: 0.373688
2023-03-16 15:34:11,405 INFO     Train negative_sample_loss at step 4700: 0.162405
2023-03-16 15:34:11,405 INFO     Train loss at step 4700: 0.268046
2023-03-16 15:34:37,950 INFO     Train positive_sample_loss at step 4800: 0.375822
2023-03-16 15:34:37,951 INFO     Train negative_sample_loss at step 4800: 0.160400
2023-03-16 15:34:37,951 INFO     Train loss at step 4800: 0.268111
2023-03-16 15:34:57,264 INFO     Train positive_sample_loss at step 4900: 0.379453
2023-03-16 15:34:57,264 INFO     Train negative_sample_loss at step 4900: 0.158267
2023-03-16 15:34:57,264 INFO     Train loss at step 4900: 0.268860
2023-03-16 15:35:16,578 INFO     Train positive_sample_loss at step 5000: 0.380377
2023-03-16 15:35:16,578 INFO     Train negative_sample_loss at step 5000: 0.156395
2023-03-16 15:35:16,578 INFO     Train loss at step 5000: 0.268386
2023-03-16 15:35:35,892 INFO     Train positive_sample_loss at step 5100: 0.382247
2023-03-16 15:35:35,892 INFO     Train negative_sample_loss at step 5100: 0.154554
2023-03-16 15:35:35,893 INFO     Train loss at step 5100: 0.268401
2023-03-16 15:35:55,209 INFO     Train positive_sample_loss at step 5200: 0.383680
2023-03-16 15:35:55,210 INFO     Train negative_sample_loss at step 5200: 0.153279
2023-03-16 15:35:55,210 INFO     Train loss at step 5200: 0.268479
2023-03-16 15:36:14,528 INFO     Train positive_sample_loss at step 5300: 0.384452
2023-03-16 15:36:14,528 INFO     Train negative_sample_loss at step 5300: 0.151233
2023-03-16 15:36:14,528 INFO     Train loss at step 5300: 0.267843
2023-03-16 15:36:33,848 INFO     Train positive_sample_loss at step 5400: 0.388860
2023-03-16 15:36:33,849 INFO     Train negative_sample_loss at step 5400: 0.150918
2023-03-16 15:36:33,849 INFO     Train loss at step 5400: 0.269889
2023-03-16 15:36:53,171 INFO     Train positive_sample_loss at step 5500: 0.389538
2023-03-16 15:36:53,171 INFO     Train negative_sample_loss at step 5500: 0.149177
2023-03-16 15:36:53,171 INFO     Train loss at step 5500: 0.269357
2023-03-16 15:37:12,494 INFO     Train positive_sample_loss at step 5600: 0.391529
2023-03-16 15:37:12,494 INFO     Train negative_sample_loss at step 5600: 0.148098
2023-03-16 15:37:12,494 INFO     Train loss at step 5600: 0.269814
2023-03-16 15:37:31,813 INFO     Train positive_sample_loss at step 5700: 0.394410
2023-03-16 15:37:31,814 INFO     Train negative_sample_loss at step 5700: 0.147701
2023-03-16 15:37:31,814 INFO     Train loss at step 5700: 0.271055
2023-03-16 15:37:51,124 INFO     Train positive_sample_loss at step 5800: 0.393935
2023-03-16 15:37:51,125 INFO     Train negative_sample_loss at step 5800: 0.146299
2023-03-16 15:37:51,125 INFO     Train loss at step 5800: 0.270117
2023-03-16 15:38:17,366 INFO     Train positive_sample_loss at step 5900: 0.395401
2023-03-16 15:38:17,366 INFO     Train negative_sample_loss at step 5900: 0.145944
2023-03-16 15:38:17,366 INFO     Train loss at step 5900: 0.270672
2023-03-16 15:38:36,692 INFO     Train positive_sample_loss at step 6000: 0.393695
2023-03-16 15:38:36,692 INFO     Train negative_sample_loss at step 6000: 0.144448
2023-03-16 15:38:36,692 INFO     Train loss at step 6000: 0.269072
2023-03-16 15:38:56,015 INFO     Train positive_sample_loss at step 6100: 0.395525
2023-03-16 15:38:56,016 INFO     Train negative_sample_loss at step 6100: 0.144066
2023-03-16 15:38:56,016 INFO     Train loss at step 6100: 0.269796
2023-03-16 15:39:15,333 INFO     Train positive_sample_loss at step 6200: 0.395911
2023-03-16 15:39:15,334 INFO     Train negative_sample_loss at step 6200: 0.143084
2023-03-16 15:39:15,334 INFO     Train loss at step 6200: 0.269497
2023-03-16 15:39:34,662 INFO     Train positive_sample_loss at step 6300: 0.395123
2023-03-16 15:39:34,662 INFO     Train negative_sample_loss at step 6300: 0.142407
2023-03-16 15:39:34,663 INFO     Train loss at step 6300: 0.268765
2023-03-16 15:39:53,990 INFO     Train positive_sample_loss at step 6400: 0.395694
2023-03-16 15:39:53,991 INFO     Train negative_sample_loss at step 6400: 0.142113
2023-03-16 15:39:53,991 INFO     Train loss at step 6400: 0.268904
2023-03-16 15:40:13,321 INFO     Train positive_sample_loss at step 6500: 0.394787
2023-03-16 15:40:13,321 INFO     Train negative_sample_loss at step 6500: 0.141263
2023-03-16 15:40:13,321 INFO     Train loss at step 6500: 0.268025
2023-03-16 15:40:32,649 INFO     Train positive_sample_loss at step 6600: 0.394499
2023-03-16 15:40:32,650 INFO     Train negative_sample_loss at step 6600: 0.140423
2023-03-16 15:40:32,650 INFO     Train loss at step 6600: 0.267461
2023-03-16 15:40:51,971 INFO     Train positive_sample_loss at step 6700: 0.393336
2023-03-16 15:40:51,971 INFO     Train negative_sample_loss at step 6700: 0.139913
2023-03-16 15:40:51,971 INFO     Train loss at step 6700: 0.266625
2023-03-16 15:41:11,293 INFO     Train positive_sample_loss at step 6800: 0.393118
2023-03-16 15:41:11,293 INFO     Train negative_sample_loss at step 6800: 0.139774
2023-03-16 15:41:11,294 INFO     Train loss at step 6800: 0.266446
2023-03-16 15:41:30,630 INFO     Train positive_sample_loss at step 6900: 0.393061
2023-03-16 15:41:30,630 INFO     Train negative_sample_loss at step 6900: 0.138596
2023-03-16 15:41:30,630 INFO     Train loss at step 6900: 0.265829
2023-03-16 15:41:57,051 INFO     Train positive_sample_loss at step 7000: 0.390173
2023-03-16 15:41:57,051 INFO     Train negative_sample_loss at step 7000: 0.138808
2023-03-16 15:41:57,051 INFO     Train loss at step 7000: 0.264491
2023-03-16 15:42:16,385 INFO     Train positive_sample_loss at step 7100: 0.389730
2023-03-16 15:42:16,385 INFO     Train negative_sample_loss at step 7100: 0.138212
2023-03-16 15:42:16,386 INFO     Train loss at step 7100: 0.263971
2023-03-16 15:42:35,709 INFO     Train positive_sample_loss at step 7200: 0.389633
2023-03-16 15:42:35,709 INFO     Train negative_sample_loss at step 7200: 0.137890
2023-03-16 15:42:35,709 INFO     Train loss at step 7200: 0.263762
2023-03-16 15:42:55,023 INFO     Train positive_sample_loss at step 7300: 0.385401
2023-03-16 15:42:55,023 INFO     Train negative_sample_loss at step 7300: 0.137119
2023-03-16 15:42:55,023 INFO     Train loss at step 7300: 0.261260
2023-03-16 15:43:14,348 INFO     Train positive_sample_loss at step 7400: 0.383513
2023-03-16 15:43:14,349 INFO     Train negative_sample_loss at step 7400: 0.136386
2023-03-16 15:43:14,349 INFO     Train loss at step 7400: 0.259950
2023-03-16 15:43:33,686 INFO     Train positive_sample_loss at step 7500: 0.383399
2023-03-16 15:43:33,686 INFO     Train negative_sample_loss at step 7500: 0.136698
2023-03-16 15:43:33,686 INFO     Train loss at step 7500: 0.260049
2023-03-16 15:43:53,027 INFO     Train positive_sample_loss at step 7600: 0.382473
2023-03-16 15:43:53,027 INFO     Train negative_sample_loss at step 7600: 0.135169
2023-03-16 15:43:53,027 INFO     Train loss at step 7600: 0.258821
2023-03-16 15:44:12,348 INFO     Train positive_sample_loss at step 7700: 0.378537
2023-03-16 15:44:12,349 INFO     Train negative_sample_loss at step 7700: 0.134960
2023-03-16 15:44:12,349 INFO     Train loss at step 7700: 0.256748
2023-03-16 15:44:31,671 INFO     Train positive_sample_loss at step 7800: 0.379352
2023-03-16 15:44:31,671 INFO     Train negative_sample_loss at step 7800: 0.134827
2023-03-16 15:44:31,672 INFO     Train loss at step 7800: 0.257090
2023-03-16 15:44:56,767 INFO     Train positive_sample_loss at step 7900: 0.348253
2023-03-16 15:44:56,767 INFO     Train negative_sample_loss at step 7900: 0.132881
2023-03-16 15:44:56,767 INFO     Train loss at step 7900: 0.240567
2023-03-16 15:45:16,095 INFO     Train positive_sample_loss at step 8000: 0.293605
2023-03-16 15:45:16,096 INFO     Train negative_sample_loss at step 8000: 0.127100
2023-03-16 15:45:16,096 INFO     Train loss at step 8000: 0.210353
2023-03-16 15:45:35,415 INFO     Train positive_sample_loss at step 8100: 0.297637
2023-03-16 15:45:35,416 INFO     Train negative_sample_loss at step 8100: 0.123378
2023-03-16 15:45:35,416 INFO     Train loss at step 8100: 0.210507
2023-03-16 15:45:54,723 INFO     Train positive_sample_loss at step 8200: 0.301089
2023-03-16 15:45:54,724 INFO     Train negative_sample_loss at step 8200: 0.122256
2023-03-16 15:45:54,724 INFO     Train loss at step 8200: 0.211673
2023-03-16 15:46:14,026 INFO     Train positive_sample_loss at step 8300: 0.306769
2023-03-16 15:46:14,027 INFO     Train negative_sample_loss at step 8300: 0.121127
2023-03-16 15:46:14,027 INFO     Train loss at step 8300: 0.213948
2023-03-16 15:46:33,334 INFO     Train positive_sample_loss at step 8400: 0.312983
2023-03-16 15:46:33,334 INFO     Train negative_sample_loss at step 8400: 0.120377
2023-03-16 15:46:33,334 INFO     Train loss at step 8400: 0.216680
2023-03-16 15:46:52,653 INFO     Train positive_sample_loss at step 8500: 0.317076
2023-03-16 15:46:52,654 INFO     Train negative_sample_loss at step 8500: 0.119527
2023-03-16 15:46:52,654 INFO     Train loss at step 8500: 0.218301
2023-03-16 15:47:11,980 INFO     Train positive_sample_loss at step 8600: 0.321275
2023-03-16 15:47:11,980 INFO     Train negative_sample_loss at step 8600: 0.119918
2023-03-16 15:47:11,981 INFO     Train loss at step 8600: 0.220596
2023-03-16 15:47:31,305 INFO     Train positive_sample_loss at step 8700: 0.327072
2023-03-16 15:47:31,306 INFO     Train negative_sample_loss at step 8700: 0.118819
2023-03-16 15:47:31,306 INFO     Train loss at step 8700: 0.222945
2023-03-16 15:47:58,000 INFO     Train positive_sample_loss at step 8800: 0.332897
2023-03-16 15:47:58,000 INFO     Train negative_sample_loss at step 8800: 0.118661
2023-03-16 15:47:58,001 INFO     Train loss at step 8800: 0.225779
2023-03-16 15:48:17,326 INFO     Train positive_sample_loss at step 8900: 0.339890
2023-03-16 15:48:17,327 INFO     Train negative_sample_loss at step 8900: 0.118210
2023-03-16 15:48:17,327 INFO     Train loss at step 8900: 0.229050
2023-03-16 15:48:36,656 INFO     Train positive_sample_loss at step 9000: 0.343574
2023-03-16 15:48:36,656 INFO     Train negative_sample_loss at step 9000: 0.119480
2023-03-16 15:48:36,656 INFO     Train loss at step 9000: 0.231527
2023-03-16 15:48:55,982 INFO     Train positive_sample_loss at step 9100: 0.348913
2023-03-16 15:48:55,982 INFO     Train negative_sample_loss at step 9100: 0.118722
2023-03-16 15:48:55,982 INFO     Train loss at step 9100: 0.233817
2023-03-16 15:49:15,300 INFO     Train positive_sample_loss at step 9200: 0.355281
2023-03-16 15:49:15,301 INFO     Train negative_sample_loss at step 9200: 0.118998
2023-03-16 15:49:15,301 INFO     Train loss at step 9200: 0.237140
2023-03-16 15:49:34,629 INFO     Train positive_sample_loss at step 9300: 0.361295
2023-03-16 15:49:34,629 INFO     Train negative_sample_loss at step 9300: 0.119188
2023-03-16 15:49:34,629 INFO     Train loss at step 9300: 0.240242
2023-03-16 15:49:53,950 INFO     Train positive_sample_loss at step 9400: 0.364493
2023-03-16 15:49:53,950 INFO     Train negative_sample_loss at step 9400: 0.119481
2023-03-16 15:49:53,951 INFO     Train loss at step 9400: 0.241987
2023-03-16 15:50:13,268 INFO     Train positive_sample_loss at step 9500: 0.370480
2023-03-16 15:50:13,269 INFO     Train negative_sample_loss at step 9500: 0.120290
2023-03-16 15:50:13,269 INFO     Train loss at step 9500: 0.245385
2023-03-16 15:50:32,586 INFO     Train positive_sample_loss at step 9600: 0.373076
2023-03-16 15:50:32,587 INFO     Train negative_sample_loss at step 9600: 0.119585
2023-03-16 15:50:32,587 INFO     Train loss at step 9600: 0.246331
2023-03-16 15:50:51,897 INFO     Train positive_sample_loss at step 9700: 0.375996
2023-03-16 15:50:51,897 INFO     Train negative_sample_loss at step 9700: 0.119968
2023-03-16 15:50:51,897 INFO     Train loss at step 9700: 0.247982
2023-03-16 15:51:18,249 INFO     Train positive_sample_loss at step 9800: 0.380410
2023-03-16 15:51:18,250 INFO     Train negative_sample_loss at step 9800: 0.119877
2023-03-16 15:51:18,250 INFO     Train loss at step 9800: 0.250143
2023-03-16 15:51:37,567 INFO     Train positive_sample_loss at step 9900: 0.381984
2023-03-16 15:51:37,568 INFO     Train negative_sample_loss at step 9900: 0.120847
2023-03-16 15:51:37,568 INFO     Train loss at step 9900: 0.251416
2023-03-16 15:51:58,232 INFO     Train positive_sample_loss at step 10000: 0.385737
2023-03-16 15:51:58,232 INFO     Train negative_sample_loss at step 10000: 0.120607
2023-03-16 15:51:58,232 INFO     Train loss at step 10000: 0.253172
2023-03-16 15:51:58,232 INFO     Evaluating on Valid Dataset...
2023-03-16 15:51:59,199 INFO     Evaluating the model... (0/26842)
2023-03-16 15:52:00,852 INFO     Evaluating the model... (1000/26842)
2023-03-16 15:52:02,071 INFO     Evaluating the model... (2000/26842)
2023-03-16 15:52:03,301 INFO     Evaluating the model... (3000/26842)
2023-03-16 15:52:04,529 INFO     Evaluating the model... (4000/26842)
2023-03-16 15:52:05,743 INFO     Evaluating the model... (5000/26842)
2023-03-16 15:52:06,957 INFO     Evaluating the model... (6000/26842)
2023-03-16 15:52:08,185 INFO     Evaluating the model... (7000/26842)
2023-03-16 15:52:09,410 INFO     Evaluating the model... (8000/26842)
2023-03-16 15:52:10,626 INFO     Evaluating the model... (9000/26842)
2023-03-16 15:52:11,830 INFO     Evaluating the model... (10000/26842)
2023-03-16 15:52:13,041 INFO     Evaluating the model... (11000/26842)
2023-03-16 15:52:14,259 INFO     Evaluating the model... (12000/26842)
2023-03-16 15:52:15,483 INFO     Evaluating the model... (13000/26842)
2023-03-16 15:52:17,754 INFO     Evaluating the model... (14000/26842)
2023-03-16 15:52:21,015 INFO     Evaluating the model... (15000/26842)
2023-03-16 15:52:22,498 INFO     Evaluating the model... (16000/26842)
2023-03-16 15:52:23,981 INFO     Evaluating the model... (17000/26842)
2023-03-16 15:52:25,464 INFO     Evaluating the model... (18000/26842)
2023-03-16 15:52:26,946 INFO     Evaluating the model... (19000/26842)
2023-03-16 15:52:28,424 INFO     Evaluating the model... (20000/26842)
2023-03-16 15:52:29,891 INFO     Evaluating the model... (21000/26842)
2023-03-16 15:52:31,359 INFO     Evaluating the model... (22000/26842)
2023-03-16 15:52:32,832 INFO     Evaluating the model... (23000/26842)
2023-03-16 15:52:34,309 INFO     Evaluating the model... (24000/26842)
2023-03-16 15:52:35,773 INFO     Evaluating the model... (25000/26842)
2023-03-16 15:52:37,242 INFO     Evaluating the model... (26000/26842)
2023-03-16 15:52:38,795 INFO     Valid hits@1_list at step 10000: 0.554054
2023-03-16 15:52:38,795 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 15:52:38,795 INFO     Valid hits@3_list at step 10000: 0.636478
2023-03-16 15:52:38,795 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 15:52:38,795 INFO     Valid hits@10_list at step 10000: 0.717184
2023-03-16 15:52:38,795 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 15:52:38,795 INFO     Valid mrr_list at step 10000: 0.611425
2023-03-16 15:52:58,148 INFO     Train positive_sample_loss at step 10100: 0.388470
2023-03-16 15:52:58,149 INFO     Train negative_sample_loss at step 10100: 0.120758
2023-03-16 15:52:58,149 INFO     Train loss at step 10100: 0.254614
2023-03-16 15:53:17,508 INFO     Train positive_sample_loss at step 10200: 0.389540
2023-03-16 15:53:17,508 INFO     Train negative_sample_loss at step 10200: 0.121125
2023-03-16 15:53:17,508 INFO     Train loss at step 10200: 0.255332
2023-03-16 15:53:36,877 INFO     Train positive_sample_loss at step 10300: 0.389130
2023-03-16 15:53:36,878 INFO     Train negative_sample_loss at step 10300: 0.122174
2023-03-16 15:53:36,878 INFO     Train loss at step 10300: 0.255652
2023-03-16 15:53:56,231 INFO     Train positive_sample_loss at step 10400: 0.392052
2023-03-16 15:53:56,231 INFO     Train negative_sample_loss at step 10400: 0.121603
2023-03-16 15:53:56,232 INFO     Train loss at step 10400: 0.256828
2023-03-16 15:54:15,577 INFO     Train positive_sample_loss at step 10500: 0.391315
2023-03-16 15:54:15,578 INFO     Train negative_sample_loss at step 10500: 0.122068
2023-03-16 15:54:15,578 INFO     Train loss at step 10500: 0.256691
2023-03-16 15:54:34,929 INFO     Train positive_sample_loss at step 10600: 0.393059
2023-03-16 15:54:34,930 INFO     Train negative_sample_loss at step 10600: 0.121854
2023-03-16 15:54:34,930 INFO     Train loss at step 10600: 0.257457
2023-03-16 15:54:54,283 INFO     Train positive_sample_loss at step 10700: 0.393374
2023-03-16 15:54:54,284 INFO     Train negative_sample_loss at step 10700: 0.122564
2023-03-16 15:54:54,284 INFO     Train loss at step 10700: 0.257969
2023-03-16 15:55:13,638 INFO     Train positive_sample_loss at step 10800: 0.396039
2023-03-16 15:55:13,638 INFO     Train negative_sample_loss at step 10800: 0.122795
2023-03-16 15:55:13,639 INFO     Train loss at step 10800: 0.259417
2023-03-16 15:55:39,968 INFO     Train positive_sample_loss at step 10900: 0.391035
2023-03-16 15:55:39,968 INFO     Train negative_sample_loss at step 10900: 0.122261
2023-03-16 15:55:39,968 INFO     Train loss at step 10900: 0.256648
2023-03-16 15:55:59,329 INFO     Train positive_sample_loss at step 11000: 0.391113
2023-03-16 15:55:59,330 INFO     Train negative_sample_loss at step 11000: 0.123395
2023-03-16 15:55:59,330 INFO     Train loss at step 11000: 0.257254
2023-03-16 15:56:18,680 INFO     Train positive_sample_loss at step 11100: 0.391565
2023-03-16 15:56:18,681 INFO     Train negative_sample_loss at step 11100: 0.122587
2023-03-16 15:56:18,681 INFO     Train loss at step 11100: 0.257076
2023-03-16 15:56:38,043 INFO     Train positive_sample_loss at step 11200: 0.390604
2023-03-16 15:56:38,043 INFO     Train negative_sample_loss at step 11200: 0.123561
2023-03-16 15:56:38,043 INFO     Train loss at step 11200: 0.257082
2023-03-16 15:56:57,404 INFO     Train positive_sample_loss at step 11300: 0.388289
2023-03-16 15:56:57,405 INFO     Train negative_sample_loss at step 11300: 0.122665
2023-03-16 15:56:57,405 INFO     Train loss at step 11300: 0.255477
2023-03-16 15:57:16,756 INFO     Train positive_sample_loss at step 11400: 0.386318
2023-03-16 15:57:16,756 INFO     Train negative_sample_loss at step 11400: 0.122855
2023-03-16 15:57:16,757 INFO     Train loss at step 11400: 0.254586
2023-03-16 15:57:36,108 INFO     Train positive_sample_loss at step 11500: 0.384764
2023-03-16 15:57:36,108 INFO     Train negative_sample_loss at step 11500: 0.122466
2023-03-16 15:57:36,108 INFO     Train loss at step 11500: 0.253615
2023-03-16 15:57:55,466 INFO     Train positive_sample_loss at step 11600: 0.383421
2023-03-16 15:57:55,467 INFO     Train negative_sample_loss at step 11600: 0.123434
2023-03-16 15:57:55,467 INFO     Train loss at step 11600: 0.253428
2023-03-16 15:58:14,808 INFO     Train positive_sample_loss at step 11700: 0.382499
2023-03-16 15:58:14,809 INFO     Train negative_sample_loss at step 11700: 0.123262
2023-03-16 15:58:14,809 INFO     Train loss at step 11700: 0.252880
2023-03-16 15:58:35,906 INFO     Train positive_sample_loss at step 11800: 0.381763
2023-03-16 15:58:35,906 INFO     Train negative_sample_loss at step 11800: 0.123588
2023-03-16 15:58:35,906 INFO     Train loss at step 11800: 0.252676
funtion time use:40386ms
2023-03-16 15:58:59,403 INFO     Train positive_sample_loss at step 11900: 0.304059
2023-03-16 15:58:59,404 INFO     Train negative_sample_loss at step 11900: 0.119215
2023-03-16 15:58:59,404 INFO     Train loss at step 11900: 0.211637
2023-03-16 15:59:18,711 INFO     Train positive_sample_loss at step 12000: 0.307042
2023-03-16 15:59:18,711 INFO     Train negative_sample_loss at step 12000: 0.115941
2023-03-16 15:59:18,712 INFO     Train loss at step 12000: 0.211492
2023-03-16 15:59:38,018 INFO     Train positive_sample_loss at step 12100: 0.308556
2023-03-16 15:59:38,018 INFO     Train negative_sample_loss at step 12100: 0.114579
2023-03-16 15:59:38,018 INFO     Train loss at step 12100: 0.211568
2023-03-16 15:59:57,339 INFO     Train positive_sample_loss at step 12200: 0.312929
2023-03-16 15:59:57,339 INFO     Train negative_sample_loss at step 12200: 0.114196
2023-03-16 15:59:57,339 INFO     Train loss at step 12200: 0.213563
2023-03-16 16:00:16,653 INFO     Train positive_sample_loss at step 12300: 0.317944
2023-03-16 16:00:16,654 INFO     Train negative_sample_loss at step 12300: 0.113944
2023-03-16 16:00:16,654 INFO     Train loss at step 12300: 0.215944
2023-03-16 16:00:35,957 INFO     Train positive_sample_loss at step 12400: 0.321597
2023-03-16 16:00:35,958 INFO     Train negative_sample_loss at step 12400: 0.113294
2023-03-16 16:00:35,958 INFO     Train loss at step 12400: 0.217445
2023-03-16 16:00:55,278 INFO     Train positive_sample_loss at step 12500: 0.327237
2023-03-16 16:00:55,278 INFO     Train negative_sample_loss at step 12500: 0.113486
2023-03-16 16:00:55,278 INFO     Train loss at step 12500: 0.220362
2023-03-16 16:01:14,600 INFO     Train positive_sample_loss at step 12600: 0.332839
2023-03-16 16:01:14,600 INFO     Train negative_sample_loss at step 12600: 0.113222
2023-03-16 16:01:14,601 INFO     Train loss at step 12600: 0.223030
2023-03-16 16:01:41,374 INFO     Train positive_sample_loss at step 12700: 0.335865
2023-03-16 16:01:41,375 INFO     Train negative_sample_loss at step 12700: 0.113324
2023-03-16 16:01:41,375 INFO     Train loss at step 12700: 0.224594
2023-03-16 16:02:00,689 INFO     Train positive_sample_loss at step 12800: 0.341979
2023-03-16 16:02:00,690 INFO     Train negative_sample_loss at step 12800: 0.113399
2023-03-16 16:02:00,690 INFO     Train loss at step 12800: 0.227689
2023-03-16 16:02:20,002 INFO     Train positive_sample_loss at step 12900: 0.345424
2023-03-16 16:02:20,002 INFO     Train negative_sample_loss at step 12900: 0.113115
2023-03-16 16:02:20,002 INFO     Train loss at step 12900: 0.229270
2023-03-16 16:02:39,316 INFO     Train positive_sample_loss at step 13000: 0.350052
2023-03-16 16:02:39,316 INFO     Train negative_sample_loss at step 13000: 0.113770
2023-03-16 16:02:39,316 INFO     Train loss at step 13000: 0.231911
2023-03-16 16:02:58,635 INFO     Train positive_sample_loss at step 13100: 0.356138
2023-03-16 16:02:58,635 INFO     Train negative_sample_loss at step 13100: 0.114140
2023-03-16 16:02:58,636 INFO     Train loss at step 13100: 0.235139
2023-03-16 16:03:17,974 INFO     Train positive_sample_loss at step 13200: 0.359806
2023-03-16 16:03:17,975 INFO     Train negative_sample_loss at step 13200: 0.114345
2023-03-16 16:03:17,975 INFO     Train loss at step 13200: 0.237075
2023-03-16 16:03:37,320 INFO     Train positive_sample_loss at step 13300: 0.366872
2023-03-16 16:03:37,321 INFO     Train negative_sample_loss at step 13300: 0.114347
2023-03-16 16:03:37,321 INFO     Train loss at step 13300: 0.240610
2023-03-16 16:03:56,662 INFO     Train positive_sample_loss at step 13400: 0.369850
2023-03-16 16:03:56,663 INFO     Train negative_sample_loss at step 13400: 0.114640
2023-03-16 16:03:56,663 INFO     Train loss at step 13400: 0.242245
2023-03-16 16:04:16,000 INFO     Train positive_sample_loss at step 13500: 0.372522
2023-03-16 16:04:16,000 INFO     Train negative_sample_loss at step 13500: 0.114894
2023-03-16 16:04:16,000 INFO     Train loss at step 13500: 0.243708
2023-03-16 16:04:35,343 INFO     Train positive_sample_loss at step 13600: 0.376785
2023-03-16 16:04:35,343 INFO     Train negative_sample_loss at step 13600: 0.114696
2023-03-16 16:04:35,343 INFO     Train loss at step 13600: 0.245741
2023-03-16 16:05:04,359 INFO     Train positive_sample_loss at step 13700: 0.378196
2023-03-16 16:05:04,360 INFO     Train negative_sample_loss at step 13700: 0.115010
2023-03-16 16:05:04,360 INFO     Train loss at step 13700: 0.246603
2023-03-16 16:05:23,697 INFO     Train positive_sample_loss at step 13800: 0.380852
2023-03-16 16:05:23,697 INFO     Train negative_sample_loss at step 13800: 0.115577
2023-03-16 16:05:23,697 INFO     Train loss at step 13800: 0.248214
2023-03-16 16:05:43,041 INFO     Train positive_sample_loss at step 13900: 0.383219
2023-03-16 16:05:43,042 INFO     Train negative_sample_loss at step 13900: 0.115192
2023-03-16 16:05:43,042 INFO     Train loss at step 13900: 0.249206
2023-03-16 16:06:02,383 INFO     Train positive_sample_loss at step 14000: 0.385671
2023-03-16 16:06:02,383 INFO     Train negative_sample_loss at step 14000: 0.116122
2023-03-16 16:06:02,384 INFO     Train loss at step 14000: 0.250897
2023-03-16 16:06:21,724 INFO     Train positive_sample_loss at step 14100: 0.386198
2023-03-16 16:06:21,725 INFO     Train negative_sample_loss at step 14100: 0.117042
2023-03-16 16:06:21,725 INFO     Train loss at step 14100: 0.251620
2023-03-16 16:06:41,078 INFO     Train positive_sample_loss at step 14200: 0.387762
2023-03-16 16:06:41,079 INFO     Train negative_sample_loss at step 14200: 0.116680
2023-03-16 16:06:41,079 INFO     Train loss at step 14200: 0.252221
2023-03-16 16:07:00,422 INFO     Train positive_sample_loss at step 14300: 0.389027
2023-03-16 16:07:00,423 INFO     Train negative_sample_loss at step 14300: 0.116615
2023-03-16 16:07:00,423 INFO     Train loss at step 14300: 0.252821
2023-03-16 16:07:19,766 INFO     Train positive_sample_loss at step 14400: 0.390443
2023-03-16 16:07:19,766 INFO     Train negative_sample_loss at step 14400: 0.117468
2023-03-16 16:07:19,766 INFO     Train loss at step 14400: 0.253956
2023-03-16 16:07:39,106 INFO     Train positive_sample_loss at step 14500: 0.391245
2023-03-16 16:07:39,107 INFO     Train negative_sample_loss at step 14500: 0.117414
2023-03-16 16:07:39,107 INFO     Train loss at step 14500: 0.254329
2023-03-16 16:07:58,452 INFO     Train positive_sample_loss at step 14600: 0.390461
2023-03-16 16:07:58,452 INFO     Train negative_sample_loss at step 14600: 0.117405
2023-03-16 16:07:58,452 INFO     Train loss at step 14600: 0.253933
2023-03-16 16:08:17,799 INFO     Train positive_sample_loss at step 14700: 0.390999
2023-03-16 16:08:17,800 INFO     Train negative_sample_loss at step 14700: 0.118194
2023-03-16 16:08:17,800 INFO     Train loss at step 14700: 0.254596
2023-03-16 16:08:43,961 INFO     Train positive_sample_loss at step 14800: 0.392697
2023-03-16 16:08:43,962 INFO     Train negative_sample_loss at step 14800: 0.118105
2023-03-16 16:08:43,962 INFO     Train loss at step 14800: 0.255401
2023-03-16 16:09:03,298 INFO     Train positive_sample_loss at step 14900: 0.389249
2023-03-16 16:09:03,298 INFO     Train negative_sample_loss at step 14900: 0.118960
2023-03-16 16:09:03,298 INFO     Train loss at step 14900: 0.254105
2023-03-16 16:09:22,630 INFO     Train positive_sample_loss at step 15000: 0.391713
2023-03-16 16:09:22,630 INFO     Train negative_sample_loss at step 15000: 0.118702
2023-03-16 16:09:22,630 INFO     Train loss at step 15000: 0.255207
2023-03-16 16:09:41,970 INFO     Train positive_sample_loss at step 15100: 0.388826
2023-03-16 16:09:41,970 INFO     Train negative_sample_loss at step 15100: 0.118821
2023-03-16 16:09:41,970 INFO     Train loss at step 15100: 0.253824
2023-03-16 16:10:01,300 INFO     Train positive_sample_loss at step 15200: 0.387721
2023-03-16 16:10:01,300 INFO     Train negative_sample_loss at step 15200: 0.118869
2023-03-16 16:10:01,300 INFO     Train loss at step 15200: 0.253295
2023-03-16 16:10:20,633 INFO     Train positive_sample_loss at step 15300: 0.387251
2023-03-16 16:10:20,633 INFO     Train negative_sample_loss at step 15300: 0.118947
2023-03-16 16:10:20,633 INFO     Train loss at step 15300: 0.253099
2023-03-16 16:10:39,970 INFO     Train positive_sample_loss at step 15400: 0.385327
2023-03-16 16:10:39,970 INFO     Train negative_sample_loss at step 15400: 0.119769
2023-03-16 16:10:39,971 INFO     Train loss at step 15400: 0.252548
2023-03-16 16:10:59,300 INFO     Train positive_sample_loss at step 15500: 0.385080
2023-03-16 16:10:59,300 INFO     Train negative_sample_loss at step 15500: 0.119557
2023-03-16 16:10:59,301 INFO     Train loss at step 15500: 0.252318
2023-03-16 16:11:18,628 INFO     Train positive_sample_loss at step 15600: 0.383824
2023-03-16 16:11:18,629 INFO     Train negative_sample_loss at step 15600: 0.118979
2023-03-16 16:11:18,629 INFO     Train loss at step 15600: 0.251401
2023-03-16 16:11:37,960 INFO     Train positive_sample_loss at step 15700: 0.380397
2023-03-16 16:11:37,961 INFO     Train negative_sample_loss at step 15700: 0.119143
2023-03-16 16:11:37,961 INFO     Train loss at step 15700: 0.249770
2023-03-16 16:12:03,131 INFO     Train positive_sample_loss at step 15800: 0.332106
2023-03-16 16:12:03,132 INFO     Train negative_sample_loss at step 15800: 0.117988
2023-03-16 16:12:03,132 INFO     Train loss at step 15800: 0.225047
2023-03-16 16:12:22,442 INFO     Train positive_sample_loss at step 15900: 0.310205
2023-03-16 16:12:22,443 INFO     Train negative_sample_loss at step 15900: 0.113621
2023-03-16 16:12:22,443 INFO     Train loss at step 15900: 0.211913
2023-03-16 16:12:41,753 INFO     Train positive_sample_loss at step 16000: 0.311344
2023-03-16 16:12:41,754 INFO     Train negative_sample_loss at step 16000: 0.112073
2023-03-16 16:12:41,754 INFO     Train loss at step 16000: 0.211708
2023-03-16 16:13:01,059 INFO     Train positive_sample_loss at step 16100: 0.317111
2023-03-16 16:13:01,059 INFO     Train negative_sample_loss at step 16100: 0.111284
2023-03-16 16:13:01,059 INFO     Train loss at step 16100: 0.214197
2023-03-16 16:13:20,372 INFO     Train positive_sample_loss at step 16200: 0.319333
2023-03-16 16:13:20,372 INFO     Train negative_sample_loss at step 16200: 0.110409
2023-03-16 16:13:20,372 INFO     Train loss at step 16200: 0.214871
2023-03-16 16:13:39,683 INFO     Train positive_sample_loss at step 16300: 0.324167
2023-03-16 16:13:39,683 INFO     Train negative_sample_loss at step 16300: 0.110488
2023-03-16 16:13:39,683 INFO     Train loss at step 16300: 0.217327
2023-03-16 16:13:59,000 INFO     Train positive_sample_loss at step 16400: 0.328194
2023-03-16 16:13:59,000 INFO     Train negative_sample_loss at step 16400: 0.110369
2023-03-16 16:13:59,000 INFO     Train loss at step 16400: 0.219282
2023-03-16 16:14:18,318 INFO     Train positive_sample_loss at step 16500: 0.332888
2023-03-16 16:14:18,318 INFO     Train negative_sample_loss at step 16500: 0.110105
2023-03-16 16:14:18,318 INFO     Train loss at step 16500: 0.221497
2023-03-16 16:14:44,903 INFO     Train positive_sample_loss at step 16600: 0.338188
2023-03-16 16:14:44,904 INFO     Train negative_sample_loss at step 16600: 0.110608
2023-03-16 16:14:44,904 INFO     Train loss at step 16600: 0.224398
2023-03-16 16:15:04,216 INFO     Train positive_sample_loss at step 16700: 0.343167
2023-03-16 16:15:04,216 INFO     Train negative_sample_loss at step 16700: 0.110490
2023-03-16 16:15:04,216 INFO     Train loss at step 16700: 0.226829
2023-03-16 16:15:23,533 INFO     Train positive_sample_loss at step 16800: 0.348597
2023-03-16 16:15:23,534 INFO     Train negative_sample_loss at step 16800: 0.110294
2023-03-16 16:15:23,534 INFO     Train loss at step 16800: 0.229446
2023-03-16 16:15:42,850 INFO     Train positive_sample_loss at step 16900: 0.352587
2023-03-16 16:15:42,850 INFO     Train negative_sample_loss at step 16900: 0.110751
2023-03-16 16:15:42,850 INFO     Train loss at step 16900: 0.231669
2023-03-16 16:16:02,180 INFO     Train positive_sample_loss at step 17000: 0.356446
2023-03-16 16:16:02,180 INFO     Train negative_sample_loss at step 17000: 0.110521
2023-03-16 16:16:02,180 INFO     Train loss at step 17000: 0.233483
2023-03-16 16:16:21,495 INFO     Train positive_sample_loss at step 17100: 0.359126
2023-03-16 16:16:21,496 INFO     Train negative_sample_loss at step 17100: 0.111059
2023-03-16 16:16:21,496 INFO     Train loss at step 17100: 0.235093
2023-03-16 16:16:40,818 INFO     Train positive_sample_loss at step 17200: 0.365653
2023-03-16 16:16:40,819 INFO     Train negative_sample_loss at step 17200: 0.111013
2023-03-16 16:16:40,819 INFO     Train loss at step 17200: 0.238333
2023-03-16 16:17:00,148 INFO     Train positive_sample_loss at step 17300: 0.367621
2023-03-16 16:17:00,149 INFO     Train negative_sample_loss at step 17300: 0.111187
2023-03-16 16:17:00,149 INFO     Train loss at step 17300: 0.239404
2023-03-16 16:17:19,479 INFO     Train positive_sample_loss at step 17400: 0.370521
2023-03-16 16:17:19,480 INFO     Train negative_sample_loss at step 17400: 0.111613
2023-03-16 16:17:19,480 INFO     Train loss at step 17400: 0.241067
2023-03-16 16:17:38,793 INFO     Train positive_sample_loss at step 17500: 0.377836
2023-03-16 16:17:38,793 INFO     Train negative_sample_loss at step 17500: 0.112365
2023-03-16 16:17:38,794 INFO     Train loss at step 17500: 0.245101
2023-03-16 16:17:58,115 INFO     Train positive_sample_loss at step 17600: 0.379732
2023-03-16 16:17:58,116 INFO     Train negative_sample_loss at step 17600: 0.112243
2023-03-16 16:17:58,116 INFO     Train loss at step 17600: 0.245988
2023-03-16 16:18:24,468 INFO     Train positive_sample_loss at step 17700: 0.382675
2023-03-16 16:18:24,468 INFO     Train negative_sample_loss at step 17700: 0.113014
2023-03-16 16:18:24,468 INFO     Train loss at step 17700: 0.247844
2023-03-16 16:18:43,790 INFO     Train positive_sample_loss at step 17800: 0.385408
2023-03-16 16:18:43,790 INFO     Train negative_sample_loss at step 17800: 0.112916
2023-03-16 16:18:43,790 INFO     Train loss at step 17800: 0.249162
2023-03-16 16:19:03,112 INFO     Train positive_sample_loss at step 17900: 0.385440
2023-03-16 16:19:03,112 INFO     Train negative_sample_loss at step 17900: 0.113072
2023-03-16 16:19:03,112 INFO     Train loss at step 17900: 0.249256
2023-03-16 16:19:22,435 INFO     Train positive_sample_loss at step 18000: 0.387040
2023-03-16 16:19:22,436 INFO     Train negative_sample_loss at step 18000: 0.113455
2023-03-16 16:19:22,436 INFO     Train loss at step 18000: 0.250248
2023-03-16 16:19:41,759 INFO     Train positive_sample_loss at step 18100: 0.389447
2023-03-16 16:19:41,760 INFO     Train negative_sample_loss at step 18100: 0.113728
2023-03-16 16:19:41,760 INFO     Train loss at step 18100: 0.251588
2023-03-16 16:20:01,088 INFO     Train positive_sample_loss at step 18200: 0.392681
2023-03-16 16:20:01,089 INFO     Train negative_sample_loss at step 18200: 0.114126
2023-03-16 16:20:01,089 INFO     Train loss at step 18200: 0.253403
2023-03-16 16:20:20,421 INFO     Train positive_sample_loss at step 18300: 0.391723
2023-03-16 16:20:20,421 INFO     Train negative_sample_loss at step 18300: 0.115001
2023-03-16 16:20:20,421 INFO     Train loss at step 18300: 0.253362
2023-03-16 16:20:39,743 INFO     Train positive_sample_loss at step 18400: 0.392342
2023-03-16 16:20:39,744 INFO     Train negative_sample_loss at step 18400: 0.114209
2023-03-16 16:20:39,744 INFO     Train loss at step 18400: 0.253275
2023-03-16 16:20:59,060 INFO     Train positive_sample_loss at step 18500: 0.392284
2023-03-16 16:20:59,060 INFO     Train negative_sample_loss at step 18500: 0.115085
2023-03-16 16:20:59,060 INFO     Train loss at step 18500: 0.253684
2023-03-16 16:21:18,378 INFO     Train positive_sample_loss at step 18600: 0.390375
2023-03-16 16:21:18,378 INFO     Train negative_sample_loss at step 18600: 0.115284
2023-03-16 16:21:18,378 INFO     Train loss at step 18600: 0.252829
2023-03-16 16:21:44,588 INFO     Train positive_sample_loss at step 18700: 0.390622
2023-03-16 16:21:44,588 INFO     Train negative_sample_loss at step 18700: 0.115061
2023-03-16 16:21:44,588 INFO     Train loss at step 18700: 0.252842
2023-03-16 16:22:03,928 INFO     Train positive_sample_loss at step 18800: 0.392089
2023-03-16 16:22:03,929 INFO     Train negative_sample_loss at step 18800: 0.115699
2023-03-16 16:22:03,929 INFO     Train loss at step 18800: 0.253894
2023-03-16 16:22:23,258 INFO     Train positive_sample_loss at step 18900: 0.390404
2023-03-16 16:22:23,258 INFO     Train negative_sample_loss at step 18900: 0.116156
2023-03-16 16:22:23,258 INFO     Train loss at step 18900: 0.253280
2023-03-16 16:22:42,577 INFO     Train positive_sample_loss at step 19000: 0.390022
2023-03-16 16:22:42,577 INFO     Train negative_sample_loss at step 19000: 0.115539
2023-03-16 16:22:42,578 INFO     Train loss at step 19000: 0.252781
2023-03-16 16:23:01,907 INFO     Train positive_sample_loss at step 19100: 0.385339
2023-03-16 16:23:01,908 INFO     Train negative_sample_loss at step 19100: 0.116498
2023-03-16 16:23:01,908 INFO     Train loss at step 19100: 0.250919
2023-03-16 16:23:21,238 INFO     Train positive_sample_loss at step 19200: 0.387365
2023-03-16 16:23:21,239 INFO     Train negative_sample_loss at step 19200: 0.116392
2023-03-16 16:23:21,239 INFO     Train loss at step 19200: 0.251878
2023-03-16 16:23:40,572 INFO     Train positive_sample_loss at step 19300: 0.386194
2023-03-16 16:23:40,572 INFO     Train negative_sample_loss at step 19300: 0.116643
2023-03-16 16:23:40,572 INFO     Train loss at step 19300: 0.251419
2023-03-16 16:23:59,897 INFO     Train positive_sample_loss at step 19400: 0.385063
2023-03-16 16:23:59,898 INFO     Train negative_sample_loss at step 19400: 0.116655
2023-03-16 16:23:59,898 INFO     Train loss at step 19400: 0.250859
2023-03-16 16:24:19,232 INFO     Train positive_sample_loss at step 19500: 0.381767
2023-03-16 16:24:19,232 INFO     Train negative_sample_loss at step 19500: 0.116827
2023-03-16 16:24:19,232 INFO     Train loss at step 19500: 0.249297
2023-03-16 16:24:38,564 INFO     Train positive_sample_loss at step 19600: 0.382026
2023-03-16 16:24:38,564 INFO     Train negative_sample_loss at step 19600: 0.117168
2023-03-16 16:24:38,564 INFO     Train loss at step 19600: 0.249597
2023-03-16 16:25:03,837 INFO     Train positive_sample_loss at step 19700: 0.355958
2023-03-16 16:25:03,838 INFO     Train negative_sample_loss at step 19700: 0.116512
2023-03-16 16:25:03,838 INFO     Train loss at step 19700: 0.236235
2023-03-16 16:25:23,153 INFO     Train positive_sample_loss at step 19800: 0.306475
2023-03-16 16:25:23,153 INFO     Train negative_sample_loss at step 19800: 0.112214
2023-03-16 16:25:23,153 INFO     Train loss at step 19800: 0.209345
2023-03-16 16:25:42,469 INFO     Train positive_sample_loss at step 19900: 0.312307
2023-03-16 16:25:42,469 INFO     Train negative_sample_loss at step 19900: 0.110455
2023-03-16 16:25:42,469 INFO     Train loss at step 19900: 0.211381
2023-03-16 16:26:03,210 INFO     Train positive_sample_loss at step 20000: 0.315448
2023-03-16 16:26:03,211 INFO     Train negative_sample_loss at step 20000: 0.109425
2023-03-16 16:26:03,211 INFO     Train loss at step 20000: 0.212436
2023-03-16 16:26:03,211 INFO     Evaluating on Valid Dataset...
2023-03-16 16:26:04,217 INFO     Evaluating the model... (0/26842)
2023-03-16 16:26:05,738 INFO     Evaluating the model... (1000/26842)
2023-03-16 16:26:07,087 INFO     Evaluating the model... (2000/26842)
2023-03-16 16:26:08,302 INFO     Evaluating the model... (3000/26842)
2023-03-16 16:26:09,513 INFO     Evaluating the model... (4000/26842)
2023-03-16 16:26:10,728 INFO     Evaluating the model... (5000/26842)
2023-03-16 16:26:11,942 INFO     Evaluating the model... (6000/26842)
2023-03-16 16:26:13,161 INFO     Evaluating the model... (7000/26842)
2023-03-16 16:26:14,375 INFO     Evaluating the model... (8000/26842)
2023-03-16 16:26:15,593 INFO     Evaluating the model... (9000/26842)
2023-03-16 16:26:16,811 INFO     Evaluating the model... (10000/26842)
2023-03-16 16:26:18,044 INFO     Evaluating the model... (11000/26842)
2023-03-16 16:26:19,265 INFO     Evaluating the model... (12000/26842)
2023-03-16 16:26:20,490 INFO     Evaluating the model... (13000/26842)
2023-03-16 16:26:22,740 INFO     Evaluating the model... (14000/26842)
2023-03-16 16:26:24,218 INFO     Evaluating the model... (15000/26842)
2023-03-16 16:26:25,684 INFO     Evaluating the model... (16000/26842)
2023-03-16 16:26:27,154 INFO     Evaluating the model... (17000/26842)
2023-03-16 16:26:28,626 INFO     Evaluating the model... (18000/26842)
2023-03-16 16:26:30,098 INFO     Evaluating the model... (19000/26842)
2023-03-16 16:26:31,575 INFO     Evaluating the model... (20000/26842)
2023-03-16 16:26:33,069 INFO     Evaluating the model... (21000/26842)
2023-03-16 16:26:34,552 INFO     Evaluating the model... (22000/26842)
2023-03-16 16:26:36,034 INFO     Evaluating the model... (23000/26842)
2023-03-16 16:26:37,520 INFO     Evaluating the model... (24000/26842)
2023-03-16 16:26:39,007 INFO     Evaluating the model... (25000/26842)
2023-03-16 16:26:40,496 INFO     Evaluating the model... (26000/26842)
2023-03-16 16:26:42,066 INFO     Valid hits@1_list at step 20000: 0.576131
2023-03-16 16:26:42,066 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 16:26:42,067 INFO     Valid hits@3_list at step 20000: 0.665387
2023-03-16 16:26:42,067 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 16:26:42,067 INFO     Valid hits@10_list at step 20000: 0.750929
2023-03-16 16:26:42,067 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 16:26:42,067 INFO     Valid mrr_list at step 20000: 0.637286
2023-03-16 16:27:01,369 INFO     Train positive_sample_loss at step 20100: 0.317705
2023-03-16 16:27:01,369 INFO     Train negative_sample_loss at step 20100: 0.109191
2023-03-16 16:27:01,369 INFO     Train loss at step 20100: 0.213448
2023-03-16 16:27:20,682 INFO     Train positive_sample_loss at step 20200: 0.322258
2023-03-16 16:27:20,682 INFO     Train negative_sample_loss at step 20200: 0.108271
2023-03-16 16:27:20,682 INFO     Train loss at step 20200: 0.215265
2023-03-16 16:27:40,000 INFO     Train positive_sample_loss at step 20300: 0.327803
2023-03-16 16:27:40,000 INFO     Train negative_sample_loss at step 20300: 0.108567
2023-03-16 16:27:40,001 INFO     Train loss at step 20300: 0.218185
2023-03-16 16:27:59,320 INFO     Train positive_sample_loss at step 20400: 0.331747
2023-03-16 16:27:59,321 INFO     Train negative_sample_loss at step 20400: 0.108457
2023-03-16 16:27:59,321 INFO     Train loss at step 20400: 0.220102
2023-03-16 16:28:25,952 INFO     Train positive_sample_loss at step 20500: 0.337306
2023-03-16 16:28:25,953 INFO     Train negative_sample_loss at step 20500: 0.108714
2023-03-16 16:28:25,953 INFO     Train loss at step 20500: 0.223010
2023-03-16 16:28:45,273 INFO     Train positive_sample_loss at step 20600: 0.340915
2023-03-16 16:28:45,274 INFO     Train negative_sample_loss at step 20600: 0.108213
2023-03-16 16:28:45,274 INFO     Train loss at step 20600: 0.224564
2023-03-16 16:29:04,587 INFO     Train positive_sample_loss at step 20700: 0.344131
2023-03-16 16:29:04,587 INFO     Train negative_sample_loss at step 20700: 0.108477
2023-03-16 16:29:04,587 INFO     Train loss at step 20700: 0.226304
2023-03-16 16:29:23,908 INFO     Train positive_sample_loss at step 20800: 0.351087
2023-03-16 16:29:23,908 INFO     Train negative_sample_loss at step 20800: 0.109302
2023-03-16 16:29:23,908 INFO     Train loss at step 20800: 0.230195
2023-03-16 16:29:43,220 INFO     Train positive_sample_loss at step 20900: 0.355552
2023-03-16 16:29:43,221 INFO     Train negative_sample_loss at step 20900: 0.109707
2023-03-16 16:29:43,221 INFO     Train loss at step 20900: 0.232630
2023-03-16 16:30:02,543 INFO     Train positive_sample_loss at step 21000: 0.360899
2023-03-16 16:30:02,544 INFO     Train negative_sample_loss at step 21000: 0.109474
2023-03-16 16:30:02,544 INFO     Train loss at step 21000: 0.235186
2023-03-16 16:30:21,862 INFO     Train positive_sample_loss at step 21100: 0.364191
2023-03-16 16:30:21,863 INFO     Train negative_sample_loss at step 21100: 0.109546
2023-03-16 16:30:21,863 INFO     Train loss at step 21100: 0.236868
2023-03-16 16:30:41,181 INFO     Train positive_sample_loss at step 21200: 0.368730
2023-03-16 16:30:41,181 INFO     Train negative_sample_loss at step 21200: 0.109683
2023-03-16 16:30:41,181 INFO     Train loss at step 21200: 0.239206
2023-03-16 16:31:00,501 INFO     Train positive_sample_loss at step 21300: 0.373335
2023-03-16 16:31:00,502 INFO     Train negative_sample_loss at step 21300: 0.110504
2023-03-16 16:31:00,502 INFO     Train loss at step 21300: 0.241919
2023-03-16 16:31:19,835 INFO     Train positive_sample_loss at step 21400: 0.375374
2023-03-16 16:31:19,835 INFO     Train negative_sample_loss at step 21400: 0.110581
2023-03-16 16:31:19,835 INFO     Train loss at step 21400: 0.242978
2023-03-16 16:31:39,162 INFO     Train positive_sample_loss at step 21500: 0.378154
2023-03-16 16:31:39,163 INFO     Train negative_sample_loss at step 21500: 0.110712
2023-03-16 16:31:39,164 INFO     Train loss at step 21500: 0.244433
2023-03-16 16:32:08,166 INFO     Train positive_sample_loss at step 21600: 0.380597
2023-03-16 16:32:08,166 INFO     Train negative_sample_loss at step 21600: 0.111132
2023-03-16 16:32:08,166 INFO     Train loss at step 21600: 0.245865
2023-03-16 16:32:27,484 INFO     Train positive_sample_loss at step 21700: 0.383252
2023-03-16 16:32:27,484 INFO     Train negative_sample_loss at step 21700: 0.111342
2023-03-16 16:32:27,484 INFO     Train loss at step 21700: 0.247297
2023-03-16 16:32:46,806 INFO     Train positive_sample_loss at step 21800: 0.384507
2023-03-16 16:32:46,806 INFO     Train negative_sample_loss at step 21800: 0.110679
2023-03-16 16:32:46,806 INFO     Train loss at step 21800: 0.247593
2023-03-16 16:33:06,140 INFO     Train positive_sample_loss at step 21900: 0.389054
2023-03-16 16:33:06,140 INFO     Train negative_sample_loss at step 21900: 0.111765
2023-03-16 16:33:06,140 INFO     Train loss at step 21900: 0.250410
2023-03-16 16:33:25,470 INFO     Train positive_sample_loss at step 22000: 0.387888
2023-03-16 16:33:25,470 INFO     Train negative_sample_loss at step 22000: 0.112020
2023-03-16 16:33:25,470 INFO     Train loss at step 22000: 0.249954
2023-03-16 16:33:44,796 INFO     Train positive_sample_loss at step 22100: 0.390575
2023-03-16 16:33:44,797 INFO     Train negative_sample_loss at step 22100: 0.112362
2023-03-16 16:33:44,797 INFO     Train loss at step 22100: 0.251468
2023-03-16 16:34:04,121 INFO     Train positive_sample_loss at step 22200: 0.390713
2023-03-16 16:34:04,122 INFO     Train negative_sample_loss at step 22200: 0.113098
2023-03-16 16:34:04,122 INFO     Train loss at step 22200: 0.251905
2023-03-16 16:34:23,452 INFO     Train positive_sample_loss at step 22300: 0.390412
2023-03-16 16:34:23,453 INFO     Train negative_sample_loss at step 22300: 0.112904
2023-03-16 16:34:23,453 INFO     Train loss at step 22300: 0.251658
2023-03-16 16:34:42,777 INFO     Train positive_sample_loss at step 22400: 0.391733
2023-03-16 16:34:42,778 INFO     Train negative_sample_loss at step 22400: 0.113033
2023-03-16 16:34:42,778 INFO     Train loss at step 22400: 0.252383
2023-03-16 16:35:02,106 INFO     Train positive_sample_loss at step 22500: 0.392678
2023-03-16 16:35:02,107 INFO     Train negative_sample_loss at step 22500: 0.113871
2023-03-16 16:35:02,107 INFO     Train loss at step 22500: 0.253274
2023-03-16 16:35:21,439 INFO     Train positive_sample_loss at step 22600: 0.393587
2023-03-16 16:35:21,439 INFO     Train negative_sample_loss at step 22600: 0.113461
2023-03-16 16:35:21,439 INFO     Train loss at step 22600: 0.253524
2023-03-16 16:35:47,664 INFO     Train positive_sample_loss at step 22700: 0.393421
2023-03-16 16:35:47,665 INFO     Train negative_sample_loss at step 22700: 0.114334
2023-03-16 16:35:47,665 INFO     Train loss at step 22700: 0.253877
2023-03-16 16:36:06,984 INFO     Train positive_sample_loss at step 22800: 0.392067
2023-03-16 16:36:06,985 INFO     Train negative_sample_loss at step 22800: 0.114119
2023-03-16 16:36:06,985 INFO     Train loss at step 22800: 0.253093
2023-03-16 16:36:26,310 INFO     Train positive_sample_loss at step 22900: 0.391069
2023-03-16 16:36:26,311 INFO     Train negative_sample_loss at step 22900: 0.114284
2023-03-16 16:36:26,311 INFO     Train loss at step 22900: 0.252677
2023-03-16 16:36:45,644 INFO     Train positive_sample_loss at step 23000: 0.388309
2023-03-16 16:36:45,644 INFO     Train negative_sample_loss at step 23000: 0.114986
2023-03-16 16:36:45,645 INFO     Train loss at step 23000: 0.251648
2023-03-16 16:37:04,976 INFO     Train positive_sample_loss at step 23100: 0.389838
2023-03-16 16:37:04,976 INFO     Train negative_sample_loss at step 23100: 0.114851
2023-03-16 16:37:04,976 INFO     Train loss at step 23100: 0.252344
2023-03-16 16:37:24,309 INFO     Train positive_sample_loss at step 23200: 0.386191
2023-03-16 16:37:24,309 INFO     Train negative_sample_loss at step 23200: 0.114650
2023-03-16 16:37:24,309 INFO     Train loss at step 23200: 0.250420
2023-03-16 16:37:43,638 INFO     Train positive_sample_loss at step 23300: 0.385249
2023-03-16 16:37:43,639 INFO     Train negative_sample_loss at step 23300: 0.115078
2023-03-16 16:37:43,639 INFO     Train loss at step 23300: 0.250163
2023-03-16 16:38:02,968 INFO     Train positive_sample_loss at step 23400: 0.383091
2023-03-16 16:38:02,969 INFO     Train negative_sample_loss at step 23400: 0.115183
2023-03-16 16:38:02,969 INFO     Train loss at step 23400: 0.249137
2023-03-16 16:38:22,298 INFO     Train positive_sample_loss at step 23500: 0.383051
2023-03-16 16:38:22,298 INFO     Train negative_sample_loss at step 23500: 0.115390
2023-03-16 16:38:22,298 INFO     Train loss at step 23500: 0.249220
2023-03-16 16:38:43,428 INFO     Train positive_sample_loss at step 23600: 0.380865
2023-03-16 16:38:43,429 INFO     Train negative_sample_loss at step 23600: 0.115668
2023-03-16 16:38:43,429 INFO     Train loss at step 23600: 0.248267
funtion time use:38679ms
2023-03-16 16:39:06,854 INFO     Train positive_sample_loss at step 23700: 0.310606
2023-03-16 16:39:06,854 INFO     Train negative_sample_loss at step 23700: 0.112388
2023-03-16 16:39:06,854 INFO     Train loss at step 23700: 0.211497
2023-03-16 16:39:26,168 INFO     Train positive_sample_loss at step 23800: 0.312375
2023-03-16 16:39:26,169 INFO     Train negative_sample_loss at step 23800: 0.110054
2023-03-16 16:39:26,169 INFO     Train loss at step 23800: 0.211214
2023-03-16 16:39:45,481 INFO     Train positive_sample_loss at step 23900: 0.314984
2023-03-16 16:39:45,482 INFO     Train negative_sample_loss at step 23900: 0.107940
2023-03-16 16:39:45,482 INFO     Train loss at step 23900: 0.211462
2023-03-16 16:40:04,791 INFO     Train positive_sample_loss at step 24000: 0.320661
2023-03-16 16:40:04,791 INFO     Train negative_sample_loss at step 24000: 0.107558
2023-03-16 16:40:04,791 INFO     Train loss at step 24000: 0.214110
2023-03-16 16:40:24,094 INFO     Train positive_sample_loss at step 24100: 0.322912
2023-03-16 16:40:24,094 INFO     Train negative_sample_loss at step 24100: 0.107804
2023-03-16 16:40:24,094 INFO     Train loss at step 24100: 0.215358
2023-03-16 16:40:43,407 INFO     Train positive_sample_loss at step 24200: 0.328739
2023-03-16 16:40:43,408 INFO     Train negative_sample_loss at step 24200: 0.107139
2023-03-16 16:40:43,408 INFO     Train loss at step 24200: 0.217939
2023-03-16 16:41:02,718 INFO     Train positive_sample_loss at step 24300: 0.331282
2023-03-16 16:41:02,718 INFO     Train negative_sample_loss at step 24300: 0.107089
2023-03-16 16:41:02,719 INFO     Train loss at step 24300: 0.219186
2023-03-16 16:41:29,612 INFO     Train positive_sample_loss at step 24400: 0.336338
2023-03-16 16:41:29,612 INFO     Train negative_sample_loss at step 24400: 0.106672
2023-03-16 16:41:29,612 INFO     Train loss at step 24400: 0.221505
2023-03-16 16:41:48,937 INFO     Train positive_sample_loss at step 24500: 0.341434
2023-03-16 16:41:48,937 INFO     Train negative_sample_loss at step 24500: 0.107550
2023-03-16 16:41:48,937 INFO     Train loss at step 24500: 0.224492
2023-03-16 16:42:08,258 INFO     Train positive_sample_loss at step 24600: 0.344372
2023-03-16 16:42:08,259 INFO     Train negative_sample_loss at step 24600: 0.106984
2023-03-16 16:42:08,259 INFO     Train loss at step 24600: 0.225678
2023-03-16 16:42:27,590 INFO     Train positive_sample_loss at step 24700: 0.348336
2023-03-16 16:42:27,590 INFO     Train negative_sample_loss at step 24700: 0.107631
2023-03-16 16:42:27,590 INFO     Train loss at step 24700: 0.227983
2023-03-16 16:42:46,914 INFO     Train positive_sample_loss at step 24800: 0.354043
2023-03-16 16:42:46,915 INFO     Train negative_sample_loss at step 24800: 0.107808
2023-03-16 16:42:46,915 INFO     Train loss at step 24800: 0.230926
2023-03-16 16:43:06,237 INFO     Train positive_sample_loss at step 24900: 0.360293
2023-03-16 16:43:06,238 INFO     Train negative_sample_loss at step 24900: 0.108632
2023-03-16 16:43:06,238 INFO     Train loss at step 24900: 0.234463
2023-03-16 16:43:25,566 INFO     Train positive_sample_loss at step 25000: 0.362797
2023-03-16 16:43:25,566 INFO     Train negative_sample_loss at step 25000: 0.107906
2023-03-16 16:43:25,566 INFO     Train loss at step 25000: 0.235351
2023-03-16 16:43:44,886 INFO     Train positive_sample_loss at step 25100: 0.366982
2023-03-16 16:43:44,886 INFO     Train negative_sample_loss at step 25100: 0.109112
2023-03-16 16:43:44,887 INFO     Train loss at step 25100: 0.238047
2023-03-16 16:44:04,211 INFO     Train positive_sample_loss at step 25200: 0.372117
2023-03-16 16:44:04,212 INFO     Train negative_sample_loss at step 25200: 0.108886
2023-03-16 16:44:04,212 INFO     Train loss at step 25200: 0.240501
2023-03-16 16:44:23,524 INFO     Train positive_sample_loss at step 25300: 0.374836
2023-03-16 16:44:23,525 INFO     Train negative_sample_loss at step 25300: 0.109259
2023-03-16 16:44:23,525 INFO     Train loss at step 25300: 0.242048
2023-03-16 16:44:42,845 INFO     Train positive_sample_loss at step 25400: 0.378762
2023-03-16 16:44:42,846 INFO     Train negative_sample_loss at step 25400: 0.109313
2023-03-16 16:44:42,846 INFO     Train loss at step 25400: 0.244037
2023-03-16 16:45:08,939 INFO     Train positive_sample_loss at step 25500: 0.381975
2023-03-16 16:45:08,940 INFO     Train negative_sample_loss at step 25500: 0.109537
2023-03-16 16:45:08,940 INFO     Train loss at step 25500: 0.245756
2023-03-16 16:45:28,271 INFO     Train positive_sample_loss at step 25600: 0.384554
2023-03-16 16:45:28,271 INFO     Train negative_sample_loss at step 25600: 0.109605
2023-03-16 16:45:28,272 INFO     Train loss at step 25600: 0.247079
2023-03-16 16:45:47,601 INFO     Train positive_sample_loss at step 25700: 0.385945
2023-03-16 16:45:47,601 INFO     Train negative_sample_loss at step 25700: 0.110715
2023-03-16 16:45:47,601 INFO     Train loss at step 25700: 0.248330
2023-03-16 16:46:06,935 INFO     Train positive_sample_loss at step 25800: 0.386580
2023-03-16 16:46:06,936 INFO     Train negative_sample_loss at step 25800: 0.109960
2023-03-16 16:46:06,936 INFO     Train loss at step 25800: 0.248270
2023-03-16 16:46:26,263 INFO     Train positive_sample_loss at step 25900: 0.388438
2023-03-16 16:46:26,264 INFO     Train negative_sample_loss at step 25900: 0.111104
2023-03-16 16:46:26,264 INFO     Train loss at step 25900: 0.249771
2023-03-16 16:46:45,596 INFO     Train positive_sample_loss at step 26000: 0.389588
2023-03-16 16:46:45,597 INFO     Train negative_sample_loss at step 26000: 0.110949
2023-03-16 16:46:45,597 INFO     Train loss at step 26000: 0.250268
2023-03-16 16:47:04,927 INFO     Train positive_sample_loss at step 26100: 0.391290
2023-03-16 16:47:04,927 INFO     Train negative_sample_loss at step 26100: 0.111272
2023-03-16 16:47:04,927 INFO     Train loss at step 26100: 0.251281
2023-03-16 16:47:24,256 INFO     Train positive_sample_loss at step 26200: 0.391283
2023-03-16 16:47:24,257 INFO     Train negative_sample_loss at step 26200: 0.111660
2023-03-16 16:47:24,257 INFO     Train loss at step 26200: 0.251471
2023-03-16 16:47:43,582 INFO     Train positive_sample_loss at step 26300: 0.389712
2023-03-16 16:47:43,582 INFO     Train negative_sample_loss at step 26300: 0.111930
2023-03-16 16:47:43,582 INFO     Train loss at step 26300: 0.250821
2023-03-16 16:48:02,908 INFO     Train positive_sample_loss at step 26400: 0.390901
2023-03-16 16:48:02,909 INFO     Train negative_sample_loss at step 26400: 0.112549
2023-03-16 16:48:02,909 INFO     Train loss at step 26400: 0.251725
2023-03-16 16:48:22,252 INFO     Train positive_sample_loss at step 26500: 0.390877
2023-03-16 16:48:22,252 INFO     Train negative_sample_loss at step 26500: 0.112442
2023-03-16 16:48:22,253 INFO     Train loss at step 26500: 0.251660
2023-03-16 16:48:48,486 INFO     Train positive_sample_loss at step 26600: 0.391704
2023-03-16 16:48:48,486 INFO     Train negative_sample_loss at step 26600: 0.113263
2023-03-16 16:48:48,486 INFO     Train loss at step 26600: 0.252483
2023-03-16 16:49:07,814 INFO     Train positive_sample_loss at step 26700: 0.390540
2023-03-16 16:49:07,814 INFO     Train negative_sample_loss at step 26700: 0.113320
2023-03-16 16:49:07,814 INFO     Train loss at step 26700: 0.251930
2023-03-16 16:49:27,144 INFO     Train positive_sample_loss at step 26800: 0.389516
2023-03-16 16:49:27,144 INFO     Train negative_sample_loss at step 26800: 0.113338
2023-03-16 16:49:27,145 INFO     Train loss at step 26800: 0.251427
2023-03-16 16:49:46,473 INFO     Train positive_sample_loss at step 26900: 0.388294
2023-03-16 16:49:46,473 INFO     Train negative_sample_loss at step 26900: 0.113444
2023-03-16 16:49:46,473 INFO     Train loss at step 26900: 0.250869
2023-03-16 16:50:05,797 INFO     Train positive_sample_loss at step 27000: 0.387579
2023-03-16 16:50:05,798 INFO     Train negative_sample_loss at step 27000: 0.112881
2023-03-16 16:50:05,798 INFO     Train loss at step 27000: 0.250230
2023-03-16 16:50:25,121 INFO     Train positive_sample_loss at step 27100: 0.386502
2023-03-16 16:50:25,122 INFO     Train negative_sample_loss at step 27100: 0.113839
2023-03-16 16:50:25,122 INFO     Train loss at step 27100: 0.250171
2023-03-16 16:50:44,447 INFO     Train positive_sample_loss at step 27200: 0.385787
2023-03-16 16:50:44,447 INFO     Train negative_sample_loss at step 27200: 0.114160
2023-03-16 16:50:44,447 INFO     Train loss at step 27200: 0.249974
2023-03-16 16:51:03,771 INFO     Train positive_sample_loss at step 27300: 0.384956
2023-03-16 16:51:03,771 INFO     Train negative_sample_loss at step 27300: 0.114195
2023-03-16 16:51:03,771 INFO     Train loss at step 27300: 0.249576
2023-03-16 16:51:23,092 INFO     Train positive_sample_loss at step 27400: 0.383556
2023-03-16 16:51:23,093 INFO     Train negative_sample_loss at step 27400: 0.114390
2023-03-16 16:51:23,093 INFO     Train loss at step 27400: 0.248973
2023-03-16 16:51:42,423 INFO     Train positive_sample_loss at step 27500: 0.381846
2023-03-16 16:51:42,424 INFO     Train negative_sample_loss at step 27500: 0.114322
2023-03-16 16:51:42,424 INFO     Train loss at step 27500: 0.248084
2023-03-16 16:52:07,783 INFO     Train positive_sample_loss at step 27600: 0.334176
2023-03-16 16:52:07,783 INFO     Train negative_sample_loss at step 27600: 0.113473
2023-03-16 16:52:07,784 INFO     Train loss at step 27600: 0.223825
2023-03-16 16:52:27,091 INFO     Train positive_sample_loss at step 27700: 0.312539
2023-03-16 16:52:27,092 INFO     Train negative_sample_loss at step 27700: 0.109354
2023-03-16 16:52:27,092 INFO     Train loss at step 27700: 0.210947
2023-03-16 16:52:46,391 INFO     Train positive_sample_loss at step 27800: 0.314993
2023-03-16 16:52:46,391 INFO     Train negative_sample_loss at step 27800: 0.107690
2023-03-16 16:52:46,391 INFO     Train loss at step 27800: 0.211341
2023-03-16 16:53:05,698 INFO     Train positive_sample_loss at step 27900: 0.318557
2023-03-16 16:53:05,699 INFO     Train negative_sample_loss at step 27900: 0.107358
2023-03-16 16:53:05,699 INFO     Train loss at step 27900: 0.212958
2023-03-16 16:53:25,011 INFO     Train positive_sample_loss at step 28000: 0.321917
2023-03-16 16:53:25,012 INFO     Train negative_sample_loss at step 28000: 0.106259
2023-03-16 16:53:25,012 INFO     Train loss at step 28000: 0.214088
2023-03-16 16:53:44,311 INFO     Train positive_sample_loss at step 28100: 0.327979
2023-03-16 16:53:44,311 INFO     Train negative_sample_loss at step 28100: 0.106742
2023-03-16 16:53:44,311 INFO     Train loss at step 28100: 0.217360
2023-03-16 16:54:03,626 INFO     Train positive_sample_loss at step 28200: 0.331150
2023-03-16 16:54:03,626 INFO     Train negative_sample_loss at step 28200: 0.106857
2023-03-16 16:54:03,626 INFO     Train loss at step 28200: 0.219003
2023-03-16 16:54:22,936 INFO     Train positive_sample_loss at step 28300: 0.335482
2023-03-16 16:54:22,937 INFO     Train negative_sample_loss at step 28300: 0.106480
2023-03-16 16:54:22,937 INFO     Train loss at step 28300: 0.220981
2023-03-16 16:54:49,660 INFO     Train positive_sample_loss at step 28400: 0.340602
2023-03-16 16:54:49,660 INFO     Train negative_sample_loss at step 28400: 0.107032
2023-03-16 16:54:49,660 INFO     Train loss at step 28400: 0.223817
2023-03-16 16:55:08,977 INFO     Train positive_sample_loss at step 28500: 0.345941
2023-03-16 16:55:08,977 INFO     Train negative_sample_loss at step 28500: 0.106812
2023-03-16 16:55:08,977 INFO     Train loss at step 28500: 0.226377
2023-03-16 16:55:28,299 INFO     Train positive_sample_loss at step 28600: 0.350146
2023-03-16 16:55:28,300 INFO     Train negative_sample_loss at step 28600: 0.107094
2023-03-16 16:55:28,300 INFO     Train loss at step 28600: 0.228620
2023-03-16 16:55:47,620 INFO     Train positive_sample_loss at step 28700: 0.352256
2023-03-16 16:55:47,620 INFO     Train negative_sample_loss at step 28700: 0.106414
2023-03-16 16:55:47,621 INFO     Train loss at step 28700: 0.229335
2023-03-16 16:56:06,938 INFO     Train positive_sample_loss at step 28800: 0.358945
2023-03-16 16:56:06,939 INFO     Train negative_sample_loss at step 28800: 0.107778
2023-03-16 16:56:06,939 INFO     Train loss at step 28800: 0.233361
2023-03-16 16:56:26,258 INFO     Train positive_sample_loss at step 28900: 0.362937
2023-03-16 16:56:26,259 INFO     Train negative_sample_loss at step 28900: 0.107044
2023-03-16 16:56:26,259 INFO     Train loss at step 28900: 0.234991
2023-03-16 16:56:45,581 INFO     Train positive_sample_loss at step 29000: 0.363933
2023-03-16 16:56:45,581 INFO     Train negative_sample_loss at step 29000: 0.107360
2023-03-16 16:56:45,581 INFO     Train loss at step 29000: 0.235646
2023-03-16 16:57:04,898 INFO     Train positive_sample_loss at step 29100: 0.368698
2023-03-16 16:57:04,898 INFO     Train negative_sample_loss at step 29100: 0.107659
2023-03-16 16:57:04,898 INFO     Train loss at step 29100: 0.238178
2023-03-16 16:57:24,213 INFO     Train positive_sample_loss at step 29200: 0.372291
2023-03-16 16:57:24,214 INFO     Train negative_sample_loss at step 29200: 0.108411
2023-03-16 16:57:24,214 INFO     Train loss at step 29200: 0.240351
2023-03-16 16:57:43,529 INFO     Train positive_sample_loss at step 29300: 0.374680
2023-03-16 16:57:43,529 INFO     Train negative_sample_loss at step 29300: 0.108398
2023-03-16 16:57:43,529 INFO     Train loss at step 29300: 0.241539
2023-03-16 16:58:02,853 INFO     Train positive_sample_loss at step 29400: 0.378375
2023-03-16 16:58:02,853 INFO     Train negative_sample_loss at step 29400: 0.108819
2023-03-16 16:58:02,854 INFO     Train loss at step 29400: 0.243597
2023-03-16 16:58:29,007 INFO     Train positive_sample_loss at step 29500: 0.380697
2023-03-16 16:58:29,007 INFO     Train negative_sample_loss at step 29500: 0.108972
2023-03-16 16:58:29,008 INFO     Train loss at step 29500: 0.244834
2023-03-16 16:58:48,329 INFO     Train positive_sample_loss at step 29600: 0.384294
2023-03-16 16:58:48,329 INFO     Train negative_sample_loss at step 29600: 0.108580
2023-03-16 16:58:48,329 INFO     Train loss at step 29600: 0.246437
2023-03-16 16:59:07,657 INFO     Train positive_sample_loss at step 29700: 0.386661
2023-03-16 16:59:07,658 INFO     Train negative_sample_loss at step 29700: 0.109470
2023-03-16 16:59:07,658 INFO     Train loss at step 29700: 0.248066
2023-03-16 16:59:26,982 INFO     Train positive_sample_loss at step 29800: 0.388218
2023-03-16 16:59:26,983 INFO     Train negative_sample_loss at step 29800: 0.109844
2023-03-16 16:59:26,983 INFO     Train loss at step 29800: 0.249031
2023-03-16 16:59:46,304 INFO     Train positive_sample_loss at step 29900: 0.390280
2023-03-16 16:59:46,304 INFO     Train negative_sample_loss at step 29900: 0.110151
2023-03-16 16:59:46,304 INFO     Train loss at step 29900: 0.250216
2023-03-16 17:00:07,205 INFO     Train positive_sample_loss at step 30000: 0.389785
2023-03-16 17:00:07,205 INFO     Train negative_sample_loss at step 30000: 0.111001
2023-03-16 17:00:07,205 INFO     Train loss at step 30000: 0.250393
2023-03-16 17:00:07,205 INFO     Evaluating on Valid Dataset...
2023-03-16 17:00:08,232 INFO     Evaluating the model... (0/26842)
2023-03-16 17:00:09,864 INFO     Evaluating the model... (1000/26842)
2023-03-16 17:00:11,079 INFO     Evaluating the model... (2000/26842)
2023-03-16 17:00:12,299 INFO     Evaluating the model... (3000/26842)
2023-03-16 17:00:13,518 INFO     Evaluating the model... (4000/26842)
2023-03-16 17:00:14,739 INFO     Evaluating the model... (5000/26842)
2023-03-16 17:00:15,957 INFO     Evaluating the model... (6000/26842)
2023-03-16 17:00:17,178 INFO     Evaluating the model... (7000/26842)
2023-03-16 17:00:18,403 INFO     Evaluating the model... (8000/26842)
2023-03-16 17:00:19,628 INFO     Evaluating the model... (9000/26842)
2023-03-16 17:00:20,854 INFO     Evaluating the model... (10000/26842)
2023-03-16 17:00:22,082 INFO     Evaluating the model... (11000/26842)
2023-03-16 17:00:23,309 INFO     Evaluating the model... (12000/26842)
2023-03-16 17:00:24,542 INFO     Evaluating the model... (13000/26842)
2023-03-16 17:00:26,824 INFO     Evaluating the model... (14000/26842)
2023-03-16 17:00:28,288 INFO     Evaluating the model... (15000/26842)
2023-03-16 17:00:29,748 INFO     Evaluating the model... (16000/26842)
2023-03-16 17:00:31,211 INFO     Evaluating the model... (17000/26842)
2023-03-16 17:00:32,672 INFO     Evaluating the model... (18000/26842)
2023-03-16 17:00:34,136 INFO     Evaluating the model... (19000/26842)
2023-03-16 17:00:35,602 INFO     Evaluating the model... (20000/26842)
2023-03-16 17:00:37,064 INFO     Evaluating the model... (21000/26842)
2023-03-16 17:00:38,537 INFO     Evaluating the model... (22000/26842)
2023-03-16 17:00:40,013 INFO     Evaluating the model... (23000/26842)
2023-03-16 17:00:41,492 INFO     Evaluating the model... (24000/26842)
2023-03-16 17:00:42,964 INFO     Evaluating the model... (25000/26842)
2023-03-16 17:00:44,433 INFO     Evaluating the model... (26000/26842)
2023-03-16 17:00:46,000 INFO     Valid hits@1_list at step 30000: 0.581887
2023-03-16 17:00:46,000 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 17:00:46,001 INFO     Valid hits@3_list at step 30000: 0.672110
2023-03-16 17:00:46,001 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 17:00:46,001 INFO     Valid hits@10_list at step 30000: 0.757088
2023-03-16 17:00:46,001 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 17:00:46,001 INFO     Valid mrr_list at step 30000: 0.643295
2023-03-16 17:01:05,350 INFO     Train positive_sample_loss at step 30100: 0.393515
2023-03-16 17:01:05,350 INFO     Train negative_sample_loss at step 30100: 0.110894
2023-03-16 17:01:05,350 INFO     Train loss at step 30100: 0.252205
2023-03-16 17:01:24,694 INFO     Train positive_sample_loss at step 30200: 0.391074
2023-03-16 17:01:24,694 INFO     Train negative_sample_loss at step 30200: 0.110978
2023-03-16 17:01:24,694 INFO     Train loss at step 30200: 0.251026
2023-03-16 17:01:44,043 INFO     Train positive_sample_loss at step 30300: 0.393713
2023-03-16 17:01:44,043 INFO     Train negative_sample_loss at step 30300: 0.111485
2023-03-16 17:01:44,043 INFO     Train loss at step 30300: 0.252599
2023-03-16 17:02:03,389 INFO     Train positive_sample_loss at step 30400: 0.392051
2023-03-16 17:02:03,389 INFO     Train negative_sample_loss at step 30400: 0.112094
2023-03-16 17:02:03,389 INFO     Train loss at step 30400: 0.252073
2023-03-16 17:02:29,625 INFO     Train positive_sample_loss at step 30500: 0.393115
2023-03-16 17:02:29,625 INFO     Train negative_sample_loss at step 30500: 0.111594
2023-03-16 17:02:29,625 INFO     Train loss at step 30500: 0.252354
2023-03-16 17:02:48,959 INFO     Train positive_sample_loss at step 30600: 0.391394
2023-03-16 17:02:48,960 INFO     Train negative_sample_loss at step 30600: 0.112830
2023-03-16 17:02:48,960 INFO     Train loss at step 30600: 0.252112
2023-03-16 17:03:08,297 INFO     Train positive_sample_loss at step 30700: 0.390698
2023-03-16 17:03:08,297 INFO     Train negative_sample_loss at step 30700: 0.112294
2023-03-16 17:03:08,297 INFO     Train loss at step 30700: 0.251496
2023-03-16 17:03:27,640 INFO     Train positive_sample_loss at step 30800: 0.390142
2023-03-16 17:03:27,641 INFO     Train negative_sample_loss at step 30800: 0.112380
2023-03-16 17:03:27,641 INFO     Train loss at step 30800: 0.251261
2023-03-16 17:03:46,986 INFO     Train positive_sample_loss at step 30900: 0.387649
2023-03-16 17:03:46,986 INFO     Train negative_sample_loss at step 30900: 0.113384
2023-03-16 17:03:46,986 INFO     Train loss at step 30900: 0.250516
2023-03-16 17:04:06,323 INFO     Train positive_sample_loss at step 31000: 0.387516
2023-03-16 17:04:06,323 INFO     Train negative_sample_loss at step 31000: 0.113176
2023-03-16 17:04:06,323 INFO     Train loss at step 31000: 0.250346
2023-03-16 17:04:25,656 INFO     Train positive_sample_loss at step 31100: 0.386196
2023-03-16 17:04:25,656 INFO     Train negative_sample_loss at step 31100: 0.113493
2023-03-16 17:04:25,657 INFO     Train loss at step 31100: 0.249845
2023-03-16 17:04:44,986 INFO     Train positive_sample_loss at step 31200: 0.387312
2023-03-16 17:04:44,986 INFO     Train negative_sample_loss at step 31200: 0.112723
2023-03-16 17:04:44,986 INFO     Train loss at step 31200: 0.250018
2023-03-16 17:05:04,325 INFO     Train positive_sample_loss at step 31300: 0.382850
2023-03-16 17:05:04,325 INFO     Train negative_sample_loss at step 31300: 0.112713
2023-03-16 17:05:04,326 INFO     Train loss at step 31300: 0.247782
2023-03-16 17:05:23,663 INFO     Train positive_sample_loss at step 31400: 0.380785
2023-03-16 17:05:23,664 INFO     Train negative_sample_loss at step 31400: 0.113916
2023-03-16 17:05:23,664 INFO     Train loss at step 31400: 0.247350
funtion time use:38610ms
2023-03-16 17:05:48,900 INFO     Train positive_sample_loss at step 31500: 0.360895
2023-03-16 17:05:48,900 INFO     Train negative_sample_loss at step 31500: 0.112659
2023-03-16 17:05:48,900 INFO     Train loss at step 31500: 0.236777
2023-03-16 17:06:08,215 INFO     Train positive_sample_loss at step 31600: 0.311121
2023-03-16 17:06:08,216 INFO     Train negative_sample_loss at step 31600: 0.109126
2023-03-16 17:06:08,216 INFO     Train loss at step 31600: 0.210124
2023-03-16 17:06:27,535 INFO     Train positive_sample_loss at step 31700: 0.314075
2023-03-16 17:06:27,535 INFO     Train negative_sample_loss at step 31700: 0.107361
2023-03-16 17:06:27,535 INFO     Train loss at step 31700: 0.210718
2023-03-16 17:06:46,843 INFO     Train positive_sample_loss at step 31800: 0.317428
2023-03-16 17:06:46,844 INFO     Train negative_sample_loss at step 31800: 0.107531
2023-03-16 17:06:46,844 INFO     Train loss at step 31800: 0.212480
2023-03-16 17:07:06,155 INFO     Train positive_sample_loss at step 31900: 0.321183
2023-03-16 17:07:06,156 INFO     Train negative_sample_loss at step 31900: 0.106260
2023-03-16 17:07:06,156 INFO     Train loss at step 31900: 0.213722
2023-03-16 17:07:25,467 INFO     Train positive_sample_loss at step 32000: 0.326257
2023-03-16 17:07:25,467 INFO     Train negative_sample_loss at step 32000: 0.105790
2023-03-16 17:07:25,467 INFO     Train loss at step 32000: 0.216024
2023-03-16 17:07:44,787 INFO     Train positive_sample_loss at step 32100: 0.329896
2023-03-16 17:07:44,787 INFO     Train negative_sample_loss at step 32100: 0.105720
2023-03-16 17:07:44,788 INFO     Train loss at step 32100: 0.217808
2023-03-16 17:08:04,108 INFO     Train positive_sample_loss at step 32200: 0.333050
2023-03-16 17:08:04,108 INFO     Train negative_sample_loss at step 32200: 0.105620
2023-03-16 17:08:04,108 INFO     Train loss at step 32200: 0.219335
2023-03-16 17:08:30,832 INFO     Train positive_sample_loss at step 32300: 0.337578
2023-03-16 17:08:30,833 INFO     Train negative_sample_loss at step 32300: 0.106249
2023-03-16 17:08:30,833 INFO     Train loss at step 32300: 0.221914
2023-03-16 17:08:50,150 INFO     Train positive_sample_loss at step 32400: 0.344688
2023-03-16 17:08:50,150 INFO     Train negative_sample_loss at step 32400: 0.106708
2023-03-16 17:08:50,150 INFO     Train loss at step 32400: 0.225698
2023-03-16 17:09:09,469 INFO     Train positive_sample_loss at step 32500: 0.348737
2023-03-16 17:09:09,470 INFO     Train negative_sample_loss at step 32500: 0.106417
2023-03-16 17:09:09,470 INFO     Train loss at step 32500: 0.227577
2023-03-16 17:09:28,786 INFO     Train positive_sample_loss at step 32600: 0.352228
2023-03-16 17:09:28,787 INFO     Train negative_sample_loss at step 32600: 0.106219
2023-03-16 17:09:28,787 INFO     Train loss at step 32600: 0.229224
2023-03-16 17:09:48,106 INFO     Train positive_sample_loss at step 32700: 0.356223
2023-03-16 17:09:48,106 INFO     Train negative_sample_loss at step 32700: 0.106533
2023-03-16 17:09:48,106 INFO     Train loss at step 32700: 0.231378
2023-03-16 17:10:07,439 INFO     Train positive_sample_loss at step 32800: 0.362386
2023-03-16 17:10:07,439 INFO     Train negative_sample_loss at step 32800: 0.106601
2023-03-16 17:10:07,439 INFO     Train loss at step 32800: 0.234494
2023-03-16 17:10:26,765 INFO     Train positive_sample_loss at step 32900: 0.365556
2023-03-16 17:10:26,765 INFO     Train negative_sample_loss at step 32900: 0.106936
2023-03-16 17:10:26,765 INFO     Train loss at step 32900: 0.236246
2023-03-16 17:10:46,093 INFO     Train positive_sample_loss at step 33000: 0.369713
2023-03-16 17:10:46,093 INFO     Train negative_sample_loss at step 33000: 0.107289
2023-03-16 17:10:46,093 INFO     Train loss at step 33000: 0.238501
2023-03-16 17:11:05,416 INFO     Train positive_sample_loss at step 33100: 0.371144
2023-03-16 17:11:05,417 INFO     Train negative_sample_loss at step 33100: 0.106971
2023-03-16 17:11:05,417 INFO     Train loss at step 33100: 0.239057
2023-03-16 17:11:24,736 INFO     Train positive_sample_loss at step 33200: 0.374028
2023-03-16 17:11:24,737 INFO     Train negative_sample_loss at step 33200: 0.106833
2023-03-16 17:11:24,737 INFO     Train loss at step 33200: 0.240430
2023-03-16 17:11:44,064 INFO     Train positive_sample_loss at step 33300: 0.378254
2023-03-16 17:11:44,065 INFO     Train negative_sample_loss at step 33300: 0.108482
2023-03-16 17:11:44,065 INFO     Train loss at step 33300: 0.243368
2023-03-16 17:12:10,321 INFO     Train positive_sample_loss at step 33400: 0.380143
2023-03-16 17:12:10,321 INFO     Train negative_sample_loss at step 33400: 0.107843
2023-03-16 17:12:10,322 INFO     Train loss at step 33400: 0.243993
2023-03-16 17:12:29,647 INFO     Train positive_sample_loss at step 33500: 0.382102
2023-03-16 17:12:29,648 INFO     Train negative_sample_loss at step 33500: 0.109099
2023-03-16 17:12:29,648 INFO     Train loss at step 33500: 0.245600
2023-03-16 17:12:48,966 INFO     Train positive_sample_loss at step 33600: 0.385619
2023-03-16 17:12:48,966 INFO     Train negative_sample_loss at step 33600: 0.109345
2023-03-16 17:12:48,966 INFO     Train loss at step 33600: 0.247482
2023-03-16 17:13:08,293 INFO     Train positive_sample_loss at step 33700: 0.387210
2023-03-16 17:13:08,293 INFO     Train negative_sample_loss at step 33700: 0.109176
2023-03-16 17:13:08,293 INFO     Train loss at step 33700: 0.248193
2023-03-16 17:13:27,622 INFO     Train positive_sample_loss at step 33800: 0.387440
2023-03-16 17:13:27,622 INFO     Train negative_sample_loss at step 33800: 0.109853
2023-03-16 17:13:27,622 INFO     Train loss at step 33800: 0.248647
2023-03-16 17:13:46,949 INFO     Train positive_sample_loss at step 33900: 0.387036
2023-03-16 17:13:46,949 INFO     Train negative_sample_loss at step 33900: 0.109809
2023-03-16 17:13:46,950 INFO     Train loss at step 33900: 0.248422
2023-03-16 17:14:06,276 INFO     Train positive_sample_loss at step 34000: 0.389652
2023-03-16 17:14:06,276 INFO     Train negative_sample_loss at step 34000: 0.109612
2023-03-16 17:14:06,276 INFO     Train loss at step 34000: 0.249632
2023-03-16 17:14:25,600 INFO     Train positive_sample_loss at step 34100: 0.390822
2023-03-16 17:14:25,601 INFO     Train negative_sample_loss at step 34100: 0.110266
2023-03-16 17:14:25,601 INFO     Train loss at step 34100: 0.250544
2023-03-16 17:14:44,928 INFO     Train positive_sample_loss at step 34200: 0.391438
2023-03-16 17:14:44,929 INFO     Train negative_sample_loss at step 34200: 0.110599
2023-03-16 17:14:44,929 INFO     Train loss at step 34200: 0.251018
2023-03-16 17:15:04,254 INFO     Train positive_sample_loss at step 34300: 0.391780
2023-03-16 17:15:04,254 INFO     Train negative_sample_loss at step 34300: 0.111170
2023-03-16 17:15:04,255 INFO     Train loss at step 34300: 0.251475
2023-03-16 17:15:30,385 INFO     Train positive_sample_loss at step 34400: 0.390215
2023-03-16 17:15:30,386 INFO     Train negative_sample_loss at step 34400: 0.111014
2023-03-16 17:15:30,386 INFO     Train loss at step 34400: 0.250614
2023-03-16 17:15:49,708 INFO     Train positive_sample_loss at step 34500: 0.391152
2023-03-16 17:15:49,708 INFO     Train negative_sample_loss at step 34500: 0.111309
2023-03-16 17:15:49,708 INFO     Train loss at step 34500: 0.251231
2023-03-16 17:16:09,026 INFO     Train positive_sample_loss at step 34600: 0.389592
2023-03-16 17:16:09,027 INFO     Train negative_sample_loss at step 34600: 0.111213
2023-03-16 17:16:09,027 INFO     Train loss at step 34600: 0.250403
2023-03-16 17:16:28,350 INFO     Train positive_sample_loss at step 34700: 0.389062
2023-03-16 17:16:28,351 INFO     Train negative_sample_loss at step 34700: 0.112082
2023-03-16 17:16:28,351 INFO     Train loss at step 34700: 0.250572
2023-03-16 17:16:47,675 INFO     Train positive_sample_loss at step 34800: 0.387432
2023-03-16 17:16:47,675 INFO     Train negative_sample_loss at step 34800: 0.111401
2023-03-16 17:16:47,675 INFO     Train loss at step 34800: 0.249417
2023-03-16 17:17:07,002 INFO     Train positive_sample_loss at step 34900: 0.386408
2023-03-16 17:17:07,002 INFO     Train negative_sample_loss at step 34900: 0.112360
2023-03-16 17:17:07,002 INFO     Train loss at step 34900: 0.249384
2023-03-16 17:17:26,326 INFO     Train positive_sample_loss at step 35000: 0.386259
2023-03-16 17:17:26,327 INFO     Train negative_sample_loss at step 35000: 0.112504
2023-03-16 17:17:26,327 INFO     Train loss at step 35000: 0.249381
2023-03-16 17:17:45,647 INFO     Train positive_sample_loss at step 35100: 0.384875
2023-03-16 17:17:45,647 INFO     Train negative_sample_loss at step 35100: 0.112308
2023-03-16 17:17:45,647 INFO     Train loss at step 35100: 0.248592
2023-03-16 17:18:04,968 INFO     Train positive_sample_loss at step 35200: 0.383566
2023-03-16 17:18:04,969 INFO     Train negative_sample_loss at step 35200: 0.111902
2023-03-16 17:18:04,969 INFO     Train loss at step 35200: 0.247734
2023-03-16 17:18:24,297 INFO     Train positive_sample_loss at step 35300: 0.380526
2023-03-16 17:18:24,297 INFO     Train negative_sample_loss at step 35300: 0.112681
2023-03-16 17:18:24,297 INFO     Train loss at step 35300: 0.246603
2023-03-16 17:18:45,409 INFO     Train positive_sample_loss at step 35400: 0.381019
2023-03-16 17:18:45,410 INFO     Train negative_sample_loss at step 35400: 0.112576
2023-03-16 17:18:45,410 INFO     Train loss at step 35400: 0.246798
2023-03-16 17:19:08,669 INFO     Train positive_sample_loss at step 35500: 0.313065
2023-03-16 17:19:08,669 INFO     Train negative_sample_loss at step 35500: 0.110390
2023-03-16 17:19:08,669 INFO     Train loss at step 35500: 0.211728
2023-03-16 17:19:27,987 INFO     Train positive_sample_loss at step 35600: 0.313333
2023-03-16 17:19:27,987 INFO     Train negative_sample_loss at step 35600: 0.107233
2023-03-16 17:19:27,988 INFO     Train loss at step 35600: 0.210283
2023-03-16 17:19:47,294 INFO     Train positive_sample_loss at step 35700: 0.316654
2023-03-16 17:19:47,295 INFO     Train negative_sample_loss at step 35700: 0.106510
2023-03-16 17:19:47,295 INFO     Train loss at step 35700: 0.211582
2023-03-16 17:20:06,608 INFO     Train positive_sample_loss at step 35800: 0.318875
2023-03-16 17:20:06,608 INFO     Train negative_sample_loss at step 35800: 0.105559
2023-03-16 17:20:06,609 INFO     Train loss at step 35800: 0.212217
2023-03-16 17:20:25,933 INFO     Train positive_sample_loss at step 35900: 0.322408
2023-03-16 17:20:25,933 INFO     Train negative_sample_loss at step 35900: 0.105679
2023-03-16 17:20:25,933 INFO     Train loss at step 35900: 0.214044
2023-03-16 17:20:45,256 INFO     Train positive_sample_loss at step 36000: 0.327422
2023-03-16 17:20:45,257 INFO     Train negative_sample_loss at step 36000: 0.105895
2023-03-16 17:20:45,257 INFO     Train loss at step 36000: 0.216659
2023-03-16 17:21:04,586 INFO     Train positive_sample_loss at step 36100: 0.333368
2023-03-16 17:21:04,587 INFO     Train negative_sample_loss at step 36100: 0.105271
2023-03-16 17:21:04,587 INFO     Train loss at step 36100: 0.219319
2023-03-16 17:21:31,272 INFO     Train positive_sample_loss at step 36200: 0.337769
2023-03-16 17:21:31,273 INFO     Train negative_sample_loss at step 36200: 0.105106
2023-03-16 17:21:31,273 INFO     Train loss at step 36200: 0.221437
2023-03-16 17:21:50,591 INFO     Train positive_sample_loss at step 36300: 0.341729
2023-03-16 17:21:50,592 INFO     Train negative_sample_loss at step 36300: 0.105642
2023-03-16 17:21:50,592 INFO     Train loss at step 36300: 0.223685
2023-03-16 17:22:09,906 INFO     Train positive_sample_loss at step 36400: 0.345995
2023-03-16 17:22:09,906 INFO     Train negative_sample_loss at step 36400: 0.105569
2023-03-16 17:22:09,906 INFO     Train loss at step 36400: 0.225782
2023-03-16 17:22:29,234 INFO     Train positive_sample_loss at step 36500: 0.351376
2023-03-16 17:22:29,235 INFO     Train negative_sample_loss at step 36500: 0.105578
2023-03-16 17:22:29,235 INFO     Train loss at step 36500: 0.228477
2023-03-16 17:22:48,566 INFO     Train positive_sample_loss at step 36600: 0.355734
2023-03-16 17:22:48,566 INFO     Train negative_sample_loss at step 36600: 0.105957
2023-03-16 17:22:48,567 INFO     Train loss at step 36600: 0.230845
2023-03-16 17:23:07,889 INFO     Train positive_sample_loss at step 36700: 0.360245
2023-03-16 17:23:07,890 INFO     Train negative_sample_loss at step 36700: 0.106822
2023-03-16 17:23:07,890 INFO     Train loss at step 36700: 0.233534
2023-03-16 17:23:27,218 INFO     Train positive_sample_loss at step 36800: 0.364612
2023-03-16 17:23:27,219 INFO     Train negative_sample_loss at step 36800: 0.106725
2023-03-16 17:23:27,219 INFO     Train loss at step 36800: 0.235668
2023-03-16 17:23:46,549 INFO     Train positive_sample_loss at step 36900: 0.366531
2023-03-16 17:23:46,550 INFO     Train negative_sample_loss at step 36900: 0.105980
2023-03-16 17:23:46,550 INFO     Train loss at step 36900: 0.236255
2023-03-16 17:24:05,872 INFO     Train positive_sample_loss at step 37000: 0.370960
2023-03-16 17:24:05,873 INFO     Train negative_sample_loss at step 37000: 0.105997
2023-03-16 17:24:05,873 INFO     Train loss at step 37000: 0.238479
2023-03-16 17:24:25,192 INFO     Train positive_sample_loss at step 37100: 0.374261
2023-03-16 17:24:25,193 INFO     Train negative_sample_loss at step 37100: 0.106954
2023-03-16 17:24:25,193 INFO     Train loss at step 37100: 0.240607
2023-03-16 17:24:44,514 INFO     Train positive_sample_loss at step 37200: 0.376174
2023-03-16 17:24:44,514 INFO     Train negative_sample_loss at step 37200: 0.107396
2023-03-16 17:24:44,515 INFO     Train loss at step 37200: 0.241785
2023-03-16 17:25:10,656 INFO     Train positive_sample_loss at step 37300: 0.382719
2023-03-16 17:25:10,657 INFO     Train negative_sample_loss at step 37300: 0.108627
2023-03-16 17:25:10,657 INFO     Train loss at step 37300: 0.245673
2023-03-16 17:25:29,990 INFO     Train positive_sample_loss at step 37400: 0.382950
2023-03-16 17:25:29,990 INFO     Train negative_sample_loss at step 37400: 0.107960
2023-03-16 17:25:29,991 INFO     Train loss at step 37400: 0.245455
2023-03-16 17:25:49,324 INFO     Train positive_sample_loss at step 37500: 0.384857
2023-03-16 17:25:49,324 INFO     Train negative_sample_loss at step 37500: 0.108159
2023-03-16 17:25:49,325 INFO     Train loss at step 37500: 0.246508
2023-03-16 17:26:08,666 INFO     Train positive_sample_loss at step 37600: 0.385683
2023-03-16 17:26:08,667 INFO     Train negative_sample_loss at step 37600: 0.109124
2023-03-16 17:26:08,667 INFO     Train loss at step 37600: 0.247403
2023-03-16 17:26:27,998 INFO     Train positive_sample_loss at step 37700: 0.387205
2023-03-16 17:26:27,999 INFO     Train negative_sample_loss at step 37700: 0.109111
2023-03-16 17:26:27,999 INFO     Train loss at step 37700: 0.248158
2023-03-16 17:26:47,330 INFO     Train positive_sample_loss at step 37800: 0.390035
2023-03-16 17:26:47,331 INFO     Train negative_sample_loss at step 37800: 0.109029
2023-03-16 17:26:47,331 INFO     Train loss at step 37800: 0.249532
2023-03-16 17:27:06,661 INFO     Train positive_sample_loss at step 37900: 0.391865
2023-03-16 17:27:06,661 INFO     Train negative_sample_loss at step 37900: 0.109687
2023-03-16 17:27:06,661 INFO     Train loss at step 37900: 0.250776
2023-03-16 17:27:25,993 INFO     Train positive_sample_loss at step 38000: 0.391332
2023-03-16 17:27:25,993 INFO     Train negative_sample_loss at step 38000: 0.109555
2023-03-16 17:27:25,993 INFO     Train loss at step 38000: 0.250443
2023-03-16 17:27:45,325 INFO     Train positive_sample_loss at step 38100: 0.390946
2023-03-16 17:27:45,326 INFO     Train negative_sample_loss at step 38100: 0.110299
2023-03-16 17:27:45,326 INFO     Train loss at step 38100: 0.250623
2023-03-16 17:28:04,654 INFO     Train positive_sample_loss at step 38200: 0.390858
2023-03-16 17:28:04,654 INFO     Train negative_sample_loss at step 38200: 0.109884
2023-03-16 17:28:04,654 INFO     Train loss at step 38200: 0.250371
2023-03-16 17:28:23,991 INFO     Train positive_sample_loss at step 38300: 0.393106
2023-03-16 17:28:23,992 INFO     Train negative_sample_loss at step 38300: 0.110730
2023-03-16 17:28:23,992 INFO     Train loss at step 38300: 0.251918
2023-03-16 17:28:50,187 INFO     Train positive_sample_loss at step 38400: 0.391130
2023-03-16 17:28:50,187 INFO     Train negative_sample_loss at step 38400: 0.110424
2023-03-16 17:28:50,187 INFO     Train loss at step 38400: 0.250777
2023-03-16 17:29:09,516 INFO     Train positive_sample_loss at step 38500: 0.391170
2023-03-16 17:29:09,517 INFO     Train negative_sample_loss at step 38500: 0.110814
2023-03-16 17:29:09,517 INFO     Train loss at step 38500: 0.250992
2023-03-16 17:29:28,841 INFO     Train positive_sample_loss at step 38600: 0.392433
2023-03-16 17:29:28,841 INFO     Train negative_sample_loss at step 38600: 0.111400
2023-03-16 17:29:28,841 INFO     Train loss at step 38600: 0.251917
2023-03-16 17:29:48,166 INFO     Train positive_sample_loss at step 38700: 0.388818
2023-03-16 17:29:48,166 INFO     Train negative_sample_loss at step 38700: 0.111760
2023-03-16 17:29:48,166 INFO     Train loss at step 38700: 0.250289
2023-03-16 17:30:07,496 INFO     Train positive_sample_loss at step 38800: 0.389537
2023-03-16 17:30:07,496 INFO     Train negative_sample_loss at step 38800: 0.111587
2023-03-16 17:30:07,496 INFO     Train loss at step 38800: 0.250562
2023-03-16 17:30:26,834 INFO     Train positive_sample_loss at step 38900: 0.385759
2023-03-16 17:30:26,835 INFO     Train negative_sample_loss at step 38900: 0.111774
2023-03-16 17:30:26,835 INFO     Train loss at step 38900: 0.248767
2023-03-16 17:30:46,165 INFO     Train positive_sample_loss at step 39000: 0.387286
2023-03-16 17:30:46,166 INFO     Train negative_sample_loss at step 39000: 0.112262
2023-03-16 17:30:46,166 INFO     Train loss at step 39000: 0.249774
2023-03-16 17:31:05,501 INFO     Train positive_sample_loss at step 39100: 0.384068
2023-03-16 17:31:05,502 INFO     Train negative_sample_loss at step 39100: 0.112196
2023-03-16 17:31:05,502 INFO     Train loss at step 39100: 0.248132
2023-03-16 17:31:24,829 INFO     Train positive_sample_loss at step 39200: 0.383660
2023-03-16 17:31:24,830 INFO     Train negative_sample_loss at step 39200: 0.112153
2023-03-16 17:31:24,830 INFO     Train loss at step 39200: 0.247907
2023-03-16 17:31:44,162 INFO     Train positive_sample_loss at step 39300: 0.382757
2023-03-16 17:31:44,162 INFO     Train negative_sample_loss at step 39300: 0.111947
2023-03-16 17:31:44,162 INFO     Train loss at step 39300: 0.247352
2023-03-16 17:32:09,291 INFO     Train positive_sample_loss at step 39400: 0.336645
2023-03-16 17:32:09,291 INFO     Train negative_sample_loss at step 39400: 0.110481
2023-03-16 17:32:09,292 INFO     Train loss at step 39400: 0.223563
2023-03-16 17:32:28,613 INFO     Train positive_sample_loss at step 39500: 0.310359
2023-03-16 17:32:28,613 INFO     Train negative_sample_loss at step 39500: 0.108071
2023-03-16 17:32:28,614 INFO     Train loss at step 39500: 0.209215
2023-03-16 17:32:47,929 INFO     Train positive_sample_loss at step 39600: 0.315124
2023-03-16 17:32:47,929 INFO     Train negative_sample_loss at step 39600: 0.106207
2023-03-16 17:32:47,929 INFO     Train loss at step 39600: 0.210665
2023-03-16 17:33:07,253 INFO     Train positive_sample_loss at step 39700: 0.318996
2023-03-16 17:33:07,253 INFO     Train negative_sample_loss at step 39700: 0.106039
2023-03-16 17:33:07,254 INFO     Train loss at step 39700: 0.212518
2023-03-16 17:33:26,562 INFO     Train positive_sample_loss at step 39800: 0.322478
2023-03-16 17:33:26,562 INFO     Train negative_sample_loss at step 39800: 0.105145
2023-03-16 17:33:26,562 INFO     Train loss at step 39800: 0.213811
2023-03-16 17:33:45,882 INFO     Train positive_sample_loss at step 39900: 0.327443
2023-03-16 17:33:45,882 INFO     Train negative_sample_loss at step 39900: 0.105093
2023-03-16 17:33:45,882 INFO     Train loss at step 39900: 0.216268
2023-03-16 17:34:06,774 INFO     Train positive_sample_loss at step 40000: 0.331357
2023-03-16 17:34:06,774 INFO     Train negative_sample_loss at step 40000: 0.104135
2023-03-16 17:34:06,775 INFO     Train loss at step 40000: 0.217746
2023-03-16 17:34:06,775 INFO     Evaluating on Valid Dataset...
2023-03-16 17:34:08,066 INFO     Evaluating the model... (0/26842)
2023-03-16 17:34:09,408 INFO     Evaluating the model... (1000/26842)
2023-03-16 17:34:10,627 INFO     Evaluating the model... (2000/26842)
2023-03-16 17:34:11,850 INFO     Evaluating the model... (3000/26842)
2023-03-16 17:34:13,073 INFO     Evaluating the model... (4000/26842)
2023-03-16 17:34:14,298 INFO     Evaluating the model... (5000/26842)
2023-03-16 17:34:15,515 INFO     Evaluating the model... (6000/26842)
2023-03-16 17:34:16,733 INFO     Evaluating the model... (7000/26842)
2023-03-16 17:34:17,950 INFO     Evaluating the model... (8000/26842)
2023-03-16 17:34:19,171 INFO     Evaluating the model... (9000/26842)
2023-03-16 17:34:20,393 INFO     Evaluating the model... (10000/26842)
2023-03-16 17:34:21,613 INFO     Evaluating the model... (11000/26842)
2023-03-16 17:34:22,830 INFO     Evaluating the model... (12000/26842)
2023-03-16 17:34:24,050 INFO     Evaluating the model... (13000/26842)
2023-03-16 17:34:26,287 INFO     Evaluating the model... (14000/26842)
2023-03-16 17:34:27,764 INFO     Evaluating the model... (15000/26842)
2023-03-16 17:34:29,243 INFO     Evaluating the model... (16000/26842)
2023-03-16 17:34:30,721 INFO     Evaluating the model... (17000/26842)
2023-03-16 17:34:32,204 INFO     Evaluating the model... (18000/26842)
2023-03-16 17:34:33,695 INFO     Evaluating the model... (19000/26842)
2023-03-16 17:34:35,193 INFO     Evaluating the model... (20000/26842)
2023-03-16 17:34:36,678 INFO     Evaluating the model... (21000/26842)
2023-03-16 17:34:38,163 INFO     Evaluating the model... (22000/26842)
2023-03-16 17:34:39,646 INFO     Evaluating the model... (23000/26842)
2023-03-16 17:34:41,119 INFO     Evaluating the model... (24000/26842)
2023-03-16 17:34:42,587 INFO     Evaluating the model... (25000/26842)
2023-03-16 17:34:44,058 INFO     Evaluating the model... (26000/26842)
2023-03-16 17:34:45,600 INFO     Valid hits@1_list at step 40000: 0.584319
2023-03-16 17:34:45,600 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 17:34:45,601 INFO     Valid hits@3_list at step 40000: 0.676465
2023-03-16 17:34:45,601 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 17:34:45,601 INFO     Valid hits@10_list at step 40000: 0.763266
2023-03-16 17:34:45,601 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 17:34:45,601 INFO     Valid mrr_list at step 40000: 0.646833
2023-03-16 17:35:04,930 INFO     Train positive_sample_loss at step 40100: 0.334698
2023-03-16 17:35:04,931 INFO     Train negative_sample_loss at step 40100: 0.104505
2023-03-16 17:35:04,931 INFO     Train loss at step 40100: 0.219602
2023-03-16 17:35:31,644 INFO     Train positive_sample_loss at step 40200: 0.339518
2023-03-16 17:35:31,645 INFO     Train negative_sample_loss at step 40200: 0.104407
2023-03-16 17:35:31,645 INFO     Train loss at step 40200: 0.221962
2023-03-16 17:35:50,969 INFO     Train positive_sample_loss at step 40300: 0.341472
2023-03-16 17:35:50,970 INFO     Train negative_sample_loss at step 40300: 0.105581
2023-03-16 17:35:50,970 INFO     Train loss at step 40300: 0.223527
2023-03-16 17:36:10,289 INFO     Train positive_sample_loss at step 40400: 0.348007
2023-03-16 17:36:10,290 INFO     Train negative_sample_loss at step 40400: 0.105648
2023-03-16 17:36:10,290 INFO     Train loss at step 40400: 0.226827
2023-03-16 17:36:29,624 INFO     Train positive_sample_loss at step 40500: 0.353190
2023-03-16 17:36:29,625 INFO     Train negative_sample_loss at step 40500: 0.105388
2023-03-16 17:36:29,625 INFO     Train loss at step 40500: 0.229289
2023-03-16 17:36:48,951 INFO     Train positive_sample_loss at step 40600: 0.357241
2023-03-16 17:36:48,952 INFO     Train negative_sample_loss at step 40600: 0.106256
2023-03-16 17:36:48,952 INFO     Train loss at step 40600: 0.231749
2023-03-16 17:37:08,274 INFO     Train positive_sample_loss at step 40700: 0.362006
2023-03-16 17:37:08,274 INFO     Train negative_sample_loss at step 40700: 0.105301
2023-03-16 17:37:08,274 INFO     Train loss at step 40700: 0.233653
2023-03-16 17:37:27,602 INFO     Train positive_sample_loss at step 40800: 0.364372
2023-03-16 17:37:27,603 INFO     Train negative_sample_loss at step 40800: 0.105307
2023-03-16 17:37:27,603 INFO     Train loss at step 40800: 0.234840
2023-03-16 17:37:46,927 INFO     Train positive_sample_loss at step 40900: 0.368384
2023-03-16 17:37:46,928 INFO     Train negative_sample_loss at step 40900: 0.105967
2023-03-16 17:37:46,928 INFO     Train loss at step 40900: 0.237175
2023-03-16 17:38:06,251 INFO     Train positive_sample_loss at step 41000: 0.371154
2023-03-16 17:38:06,252 INFO     Train negative_sample_loss at step 41000: 0.106640
2023-03-16 17:38:06,252 INFO     Train loss at step 41000: 0.238897
2023-03-16 17:38:25,579 INFO     Train positive_sample_loss at step 41100: 0.376364
2023-03-16 17:38:25,580 INFO     Train negative_sample_loss at step 41100: 0.107225
2023-03-16 17:38:25,580 INFO     Train loss at step 41100: 0.241795
2023-03-16 17:38:51,951 INFO     Train positive_sample_loss at step 41200: 0.378444
2023-03-16 17:38:51,952 INFO     Train negative_sample_loss at step 41200: 0.107032
2023-03-16 17:38:51,952 INFO     Train loss at step 41200: 0.242738
2023-03-16 17:39:11,278 INFO     Train positive_sample_loss at step 41300: 0.382094
2023-03-16 17:39:11,279 INFO     Train negative_sample_loss at step 41300: 0.107934
2023-03-16 17:39:11,279 INFO     Train loss at step 41300: 0.245014
2023-03-16 17:39:30,607 INFO     Train positive_sample_loss at step 41400: 0.384230
2023-03-16 17:39:30,608 INFO     Train negative_sample_loss at step 41400: 0.108414
2023-03-16 17:39:30,608 INFO     Train loss at step 41400: 0.246322
2023-03-16 17:39:49,947 INFO     Train positive_sample_loss at step 41500: 0.385755
2023-03-16 17:39:49,947 INFO     Train negative_sample_loss at step 41500: 0.107752
2023-03-16 17:39:49,947 INFO     Train loss at step 41500: 0.246753
2023-03-16 17:40:09,289 INFO     Train positive_sample_loss at step 41600: 0.389141
2023-03-16 17:40:09,289 INFO     Train negative_sample_loss at step 41600: 0.109136
2023-03-16 17:40:09,289 INFO     Train loss at step 41600: 0.249139
2023-03-16 17:40:28,623 INFO     Train positive_sample_loss at step 41700: 0.388971
2023-03-16 17:40:28,624 INFO     Train negative_sample_loss at step 41700: 0.108320
2023-03-16 17:40:28,624 INFO     Train loss at step 41700: 0.248646
2023-03-16 17:40:47,967 INFO     Train positive_sample_loss at step 41800: 0.388645
2023-03-16 17:40:47,968 INFO     Train negative_sample_loss at step 41800: 0.109146
2023-03-16 17:40:47,968 INFO     Train loss at step 41800: 0.248896
2023-03-16 17:41:07,299 INFO     Train positive_sample_loss at step 41900: 0.390757
2023-03-16 17:41:07,299 INFO     Train negative_sample_loss at step 41900: 0.109112
2023-03-16 17:41:07,299 INFO     Train loss at step 41900: 0.249934
2023-03-16 17:41:26,626 INFO     Train positive_sample_loss at step 42000: 0.389092
2023-03-16 17:41:26,627 INFO     Train negative_sample_loss at step 42000: 0.109107
2023-03-16 17:41:26,627 INFO     Train loss at step 42000: 0.249100
2023-03-16 17:41:45,961 INFO     Train positive_sample_loss at step 42100: 0.391362
2023-03-16 17:41:45,961 INFO     Train negative_sample_loss at step 42100: 0.110398
2023-03-16 17:41:45,961 INFO     Train loss at step 42100: 0.250880
2023-03-16 17:42:05,283 INFO     Train positive_sample_loss at step 42200: 0.389941
2023-03-16 17:42:05,283 INFO     Train negative_sample_loss at step 42200: 0.110085
2023-03-16 17:42:05,283 INFO     Train loss at step 42200: 0.250013
2023-03-16 17:42:31,472 INFO     Train positive_sample_loss at step 42300: 0.390487
2023-03-16 17:42:31,472 INFO     Train negative_sample_loss at step 42300: 0.110002
2023-03-16 17:42:31,472 INFO     Train loss at step 42300: 0.250245
2023-03-16 17:42:50,797 INFO     Train positive_sample_loss at step 42400: 0.389736
2023-03-16 17:42:50,797 INFO     Train negative_sample_loss at step 42400: 0.111085
2023-03-16 17:42:50,798 INFO     Train loss at step 42400: 0.250411
2023-03-16 17:43:10,126 INFO     Train positive_sample_loss at step 42500: 0.391447
2023-03-16 17:43:10,127 INFO     Train negative_sample_loss at step 42500: 0.110527
2023-03-16 17:43:10,127 INFO     Train loss at step 42500: 0.250987
2023-03-16 17:43:29,459 INFO     Train positive_sample_loss at step 42600: 0.390039
2023-03-16 17:43:29,460 INFO     Train negative_sample_loss at step 42600: 0.111310
2023-03-16 17:43:29,460 INFO     Train loss at step 42600: 0.250674
2023-03-16 17:43:48,800 INFO     Train positive_sample_loss at step 42700: 0.388221
2023-03-16 17:43:48,801 INFO     Train negative_sample_loss at step 42700: 0.111123
2023-03-16 17:43:48,801 INFO     Train loss at step 42700: 0.249672
2023-03-16 17:44:08,129 INFO     Train positive_sample_loss at step 42800: 0.385561
2023-03-16 17:44:08,129 INFO     Train negative_sample_loss at step 42800: 0.111702
2023-03-16 17:44:08,129 INFO     Train loss at step 42800: 0.248631
2023-03-16 17:44:27,464 INFO     Train positive_sample_loss at step 42900: 0.385039
2023-03-16 17:44:27,464 INFO     Train negative_sample_loss at step 42900: 0.111773
2023-03-16 17:44:27,464 INFO     Train loss at step 42900: 0.248406
2023-03-16 17:44:46,795 INFO     Train positive_sample_loss at step 43000: 0.384710
2023-03-16 17:44:46,795 INFO     Train negative_sample_loss at step 43000: 0.111589
2023-03-16 17:44:46,796 INFO     Train loss at step 43000: 0.248150
2023-03-16 17:45:06,127 INFO     Train positive_sample_loss at step 43100: 0.383088
2023-03-16 17:45:06,127 INFO     Train negative_sample_loss at step 43100: 0.111977
2023-03-16 17:45:06,128 INFO     Train loss at step 43100: 0.247532
2023-03-16 17:45:25,457 INFO     Train positive_sample_loss at step 43200: 0.383832
2023-03-16 17:45:25,458 INFO     Train negative_sample_loss at step 43200: 0.111631
2023-03-16 17:45:25,458 INFO     Train loss at step 43200: 0.247731
funtion time use:38649ms
2023-03-16 17:45:50,532 INFO     Train positive_sample_loss at step 43300: 0.361473
2023-03-16 17:45:50,533 INFO     Train negative_sample_loss at step 43300: 0.112339
2023-03-16 17:45:50,533 INFO     Train loss at step 43300: 0.236906
2023-03-16 17:46:09,853 INFO     Train positive_sample_loss at step 43400: 0.310982
2023-03-16 17:46:09,853 INFO     Train negative_sample_loss at step 43400: 0.108210
2023-03-16 17:46:09,853 INFO     Train loss at step 43400: 0.209596
2023-03-16 17:46:29,163 INFO     Train positive_sample_loss at step 43500: 0.314584
2023-03-16 17:46:29,163 INFO     Train negative_sample_loss at step 43500: 0.106219
2023-03-16 17:46:29,163 INFO     Train loss at step 43500: 0.210401
2023-03-16 17:46:48,480 INFO     Train positive_sample_loss at step 43600: 0.319197
2023-03-16 17:46:48,481 INFO     Train negative_sample_loss at step 43600: 0.105520
2023-03-16 17:46:48,481 INFO     Train loss at step 43600: 0.212359
2023-03-16 17:47:07,789 INFO     Train positive_sample_loss at step 43700: 0.320481
2023-03-16 17:47:07,789 INFO     Train negative_sample_loss at step 43700: 0.104291
2023-03-16 17:47:07,789 INFO     Train loss at step 43700: 0.212386
2023-03-16 17:47:27,091 INFO     Train positive_sample_loss at step 43800: 0.325236
2023-03-16 17:47:27,092 INFO     Train negative_sample_loss at step 43800: 0.104585
2023-03-16 17:47:27,092 INFO     Train loss at step 43800: 0.214910
2023-03-16 17:47:46,404 INFO     Train positive_sample_loss at step 43900: 0.326989
2023-03-16 17:47:46,405 INFO     Train negative_sample_loss at step 43900: 0.104373
2023-03-16 17:47:46,405 INFO     Train loss at step 43900: 0.215681
2023-03-16 17:48:05,727 INFO     Train positive_sample_loss at step 44000: 0.334017
2023-03-16 17:48:05,728 INFO     Train negative_sample_loss at step 44000: 0.105063
2023-03-16 17:48:05,729 INFO     Train loss at step 44000: 0.219540
2023-03-16 17:48:36,483 INFO     Train positive_sample_loss at step 44100: 0.338451
2023-03-16 17:48:36,483 INFO     Train negative_sample_loss at step 44100: 0.104702
2023-03-16 17:48:36,483 INFO     Train loss at step 44100: 0.221577
2023-03-16 17:48:55,799 INFO     Train positive_sample_loss at step 44200: 0.344645
2023-03-16 17:48:55,800 INFO     Train negative_sample_loss at step 44200: 0.104890
2023-03-16 17:48:55,800 INFO     Train loss at step 44200: 0.224767
2023-03-16 17:49:15,130 INFO     Train positive_sample_loss at step 44300: 0.346249
2023-03-16 17:49:15,131 INFO     Train negative_sample_loss at step 44300: 0.104436
2023-03-16 17:49:15,131 INFO     Train loss at step 44300: 0.225343
2023-03-16 17:49:34,452 INFO     Train positive_sample_loss at step 44400: 0.351917
2023-03-16 17:49:34,452 INFO     Train negative_sample_loss at step 44400: 0.105281
2023-03-16 17:49:34,452 INFO     Train loss at step 44400: 0.228599
2023-03-16 17:49:53,783 INFO     Train positive_sample_loss at step 44500: 0.355889
2023-03-16 17:49:53,783 INFO     Train negative_sample_loss at step 44500: 0.105196
2023-03-16 17:49:53,783 INFO     Train loss at step 44500: 0.230543
2023-03-16 17:50:13,111 INFO     Train positive_sample_loss at step 44600: 0.359056
2023-03-16 17:50:13,111 INFO     Train negative_sample_loss at step 44600: 0.105371
2023-03-16 17:50:13,111 INFO     Train loss at step 44600: 0.232214
2023-03-16 17:50:32,433 INFO     Train positive_sample_loss at step 44700: 0.367122
2023-03-16 17:50:32,433 INFO     Train negative_sample_loss at step 44700: 0.106003
2023-03-16 17:50:32,433 INFO     Train loss at step 44700: 0.236563
2023-03-16 17:50:51,756 INFO     Train positive_sample_loss at step 44800: 0.368079
2023-03-16 17:50:51,757 INFO     Train negative_sample_loss at step 44800: 0.105990
2023-03-16 17:50:51,757 INFO     Train loss at step 44800: 0.237035
2023-03-16 17:51:11,082 INFO     Train positive_sample_loss at step 44900: 0.373196
2023-03-16 17:51:11,082 INFO     Train negative_sample_loss at step 44900: 0.106019
2023-03-16 17:51:11,082 INFO     Train loss at step 44900: 0.239607
2023-03-16 17:51:30,409 INFO     Train positive_sample_loss at step 45000: 0.376516
2023-03-16 17:51:30,410 INFO     Train negative_sample_loss at step 45000: 0.106221
2023-03-16 17:51:30,410 INFO     Train loss at step 45000: 0.241368
2023-03-16 17:51:56,717 INFO     Train positive_sample_loss at step 45100: 0.376097
2023-03-16 17:51:56,717 INFO     Train negative_sample_loss at step 45100: 0.106521
2023-03-16 17:51:56,717 INFO     Train loss at step 45100: 0.241309
2023-03-16 17:52:16,051 INFO     Train positive_sample_loss at step 45200: 0.379559
2023-03-16 17:52:16,052 INFO     Train negative_sample_loss at step 45200: 0.107030
2023-03-16 17:52:16,052 INFO     Train loss at step 45200: 0.243294
2023-03-16 17:52:35,382 INFO     Train positive_sample_loss at step 45300: 0.383639
2023-03-16 17:52:35,382 INFO     Train negative_sample_loss at step 45300: 0.107424
2023-03-16 17:52:35,382 INFO     Train loss at step 45300: 0.245531
2023-03-16 17:52:54,711 INFO     Train positive_sample_loss at step 45400: 0.384776
2023-03-16 17:52:54,712 INFO     Train negative_sample_loss at step 45400: 0.107747
2023-03-16 17:52:54,712 INFO     Train loss at step 45400: 0.246261
2023-03-16 17:53:14,049 INFO     Train positive_sample_loss at step 45500: 0.386328
2023-03-16 17:53:14,049 INFO     Train negative_sample_loss at step 45500: 0.107832
2023-03-16 17:53:14,049 INFO     Train loss at step 45500: 0.247080
2023-03-16 17:53:33,383 INFO     Train positive_sample_loss at step 45600: 0.389989
2023-03-16 17:53:33,384 INFO     Train negative_sample_loss at step 45600: 0.108071
2023-03-16 17:53:33,384 INFO     Train loss at step 45600: 0.249030
2023-03-16 17:53:52,712 INFO     Train positive_sample_loss at step 45700: 0.389743
2023-03-16 17:53:52,713 INFO     Train negative_sample_loss at step 45700: 0.108084
2023-03-16 17:53:52,713 INFO     Train loss at step 45700: 0.248913
2023-03-16 17:54:12,039 INFO     Train positive_sample_loss at step 45800: 0.389200
2023-03-16 17:54:12,040 INFO     Train negative_sample_loss at step 45800: 0.108761
2023-03-16 17:54:12,040 INFO     Train loss at step 45800: 0.248981
2023-03-16 17:54:31,375 INFO     Train positive_sample_loss at step 45900: 0.389093
2023-03-16 17:54:31,375 INFO     Train negative_sample_loss at step 45900: 0.109148
2023-03-16 17:54:31,376 INFO     Train loss at step 45900: 0.249120
2023-03-16 17:54:50,706 INFO     Train positive_sample_loss at step 46000: 0.390374
2023-03-16 17:54:50,706 INFO     Train negative_sample_loss at step 46000: 0.109734
2023-03-16 17:54:50,706 INFO     Train loss at step 46000: 0.250054
2023-03-16 17:55:10,038 INFO     Train positive_sample_loss at step 46100: 0.390489
2023-03-16 17:55:10,039 INFO     Train negative_sample_loss at step 46100: 0.109448
2023-03-16 17:55:10,039 INFO     Train loss at step 46100: 0.249968
2023-03-16 17:55:36,232 INFO     Train positive_sample_loss at step 46200: 0.390158
2023-03-16 17:55:36,232 INFO     Train negative_sample_loss at step 46200: 0.109782
2023-03-16 17:55:36,232 INFO     Train loss at step 46200: 0.249970
2023-03-16 17:55:55,564 INFO     Train positive_sample_loss at step 46300: 0.390986
2023-03-16 17:55:55,565 INFO     Train negative_sample_loss at step 46300: 0.109881
2023-03-16 17:55:55,565 INFO     Train loss at step 46300: 0.250434
2023-03-16 17:56:14,892 INFO     Train positive_sample_loss at step 46400: 0.390404
2023-03-16 17:56:14,892 INFO     Train negative_sample_loss at step 46400: 0.110506
2023-03-16 17:56:14,892 INFO     Train loss at step 46400: 0.250455
2023-03-16 17:56:34,218 INFO     Train positive_sample_loss at step 46500: 0.390130
2023-03-16 17:56:34,219 INFO     Train negative_sample_loss at step 46500: 0.110560
2023-03-16 17:56:34,219 INFO     Train loss at step 46500: 0.250345
2023-03-16 17:56:53,551 INFO     Train positive_sample_loss at step 46600: 0.388314
2023-03-16 17:56:53,552 INFO     Train negative_sample_loss at step 46600: 0.110809
2023-03-16 17:56:53,552 INFO     Train loss at step 46600: 0.249561
2023-03-16 17:57:12,883 INFO     Train positive_sample_loss at step 46700: 0.387682
2023-03-16 17:57:12,884 INFO     Train negative_sample_loss at step 46700: 0.111134
2023-03-16 17:57:12,884 INFO     Train loss at step 46700: 0.249408
2023-03-16 17:57:32,219 INFO     Train positive_sample_loss at step 46800: 0.387468
2023-03-16 17:57:32,220 INFO     Train negative_sample_loss at step 46800: 0.111643
2023-03-16 17:57:32,220 INFO     Train loss at step 46800: 0.249555
2023-03-16 17:57:51,552 INFO     Train positive_sample_loss at step 46900: 0.383892
2023-03-16 17:57:51,553 INFO     Train negative_sample_loss at step 46900: 0.111573
2023-03-16 17:57:51,553 INFO     Train loss at step 46900: 0.247732
2023-03-16 17:58:10,900 INFO     Train positive_sample_loss at step 47000: 0.383064
2023-03-16 17:58:10,901 INFO     Train negative_sample_loss at step 47000: 0.111301
2023-03-16 17:58:10,901 INFO     Train loss at step 47000: 0.247182
2023-03-16 17:58:30,234 INFO     Train positive_sample_loss at step 47100: 0.381452
2023-03-16 17:58:30,235 INFO     Train negative_sample_loss at step 47100: 0.111184
2023-03-16 17:58:30,235 INFO     Train loss at step 47100: 0.246318
2023-03-16 17:58:51,385 INFO     Train positive_sample_loss at step 47200: 0.381538
2023-03-16 17:58:51,385 INFO     Train negative_sample_loss at step 47200: 0.111661
2023-03-16 17:58:51,385 INFO     Train loss at step 47200: 0.246600
2023-03-16 17:59:14,600 INFO     Train positive_sample_loss at step 47300: 0.314384
2023-03-16 17:59:14,601 INFO     Train negative_sample_loss at step 47300: 0.108800
2023-03-16 17:59:14,601 INFO     Train loss at step 47300: 0.211592
2023-03-16 17:59:33,918 INFO     Train positive_sample_loss at step 47400: 0.312520
2023-03-16 17:59:33,919 INFO     Train negative_sample_loss at step 47400: 0.106900
2023-03-16 17:59:33,919 INFO     Train loss at step 47400: 0.209710
2023-03-16 17:59:53,237 INFO     Train positive_sample_loss at step 47500: 0.314977
2023-03-16 17:59:53,237 INFO     Train negative_sample_loss at step 47500: 0.105741
2023-03-16 17:59:53,237 INFO     Train loss at step 47500: 0.210359
2023-03-16 18:00:12,545 INFO     Train positive_sample_loss at step 47600: 0.321178
2023-03-16 18:00:12,546 INFO     Train negative_sample_loss at step 47600: 0.105396
2023-03-16 18:00:12,546 INFO     Train loss at step 47600: 0.213287
2023-03-16 18:00:31,850 INFO     Train positive_sample_loss at step 47700: 0.325313
2023-03-16 18:00:31,851 INFO     Train negative_sample_loss at step 47700: 0.104375
2023-03-16 18:00:31,851 INFO     Train loss at step 47700: 0.214844
2023-03-16 18:00:51,160 INFO     Train positive_sample_loss at step 47800: 0.329594
2023-03-16 18:00:51,160 INFO     Train negative_sample_loss at step 47800: 0.104067
2023-03-16 18:00:51,160 INFO     Train loss at step 47800: 0.216830
2023-03-16 18:01:10,475 INFO     Train positive_sample_loss at step 47900: 0.331831
2023-03-16 18:01:10,476 INFO     Train negative_sample_loss at step 47900: 0.104098
2023-03-16 18:01:10,476 INFO     Train loss at step 47900: 0.217965
2023-03-16 18:01:41,190 INFO     Train positive_sample_loss at step 48000: 0.337056
2023-03-16 18:01:41,191 INFO     Train negative_sample_loss at step 48000: 0.104327
2023-03-16 18:01:41,191 INFO     Train loss at step 48000: 0.220691
2023-03-16 18:02:00,513 INFO     Train positive_sample_loss at step 48100: 0.341470
2023-03-16 18:02:00,514 INFO     Train negative_sample_loss at step 48100: 0.104589
2023-03-16 18:02:00,514 INFO     Train loss at step 48100: 0.223030
2023-03-16 18:02:19,837 INFO     Train positive_sample_loss at step 48200: 0.348695
2023-03-16 18:02:19,838 INFO     Train negative_sample_loss at step 48200: 0.104841
2023-03-16 18:02:19,838 INFO     Train loss at step 48200: 0.226768
2023-03-16 18:02:39,160 INFO     Train positive_sample_loss at step 48300: 0.349884
2023-03-16 18:02:39,161 INFO     Train negative_sample_loss at step 48300: 0.104039
2023-03-16 18:02:39,161 INFO     Train loss at step 48300: 0.226962
2023-03-16 18:02:58,480 INFO     Train positive_sample_loss at step 48400: 0.352372
2023-03-16 18:02:58,481 INFO     Train negative_sample_loss at step 48400: 0.104580
2023-03-16 18:02:58,481 INFO     Train loss at step 48400: 0.228476
2023-03-16 18:03:17,808 INFO     Train positive_sample_loss at step 48500: 0.358334
2023-03-16 18:03:17,808 INFO     Train negative_sample_loss at step 48500: 0.104977
2023-03-16 18:03:17,808 INFO     Train loss at step 48500: 0.231656
2023-03-16 18:03:37,140 INFO     Train positive_sample_loss at step 48600: 0.360795
2023-03-16 18:03:37,141 INFO     Train negative_sample_loss at step 48600: 0.105437
2023-03-16 18:03:37,141 INFO     Train loss at step 48600: 0.233116
2023-03-16 18:03:56,467 INFO     Train positive_sample_loss at step 48700: 0.366811
2023-03-16 18:03:56,467 INFO     Train negative_sample_loss at step 48700: 0.105462
2023-03-16 18:03:56,467 INFO     Train loss at step 48700: 0.236137
2023-03-16 18:04:15,791 INFO     Train positive_sample_loss at step 48800: 0.368176
2023-03-16 18:04:15,791 INFO     Train negative_sample_loss at step 48800: 0.106627
2023-03-16 18:04:15,791 INFO     Train loss at step 48800: 0.237402
2023-03-16 18:04:35,112 INFO     Train positive_sample_loss at step 48900: 0.373586
2023-03-16 18:04:35,112 INFO     Train negative_sample_loss at step 48900: 0.106056
2023-03-16 18:04:35,112 INFO     Train loss at step 48900: 0.239821
2023-03-16 18:04:54,449 INFO     Train positive_sample_loss at step 49000: 0.377176
2023-03-16 18:04:54,450 INFO     Train negative_sample_loss at step 49000: 0.106202
2023-03-16 18:04:54,450 INFO     Train loss at step 49000: 0.241689
2023-03-16 18:05:20,606 INFO     Train positive_sample_loss at step 49100: 0.377110
2023-03-16 18:05:20,606 INFO     Train negative_sample_loss at step 49100: 0.106588
2023-03-16 18:05:20,606 INFO     Train loss at step 49100: 0.241849
2023-03-16 18:05:39,947 INFO     Train positive_sample_loss at step 49200: 0.379543
2023-03-16 18:05:39,947 INFO     Train negative_sample_loss at step 49200: 0.106876
2023-03-16 18:05:39,947 INFO     Train loss at step 49200: 0.243209
2023-03-16 18:05:59,276 INFO     Train positive_sample_loss at step 49300: 0.383807
2023-03-16 18:05:59,276 INFO     Train negative_sample_loss at step 49300: 0.107364
2023-03-16 18:05:59,276 INFO     Train loss at step 49300: 0.245585
2023-03-16 18:06:18,602 INFO     Train positive_sample_loss at step 49400: 0.384861
2023-03-16 18:06:18,603 INFO     Train negative_sample_loss at step 49400: 0.107544
2023-03-16 18:06:18,603 INFO     Train loss at step 49400: 0.246202
2023-03-16 18:06:37,933 INFO     Train positive_sample_loss at step 49500: 0.388181
2023-03-16 18:06:37,934 INFO     Train negative_sample_loss at step 49500: 0.108670
2023-03-16 18:06:37,934 INFO     Train loss at step 49500: 0.248426
2023-03-16 18:06:57,270 INFO     Train positive_sample_loss at step 49600: 0.390417
2023-03-16 18:06:57,270 INFO     Train negative_sample_loss at step 49600: 0.107883
2023-03-16 18:06:57,271 INFO     Train loss at step 49600: 0.249150
2023-03-16 18:07:16,609 INFO     Train positive_sample_loss at step 49700: 0.387826
2023-03-16 18:07:16,609 INFO     Train negative_sample_loss at step 49700: 0.108459
2023-03-16 18:07:16,609 INFO     Train loss at step 49700: 0.248143
2023-03-16 18:07:35,940 INFO     Train positive_sample_loss at step 49800: 0.391373
2023-03-16 18:07:35,940 INFO     Train negative_sample_loss at step 49800: 0.109130
2023-03-16 18:07:35,941 INFO     Train loss at step 49800: 0.250251
2023-03-16 18:07:55,265 INFO     Train positive_sample_loss at step 49900: 0.389573
2023-03-16 18:07:55,266 INFO     Train negative_sample_loss at step 49900: 0.109067
2023-03-16 18:07:55,266 INFO     Train loss at step 49900: 0.249320
2023-03-16 18:08:15,996 INFO     Train positive_sample_loss at step 50000: 0.391594
2023-03-16 18:08:15,996 INFO     Train negative_sample_loss at step 50000: 0.108840
2023-03-16 18:08:15,996 INFO     Train loss at step 50000: 0.250217
2023-03-16 18:08:15,997 INFO     Evaluating on Valid Dataset...
2023-03-16 18:08:17,032 INFO     Evaluating the model... (0/26842)
2023-03-16 18:08:18,572 INFO     Evaluating the model... (1000/26842)
2023-03-16 18:08:19,947 INFO     Evaluating the model... (2000/26842)
2023-03-16 18:08:21,174 INFO     Evaluating the model... (3000/26842)
2023-03-16 18:08:22,401 INFO     Evaluating the model... (4000/26842)
2023-03-16 18:08:23,628 INFO     Evaluating the model... (5000/26842)
2023-03-16 18:08:24,861 INFO     Evaluating the model... (6000/26842)
2023-03-16 18:08:26,087 INFO     Evaluating the model... (7000/26842)
2023-03-16 18:08:27,310 INFO     Evaluating the model... (8000/26842)
2023-03-16 18:08:28,538 INFO     Evaluating the model... (9000/26842)
2023-03-16 18:08:29,754 INFO     Evaluating the model... (10000/26842)
2023-03-16 18:08:30,981 INFO     Evaluating the model... (11000/26842)
2023-03-16 18:08:32,211 INFO     Evaluating the model... (12000/26842)
2023-03-16 18:08:33,428 INFO     Evaluating the model... (13000/26842)
2023-03-16 18:08:35,737 INFO     Evaluating the model... (14000/26842)
2023-03-16 18:08:37,223 INFO     Evaluating the model... (15000/26842)
2023-03-16 18:08:38,701 INFO     Evaluating the model... (16000/26842)
2023-03-16 18:08:40,178 INFO     Evaluating the model... (17000/26842)
2023-03-16 18:08:41,651 INFO     Evaluating the model... (18000/26842)
2023-03-16 18:08:43,127 INFO     Evaluating the model... (19000/26842)
2023-03-16 18:08:44,608 INFO     Evaluating the model... (20000/26842)
2023-03-16 18:08:46,096 INFO     Evaluating the model... (21000/26842)
2023-03-16 18:08:47,581 INFO     Evaluating the model... (22000/26842)
2023-03-16 18:08:49,062 INFO     Evaluating the model... (23000/26842)
2023-03-16 18:08:50,554 INFO     Evaluating the model... (24000/26842)
2023-03-16 18:08:52,040 INFO     Evaluating the model... (25000/26842)
2023-03-16 18:08:53,518 INFO     Evaluating the model... (26000/26842)
2023-03-16 18:08:55,066 INFO     Valid hits@1_list at step 50000: 0.585209
2023-03-16 18:08:55,066 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 18:08:55,067 INFO     Valid hits@3_list at step 50000: 0.675825
2023-03-16 18:08:55,067 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 18:08:55,067 INFO     Valid hits@10_list at step 50000: 0.761641
2023-03-16 18:08:55,067 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 18:08:55,067 INFO     Valid mrr_list at step 50000: 0.646960
2023-03-16 18:09:21,195 INFO     Train positive_sample_loss at step 50100: 0.393438
2023-03-16 18:09:21,195 INFO     Train negative_sample_loss at step 50100: 0.109331
2023-03-16 18:09:21,195 INFO     Train loss at step 50100: 0.251385
2023-03-16 18:09:40,543 INFO     Train positive_sample_loss at step 50200: 0.388812
2023-03-16 18:09:40,544 INFO     Train negative_sample_loss at step 50200: 0.109733
2023-03-16 18:09:40,544 INFO     Train loss at step 50200: 0.249273
2023-03-16 18:09:59,891 INFO     Train positive_sample_loss at step 50300: 0.389802
2023-03-16 18:09:59,892 INFO     Train negative_sample_loss at step 50300: 0.110045
2023-03-16 18:09:59,892 INFO     Train loss at step 50300: 0.249923
2023-03-16 18:10:19,242 INFO     Train positive_sample_loss at step 50400: 0.387769
2023-03-16 18:10:19,242 INFO     Train negative_sample_loss at step 50400: 0.110557
2023-03-16 18:10:19,242 INFO     Train loss at step 50400: 0.249163
2023-03-16 18:10:38,589 INFO     Train positive_sample_loss at step 50500: 0.390410
2023-03-16 18:10:38,589 INFO     Train negative_sample_loss at step 50500: 0.111135
2023-03-16 18:10:38,589 INFO     Train loss at step 50500: 0.250772
2023-03-16 18:10:57,932 INFO     Train positive_sample_loss at step 50600: 0.390489
2023-03-16 18:10:57,932 INFO     Train negative_sample_loss at step 50600: 0.111529
2023-03-16 18:10:57,932 INFO     Train loss at step 50600: 0.251009
2023-03-16 18:11:17,274 INFO     Train positive_sample_loss at step 50700: 0.388536
2023-03-16 18:11:17,275 INFO     Train negative_sample_loss at step 50700: 0.110030
2023-03-16 18:11:17,275 INFO     Train loss at step 50700: 0.249283
2023-03-16 18:11:36,628 INFO     Train positive_sample_loss at step 50800: 0.384988
2023-03-16 18:11:36,629 INFO     Train negative_sample_loss at step 50800: 0.111487
2023-03-16 18:11:36,629 INFO     Train loss at step 50800: 0.248238
2023-03-16 18:11:55,989 INFO     Train positive_sample_loss at step 50900: 0.382837
2023-03-16 18:11:55,989 INFO     Train negative_sample_loss at step 50900: 0.110653
2023-03-16 18:11:55,989 INFO     Train loss at step 50900: 0.246745
2023-03-16 18:12:15,346 INFO     Train positive_sample_loss at step 51000: 0.384090
2023-03-16 18:12:15,347 INFO     Train negative_sample_loss at step 51000: 0.111700
2023-03-16 18:12:15,347 INFO     Train loss at step 51000: 0.247895
2023-03-16 18:12:34,695 INFO     Train positive_sample_loss at step 51100: 0.380837
2023-03-16 18:12:34,696 INFO     Train negative_sample_loss at step 51100: 0.111526
2023-03-16 18:12:34,696 INFO     Train loss at step 51100: 0.246181
funtion time use:38897ms
2023-03-16 18:12:59,980 INFO     Train positive_sample_loss at step 51200: 0.337916
2023-03-16 18:12:59,981 INFO     Train negative_sample_loss at step 51200: 0.110093
2023-03-16 18:12:59,981 INFO     Train loss at step 51200: 0.224005
2023-03-16 18:13:19,299 INFO     Train positive_sample_loss at step 51300: 0.311035
2023-03-16 18:13:19,299 INFO     Train negative_sample_loss at step 51300: 0.106824
2023-03-16 18:13:19,299 INFO     Train loss at step 51300: 0.208930
2023-03-16 18:13:38,615 INFO     Train positive_sample_loss at step 51400: 0.316603
2023-03-16 18:13:38,616 INFO     Train negative_sample_loss at step 51400: 0.105500
2023-03-16 18:13:38,616 INFO     Train loss at step 51400: 0.211051
2023-03-16 18:13:57,938 INFO     Train positive_sample_loss at step 51500: 0.320679
2023-03-16 18:13:57,938 INFO     Train negative_sample_loss at step 51500: 0.105541
2023-03-16 18:13:57,938 INFO     Train loss at step 51500: 0.213110
2023-03-16 18:14:17,255 INFO     Train positive_sample_loss at step 51600: 0.323669
2023-03-16 18:14:17,255 INFO     Train negative_sample_loss at step 51600: 0.103538
2023-03-16 18:14:17,255 INFO     Train loss at step 51600: 0.213604
2023-03-16 18:14:36,573 INFO     Train positive_sample_loss at step 51700: 0.327196
2023-03-16 18:14:36,573 INFO     Train negative_sample_loss at step 51700: 0.103757
2023-03-16 18:14:36,573 INFO     Train loss at step 51700: 0.215476
2023-03-16 18:14:55,895 INFO     Train positive_sample_loss at step 51800: 0.330626
2023-03-16 18:14:55,896 INFO     Train negative_sample_loss at step 51800: 0.103663
2023-03-16 18:14:55,896 INFO     Train loss at step 51800: 0.217145
2023-03-16 18:15:22,522 INFO     Train positive_sample_loss at step 51900: 0.335246
2023-03-16 18:15:22,523 INFO     Train negative_sample_loss at step 51900: 0.104058
2023-03-16 18:15:22,523 INFO     Train loss at step 51900: 0.219652
2023-03-16 18:15:41,842 INFO     Train positive_sample_loss at step 52000: 0.339637
2023-03-16 18:15:41,843 INFO     Train negative_sample_loss at step 52000: 0.103920
2023-03-16 18:15:41,843 INFO     Train loss at step 52000: 0.221779
2023-03-16 18:16:01,158 INFO     Train positive_sample_loss at step 52100: 0.346213
2023-03-16 18:16:01,159 INFO     Train negative_sample_loss at step 52100: 0.103708
2023-03-16 18:16:01,159 INFO     Train loss at step 52100: 0.224960
2023-03-16 18:16:20,474 INFO     Train positive_sample_loss at step 52200: 0.349551
2023-03-16 18:16:20,475 INFO     Train negative_sample_loss at step 52200: 0.104226
2023-03-16 18:16:20,475 INFO     Train loss at step 52200: 0.226888
2023-03-16 18:16:39,797 INFO     Train positive_sample_loss at step 52300: 0.351944
2023-03-16 18:16:39,797 INFO     Train negative_sample_loss at step 52300: 0.104513
2023-03-16 18:16:39,798 INFO     Train loss at step 52300: 0.228229
2023-03-16 18:16:59,138 INFO     Train positive_sample_loss at step 52400: 0.356716
2023-03-16 18:16:59,139 INFO     Train negative_sample_loss at step 52400: 0.104610
2023-03-16 18:16:59,139 INFO     Train loss at step 52400: 0.230663
2023-03-16 18:17:18,462 INFO     Train positive_sample_loss at step 52500: 0.359991
2023-03-16 18:17:18,463 INFO     Train negative_sample_loss at step 52500: 0.104804
2023-03-16 18:17:18,463 INFO     Train loss at step 52500: 0.232397
2023-03-16 18:17:37,787 INFO     Train positive_sample_loss at step 52600: 0.364277
2023-03-16 18:17:37,788 INFO     Train negative_sample_loss at step 52600: 0.105311
2023-03-16 18:17:37,788 INFO     Train loss at step 52600: 0.234794
2023-03-16 18:17:57,107 INFO     Train positive_sample_loss at step 52700: 0.367661
2023-03-16 18:17:57,108 INFO     Train negative_sample_loss at step 52700: 0.105563
2023-03-16 18:17:57,108 INFO     Train loss at step 52700: 0.236612
2023-03-16 18:18:16,441 INFO     Train positive_sample_loss at step 52800: 0.370524
2023-03-16 18:18:16,441 INFO     Train negative_sample_loss at step 52800: 0.105335
2023-03-16 18:18:16,442 INFO     Train loss at step 52800: 0.237929
2023-03-16 18:18:35,772 INFO     Train positive_sample_loss at step 52900: 0.374141
2023-03-16 18:18:35,773 INFO     Train negative_sample_loss at step 52900: 0.106010
2023-03-16 18:18:35,773 INFO     Train loss at step 52900: 0.240076
2023-03-16 18:19:02,146 INFO     Train positive_sample_loss at step 53000: 0.376325
2023-03-16 18:19:02,147 INFO     Train negative_sample_loss at step 53000: 0.106129
2023-03-16 18:19:02,147 INFO     Train loss at step 53000: 0.241227
2023-03-16 18:19:21,476 INFO     Train positive_sample_loss at step 53100: 0.380348
2023-03-16 18:19:21,477 INFO     Train negative_sample_loss at step 53100: 0.106250
2023-03-16 18:19:21,477 INFO     Train loss at step 53100: 0.243299
2023-03-16 18:19:40,799 INFO     Train positive_sample_loss at step 53200: 0.381863
2023-03-16 18:19:40,800 INFO     Train negative_sample_loss at step 53200: 0.106881
2023-03-16 18:19:40,800 INFO     Train loss at step 53200: 0.244372
2023-03-16 18:20:00,135 INFO     Train positive_sample_loss at step 53300: 0.383924
2023-03-16 18:20:00,136 INFO     Train negative_sample_loss at step 53300: 0.107398
2023-03-16 18:20:00,136 INFO     Train loss at step 53300: 0.245661
2023-03-16 18:20:19,464 INFO     Train positive_sample_loss at step 53400: 0.385087
2023-03-16 18:20:19,464 INFO     Train negative_sample_loss at step 53400: 0.107314
2023-03-16 18:20:19,464 INFO     Train loss at step 53400: 0.246200
2023-03-16 18:20:38,806 INFO     Train positive_sample_loss at step 53500: 0.387473
2023-03-16 18:20:38,806 INFO     Train negative_sample_loss at step 53500: 0.107607
2023-03-16 18:20:38,806 INFO     Train loss at step 53500: 0.247540
2023-03-16 18:20:58,135 INFO     Train positive_sample_loss at step 53600: 0.388183
2023-03-16 18:20:58,135 INFO     Train negative_sample_loss at step 53600: 0.108349
2023-03-16 18:20:58,135 INFO     Train loss at step 53600: 0.248266
2023-03-16 18:21:17,464 INFO     Train positive_sample_loss at step 53700: 0.389543
2023-03-16 18:21:17,464 INFO     Train negative_sample_loss at step 53700: 0.108883
2023-03-16 18:21:17,464 INFO     Train loss at step 53700: 0.249213
2023-03-16 18:21:36,797 INFO     Train positive_sample_loss at step 53800: 0.388713
2023-03-16 18:21:36,797 INFO     Train negative_sample_loss at step 53800: 0.109315
2023-03-16 18:21:36,797 INFO     Train loss at step 53800: 0.249014
2023-03-16 18:21:56,136 INFO     Train positive_sample_loss at step 53900: 0.388318
2023-03-16 18:21:56,137 INFO     Train negative_sample_loss at step 53900: 0.108981
2023-03-16 18:21:56,137 INFO     Train loss at step 53900: 0.248649
2023-03-16 18:22:22,275 INFO     Train positive_sample_loss at step 54000: 0.390934
2023-03-16 18:22:22,275 INFO     Train negative_sample_loss at step 54000: 0.108945
2023-03-16 18:22:22,276 INFO     Train loss at step 54000: 0.249940
2023-03-16 18:22:41,601 INFO     Train positive_sample_loss at step 54100: 0.391134
2023-03-16 18:22:41,602 INFO     Train negative_sample_loss at step 54100: 0.109258
2023-03-16 18:22:41,602 INFO     Train loss at step 54100: 0.250196
2023-03-16 18:23:00,935 INFO     Train positive_sample_loss at step 54200: 0.391866
2023-03-16 18:23:00,936 INFO     Train negative_sample_loss at step 54200: 0.110046
2023-03-16 18:23:00,936 INFO     Train loss at step 54200: 0.250956
2023-03-16 18:23:20,265 INFO     Train positive_sample_loss at step 54300: 0.388900
2023-03-16 18:23:20,265 INFO     Train negative_sample_loss at step 54300: 0.110337
2023-03-16 18:23:20,265 INFO     Train loss at step 54300: 0.249618
2023-03-16 18:23:39,595 INFO     Train positive_sample_loss at step 54400: 0.387845
2023-03-16 18:23:39,595 INFO     Train negative_sample_loss at step 54400: 0.109354
2023-03-16 18:23:39,596 INFO     Train loss at step 54400: 0.248600
2023-03-16 18:23:58,929 INFO     Train positive_sample_loss at step 54500: 0.389835
2023-03-16 18:23:58,930 INFO     Train negative_sample_loss at step 54500: 0.110625
2023-03-16 18:23:58,930 INFO     Train loss at step 54500: 0.250230
2023-03-16 18:24:18,255 INFO     Train positive_sample_loss at step 54600: 0.389050
2023-03-16 18:24:18,255 INFO     Train negative_sample_loss at step 54600: 0.110581
2023-03-16 18:24:18,255 INFO     Train loss at step 54600: 0.249815
2023-03-16 18:24:37,581 INFO     Train positive_sample_loss at step 54700: 0.385772
2023-03-16 18:24:37,581 INFO     Train negative_sample_loss at step 54700: 0.110242
2023-03-16 18:24:37,581 INFO     Train loss at step 54700: 0.248007
2023-03-16 18:24:56,912 INFO     Train positive_sample_loss at step 54800: 0.385732
2023-03-16 18:24:56,913 INFO     Train negative_sample_loss at step 54800: 0.110530
2023-03-16 18:24:56,913 INFO     Train loss at step 54800: 0.248131
2023-03-16 18:25:16,255 INFO     Train positive_sample_loss at step 54900: 0.383288
2023-03-16 18:25:16,255 INFO     Train negative_sample_loss at step 54900: 0.110791
2023-03-16 18:25:16,255 INFO     Train loss at step 54900: 0.247039
2023-03-16 18:25:35,593 INFO     Train positive_sample_loss at step 55000: 0.380929
2023-03-16 18:25:35,593 INFO     Train negative_sample_loss at step 55000: 0.110563
2023-03-16 18:25:35,593 INFO     Train loss at step 55000: 0.245746
2023-03-16 18:26:07,612 INFO     Train positive_sample_loss at step 55100: 0.361116
2023-03-16 18:26:07,612 INFO     Train negative_sample_loss at step 55100: 0.110025
2023-03-16 18:26:07,612 INFO     Train loss at step 55100: 0.235571
2023-03-16 18:26:26,945 INFO     Train positive_sample_loss at step 55200: 0.310541
2023-03-16 18:26:26,945 INFO     Train negative_sample_loss at step 55200: 0.107991
2023-03-16 18:26:26,945 INFO     Train loss at step 55200: 0.209266
2023-03-16 18:26:46,264 INFO     Train positive_sample_loss at step 55300: 0.312957
2023-03-16 18:26:46,265 INFO     Train negative_sample_loss at step 55300: 0.105755
2023-03-16 18:26:46,265 INFO     Train loss at step 55300: 0.209356
2023-03-16 18:27:05,592 INFO     Train positive_sample_loss at step 55400: 0.317772
2023-03-16 18:27:05,593 INFO     Train negative_sample_loss at step 55400: 0.104788
2023-03-16 18:27:05,593 INFO     Train loss at step 55400: 0.211280
2023-03-16 18:27:24,906 INFO     Train positive_sample_loss at step 55500: 0.320527
2023-03-16 18:27:24,906 INFO     Train negative_sample_loss at step 55500: 0.103852
2023-03-16 18:27:24,906 INFO     Train loss at step 55500: 0.212189
2023-03-16 18:27:44,205 INFO     Train positive_sample_loss at step 55600: 0.324193
2023-03-16 18:27:44,206 INFO     Train negative_sample_loss at step 55600: 0.104490
2023-03-16 18:27:44,206 INFO     Train loss at step 55600: 0.214342
2023-03-16 18:28:03,524 INFO     Train positive_sample_loss at step 55700: 0.329363
2023-03-16 18:28:03,524 INFO     Train negative_sample_loss at step 55700: 0.103884
2023-03-16 18:28:03,525 INFO     Train loss at step 55700: 0.216624
2023-03-16 18:28:30,132 INFO     Train positive_sample_loss at step 55800: 0.333715
2023-03-16 18:28:30,133 INFO     Train negative_sample_loss at step 55800: 0.103864
2023-03-16 18:28:30,133 INFO     Train loss at step 55800: 0.218790
2023-03-16 18:28:49,451 INFO     Train positive_sample_loss at step 55900: 0.337552
2023-03-16 18:28:49,452 INFO     Train negative_sample_loss at step 55900: 0.103959
2023-03-16 18:28:49,452 INFO     Train loss at step 55900: 0.220756
2023-03-16 18:29:08,762 INFO     Train positive_sample_loss at step 56000: 0.343412
2023-03-16 18:29:08,762 INFO     Train negative_sample_loss at step 56000: 0.104203
2023-03-16 18:29:08,762 INFO     Train loss at step 56000: 0.223807
2023-03-16 18:29:28,074 INFO     Train positive_sample_loss at step 56100: 0.348310
2023-03-16 18:29:28,075 INFO     Train negative_sample_loss at step 56100: 0.104180
2023-03-16 18:29:28,075 INFO     Train loss at step 56100: 0.226245
2023-03-16 18:29:47,384 INFO     Train positive_sample_loss at step 56200: 0.352284
2023-03-16 18:29:47,384 INFO     Train negative_sample_loss at step 56200: 0.104628
2023-03-16 18:29:47,384 INFO     Train loss at step 56200: 0.228456
2023-03-16 18:30:06,712 INFO     Train positive_sample_loss at step 56300: 0.356812
2023-03-16 18:30:06,713 INFO     Train negative_sample_loss at step 56300: 0.104304
2023-03-16 18:30:06,713 INFO     Train loss at step 56300: 0.230558
2023-03-16 18:30:26,036 INFO     Train positive_sample_loss at step 56400: 0.360326
2023-03-16 18:30:26,036 INFO     Train negative_sample_loss at step 56400: 0.104899
2023-03-16 18:30:26,036 INFO     Train loss at step 56400: 0.232612
2023-03-16 18:30:45,356 INFO     Train positive_sample_loss at step 56500: 0.364429
2023-03-16 18:30:45,356 INFO     Train negative_sample_loss at step 56500: 0.105331
2023-03-16 18:30:45,356 INFO     Train loss at step 56500: 0.234880
2023-03-16 18:31:04,674 INFO     Train positive_sample_loss at step 56600: 0.368335
2023-03-16 18:31:04,674 INFO     Train negative_sample_loss at step 56600: 0.105374
2023-03-16 18:31:04,674 INFO     Train loss at step 56600: 0.236854
2023-03-16 18:31:23,995 INFO     Train positive_sample_loss at step 56700: 0.370410
2023-03-16 18:31:23,995 INFO     Train negative_sample_loss at step 56700: 0.104921
2023-03-16 18:31:23,995 INFO     Train loss at step 56700: 0.237665
2023-03-16 18:31:43,321 INFO     Train positive_sample_loss at step 56800: 0.373710
2023-03-16 18:31:43,322 INFO     Train negative_sample_loss at step 56800: 0.105514
2023-03-16 18:31:43,322 INFO     Train loss at step 56800: 0.239612
2023-03-16 18:32:09,650 INFO     Train positive_sample_loss at step 56900: 0.376659
2023-03-16 18:32:09,651 INFO     Train negative_sample_loss at step 56900: 0.105903
2023-03-16 18:32:09,651 INFO     Train loss at step 56900: 0.241281
2023-03-16 18:32:28,978 INFO     Train positive_sample_loss at step 57000: 0.378433
2023-03-16 18:32:28,979 INFO     Train negative_sample_loss at step 57000: 0.106586
2023-03-16 18:32:28,979 INFO     Train loss at step 57000: 0.242509
2023-03-16 18:32:48,302 INFO     Train positive_sample_loss at step 57100: 0.381932
2023-03-16 18:32:48,303 INFO     Train negative_sample_loss at step 57100: 0.106708
2023-03-16 18:32:48,303 INFO     Train loss at step 57100: 0.244320
2023-03-16 18:33:07,622 INFO     Train positive_sample_loss at step 57200: 0.383876
2023-03-16 18:33:07,623 INFO     Train negative_sample_loss at step 57200: 0.106626
2023-03-16 18:33:07,623 INFO     Train loss at step 57200: 0.245251
2023-03-16 18:33:26,953 INFO     Train positive_sample_loss at step 57300: 0.386531
2023-03-16 18:33:26,953 INFO     Train negative_sample_loss at step 57300: 0.107953
2023-03-16 18:33:26,954 INFO     Train loss at step 57300: 0.247242
2023-03-16 18:33:46,278 INFO     Train positive_sample_loss at step 57400: 0.388286
2023-03-16 18:33:46,278 INFO     Train negative_sample_loss at step 57400: 0.107795
2023-03-16 18:33:46,278 INFO     Train loss at step 57400: 0.248040
2023-03-16 18:34:05,607 INFO     Train positive_sample_loss at step 57500: 0.390543
2023-03-16 18:34:05,608 INFO     Train negative_sample_loss at step 57500: 0.107530
2023-03-16 18:34:05,608 INFO     Train loss at step 57500: 0.249037
2023-03-16 18:34:24,929 INFO     Train positive_sample_loss at step 57600: 0.388328
2023-03-16 18:34:24,929 INFO     Train negative_sample_loss at step 57600: 0.108559
2023-03-16 18:34:24,929 INFO     Train loss at step 57600: 0.248443
2023-03-16 18:34:44,249 INFO     Train positive_sample_loss at step 57700: 0.389137
2023-03-16 18:34:44,250 INFO     Train negative_sample_loss at step 57700: 0.108277
2023-03-16 18:34:44,250 INFO     Train loss at step 57700: 0.248707
2023-03-16 18:35:03,587 INFO     Train positive_sample_loss at step 57800: 0.390603
2023-03-16 18:35:03,588 INFO     Train negative_sample_loss at step 57800: 0.108266
2023-03-16 18:35:03,588 INFO     Train loss at step 57800: 0.249435
2023-03-16 18:35:22,913 INFO     Train positive_sample_loss at step 57900: 0.390046
2023-03-16 18:35:22,914 INFO     Train negative_sample_loss at step 57900: 0.108547
2023-03-16 18:35:22,914 INFO     Train loss at step 57900: 0.249297
2023-03-16 18:35:51,695 INFO     Train positive_sample_loss at step 58000: 0.389890
2023-03-16 18:35:51,696 INFO     Train negative_sample_loss at step 58000: 0.108832
2023-03-16 18:35:51,696 INFO     Train loss at step 58000: 0.249361
2023-03-16 18:36:11,021 INFO     Train positive_sample_loss at step 58100: 0.387017
2023-03-16 18:36:11,021 INFO     Train negative_sample_loss at step 58100: 0.109413
2023-03-16 18:36:11,021 INFO     Train loss at step 58100: 0.248215
2023-03-16 18:36:30,345 INFO     Train positive_sample_loss at step 58200: 0.388247
2023-03-16 18:36:30,346 INFO     Train negative_sample_loss at step 58200: 0.109460
2023-03-16 18:36:30,346 INFO     Train loss at step 58200: 0.248853
2023-03-16 18:36:49,668 INFO     Train positive_sample_loss at step 58300: 0.387602
2023-03-16 18:36:49,668 INFO     Train negative_sample_loss at step 58300: 0.110028
2023-03-16 18:36:49,668 INFO     Train loss at step 58300: 0.248815
2023-03-16 18:37:08,990 INFO     Train positive_sample_loss at step 58400: 0.386746
2023-03-16 18:37:08,990 INFO     Train negative_sample_loss at step 58400: 0.109741
2023-03-16 18:37:08,991 INFO     Train loss at step 58400: 0.248244
2023-03-16 18:37:28,323 INFO     Train positive_sample_loss at step 58500: 0.385293
2023-03-16 18:37:28,323 INFO     Train negative_sample_loss at step 58500: 0.109973
2023-03-16 18:37:28,323 INFO     Train loss at step 58500: 0.247633
2023-03-16 18:37:47,649 INFO     Train positive_sample_loss at step 58600: 0.386355
2023-03-16 18:37:47,649 INFO     Train negative_sample_loss at step 58600: 0.110075
2023-03-16 18:37:47,649 INFO     Train loss at step 58600: 0.248215
2023-03-16 18:38:06,974 INFO     Train positive_sample_loss at step 58700: 0.383363
2023-03-16 18:38:06,975 INFO     Train negative_sample_loss at step 58700: 0.110537
2023-03-16 18:38:06,975 INFO     Train loss at step 58700: 0.246950
2023-03-16 18:38:26,305 INFO     Train positive_sample_loss at step 58800: 0.383889
2023-03-16 18:38:26,305 INFO     Train negative_sample_loss at step 58800: 0.110676
2023-03-16 18:38:26,305 INFO     Train loss at step 58800: 0.247282
2023-03-16 18:38:45,638 INFO     Train positive_sample_loss at step 58900: 0.381328
2023-03-16 18:38:45,639 INFO     Train negative_sample_loss at step 58900: 0.110783
2023-03-16 18:38:45,639 INFO     Train loss at step 58900: 0.246056
2023-03-16 18:39:13,732 INFO     Train positive_sample_loss at step 59000: 0.380085
2023-03-16 18:39:13,732 INFO     Train negative_sample_loss at step 59000: 0.110213
2023-03-16 18:39:13,733 INFO     Train loss at step 59000: 0.245149
2023-03-16 18:39:37,122 INFO     Train positive_sample_loss at step 59100: 0.316586
2023-03-16 18:39:37,123 INFO     Train negative_sample_loss at step 59100: 0.108651
2023-03-16 18:39:37,123 INFO     Train loss at step 59100: 0.212619
2023-03-16 18:39:56,437 INFO     Train positive_sample_loss at step 59200: 0.312405
2023-03-16 18:39:56,437 INFO     Train negative_sample_loss at step 59200: 0.106171
2023-03-16 18:39:56,437 INFO     Train loss at step 59200: 0.209288
2023-03-16 18:40:15,755 INFO     Train positive_sample_loss at step 59300: 0.315716
2023-03-16 18:40:15,756 INFO     Train negative_sample_loss at step 59300: 0.104360
2023-03-16 18:40:15,756 INFO     Train loss at step 59300: 0.210038
2023-03-16 18:40:35,074 INFO     Train positive_sample_loss at step 59400: 0.321712
2023-03-16 18:40:35,075 INFO     Train negative_sample_loss at step 59400: 0.104210
2023-03-16 18:40:35,075 INFO     Train loss at step 59400: 0.212961
2023-03-16 18:40:54,379 INFO     Train positive_sample_loss at step 59500: 0.323967
2023-03-16 18:40:54,379 INFO     Train negative_sample_loss at step 59500: 0.104093
2023-03-16 18:40:54,380 INFO     Train loss at step 59500: 0.214030
2023-03-16 18:41:13,685 INFO     Train positive_sample_loss at step 59600: 0.326664
2023-03-16 18:41:13,685 INFO     Train negative_sample_loss at step 59600: 0.103576
2023-03-16 18:41:13,685 INFO     Train loss at step 59600: 0.215120
2023-03-16 18:41:32,998 INFO     Train positive_sample_loss at step 59700: 0.334351
2023-03-16 18:41:32,998 INFO     Train negative_sample_loss at step 59700: 0.102964
2023-03-16 18:41:32,998 INFO     Train loss at step 59700: 0.218657
2023-03-16 18:41:59,660 INFO     Train positive_sample_loss at step 59800: 0.334795
2023-03-16 18:41:59,660 INFO     Train negative_sample_loss at step 59800: 0.103251
2023-03-16 18:41:59,660 INFO     Train loss at step 59800: 0.219023
2023-03-16 18:42:18,984 INFO     Train positive_sample_loss at step 59900: 0.342064
2023-03-16 18:42:18,984 INFO     Train negative_sample_loss at step 59900: 0.103971
2023-03-16 18:42:18,984 INFO     Train loss at step 59900: 0.223017
2023-03-16 18:42:39,782 INFO     Train positive_sample_loss at step 60000: 0.346733
2023-03-16 18:42:39,782 INFO     Train negative_sample_loss at step 60000: 0.103138
2023-03-16 18:42:39,782 INFO     Train loss at step 60000: 0.224936
2023-03-16 18:42:39,782 INFO     Evaluating on Valid Dataset...
2023-03-16 18:42:40,792 INFO     Evaluating the model... (0/26842)
2023-03-16 18:42:42,184 INFO     Evaluating the model... (1000/26842)
2023-03-16 18:42:43,408 INFO     Evaluating the model... (2000/26842)
2023-03-16 18:42:44,632 INFO     Evaluating the model... (3000/26842)
2023-03-16 18:42:45,851 INFO     Evaluating the model... (4000/26842)
2023-03-16 18:42:47,065 INFO     Evaluating the model... (5000/26842)
2023-03-16 18:42:48,284 INFO     Evaluating the model... (6000/26842)
2023-03-16 18:42:49,512 INFO     Evaluating the model... (7000/26842)
2023-03-16 18:42:50,733 INFO     Evaluating the model... (8000/26842)
2023-03-16 18:42:51,956 INFO     Evaluating the model... (9000/26842)
2023-03-16 18:42:53,186 INFO     Evaluating the model... (10000/26842)
2023-03-16 18:42:54,424 INFO     Evaluating the model... (11000/26842)
2023-03-16 18:42:55,653 INFO     Evaluating the model... (12000/26842)
2023-03-16 18:42:56,875 INFO     Evaluating the model... (13000/26842)
2023-03-16 18:42:59,135 INFO     Evaluating the model... (14000/26842)
2023-03-16 18:43:00,606 INFO     Evaluating the model... (15000/26842)
2023-03-16 18:43:02,073 INFO     Evaluating the model... (16000/26842)
2023-03-16 18:43:03,540 INFO     Evaluating the model... (17000/26842)
2023-03-16 18:43:05,008 INFO     Evaluating the model... (18000/26842)
2023-03-16 18:43:06,479 INFO     Evaluating the model... (19000/26842)
2023-03-16 18:43:07,964 INFO     Evaluating the model... (20000/26842)
2023-03-16 18:43:09,435 INFO     Evaluating the model... (21000/26842)
2023-03-16 18:43:10,900 INFO     Evaluating the model... (22000/26842)
2023-03-16 18:43:12,371 INFO     Evaluating the model... (23000/26842)
2023-03-16 18:43:13,836 INFO     Evaluating the model... (24000/26842)
2023-03-16 18:43:15,292 INFO     Evaluating the model... (25000/26842)
2023-03-16 18:43:16,754 INFO     Evaluating the model... (26000/26842)
2023-03-16 18:43:18,300 INFO     Valid hits@1_list at step 60000: 0.586740
2023-03-16 18:43:18,300 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 18:43:18,300 INFO     Valid hits@3_list at step 60000: 0.677676
2023-03-16 18:43:18,300 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 18:43:18,300 INFO     Valid hits@10_list at step 60000: 0.763773
2023-03-16 18:43:18,300 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 18:43:18,300 INFO     Valid mrr_list at step 60000: 0.648614
2023-03-16 18:43:37,649 INFO     Train positive_sample_loss at step 60100: 0.349418
2023-03-16 18:43:37,650 INFO     Train negative_sample_loss at step 60100: 0.104366
2023-03-16 18:43:37,650 INFO     Train loss at step 60100: 0.226892
2023-03-16 18:43:56,996 INFO     Train positive_sample_loss at step 60200: 0.355167
2023-03-16 18:43:56,997 INFO     Train negative_sample_loss at step 60200: 0.104051
2023-03-16 18:43:56,997 INFO     Train loss at step 60200: 0.229609
2023-03-16 18:44:16,340 INFO     Train positive_sample_loss at step 60300: 0.358228
2023-03-16 18:44:16,340 INFO     Train negative_sample_loss at step 60300: 0.104868
2023-03-16 18:44:16,340 INFO     Train loss at step 60300: 0.231548
2023-03-16 18:44:35,687 INFO     Train positive_sample_loss at step 60400: 0.363599
2023-03-16 18:44:35,688 INFO     Train negative_sample_loss at step 60400: 0.105123
2023-03-16 18:44:35,688 INFO     Train loss at step 60400: 0.234361
2023-03-16 18:44:55,029 INFO     Train positive_sample_loss at step 60500: 0.366536
2023-03-16 18:44:55,029 INFO     Train negative_sample_loss at step 60500: 0.104627
2023-03-16 18:44:55,029 INFO     Train loss at step 60500: 0.235582
2023-03-16 18:45:14,372 INFO     Train positive_sample_loss at step 60600: 0.369301
2023-03-16 18:45:14,373 INFO     Train negative_sample_loss at step 60600: 0.104928
2023-03-16 18:45:14,373 INFO     Train loss at step 60600: 0.237115
2023-03-16 18:45:33,727 INFO     Train positive_sample_loss at step 60700: 0.374446
2023-03-16 18:45:33,727 INFO     Train negative_sample_loss at step 60700: 0.105114
2023-03-16 18:45:33,728 INFO     Train loss at step 60700: 0.239780
2023-03-16 18:45:59,914 INFO     Train positive_sample_loss at step 60800: 0.376825
2023-03-16 18:45:59,914 INFO     Train negative_sample_loss at step 60800: 0.105651
2023-03-16 18:45:59,914 INFO     Train loss at step 60800: 0.241238
2023-03-16 18:46:19,253 INFO     Train positive_sample_loss at step 60900: 0.377767
2023-03-16 18:46:19,254 INFO     Train negative_sample_loss at step 60900: 0.106121
2023-03-16 18:46:19,254 INFO     Train loss at step 60900: 0.241944
2023-03-16 18:46:38,594 INFO     Train positive_sample_loss at step 61000: 0.381932
2023-03-16 18:46:38,595 INFO     Train negative_sample_loss at step 61000: 0.106334
2023-03-16 18:46:38,595 INFO     Train loss at step 61000: 0.244133
2023-03-16 18:46:57,939 INFO     Train positive_sample_loss at step 61100: 0.381557
2023-03-16 18:46:57,940 INFO     Train negative_sample_loss at step 61100: 0.106326
2023-03-16 18:46:57,940 INFO     Train loss at step 61100: 0.243941
2023-03-16 18:47:17,292 INFO     Train positive_sample_loss at step 61200: 0.384985
2023-03-16 18:47:17,293 INFO     Train negative_sample_loss at step 61200: 0.107347
2023-03-16 18:47:17,293 INFO     Train loss at step 61200: 0.246166
2023-03-16 18:47:36,640 INFO     Train positive_sample_loss at step 61300: 0.385982
2023-03-16 18:47:36,640 INFO     Train negative_sample_loss at step 61300: 0.106602
2023-03-16 18:47:36,641 INFO     Train loss at step 61300: 0.246292
2023-03-16 18:47:55,978 INFO     Train positive_sample_loss at step 61400: 0.387561
2023-03-16 18:47:55,978 INFO     Train negative_sample_loss at step 61400: 0.107067
2023-03-16 18:47:55,978 INFO     Train loss at step 61400: 0.247314
2023-03-16 18:48:15,326 INFO     Train positive_sample_loss at step 61500: 0.387243
2023-03-16 18:48:15,327 INFO     Train negative_sample_loss at step 61500: 0.107980
2023-03-16 18:48:15,327 INFO     Train loss at step 61500: 0.247612
2023-03-16 18:48:34,671 INFO     Train positive_sample_loss at step 61600: 0.388462
2023-03-16 18:48:34,671 INFO     Train negative_sample_loss at step 61600: 0.108083
2023-03-16 18:48:34,672 INFO     Train loss at step 61600: 0.248272
2023-03-16 18:48:54,015 INFO     Train positive_sample_loss at step 61700: 0.389794
2023-03-16 18:48:54,016 INFO     Train negative_sample_loss at step 61700: 0.108848
2023-03-16 18:48:54,016 INFO     Train loss at step 61700: 0.249321
2023-03-16 18:49:13,352 INFO     Train positive_sample_loss at step 61800: 0.391347
2023-03-16 18:49:13,352 INFO     Train negative_sample_loss at step 61800: 0.108894
2023-03-16 18:49:13,352 INFO     Train loss at step 61800: 0.250121
2023-03-16 18:49:42,518 INFO     Train positive_sample_loss at step 61900: 0.389381
2023-03-16 18:49:42,518 INFO     Train negative_sample_loss at step 61900: 0.108495
2023-03-16 18:49:42,518 INFO     Train loss at step 61900: 0.248938
2023-03-16 18:50:01,861 INFO     Train positive_sample_loss at step 62000: 0.390132
2023-03-16 18:50:01,861 INFO     Train negative_sample_loss at step 62000: 0.108877
2023-03-16 18:50:01,861 INFO     Train loss at step 62000: 0.249505
2023-03-16 18:50:21,197 INFO     Train positive_sample_loss at step 62100: 0.389971
2023-03-16 18:50:21,197 INFO     Train negative_sample_loss at step 62100: 0.109887
2023-03-16 18:50:21,197 INFO     Train loss at step 62100: 0.249929
2023-03-16 18:50:40,531 INFO     Train positive_sample_loss at step 62200: 0.388972
2023-03-16 18:50:40,532 INFO     Train negative_sample_loss at step 62200: 0.110214
2023-03-16 18:50:40,532 INFO     Train loss at step 62200: 0.249593
2023-03-16 18:50:59,877 INFO     Train positive_sample_loss at step 62300: 0.389692
2023-03-16 18:50:59,878 INFO     Train negative_sample_loss at step 62300: 0.109588
2023-03-16 18:50:59,878 INFO     Train loss at step 62300: 0.249640
2023-03-16 18:51:19,212 INFO     Train positive_sample_loss at step 62400: 0.387597
2023-03-16 18:51:19,213 INFO     Train negative_sample_loss at step 62400: 0.109882
2023-03-16 18:51:19,213 INFO     Train loss at step 62400: 0.248740
2023-03-16 18:51:38,548 INFO     Train positive_sample_loss at step 62500: 0.384611
2023-03-16 18:51:38,549 INFO     Train negative_sample_loss at step 62500: 0.110183
2023-03-16 18:51:38,549 INFO     Train loss at step 62500: 0.247397
2023-03-16 18:51:57,897 INFO     Train positive_sample_loss at step 62600: 0.385749
2023-03-16 18:51:57,897 INFO     Train negative_sample_loss at step 62600: 0.110578
2023-03-16 18:51:57,897 INFO     Train loss at step 62600: 0.248163
2023-03-16 18:52:17,244 INFO     Train positive_sample_loss at step 62700: 0.384383
2023-03-16 18:52:17,244 INFO     Train negative_sample_loss at step 62700: 0.110228
2023-03-16 18:52:17,244 INFO     Train loss at step 62700: 0.247306
2023-03-16 18:52:36,588 INFO     Train positive_sample_loss at step 62800: 0.384234
2023-03-16 18:52:36,589 INFO     Train negative_sample_loss at step 62800: 0.110092
2023-03-16 18:52:36,589 INFO     Train loss at step 62800: 0.247163
2023-03-16 18:52:55,921 INFO     Train positive_sample_loss at step 62900: 0.380727
2023-03-16 18:52:55,921 INFO     Train negative_sample_loss at step 62900: 0.110360
2023-03-16 18:52:55,921 INFO     Train loss at step 62900: 0.245543
funtion time use:38341ms
2023-03-16 18:53:28,028 INFO     Train positive_sample_loss at step 63000: 0.338609
2023-03-16 18:53:28,029 INFO     Train negative_sample_loss at step 63000: 0.109950
2023-03-16 18:53:28,029 INFO     Train loss at step 63000: 0.224280
2023-03-16 18:53:47,354 INFO     Train positive_sample_loss at step 63100: 0.312208
2023-03-16 18:53:47,354 INFO     Train negative_sample_loss at step 63100: 0.106357
2023-03-16 18:53:47,354 INFO     Train loss at step 63100: 0.209282
2023-03-16 18:54:06,671 INFO     Train positive_sample_loss at step 63200: 0.314031
2023-03-16 18:54:06,671 INFO     Train negative_sample_loss at step 63200: 0.104981
2023-03-16 18:54:06,672 INFO     Train loss at step 63200: 0.209506
2023-03-16 18:54:25,981 INFO     Train positive_sample_loss at step 63300: 0.318404
2023-03-16 18:54:25,981 INFO     Train negative_sample_loss at step 63300: 0.104219
2023-03-16 18:54:25,981 INFO     Train loss at step 63300: 0.211312
2023-03-16 18:54:45,285 INFO     Train positive_sample_loss at step 63400: 0.320835
2023-03-16 18:54:45,286 INFO     Train negative_sample_loss at step 63400: 0.103612
2023-03-16 18:54:45,286 INFO     Train loss at step 63400: 0.212224
2023-03-16 18:55:04,593 INFO     Train positive_sample_loss at step 63500: 0.325786
2023-03-16 18:55:04,594 INFO     Train negative_sample_loss at step 63500: 0.103360
2023-03-16 18:55:04,594 INFO     Train loss at step 63500: 0.214573
2023-03-16 18:55:23,908 INFO     Train positive_sample_loss at step 63600: 0.332079
2023-03-16 18:55:23,909 INFO     Train negative_sample_loss at step 63600: 0.103575
2023-03-16 18:55:23,909 INFO     Train loss at step 63600: 0.217827
2023-03-16 18:55:50,531 INFO     Train positive_sample_loss at step 63700: 0.333389
2023-03-16 18:55:50,532 INFO     Train negative_sample_loss at step 63700: 0.103922
2023-03-16 18:55:50,532 INFO     Train loss at step 63700: 0.218656
2023-03-16 18:56:09,852 INFO     Train positive_sample_loss at step 63800: 0.341493
2023-03-16 18:56:09,853 INFO     Train negative_sample_loss at step 63800: 0.103689
2023-03-16 18:56:09,853 INFO     Train loss at step 63800: 0.222591
2023-03-16 18:56:29,173 INFO     Train positive_sample_loss at step 63900: 0.342229
2023-03-16 18:56:29,173 INFO     Train negative_sample_loss at step 63900: 0.103881
2023-03-16 18:56:29,174 INFO     Train loss at step 63900: 0.223055
2023-03-16 18:56:48,499 INFO     Train positive_sample_loss at step 64000: 0.347139
2023-03-16 18:56:48,499 INFO     Train negative_sample_loss at step 64000: 0.103063
2023-03-16 18:56:48,499 INFO     Train loss at step 64000: 0.225101
2023-03-16 18:57:07,830 INFO     Train positive_sample_loss at step 64100: 0.351247
2023-03-16 18:57:07,831 INFO     Train negative_sample_loss at step 64100: 0.103858
2023-03-16 18:57:07,831 INFO     Train loss at step 64100: 0.227552
2023-03-16 18:57:27,151 INFO     Train positive_sample_loss at step 64200: 0.355420
2023-03-16 18:57:27,151 INFO     Train negative_sample_loss at step 64200: 0.104645
2023-03-16 18:57:27,151 INFO     Train loss at step 64200: 0.230033
2023-03-16 18:57:46,473 INFO     Train positive_sample_loss at step 64300: 0.360380
2023-03-16 18:57:46,474 INFO     Train negative_sample_loss at step 64300: 0.104673
2023-03-16 18:57:46,474 INFO     Train loss at step 64300: 0.232527
2023-03-16 18:58:05,790 INFO     Train positive_sample_loss at step 64400: 0.362605
2023-03-16 18:58:05,790 INFO     Train negative_sample_loss at step 64400: 0.104388
2023-03-16 18:58:05,790 INFO     Train loss at step 64400: 0.233496
2023-03-16 18:58:25,109 INFO     Train positive_sample_loss at step 64500: 0.369515
2023-03-16 18:58:25,110 INFO     Train negative_sample_loss at step 64500: 0.105120
2023-03-16 18:58:25,110 INFO     Train loss at step 64500: 0.237317
2023-03-16 18:58:44,433 INFO     Train positive_sample_loss at step 64600: 0.372033
2023-03-16 18:58:44,433 INFO     Train negative_sample_loss at step 64600: 0.105216
2023-03-16 18:58:44,433 INFO     Train loss at step 64600: 0.238624
2023-03-16 18:59:10,734 INFO     Train positive_sample_loss at step 64700: 0.373413
2023-03-16 18:59:10,734 INFO     Train negative_sample_loss at step 64700: 0.105499
2023-03-16 18:59:10,734 INFO     Train loss at step 64700: 0.239456
2023-03-16 18:59:30,059 INFO     Train positive_sample_loss at step 64800: 0.376877
2023-03-16 18:59:30,059 INFO     Train negative_sample_loss at step 64800: 0.106090
2023-03-16 18:59:30,059 INFO     Train loss at step 64800: 0.241483
2023-03-16 18:59:49,384 INFO     Train positive_sample_loss at step 64900: 0.379859
2023-03-16 18:59:49,385 INFO     Train negative_sample_loss at step 64900: 0.105273
2023-03-16 18:59:49,385 INFO     Train loss at step 64900: 0.242566
2023-03-16 19:00:08,717 INFO     Train positive_sample_loss at step 65000: 0.383714
2023-03-16 19:00:08,717 INFO     Train negative_sample_loss at step 65000: 0.106314
2023-03-16 19:00:08,718 INFO     Train loss at step 65000: 0.245014
2023-03-16 19:00:28,049 INFO     Train positive_sample_loss at step 65100: 0.384862
2023-03-16 19:00:28,050 INFO     Train negative_sample_loss at step 65100: 0.106657
2023-03-16 19:00:28,050 INFO     Train loss at step 65100: 0.245760
2023-03-16 19:00:47,379 INFO     Train positive_sample_loss at step 65200: 0.384711
2023-03-16 19:00:47,379 INFO     Train negative_sample_loss at step 65200: 0.107409
2023-03-16 19:00:47,379 INFO     Train loss at step 65200: 0.246060
2023-03-16 19:01:06,713 INFO     Train positive_sample_loss at step 65300: 0.386874
2023-03-16 19:01:06,714 INFO     Train negative_sample_loss at step 65300: 0.107356
2023-03-16 19:01:06,714 INFO     Train loss at step 65300: 0.247115
2023-03-16 19:01:26,043 INFO     Train positive_sample_loss at step 65400: 0.387348
2023-03-16 19:01:26,044 INFO     Train negative_sample_loss at step 65400: 0.107870
2023-03-16 19:01:26,044 INFO     Train loss at step 65400: 0.247609
2023-03-16 19:01:45,382 INFO     Train positive_sample_loss at step 65500: 0.387597
2023-03-16 19:01:45,383 INFO     Train negative_sample_loss at step 65500: 0.107700
2023-03-16 19:01:45,383 INFO     Train loss at step 65500: 0.247649
2023-03-16 19:02:04,716 INFO     Train positive_sample_loss at step 65600: 0.388625
2023-03-16 19:02:04,716 INFO     Train negative_sample_loss at step 65600: 0.107312
2023-03-16 19:02:04,716 INFO     Train loss at step 65600: 0.247969
2023-03-16 19:02:24,050 INFO     Train positive_sample_loss at step 65700: 0.390125
2023-03-16 19:02:24,050 INFO     Train negative_sample_loss at step 65700: 0.108079
2023-03-16 19:02:24,050 INFO     Train loss at step 65700: 0.249102
2023-03-16 19:02:50,270 INFO     Train positive_sample_loss at step 65800: 0.389415
2023-03-16 19:02:50,271 INFO     Train negative_sample_loss at step 65800: 0.109285
2023-03-16 19:02:50,272 INFO     Train loss at step 65800: 0.249350
2023-03-16 19:03:09,606 INFO     Train positive_sample_loss at step 65900: 0.390048
2023-03-16 19:03:09,606 INFO     Train negative_sample_loss at step 65900: 0.108246
2023-03-16 19:03:09,606 INFO     Train loss at step 65900: 0.249147
2023-03-16 19:03:28,946 INFO     Train positive_sample_loss at step 66000: 0.391637
2023-03-16 19:03:28,946 INFO     Train negative_sample_loss at step 66000: 0.109823
2023-03-16 19:03:28,946 INFO     Train loss at step 66000: 0.250730
2023-03-16 19:03:48,274 INFO     Train positive_sample_loss at step 66100: 0.386575
2023-03-16 19:03:48,275 INFO     Train negative_sample_loss at step 66100: 0.108785
2023-03-16 19:03:48,275 INFO     Train loss at step 66100: 0.247680
2023-03-16 19:04:07,601 INFO     Train positive_sample_loss at step 66200: 0.386868
2023-03-16 19:04:07,602 INFO     Train negative_sample_loss at step 66200: 0.109201
2023-03-16 19:04:07,602 INFO     Train loss at step 66200: 0.248035
2023-03-16 19:04:26,933 INFO     Train positive_sample_loss at step 66300: 0.386655
2023-03-16 19:04:26,933 INFO     Train negative_sample_loss at step 66300: 0.110458
2023-03-16 19:04:26,933 INFO     Train loss at step 66300: 0.248556
2023-03-16 19:04:46,259 INFO     Train positive_sample_loss at step 66400: 0.387752
2023-03-16 19:04:46,260 INFO     Train negative_sample_loss at step 66400: 0.109814
2023-03-16 19:04:46,260 INFO     Train loss at step 66400: 0.248783
2023-03-16 19:05:05,590 INFO     Train positive_sample_loss at step 66500: 0.384685
2023-03-16 19:05:05,590 INFO     Train negative_sample_loss at step 66500: 0.109758
2023-03-16 19:05:05,590 INFO     Train loss at step 66500: 0.247222
2023-03-16 19:05:24,925 INFO     Train positive_sample_loss at step 66600: 0.385164
2023-03-16 19:05:24,925 INFO     Train negative_sample_loss at step 66600: 0.109840
2023-03-16 19:05:24,926 INFO     Train loss at step 66600: 0.247502
2023-03-16 19:05:44,258 INFO     Train positive_sample_loss at step 66700: 0.382089
2023-03-16 19:05:44,258 INFO     Train negative_sample_loss at step 66700: 0.111047
2023-03-16 19:05:44,259 INFO     Train loss at step 66700: 0.246568
2023-03-16 19:06:03,587 INFO     Train positive_sample_loss at step 66800: 0.379935
2023-03-16 19:06:03,587 INFO     Train negative_sample_loss at step 66800: 0.110357
2023-03-16 19:06:03,588 INFO     Train loss at step 66800: 0.245146
2023-03-16 19:06:35,428 INFO     Train positive_sample_loss at step 66900: 0.363941
2023-03-16 19:06:35,428 INFO     Train negative_sample_loss at step 66900: 0.110804
2023-03-16 19:06:35,428 INFO     Train loss at step 66900: 0.237373
2023-03-16 19:06:54,740 INFO     Train positive_sample_loss at step 67000: 0.311807
2023-03-16 19:06:54,740 INFO     Train negative_sample_loss at step 67000: 0.106675
2023-03-16 19:06:54,740 INFO     Train loss at step 67000: 0.209241
2023-03-16 19:07:14,055 INFO     Train positive_sample_loss at step 67100: 0.315079
2023-03-16 19:07:14,056 INFO     Train negative_sample_loss at step 67100: 0.105298
2023-03-16 19:07:14,056 INFO     Train loss at step 67100: 0.210188
2023-03-16 19:07:33,355 INFO     Train positive_sample_loss at step 67200: 0.320114
2023-03-16 19:07:33,355 INFO     Train negative_sample_loss at step 67200: 0.104545
2023-03-16 19:07:33,355 INFO     Train loss at step 67200: 0.212330
2023-03-16 19:07:52,665 INFO     Train positive_sample_loss at step 67300: 0.322512
2023-03-16 19:07:52,665 INFO     Train negative_sample_loss at step 67300: 0.104281
2023-03-16 19:07:52,665 INFO     Train loss at step 67300: 0.213396
2023-03-16 19:08:11,971 INFO     Train positive_sample_loss at step 67400: 0.327477
2023-03-16 19:08:11,971 INFO     Train negative_sample_loss at step 67400: 0.103397
2023-03-16 19:08:11,971 INFO     Train loss at step 67400: 0.215437
2023-03-16 19:08:31,283 INFO     Train positive_sample_loss at step 67500: 0.327241
2023-03-16 19:08:31,283 INFO     Train negative_sample_loss at step 67500: 0.103627
2023-03-16 19:08:31,283 INFO     Train loss at step 67500: 0.215434
2023-03-16 19:08:57,982 INFO     Train positive_sample_loss at step 67600: 0.335362
2023-03-16 19:08:57,982 INFO     Train negative_sample_loss at step 67600: 0.103201
2023-03-16 19:08:57,982 INFO     Train loss at step 67600: 0.219281
2023-03-16 19:09:17,306 INFO     Train positive_sample_loss at step 67700: 0.339438
2023-03-16 19:09:17,306 INFO     Train negative_sample_loss at step 67700: 0.102644
2023-03-16 19:09:17,306 INFO     Train loss at step 67700: 0.221041
2023-03-16 19:09:36,628 INFO     Train positive_sample_loss at step 67800: 0.342441
2023-03-16 19:09:36,628 INFO     Train negative_sample_loss at step 67800: 0.104638
2023-03-16 19:09:36,628 INFO     Train loss at step 67800: 0.223539
2023-03-16 19:09:55,951 INFO     Train positive_sample_loss at step 67900: 0.346669
2023-03-16 19:09:55,952 INFO     Train negative_sample_loss at step 67900: 0.103618
2023-03-16 19:09:55,952 INFO     Train loss at step 67900: 0.225144
2023-03-16 19:10:15,276 INFO     Train positive_sample_loss at step 68000: 0.350147
2023-03-16 19:10:15,276 INFO     Train negative_sample_loss at step 68000: 0.103734
2023-03-16 19:10:15,276 INFO     Train loss at step 68000: 0.226941
2023-03-16 19:10:34,598 INFO     Train positive_sample_loss at step 68100: 0.355405
2023-03-16 19:10:34,599 INFO     Train negative_sample_loss at step 68100: 0.104151
2023-03-16 19:10:34,599 INFO     Train loss at step 68100: 0.229778
2023-03-16 19:10:53,921 INFO     Train positive_sample_loss at step 68200: 0.360219
2023-03-16 19:10:53,921 INFO     Train negative_sample_loss at step 68200: 0.104743
2023-03-16 19:10:53,921 INFO     Train loss at step 68200: 0.232481
2023-03-16 19:11:13,246 INFO     Train positive_sample_loss at step 68300: 0.362999
2023-03-16 19:11:13,246 INFO     Train negative_sample_loss at step 68300: 0.104389
2023-03-16 19:11:13,247 INFO     Train loss at step 68300: 0.233694
2023-03-16 19:11:32,575 INFO     Train positive_sample_loss at step 68400: 0.368023
2023-03-16 19:11:32,575 INFO     Train negative_sample_loss at step 68400: 0.104196
2023-03-16 19:11:32,575 INFO     Train loss at step 68400: 0.236110
2023-03-16 19:11:51,911 INFO     Train positive_sample_loss at step 68500: 0.369550
2023-03-16 19:11:51,912 INFO     Train negative_sample_loss at step 68500: 0.104606
2023-03-16 19:11:51,912 INFO     Train loss at step 68500: 0.237078
2023-03-16 19:12:11,244 INFO     Train positive_sample_loss at step 68600: 0.372768
2023-03-16 19:12:11,245 INFO     Train negative_sample_loss at step 68600: 0.105570
2023-03-16 19:12:11,245 INFO     Train loss at step 68600: 0.239169
2023-03-16 19:12:37,383 INFO     Train positive_sample_loss at step 68700: 0.374869
2023-03-16 19:12:37,384 INFO     Train negative_sample_loss at step 68700: 0.106328
2023-03-16 19:12:37,384 INFO     Train loss at step 68700: 0.240598
2023-03-16 19:12:56,728 INFO     Train positive_sample_loss at step 68800: 0.380270
2023-03-16 19:12:56,729 INFO     Train negative_sample_loss at step 68800: 0.105890
2023-03-16 19:12:56,729 INFO     Train loss at step 68800: 0.243080
2023-03-16 19:13:16,062 INFO     Train positive_sample_loss at step 68900: 0.382851
2023-03-16 19:13:16,063 INFO     Train negative_sample_loss at step 68900: 0.105602
2023-03-16 19:13:16,063 INFO     Train loss at step 68900: 0.244226
2023-03-16 19:13:35,396 INFO     Train positive_sample_loss at step 69000: 0.382644
2023-03-16 19:13:35,396 INFO     Train negative_sample_loss at step 69000: 0.106955
2023-03-16 19:13:35,396 INFO     Train loss at step 69000: 0.244800
2023-03-16 19:13:54,721 INFO     Train positive_sample_loss at step 69100: 0.384293
2023-03-16 19:13:54,722 INFO     Train negative_sample_loss at step 69100: 0.106289
2023-03-16 19:13:54,722 INFO     Train loss at step 69100: 0.245291
2023-03-16 19:14:14,049 INFO     Train positive_sample_loss at step 69200: 0.386477
2023-03-16 19:14:14,049 INFO     Train negative_sample_loss at step 69200: 0.107155
2023-03-16 19:14:14,050 INFO     Train loss at step 69200: 0.246816
2023-03-16 19:14:33,377 INFO     Train positive_sample_loss at step 69300: 0.389111
2023-03-16 19:14:33,378 INFO     Train negative_sample_loss at step 69300: 0.107574
2023-03-16 19:14:33,378 INFO     Train loss at step 69300: 0.248343
2023-03-16 19:14:52,705 INFO     Train positive_sample_loss at step 69400: 0.389512
2023-03-16 19:14:52,705 INFO     Train negative_sample_loss at step 69400: 0.108212
2023-03-16 19:14:52,705 INFO     Train loss at step 69400: 0.248862
2023-03-16 19:15:12,039 INFO     Train positive_sample_loss at step 69500: 0.391650
2023-03-16 19:15:12,039 INFO     Train negative_sample_loss at step 69500: 0.107555
2023-03-16 19:15:12,040 INFO     Train loss at step 69500: 0.249602
2023-03-16 19:15:31,376 INFO     Train positive_sample_loss at step 69600: 0.389326
2023-03-16 19:15:31,377 INFO     Train negative_sample_loss at step 69600: 0.107954
2023-03-16 19:15:31,377 INFO     Train loss at step 69600: 0.248640
2023-03-16 19:15:57,540 INFO     Train positive_sample_loss at step 69700: 0.390431
2023-03-16 19:15:57,541 INFO     Train negative_sample_loss at step 69700: 0.108212
2023-03-16 19:15:57,541 INFO     Train loss at step 69700: 0.249322
2023-03-16 19:16:16,876 INFO     Train positive_sample_loss at step 69800: 0.389035
2023-03-16 19:16:16,876 INFO     Train negative_sample_loss at step 69800: 0.108064
2023-03-16 19:16:16,876 INFO     Train loss at step 69800: 0.248550
2023-03-16 19:16:36,212 INFO     Train positive_sample_loss at step 69900: 0.390438
2023-03-16 19:16:36,212 INFO     Train negative_sample_loss at step 69900: 0.108920
2023-03-16 19:16:36,212 INFO     Train loss at step 69900: 0.249679
2023-03-16 19:16:57,051 INFO     Train positive_sample_loss at step 70000: 0.390550
2023-03-16 19:16:57,052 INFO     Train negative_sample_loss at step 70000: 0.109262
2023-03-16 19:16:57,052 INFO     Train loss at step 70000: 0.249906
2023-03-16 19:16:57,052 INFO     Evaluating on Valid Dataset...
2023-03-16 19:16:58,035 INFO     Evaluating the model... (0/26842)
2023-03-16 19:16:59,699 INFO     Evaluating the model... (1000/26842)
2023-03-16 19:17:00,950 INFO     Evaluating the model... (2000/26842)
2023-03-16 19:17:02,189 INFO     Evaluating the model... (3000/26842)
2023-03-16 19:17:03,428 INFO     Evaluating the model... (4000/26842)
2023-03-16 19:17:04,675 INFO     Evaluating the model... (5000/26842)
2023-03-16 19:17:05,915 INFO     Evaluating the model... (6000/26842)
2023-03-16 19:17:07,155 INFO     Evaluating the model... (7000/26842)
2023-03-16 19:17:08,392 INFO     Evaluating the model... (8000/26842)
2023-03-16 19:17:09,622 INFO     Evaluating the model... (9000/26842)
2023-03-16 19:17:10,851 INFO     Evaluating the model... (10000/26842)
2023-03-16 19:17:12,079 INFO     Evaluating the model... (11000/26842)
2023-03-16 19:17:13,311 INFO     Evaluating the model... (12000/26842)
2023-03-16 19:17:14,539 INFO     Evaluating the model... (13000/26842)
2023-03-16 19:17:16,883 INFO     Evaluating the model... (14000/26842)
2023-03-16 19:17:18,364 INFO     Evaluating the model... (15000/26842)
2023-03-16 19:17:19,832 INFO     Evaluating the model... (16000/26842)
2023-03-16 19:17:21,301 INFO     Evaluating the model... (17000/26842)
2023-03-16 19:17:22,771 INFO     Evaluating the model... (18000/26842)
2023-03-16 19:17:24,250 INFO     Evaluating the model... (19000/26842)
2023-03-16 19:17:25,732 INFO     Evaluating the model... (20000/26842)
2023-03-16 19:17:27,226 INFO     Evaluating the model... (21000/26842)
2023-03-16 19:17:28,714 INFO     Evaluating the model... (22000/26842)
2023-03-16 19:17:30,192 INFO     Evaluating the model... (23000/26842)
2023-03-16 19:17:31,669 INFO     Evaluating the model... (24000/26842)
2023-03-16 19:17:33,136 INFO     Evaluating the model... (25000/26842)
2023-03-16 19:17:34,609 INFO     Evaluating the model... (26000/26842)
2023-03-16 19:17:36,159 INFO     Valid hits@1_list at step 70000: 0.588198
2023-03-16 19:17:36,160 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 19:17:36,160 INFO     Valid hits@3_list at step 70000: 0.678596
2023-03-16 19:17:36,160 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 19:17:36,160 INFO     Valid hits@10_list at step 70000: 0.763802
2023-03-16 19:17:36,160 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 19:17:36,160 INFO     Valid mrr_list at step 70000: 0.649707
2023-03-16 19:17:55,515 INFO     Train positive_sample_loss at step 70100: 0.388006
2023-03-16 19:17:55,515 INFO     Train negative_sample_loss at step 70100: 0.109313
2023-03-16 19:17:55,515 INFO     Train loss at step 70100: 0.248659
2023-03-16 19:18:14,866 INFO     Train positive_sample_loss at step 70200: 0.385067
2023-03-16 19:18:14,867 INFO     Train negative_sample_loss at step 70200: 0.109756
2023-03-16 19:18:14,867 INFO     Train loss at step 70200: 0.247411
2023-03-16 19:18:34,221 INFO     Train positive_sample_loss at step 70300: 0.387479
2023-03-16 19:18:34,222 INFO     Train negative_sample_loss at step 70300: 0.109549
2023-03-16 19:18:34,222 INFO     Train loss at step 70300: 0.248514
2023-03-16 19:18:53,579 INFO     Train positive_sample_loss at step 70400: 0.384346
2023-03-16 19:18:53,579 INFO     Train negative_sample_loss at step 70400: 0.109973
2023-03-16 19:18:53,579 INFO     Train loss at step 70400: 0.247160
2023-03-16 19:19:12,926 INFO     Train positive_sample_loss at step 70500: 0.384398
2023-03-16 19:19:12,927 INFO     Train negative_sample_loss at step 70500: 0.110563
2023-03-16 19:19:12,927 INFO     Train loss at step 70500: 0.247480
2023-03-16 19:19:32,269 INFO     Train positive_sample_loss at step 70600: 0.381371
2023-03-16 19:19:32,270 INFO     Train negative_sample_loss at step 70600: 0.109851
2023-03-16 19:19:32,270 INFO     Train loss at step 70600: 0.245611
2023-03-16 19:19:51,609 INFO     Train positive_sample_loss at step 70700: 0.381802
2023-03-16 19:19:51,610 INFO     Train negative_sample_loss at step 70700: 0.110508
2023-03-16 19:19:51,610 INFO     Train loss at step 70700: 0.246155
2023-03-16 19:20:19,645 INFO     Train positive_sample_loss at step 70800: 0.379004
2023-03-16 19:20:19,645 INFO     Train negative_sample_loss at step 70800: 0.110585
2023-03-16 19:20:19,645 INFO     Train loss at step 70800: 0.244794
funtion time use:38932ms
2023-03-16 19:20:42,966 INFO     Train positive_sample_loss at step 70900: 0.315524
2023-03-16 19:20:42,966 INFO     Train negative_sample_loss at step 70900: 0.107749
2023-03-16 19:20:42,966 INFO     Train loss at step 70900: 0.211637
2023-03-16 19:21:02,276 INFO     Train positive_sample_loss at step 71000: 0.313686
2023-03-16 19:21:02,277 INFO     Train negative_sample_loss at step 71000: 0.104954
2023-03-16 19:21:02,277 INFO     Train loss at step 71000: 0.209320
2023-03-16 19:21:21,587 INFO     Train positive_sample_loss at step 71100: 0.315081
2023-03-16 19:21:21,587 INFO     Train negative_sample_loss at step 71100: 0.103579
2023-03-16 19:21:21,588 INFO     Train loss at step 71100: 0.209330
2023-03-16 19:21:40,900 INFO     Train positive_sample_loss at step 71200: 0.319053
2023-03-16 19:21:40,900 INFO     Train negative_sample_loss at step 71200: 0.103799
2023-03-16 19:21:40,900 INFO     Train loss at step 71200: 0.211426
2023-03-16 19:22:00,204 INFO     Train positive_sample_loss at step 71300: 0.322190
2023-03-16 19:22:00,204 INFO     Train negative_sample_loss at step 71300: 0.103222
2023-03-16 19:22:00,204 INFO     Train loss at step 71300: 0.212706
2023-03-16 19:22:19,524 INFO     Train positive_sample_loss at step 71400: 0.328679
2023-03-16 19:22:19,524 INFO     Train negative_sample_loss at step 71400: 0.103131
2023-03-16 19:22:19,524 INFO     Train loss at step 71400: 0.215905
2023-03-16 19:22:46,555 INFO     Train positive_sample_loss at step 71500: 0.332282
2023-03-16 19:22:46,556 INFO     Train negative_sample_loss at step 71500: 0.103114
2023-03-16 19:22:46,556 INFO     Train loss at step 71500: 0.217698
2023-03-16 19:23:05,871 INFO     Train positive_sample_loss at step 71600: 0.336085
2023-03-16 19:23:05,871 INFO     Train negative_sample_loss at step 71600: 0.103192
2023-03-16 19:23:05,871 INFO     Train loss at step 71600: 0.219638
2023-03-16 19:23:25,192 INFO     Train positive_sample_loss at step 71700: 0.340906
2023-03-16 19:23:25,192 INFO     Train negative_sample_loss at step 71700: 0.103556
2023-03-16 19:23:25,192 INFO     Train loss at step 71700: 0.222231
2023-03-16 19:23:44,511 INFO     Train positive_sample_loss at step 71800: 0.344117
2023-03-16 19:23:44,511 INFO     Train negative_sample_loss at step 71800: 0.104055
2023-03-16 19:23:44,511 INFO     Train loss at step 71800: 0.224086
2023-03-16 19:24:03,828 INFO     Train positive_sample_loss at step 71900: 0.348032
2023-03-16 19:24:03,828 INFO     Train negative_sample_loss at step 71900: 0.102897
2023-03-16 19:24:03,828 INFO     Train loss at step 71900: 0.225465
2023-03-16 19:24:23,159 INFO     Train positive_sample_loss at step 72000: 0.353575
2023-03-16 19:24:23,159 INFO     Train negative_sample_loss at step 72000: 0.103774
2023-03-16 19:24:23,160 INFO     Train loss at step 72000: 0.228675
2023-03-16 19:24:42,492 INFO     Train positive_sample_loss at step 72100: 0.359714
2023-03-16 19:24:42,493 INFO     Train negative_sample_loss at step 72100: 0.104413
2023-03-16 19:24:42,493 INFO     Train loss at step 72100: 0.232063
2023-03-16 19:25:01,816 INFO     Train positive_sample_loss at step 72200: 0.361224
2023-03-16 19:25:01,816 INFO     Train negative_sample_loss at step 72200: 0.104263
2023-03-16 19:25:01,816 INFO     Train loss at step 72200: 0.232743
2023-03-16 19:25:21,146 INFO     Train positive_sample_loss at step 72300: 0.366197
2023-03-16 19:25:21,147 INFO     Train negative_sample_loss at step 72300: 0.104128
2023-03-16 19:25:21,147 INFO     Train loss at step 72300: 0.235163
2023-03-16 19:25:40,473 INFO     Train positive_sample_loss at step 72400: 0.371169
2023-03-16 19:25:40,474 INFO     Train negative_sample_loss at step 72400: 0.105043
2023-03-16 19:25:40,474 INFO     Train loss at step 72400: 0.238106
2023-03-16 19:25:59,804 INFO     Train positive_sample_loss at step 72500: 0.372436
2023-03-16 19:25:59,804 INFO     Train negative_sample_loss at step 72500: 0.104825
2023-03-16 19:25:59,805 INFO     Train loss at step 72500: 0.238631
2023-03-16 19:26:28,540 INFO     Train positive_sample_loss at step 72600: 0.376422
2023-03-16 19:26:28,540 INFO     Train negative_sample_loss at step 72600: 0.104905
2023-03-16 19:26:28,540 INFO     Train loss at step 72600: 0.240664
2023-03-16 19:26:47,875 INFO     Train positive_sample_loss at step 72700: 0.377514
2023-03-16 19:26:47,875 INFO     Train negative_sample_loss at step 72700: 0.105572
2023-03-16 19:26:47,875 INFO     Train loss at step 72700: 0.241543
2023-03-16 19:27:07,206 INFO     Train positive_sample_loss at step 72800: 0.382874
2023-03-16 19:27:07,207 INFO     Train negative_sample_loss at step 72800: 0.105193
2023-03-16 19:27:07,207 INFO     Train loss at step 72800: 0.244033
2023-03-16 19:27:26,532 INFO     Train positive_sample_loss at step 72900: 0.381771
2023-03-16 19:27:26,533 INFO     Train negative_sample_loss at step 72900: 0.105869
2023-03-16 19:27:26,533 INFO     Train loss at step 72900: 0.243820
2023-03-16 19:27:45,853 INFO     Train positive_sample_loss at step 73000: 0.385469
2023-03-16 19:27:45,854 INFO     Train negative_sample_loss at step 73000: 0.106782
2023-03-16 19:27:45,854 INFO     Train loss at step 73000: 0.246125
2023-03-16 19:28:05,174 INFO     Train positive_sample_loss at step 73100: 0.383807
2023-03-16 19:28:05,174 INFO     Train negative_sample_loss at step 73100: 0.106402
2023-03-16 19:28:05,174 INFO     Train loss at step 73100: 0.245104
2023-03-16 19:28:24,498 INFO     Train positive_sample_loss at step 73200: 0.387695
2023-03-16 19:28:24,499 INFO     Train negative_sample_loss at step 73200: 0.107254
2023-03-16 19:28:24,499 INFO     Train loss at step 73200: 0.247475
2023-03-16 19:28:43,830 INFO     Train positive_sample_loss at step 73300: 0.388051
2023-03-16 19:28:43,831 INFO     Train negative_sample_loss at step 73300: 0.106755
2023-03-16 19:28:43,831 INFO     Train loss at step 73300: 0.247403
2023-03-16 19:29:03,180 INFO     Train positive_sample_loss at step 73400: 0.388202
2023-03-16 19:29:03,180 INFO     Train negative_sample_loss at step 73400: 0.107836
2023-03-16 19:29:03,181 INFO     Train loss at step 73400: 0.248019
2023-03-16 19:29:22,516 INFO     Train positive_sample_loss at step 73500: 0.389491
2023-03-16 19:29:22,516 INFO     Train negative_sample_loss at step 73500: 0.107715
2023-03-16 19:29:22,516 INFO     Train loss at step 73500: 0.248603
2023-03-16 19:29:48,831 INFO     Train positive_sample_loss at step 73600: 0.387024
2023-03-16 19:29:48,832 INFO     Train negative_sample_loss at step 73600: 0.107916
2023-03-16 19:29:48,832 INFO     Train loss at step 73600: 0.247470
2023-03-16 19:30:08,159 INFO     Train positive_sample_loss at step 73700: 0.388315
2023-03-16 19:30:08,159 INFO     Train negative_sample_loss at step 73700: 0.108120
2023-03-16 19:30:08,159 INFO     Train loss at step 73700: 0.248217
2023-03-16 19:30:27,490 INFO     Train positive_sample_loss at step 73800: 0.390423
2023-03-16 19:30:27,490 INFO     Train negative_sample_loss at step 73800: 0.108669
2023-03-16 19:30:27,490 INFO     Train loss at step 73800: 0.249546
2023-03-16 19:30:46,825 INFO     Train positive_sample_loss at step 73900: 0.387479
2023-03-16 19:30:46,826 INFO     Train negative_sample_loss at step 73900: 0.109319
2023-03-16 19:30:46,826 INFO     Train loss at step 73900: 0.248399
2023-03-16 19:31:06,168 INFO     Train positive_sample_loss at step 74000: 0.388219
2023-03-16 19:31:06,169 INFO     Train negative_sample_loss at step 74000: 0.108409
2023-03-16 19:31:06,169 INFO     Train loss at step 74000: 0.248314
2023-03-16 19:31:25,491 INFO     Train positive_sample_loss at step 74100: 0.389330
2023-03-16 19:31:25,492 INFO     Train negative_sample_loss at step 74100: 0.109699
2023-03-16 19:31:25,492 INFO     Train loss at step 74100: 0.249514
2023-03-16 19:31:44,819 INFO     Train positive_sample_loss at step 74200: 0.385988
2023-03-16 19:31:44,820 INFO     Train negative_sample_loss at step 74200: 0.109625
2023-03-16 19:31:44,820 INFO     Train loss at step 74200: 0.247807
2023-03-16 19:32:04,148 INFO     Train positive_sample_loss at step 74300: 0.384275
2023-03-16 19:32:04,148 INFO     Train negative_sample_loss at step 74300: 0.109487
2023-03-16 19:32:04,148 INFO     Train loss at step 74300: 0.246881
2023-03-16 19:32:23,485 INFO     Train positive_sample_loss at step 74400: 0.382186
2023-03-16 19:32:23,486 INFO     Train negative_sample_loss at step 74400: 0.109979
2023-03-16 19:32:23,486 INFO     Train loss at step 74400: 0.246083
2023-03-16 19:32:42,819 INFO     Train positive_sample_loss at step 74500: 0.382100
2023-03-16 19:32:42,819 INFO     Train negative_sample_loss at step 74500: 0.110547
2023-03-16 19:32:42,819 INFO     Train loss at step 74500: 0.246323
2023-03-16 19:33:02,150 INFO     Train positive_sample_loss at step 74600: 0.383241
2023-03-16 19:33:02,150 INFO     Train negative_sample_loss at step 74600: 0.109822
2023-03-16 19:33:02,151 INFO     Train loss at step 74600: 0.246531
2023-03-16 19:33:28,427 INFO     Train positive_sample_loss at step 74700: 0.378937
2023-03-16 19:33:28,428 INFO     Train negative_sample_loss at step 74700: 0.110396
2023-03-16 19:33:28,428 INFO     Train loss at step 74700: 0.244667
2023-03-16 19:33:53,665 INFO     Train positive_sample_loss at step 74800: 0.339600
2023-03-16 19:33:53,665 INFO     Train negative_sample_loss at step 74800: 0.108797
2023-03-16 19:33:53,665 INFO     Train loss at step 74800: 0.224199
2023-03-16 19:34:13,001 INFO     Train positive_sample_loss at step 74900: 0.312049
2023-03-16 19:34:13,001 INFO     Train negative_sample_loss at step 74900: 0.105826
2023-03-16 19:34:13,002 INFO     Train loss at step 74900: 0.208938
2023-03-16 19:34:32,331 INFO     Train positive_sample_loss at step 75000: 0.315804
2023-03-16 19:34:32,331 INFO     Train negative_sample_loss at step 75000: 0.104353
2023-03-16 19:34:32,331 INFO     Train loss at step 75000: 0.210079
2023-03-16 19:34:51,650 INFO     Train positive_sample_loss at step 75100: 0.318370
2023-03-16 19:34:51,650 INFO     Train negative_sample_loss at step 75100: 0.103981
2023-03-16 19:34:51,650 INFO     Train loss at step 75100: 0.211175
2023-03-16 19:35:10,957 INFO     Train positive_sample_loss at step 75200: 0.323505
2023-03-16 19:35:10,958 INFO     Train negative_sample_loss at step 75200: 0.103071
2023-03-16 19:35:10,958 INFO     Train loss at step 75200: 0.213288
2023-03-16 19:35:30,273 INFO     Train positive_sample_loss at step 75300: 0.326907
2023-03-16 19:35:30,274 INFO     Train negative_sample_loss at step 75300: 0.103260
2023-03-16 19:35:30,274 INFO     Train loss at step 75300: 0.215083
2023-03-16 19:35:57,263 INFO     Train positive_sample_loss at step 75400: 0.329565
2023-03-16 19:35:57,263 INFO     Train negative_sample_loss at step 75400: 0.103439
2023-03-16 19:35:57,263 INFO     Train loss at step 75400: 0.216502
2023-03-16 19:36:16,585 INFO     Train positive_sample_loss at step 75500: 0.336046
2023-03-16 19:36:16,585 INFO     Train negative_sample_loss at step 75500: 0.103532
2023-03-16 19:36:16,585 INFO     Train loss at step 75500: 0.219789
2023-03-16 19:36:35,909 INFO     Train positive_sample_loss at step 75600: 0.339525
2023-03-16 19:36:35,910 INFO     Train negative_sample_loss at step 75600: 0.103288
2023-03-16 19:36:35,910 INFO     Train loss at step 75600: 0.221406
2023-03-16 19:36:55,235 INFO     Train positive_sample_loss at step 75700: 0.345608
2023-03-16 19:36:55,235 INFO     Train negative_sample_loss at step 75700: 0.102548
2023-03-16 19:36:55,236 INFO     Train loss at step 75700: 0.224078
2023-03-16 19:37:14,564 INFO     Train positive_sample_loss at step 75800: 0.347049
2023-03-16 19:37:14,564 INFO     Train negative_sample_loss at step 75800: 0.103720
2023-03-16 19:37:14,564 INFO     Train loss at step 75800: 0.225385
2023-03-16 19:37:33,890 INFO     Train positive_sample_loss at step 75900: 0.351781
2023-03-16 19:37:33,891 INFO     Train negative_sample_loss at step 75900: 0.103888
2023-03-16 19:37:33,891 INFO     Train loss at step 75900: 0.227834
2023-03-16 19:37:53,223 INFO     Train positive_sample_loss at step 76000: 0.354596
2023-03-16 19:37:53,224 INFO     Train negative_sample_loss at step 76000: 0.103683
2023-03-16 19:37:53,224 INFO     Train loss at step 76000: 0.229139
2023-03-16 19:38:12,546 INFO     Train positive_sample_loss at step 76100: 0.361860
2023-03-16 19:38:12,546 INFO     Train negative_sample_loss at step 76100: 0.103745
2023-03-16 19:38:12,546 INFO     Train loss at step 76100: 0.232803
2023-03-16 19:38:31,876 INFO     Train positive_sample_loss at step 76200: 0.365922
2023-03-16 19:38:31,877 INFO     Train negative_sample_loss at step 76200: 0.103928
2023-03-16 19:38:31,877 INFO     Train loss at step 76200: 0.234925
2023-03-16 19:38:51,215 INFO     Train positive_sample_loss at step 76300: 0.366567
2023-03-16 19:38:51,215 INFO     Train negative_sample_loss at step 76300: 0.104715
2023-03-16 19:38:51,215 INFO     Train loss at step 76300: 0.235641
2023-03-16 19:39:10,543 INFO     Train positive_sample_loss at step 76400: 0.370320
2023-03-16 19:39:10,544 INFO     Train negative_sample_loss at step 76400: 0.104221
2023-03-16 19:39:10,544 INFO     Train loss at step 76400: 0.237270
2023-03-16 19:39:36,776 INFO     Train positive_sample_loss at step 76500: 0.373537
2023-03-16 19:39:36,777 INFO     Train negative_sample_loss at step 76500: 0.104926
2023-03-16 19:39:36,777 INFO     Train loss at step 76500: 0.239231
2023-03-16 19:39:56,107 INFO     Train positive_sample_loss at step 76600: 0.378023
2023-03-16 19:39:56,107 INFO     Train negative_sample_loss at step 76600: 0.105894
2023-03-16 19:39:56,107 INFO     Train loss at step 76600: 0.241959
2023-03-16 19:40:15,437 INFO     Train positive_sample_loss at step 76700: 0.379333
2023-03-16 19:40:15,437 INFO     Train negative_sample_loss at step 76700: 0.105861
2023-03-16 19:40:15,438 INFO     Train loss at step 76700: 0.242597
2023-03-16 19:40:34,773 INFO     Train positive_sample_loss at step 76800: 0.381638
2023-03-16 19:40:34,774 INFO     Train negative_sample_loss at step 76800: 0.105428
2023-03-16 19:40:34,774 INFO     Train loss at step 76800: 0.243533
2023-03-16 19:40:54,103 INFO     Train positive_sample_loss at step 76900: 0.384179
2023-03-16 19:40:54,103 INFO     Train negative_sample_loss at step 76900: 0.105805
2023-03-16 19:40:54,104 INFO     Train loss at step 76900: 0.244992
2023-03-16 19:41:13,441 INFO     Train positive_sample_loss at step 77000: 0.384837
2023-03-16 19:41:13,442 INFO     Train negative_sample_loss at step 77000: 0.106818
2023-03-16 19:41:13,442 INFO     Train loss at step 77000: 0.245828
2023-03-16 19:41:32,763 INFO     Train positive_sample_loss at step 77100: 0.385354
2023-03-16 19:41:32,763 INFO     Train negative_sample_loss at step 77100: 0.106338
2023-03-16 19:41:32,763 INFO     Train loss at step 77100: 0.245846
2023-03-16 19:41:52,093 INFO     Train positive_sample_loss at step 77200: 0.386641
2023-03-16 19:41:52,094 INFO     Train negative_sample_loss at step 77200: 0.107317
2023-03-16 19:41:52,094 INFO     Train loss at step 77200: 0.246979
2023-03-16 19:42:11,426 INFO     Train positive_sample_loss at step 77300: 0.390128
2023-03-16 19:42:11,427 INFO     Train negative_sample_loss at step 77300: 0.107625
2023-03-16 19:42:11,427 INFO     Train loss at step 77300: 0.248876
2023-03-16 19:42:30,764 INFO     Train positive_sample_loss at step 77400: 0.388207
2023-03-16 19:42:30,764 INFO     Train negative_sample_loss at step 77400: 0.107715
2023-03-16 19:42:30,764 INFO     Train loss at step 77400: 0.247961
2023-03-16 19:42:50,100 INFO     Train positive_sample_loss at step 77500: 0.391802
2023-03-16 19:42:50,100 INFO     Train negative_sample_loss at step 77500: 0.108036
2023-03-16 19:42:50,100 INFO     Train loss at step 77500: 0.249919
2023-03-16 19:43:16,332 INFO     Train positive_sample_loss at step 77600: 0.389602
2023-03-16 19:43:16,333 INFO     Train negative_sample_loss at step 77600: 0.107690
2023-03-16 19:43:16,333 INFO     Train loss at step 77600: 0.248646
2023-03-16 19:43:35,666 INFO     Train positive_sample_loss at step 77700: 0.389398
2023-03-16 19:43:35,666 INFO     Train negative_sample_loss at step 77700: 0.108320
2023-03-16 19:43:35,666 INFO     Train loss at step 77700: 0.248859
2023-03-16 19:43:54,997 INFO     Train positive_sample_loss at step 77800: 0.390071
2023-03-16 19:43:54,997 INFO     Train negative_sample_loss at step 77800: 0.109150
2023-03-16 19:43:54,997 INFO     Train loss at step 77800: 0.249610
2023-03-16 19:44:14,325 INFO     Train positive_sample_loss at step 77900: 0.388048
2023-03-16 19:44:14,325 INFO     Train negative_sample_loss at step 77900: 0.108867
2023-03-16 19:44:14,325 INFO     Train loss at step 77900: 0.248458
2023-03-16 19:44:33,657 INFO     Train positive_sample_loss at step 78000: 0.388368
2023-03-16 19:44:33,658 INFO     Train negative_sample_loss at step 78000: 0.109468
2023-03-16 19:44:33,658 INFO     Train loss at step 78000: 0.248918
2023-03-16 19:44:52,997 INFO     Train positive_sample_loss at step 78100: 0.387648
2023-03-16 19:44:52,998 INFO     Train negative_sample_loss at step 78100: 0.109200
2023-03-16 19:44:52,998 INFO     Train loss at step 78100: 0.248424
2023-03-16 19:45:12,330 INFO     Train positive_sample_loss at step 78200: 0.386114
2023-03-16 19:45:12,330 INFO     Train negative_sample_loss at step 78200: 0.109475
2023-03-16 19:45:12,330 INFO     Train loss at step 78200: 0.247794
2023-03-16 19:45:31,663 INFO     Train positive_sample_loss at step 78300: 0.386810
2023-03-16 19:45:31,663 INFO     Train negative_sample_loss at step 78300: 0.109783
2023-03-16 19:45:31,663 INFO     Train loss at step 78300: 0.248296
2023-03-16 19:45:51,001 INFO     Train positive_sample_loss at step 78400: 0.383107
2023-03-16 19:45:51,001 INFO     Train negative_sample_loss at step 78400: 0.110045
2023-03-16 19:45:51,001 INFO     Train loss at step 78400: 0.246576
2023-03-16 19:46:10,331 INFO     Train positive_sample_loss at step 78500: 0.381078
2023-03-16 19:46:10,331 INFO     Train negative_sample_loss at step 78500: 0.110070
2023-03-16 19:46:10,331 INFO     Train loss at step 78500: 0.245574
2023-03-16 19:46:36,507 INFO     Train positive_sample_loss at step 78600: 0.379719
2023-03-16 19:46:36,507 INFO     Train negative_sample_loss at step 78600: 0.110207
2023-03-16 19:46:36,508 INFO     Train loss at step 78600: 0.244963
2023-03-16 19:47:01,783 INFO     Train positive_sample_loss at step 78700: 0.365147
2023-03-16 19:47:01,783 INFO     Train negative_sample_loss at step 78700: 0.110290
2023-03-16 19:47:01,783 INFO     Train loss at step 78700: 0.237718
2023-03-16 19:47:21,106 INFO     Train positive_sample_loss at step 78800: 0.310527
2023-03-16 19:47:21,106 INFO     Train negative_sample_loss at step 78800: 0.106554
2023-03-16 19:47:21,106 INFO     Train loss at step 78800: 0.208540
2023-03-16 19:47:40,423 INFO     Train positive_sample_loss at step 78900: 0.314934
2023-03-16 19:47:40,424 INFO     Train negative_sample_loss at step 78900: 0.104464
2023-03-16 19:47:40,424 INFO     Train loss at step 78900: 0.209699
2023-03-16 19:47:59,737 INFO     Train positive_sample_loss at step 79000: 0.317700
2023-03-16 19:47:59,737 INFO     Train negative_sample_loss at step 79000: 0.103313
2023-03-16 19:47:59,737 INFO     Train loss at step 79000: 0.210506
2023-03-16 19:48:19,048 INFO     Train positive_sample_loss at step 79100: 0.321507
2023-03-16 19:48:19,048 INFO     Train negative_sample_loss at step 79100: 0.103530
2023-03-16 19:48:19,048 INFO     Train loss at step 79100: 0.212518
2023-03-16 19:48:38,362 INFO     Train positive_sample_loss at step 79200: 0.326619
2023-03-16 19:48:38,362 INFO     Train negative_sample_loss at step 79200: 0.103031
2023-03-16 19:48:38,362 INFO     Train loss at step 79200: 0.214825
2023-03-16 19:48:57,674 INFO     Train positive_sample_loss at step 79300: 0.328746
2023-03-16 19:48:57,675 INFO     Train negative_sample_loss at step 79300: 0.103269
2023-03-16 19:48:57,675 INFO     Train loss at step 79300: 0.216007
2023-03-16 19:49:24,368 INFO     Train positive_sample_loss at step 79400: 0.333910
2023-03-16 19:49:24,369 INFO     Train negative_sample_loss at step 79400: 0.102815
2023-03-16 19:49:24,369 INFO     Train loss at step 79400: 0.218362
2023-03-16 19:49:43,684 INFO     Train positive_sample_loss at step 79500: 0.337061
2023-03-16 19:49:43,685 INFO     Train negative_sample_loss at step 79500: 0.103267
2023-03-16 19:49:43,685 INFO     Train loss at step 79500: 0.220164
2023-03-16 19:50:03,004 INFO     Train positive_sample_loss at step 79600: 0.343381
2023-03-16 19:50:03,005 INFO     Train negative_sample_loss at step 79600: 0.103510
2023-03-16 19:50:03,005 INFO     Train loss at step 79600: 0.223446
2023-03-16 19:50:22,329 INFO     Train positive_sample_loss at step 79700: 0.347051
2023-03-16 19:50:22,329 INFO     Train negative_sample_loss at step 79700: 0.103682
2023-03-16 19:50:22,329 INFO     Train loss at step 79700: 0.225366
2023-03-16 19:50:41,658 INFO     Train positive_sample_loss at step 79800: 0.350833
2023-03-16 19:50:41,658 INFO     Train negative_sample_loss at step 79800: 0.103675
2023-03-16 19:50:41,659 INFO     Train loss at step 79800: 0.227254
2023-03-16 19:51:00,981 INFO     Train positive_sample_loss at step 79900: 0.355114
2023-03-16 19:51:00,982 INFO     Train negative_sample_loss at step 79900: 0.103580
2023-03-16 19:51:00,982 INFO     Train loss at step 79900: 0.229347
2023-03-16 19:51:21,884 INFO     Train positive_sample_loss at step 80000: 0.358595
2023-03-16 19:51:21,885 INFO     Train negative_sample_loss at step 80000: 0.103420
2023-03-16 19:51:21,885 INFO     Train loss at step 80000: 0.231007
2023-03-16 19:51:21,885 INFO     Evaluating on Valid Dataset...
2023-03-16 19:51:22,873 INFO     Evaluating the model... (0/26842)
2023-03-16 19:51:24,403 INFO     Evaluating the model... (1000/26842)
2023-03-16 19:51:25,759 INFO     Evaluating the model... (2000/26842)
2023-03-16 19:51:26,999 INFO     Evaluating the model... (3000/26842)
2023-03-16 19:51:28,238 INFO     Evaluating the model... (4000/26842)
2023-03-16 19:51:29,478 INFO     Evaluating the model... (5000/26842)
2023-03-16 19:51:30,710 INFO     Evaluating the model... (6000/26842)
2023-03-16 19:51:31,934 INFO     Evaluating the model... (7000/26842)
2023-03-16 19:51:33,162 INFO     Evaluating the model... (8000/26842)
2023-03-16 19:51:34,395 INFO     Evaluating the model... (9000/26842)
2023-03-16 19:51:35,631 INFO     Evaluating the model... (10000/26842)
2023-03-16 19:51:36,868 INFO     Evaluating the model... (11000/26842)
2023-03-16 19:51:38,100 INFO     Evaluating the model... (12000/26842)
2023-03-16 19:51:39,332 INFO     Evaluating the model... (13000/26842)
2023-03-16 19:51:41,529 INFO     Evaluating the model... (14000/26842)
2023-03-16 19:51:43,018 INFO     Evaluating the model... (15000/26842)
2023-03-16 19:51:44,497 INFO     Evaluating the model... (16000/26842)
2023-03-16 19:51:45,982 INFO     Evaluating the model... (17000/26842)
2023-03-16 19:51:47,467 INFO     Evaluating the model... (18000/26842)
2023-03-16 19:51:48,945 INFO     Evaluating the model... (19000/26842)
2023-03-16 19:51:50,425 INFO     Evaluating the model... (20000/26842)
2023-03-16 19:51:51,899 INFO     Evaluating the model... (21000/26842)
2023-03-16 19:51:53,382 INFO     Evaluating the model... (22000/26842)
2023-03-16 19:51:54,865 INFO     Evaluating the model... (23000/26842)
2023-03-16 19:51:56,346 INFO     Evaluating the model... (24000/26842)
2023-03-16 19:51:57,827 INFO     Evaluating the model... (25000/26842)
2023-03-16 19:51:59,305 INFO     Evaluating the model... (26000/26842)
2023-03-16 19:52:00,863 INFO     Valid hits@1_list at step 80000: 0.588656
2023-03-16 19:52:00,863 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 19:52:00,863 INFO     Valid hits@3_list at step 80000: 0.678832
2023-03-16 19:52:00,864 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 19:52:00,864 INFO     Valid hits@10_list at step 80000: 0.764175
2023-03-16 19:52:00,864 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 19:52:00,864 INFO     Valid mrr_list at step 80000: 0.650029
2023-03-16 19:52:20,211 INFO     Train positive_sample_loss at step 80100: 0.362220
2023-03-16 19:52:20,211 INFO     Train negative_sample_loss at step 80100: 0.104501
2023-03-16 19:52:20,211 INFO     Train loss at step 80100: 0.233361
2023-03-16 19:52:39,563 INFO     Train positive_sample_loss at step 80200: 0.366910
2023-03-16 19:52:39,563 INFO     Train negative_sample_loss at step 80200: 0.104944
2023-03-16 19:52:39,563 INFO     Train loss at step 80200: 0.235927
2023-03-16 19:52:58,905 INFO     Train positive_sample_loss at step 80300: 0.369750
2023-03-16 19:52:58,905 INFO     Train negative_sample_loss at step 80300: 0.104251
2023-03-16 19:52:58,905 INFO     Train loss at step 80300: 0.237000
2023-03-16 19:53:27,716 INFO     Train positive_sample_loss at step 80400: 0.372639
2023-03-16 19:53:27,716 INFO     Train negative_sample_loss at step 80400: 0.104011
2023-03-16 19:53:27,716 INFO     Train loss at step 80400: 0.238325
2023-03-16 19:53:47,055 INFO     Train positive_sample_loss at step 80500: 0.377080
2023-03-16 19:53:47,055 INFO     Train negative_sample_loss at step 80500: 0.105706
2023-03-16 19:53:47,055 INFO     Train loss at step 80500: 0.241393
2023-03-16 19:54:06,396 INFO     Train positive_sample_loss at step 80600: 0.378702
2023-03-16 19:54:06,396 INFO     Train negative_sample_loss at step 80600: 0.105066
2023-03-16 19:54:06,396 INFO     Train loss at step 80600: 0.241884
2023-03-16 19:54:25,739 INFO     Train positive_sample_loss at step 80700: 0.379633
2023-03-16 19:54:25,739 INFO     Train negative_sample_loss at step 80700: 0.105554
2023-03-16 19:54:25,739 INFO     Train loss at step 80700: 0.242593
2023-03-16 19:54:45,077 INFO     Train positive_sample_loss at step 80800: 0.382016
2023-03-16 19:54:45,077 INFO     Train negative_sample_loss at step 80800: 0.105410
2023-03-16 19:54:45,077 INFO     Train loss at step 80800: 0.243713
2023-03-16 19:55:04,414 INFO     Train positive_sample_loss at step 80900: 0.383403
2023-03-16 19:55:04,414 INFO     Train negative_sample_loss at step 80900: 0.106827
2023-03-16 19:55:04,414 INFO     Train loss at step 80900: 0.245115
2023-03-16 19:55:23,766 INFO     Train positive_sample_loss at step 81000: 0.386220
2023-03-16 19:55:23,766 INFO     Train negative_sample_loss at step 81000: 0.106787
2023-03-16 19:55:23,766 INFO     Train loss at step 81000: 0.246504
2023-03-16 19:55:43,102 INFO     Train positive_sample_loss at step 81100: 0.387051
2023-03-16 19:55:43,102 INFO     Train negative_sample_loss at step 81100: 0.105793
2023-03-16 19:55:43,103 INFO     Train loss at step 81100: 0.246422
2023-03-16 19:56:02,436 INFO     Train positive_sample_loss at step 81200: 0.386798
2023-03-16 19:56:02,436 INFO     Train negative_sample_loss at step 81200: 0.107397
2023-03-16 19:56:02,436 INFO     Train loss at step 81200: 0.247098
2023-03-16 19:56:21,765 INFO     Train positive_sample_loss at step 81300: 0.389247
2023-03-16 19:56:21,766 INFO     Train negative_sample_loss at step 81300: 0.107915
2023-03-16 19:56:21,766 INFO     Train loss at step 81300: 0.248581
2023-03-16 19:56:41,106 INFO     Train positive_sample_loss at step 81400: 0.389764
2023-03-16 19:56:41,106 INFO     Train negative_sample_loss at step 81400: 0.107459
2023-03-16 19:56:41,106 INFO     Train loss at step 81400: 0.248612
2023-03-16 19:57:07,231 INFO     Train positive_sample_loss at step 81500: 0.390062
2023-03-16 19:57:07,232 INFO     Train negative_sample_loss at step 81500: 0.107757
2023-03-16 19:57:07,232 INFO     Train loss at step 81500: 0.248909
2023-03-16 19:57:26,562 INFO     Train positive_sample_loss at step 81600: 0.390458
2023-03-16 19:57:26,563 INFO     Train negative_sample_loss at step 81600: 0.108582
2023-03-16 19:57:26,563 INFO     Train loss at step 81600: 0.249520
2023-03-16 19:57:45,891 INFO     Train positive_sample_loss at step 81700: 0.388052
2023-03-16 19:57:45,892 INFO     Train negative_sample_loss at step 81700: 0.108976
2023-03-16 19:57:45,892 INFO     Train loss at step 81700: 0.248514
2023-03-16 19:58:05,227 INFO     Train positive_sample_loss at step 81800: 0.387123
2023-03-16 19:58:05,227 INFO     Train negative_sample_loss at step 81800: 0.109257
2023-03-16 19:58:05,228 INFO     Train loss at step 81800: 0.248190
2023-03-16 19:58:24,559 INFO     Train positive_sample_loss at step 81900: 0.388816
2023-03-16 19:58:24,559 INFO     Train negative_sample_loss at step 81900: 0.108655
2023-03-16 19:58:24,559 INFO     Train loss at step 81900: 0.248736
2023-03-16 19:58:43,906 INFO     Train positive_sample_loss at step 82000: 0.388447
2023-03-16 19:58:43,906 INFO     Train negative_sample_loss at step 82000: 0.109270
2023-03-16 19:58:43,906 INFO     Train loss at step 82000: 0.248858
2023-03-16 19:59:03,246 INFO     Train positive_sample_loss at step 82100: 0.386767
2023-03-16 19:59:03,246 INFO     Train negative_sample_loss at step 82100: 0.108812
2023-03-16 19:59:03,246 INFO     Train loss at step 82100: 0.247789
2023-03-16 19:59:22,578 INFO     Train positive_sample_loss at step 82200: 0.384838
2023-03-16 19:59:22,579 INFO     Train negative_sample_loss at step 82200: 0.110141
2023-03-16 19:59:22,579 INFO     Train loss at step 82200: 0.247490
2023-03-16 19:59:41,906 INFO     Train positive_sample_loss at step 82300: 0.384976
2023-03-16 19:59:41,906 INFO     Train negative_sample_loss at step 82300: 0.109172
2023-03-16 19:59:41,906 INFO     Train loss at step 82300: 0.247074
2023-03-16 20:00:01,229 INFO     Train positive_sample_loss at step 82400: 0.383465
2023-03-16 20:00:01,229 INFO     Train negative_sample_loss at step 82400: 0.110109
2023-03-16 20:00:01,229 INFO     Train loss at step 82400: 0.246787
2023-03-16 20:00:20,567 INFO     Train positive_sample_loss at step 82500: 0.381018
2023-03-16 20:00:20,567 INFO     Train negative_sample_loss at step 82500: 0.110438
2023-03-16 20:00:20,567 INFO     Train loss at step 82500: 0.245728
2023-03-16 20:00:48,691 INFO     Train positive_sample_loss at step 82600: 0.378523
2023-03-16 20:00:48,692 INFO     Train negative_sample_loss at step 82600: 0.109966
2023-03-16 20:00:48,692 INFO     Train loss at step 82600: 0.244244
funtion time use:38802ms
2023-03-16 20:01:11,896 INFO     Train positive_sample_loss at step 82700: 0.317329
2023-03-16 20:01:11,896 INFO     Train negative_sample_loss at step 82700: 0.107679
2023-03-16 20:01:11,896 INFO     Train loss at step 82700: 0.212504
2023-03-16 20:01:31,209 INFO     Train positive_sample_loss at step 82800: 0.312403
2023-03-16 20:01:31,210 INFO     Train negative_sample_loss at step 82800: 0.105020
2023-03-16 20:01:31,210 INFO     Train loss at step 82800: 0.208712
2023-03-16 20:01:50,516 INFO     Train positive_sample_loss at step 82900: 0.317235
2023-03-16 20:01:50,516 INFO     Train negative_sample_loss at step 82900: 0.104025
2023-03-16 20:01:50,516 INFO     Train loss at step 82900: 0.210630
2023-03-16 20:02:09,832 INFO     Train positive_sample_loss at step 83000: 0.320070
2023-03-16 20:02:09,832 INFO     Train negative_sample_loss at step 83000: 0.103509
2023-03-16 20:02:09,833 INFO     Train loss at step 83000: 0.211790
2023-03-16 20:02:29,140 INFO     Train positive_sample_loss at step 83100: 0.323240
2023-03-16 20:02:29,140 INFO     Train negative_sample_loss at step 83100: 0.103229
2023-03-16 20:02:29,140 INFO     Train loss at step 83100: 0.213234
2023-03-16 20:02:48,454 INFO     Train positive_sample_loss at step 83200: 0.327204
2023-03-16 20:02:48,455 INFO     Train negative_sample_loss at step 83200: 0.102865
2023-03-16 20:02:48,455 INFO     Train loss at step 83200: 0.215035
2023-03-16 20:03:15,150 INFO     Train positive_sample_loss at step 83300: 0.332492
2023-03-16 20:03:15,150 INFO     Train negative_sample_loss at step 83300: 0.103079
2023-03-16 20:03:15,150 INFO     Train loss at step 83300: 0.217786
2023-03-16 20:03:34,474 INFO     Train positive_sample_loss at step 83400: 0.336727
2023-03-16 20:03:34,474 INFO     Train negative_sample_loss at step 83400: 0.103453
2023-03-16 20:03:34,474 INFO     Train loss at step 83400: 0.220090
2023-03-16 20:03:53,797 INFO     Train positive_sample_loss at step 83500: 0.341424
2023-03-16 20:03:53,797 INFO     Train negative_sample_loss at step 83500: 0.103239
2023-03-16 20:03:53,797 INFO     Train loss at step 83500: 0.222331
2023-03-16 20:04:13,129 INFO     Train positive_sample_loss at step 83600: 0.344443
2023-03-16 20:04:13,130 INFO     Train negative_sample_loss at step 83600: 0.103058
2023-03-16 20:04:13,130 INFO     Train loss at step 83600: 0.223751
2023-03-16 20:04:32,451 INFO     Train positive_sample_loss at step 83700: 0.348993
2023-03-16 20:04:32,451 INFO     Train negative_sample_loss at step 83700: 0.103360
2023-03-16 20:04:32,451 INFO     Train loss at step 83700: 0.226176
2023-03-16 20:04:51,770 INFO     Train positive_sample_loss at step 83800: 0.353195
2023-03-16 20:04:51,771 INFO     Train negative_sample_loss at step 83800: 0.103481
2023-03-16 20:04:51,771 INFO     Train loss at step 83800: 0.228338
2023-03-16 20:05:11,096 INFO     Train positive_sample_loss at step 83900: 0.358105
2023-03-16 20:05:11,096 INFO     Train negative_sample_loss at step 83900: 0.104005
2023-03-16 20:05:11,097 INFO     Train loss at step 83900: 0.231055
2023-03-16 20:05:30,421 INFO     Train positive_sample_loss at step 84000: 0.360674
2023-03-16 20:05:30,421 INFO     Train negative_sample_loss at step 84000: 0.104512
2023-03-16 20:05:30,422 INFO     Train loss at step 84000: 0.232593
2023-03-16 20:05:49,751 INFO     Train positive_sample_loss at step 84100: 0.365581
2023-03-16 20:05:49,752 INFO     Train negative_sample_loss at step 84100: 0.104130
2023-03-16 20:05:49,752 INFO     Train loss at step 84100: 0.234856
2023-03-16 20:06:09,086 INFO     Train positive_sample_loss at step 84200: 0.370783
2023-03-16 20:06:09,086 INFO     Train negative_sample_loss at step 84200: 0.104378
2023-03-16 20:06:09,086 INFO     Train loss at step 84200: 0.237580
2023-03-16 20:06:35,456 INFO     Train positive_sample_loss at step 84300: 0.372559
2023-03-16 20:06:35,456 INFO     Train negative_sample_loss at step 84300: 0.104118
2023-03-16 20:06:35,457 INFO     Train loss at step 84300: 0.238338
2023-03-16 20:06:54,784 INFO     Train positive_sample_loss at step 84400: 0.376046
2023-03-16 20:06:54,784 INFO     Train negative_sample_loss at step 84400: 0.105617
2023-03-16 20:06:54,784 INFO     Train loss at step 84400: 0.240832
2023-03-16 20:07:14,110 INFO     Train positive_sample_loss at step 84500: 0.378030
2023-03-16 20:07:14,111 INFO     Train negative_sample_loss at step 84500: 0.105160
2023-03-16 20:07:14,111 INFO     Train loss at step 84500: 0.241595
2023-03-16 20:07:33,438 INFO     Train positive_sample_loss at step 84600: 0.378917
2023-03-16 20:07:33,438 INFO     Train negative_sample_loss at step 84600: 0.105134
2023-03-16 20:07:33,438 INFO     Train loss at step 84600: 0.242026
2023-03-16 20:07:52,768 INFO     Train positive_sample_loss at step 84700: 0.380523
2023-03-16 20:07:52,769 INFO     Train negative_sample_loss at step 84700: 0.106112
2023-03-16 20:07:52,769 INFO     Train loss at step 84700: 0.243317
2023-03-16 20:08:12,098 INFO     Train positive_sample_loss at step 84800: 0.384995
2023-03-16 20:08:12,099 INFO     Train negative_sample_loss at step 84800: 0.106224
2023-03-16 20:08:12,099 INFO     Train loss at step 84800: 0.245610
2023-03-16 20:08:31,428 INFO     Train positive_sample_loss at step 84900: 0.385503
2023-03-16 20:08:31,428 INFO     Train negative_sample_loss at step 84900: 0.106432
2023-03-16 20:08:31,428 INFO     Train loss at step 84900: 0.245967
2023-03-16 20:08:50,767 INFO     Train positive_sample_loss at step 85000: 0.386704
2023-03-16 20:08:50,768 INFO     Train negative_sample_loss at step 85000: 0.106447
2023-03-16 20:08:50,768 INFO     Train loss at step 85000: 0.246576
2023-03-16 20:09:10,101 INFO     Train positive_sample_loss at step 85100: 0.388652
2023-03-16 20:09:10,101 INFO     Train negative_sample_loss at step 85100: 0.106520
2023-03-16 20:09:10,101 INFO     Train loss at step 85100: 0.247586
2023-03-16 20:09:29,433 INFO     Train positive_sample_loss at step 85200: 0.389256
2023-03-16 20:09:29,433 INFO     Train negative_sample_loss at step 85200: 0.106733
2023-03-16 20:09:29,433 INFO     Train loss at step 85200: 0.247994
2023-03-16 20:09:48,756 INFO     Train positive_sample_loss at step 85300: 0.389212
2023-03-16 20:09:48,757 INFO     Train negative_sample_loss at step 85300: 0.108114
2023-03-16 20:09:48,757 INFO     Train loss at step 85300: 0.248663
2023-03-16 20:10:14,845 INFO     Train positive_sample_loss at step 85400: 0.388203
2023-03-16 20:10:14,845 INFO     Train negative_sample_loss at step 85400: 0.107802
2023-03-16 20:10:14,845 INFO     Train loss at step 85400: 0.248002
2023-03-16 20:10:34,176 INFO     Train positive_sample_loss at step 85500: 0.390996
2023-03-16 20:10:34,177 INFO     Train negative_sample_loss at step 85500: 0.107481
2023-03-16 20:10:34,177 INFO     Train loss at step 85500: 0.249239
2023-03-16 20:10:53,505 INFO     Train positive_sample_loss at step 85600: 0.388080
2023-03-16 20:10:53,506 INFO     Train negative_sample_loss at step 85600: 0.107827
2023-03-16 20:10:53,506 INFO     Train loss at step 85600: 0.247953
2023-03-16 20:11:12,833 INFO     Train positive_sample_loss at step 85700: 0.388093
2023-03-16 20:11:12,833 INFO     Train negative_sample_loss at step 85700: 0.108997
2023-03-16 20:11:12,833 INFO     Train loss at step 85700: 0.248545
2023-03-16 20:11:32,156 INFO     Train positive_sample_loss at step 85800: 0.386422
2023-03-16 20:11:32,156 INFO     Train negative_sample_loss at step 85800: 0.108783
2023-03-16 20:11:32,157 INFO     Train loss at step 85800: 0.247602
2023-03-16 20:11:51,483 INFO     Train positive_sample_loss at step 85900: 0.387215
2023-03-16 20:11:51,483 INFO     Train negative_sample_loss at step 85900: 0.108771
2023-03-16 20:11:51,483 INFO     Train loss at step 85900: 0.247993
2023-03-16 20:12:10,812 INFO     Train positive_sample_loss at step 86000: 0.384700
2023-03-16 20:12:10,812 INFO     Train negative_sample_loss at step 86000: 0.109218
2023-03-16 20:12:10,812 INFO     Train loss at step 86000: 0.246959
2023-03-16 20:12:30,140 INFO     Train positive_sample_loss at step 86100: 0.382909
2023-03-16 20:12:30,141 INFO     Train negative_sample_loss at step 86100: 0.109538
2023-03-16 20:12:30,141 INFO     Train loss at step 86100: 0.246223
2023-03-16 20:12:49,467 INFO     Train positive_sample_loss at step 86200: 0.384908
2023-03-16 20:12:49,468 INFO     Train negative_sample_loss at step 86200: 0.108907
2023-03-16 20:12:49,468 INFO     Train loss at step 86200: 0.246908
2023-03-16 20:13:08,791 INFO     Train positive_sample_loss at step 86300: 0.381187
2023-03-16 20:13:08,792 INFO     Train negative_sample_loss at step 86300: 0.109793
2023-03-16 20:13:08,792 INFO     Train loss at step 86300: 0.245490
2023-03-16 20:13:28,132 INFO     Train positive_sample_loss at step 86400: 0.380261
2023-03-16 20:13:28,132 INFO     Train negative_sample_loss at step 86400: 0.109869
2023-03-16 20:13:28,132 INFO     Train loss at step 86400: 0.245065
2023-03-16 20:13:54,275 INFO     Train positive_sample_loss at step 86500: 0.380790
2023-03-16 20:13:54,275 INFO     Train negative_sample_loss at step 86500: 0.109472
2023-03-16 20:13:54,275 INFO     Train loss at step 86500: 0.245131
2023-03-16 20:14:19,465 INFO     Train positive_sample_loss at step 86600: 0.341249
2023-03-16 20:14:19,466 INFO     Train negative_sample_loss at step 86600: 0.109445
2023-03-16 20:14:19,466 INFO     Train loss at step 86600: 0.225347
2023-03-16 20:14:38,784 INFO     Train positive_sample_loss at step 86700: 0.311520
2023-03-16 20:14:38,784 INFO     Train negative_sample_loss at step 86700: 0.105919
2023-03-16 20:14:38,784 INFO     Train loss at step 86700: 0.208719
2023-03-16 20:14:58,100 INFO     Train positive_sample_loss at step 86800: 0.314389
2023-03-16 20:14:58,100 INFO     Train negative_sample_loss at step 86800: 0.104230
2023-03-16 20:14:58,100 INFO     Train loss at step 86800: 0.209310
2023-03-16 20:15:17,414 INFO     Train positive_sample_loss at step 86900: 0.317446
2023-03-16 20:15:17,415 INFO     Train negative_sample_loss at step 86900: 0.103454
2023-03-16 20:15:17,415 INFO     Train loss at step 86900: 0.210450
2023-03-16 20:15:36,720 INFO     Train positive_sample_loss at step 87000: 0.321145
2023-03-16 20:15:36,720 INFO     Train negative_sample_loss at step 87000: 0.103483
2023-03-16 20:15:36,721 INFO     Train loss at step 87000: 0.212314
2023-03-16 20:15:56,028 INFO     Train positive_sample_loss at step 87100: 0.326473
2023-03-16 20:15:56,029 INFO     Train negative_sample_loss at step 87100: 0.103146
2023-03-16 20:15:56,029 INFO     Train loss at step 87100: 0.214809
2023-03-16 20:16:22,776 INFO     Train positive_sample_loss at step 87200: 0.332299
2023-03-16 20:16:22,777 INFO     Train negative_sample_loss at step 87200: 0.102697
2023-03-16 20:16:22,777 INFO     Train loss at step 87200: 0.217498
2023-03-16 20:16:42,094 INFO     Train positive_sample_loss at step 87300: 0.333869
2023-03-16 20:16:42,094 INFO     Train negative_sample_loss at step 87300: 0.102772
2023-03-16 20:16:42,094 INFO     Train loss at step 87300: 0.218321
2023-03-16 20:17:01,418 INFO     Train positive_sample_loss at step 87400: 0.340120
2023-03-16 20:17:01,418 INFO     Train negative_sample_loss at step 87400: 0.102736
2023-03-16 20:17:01,419 INFO     Train loss at step 87400: 0.221428
2023-03-16 20:17:20,745 INFO     Train positive_sample_loss at step 87500: 0.345147
2023-03-16 20:17:20,746 INFO     Train negative_sample_loss at step 87500: 0.102624
2023-03-16 20:17:20,746 INFO     Train loss at step 87500: 0.223886
2023-03-16 20:17:40,072 INFO     Train positive_sample_loss at step 87600: 0.347412
2023-03-16 20:17:40,073 INFO     Train negative_sample_loss at step 87600: 0.103464
2023-03-16 20:17:40,073 INFO     Train loss at step 87600: 0.225438
2023-03-16 20:17:59,396 INFO     Train positive_sample_loss at step 87700: 0.352684
2023-03-16 20:17:59,396 INFO     Train negative_sample_loss at step 87700: 0.103457
2023-03-16 20:17:59,396 INFO     Train loss at step 87700: 0.228071
2023-03-16 20:18:18,720 INFO     Train positive_sample_loss at step 87800: 0.355805
2023-03-16 20:18:18,720 INFO     Train negative_sample_loss at step 87800: 0.103280
2023-03-16 20:18:18,720 INFO     Train loss at step 87800: 0.229542
2023-03-16 20:18:38,058 INFO     Train positive_sample_loss at step 87900: 0.360351
2023-03-16 20:18:38,058 INFO     Train negative_sample_loss at step 87900: 0.103867
2023-03-16 20:18:38,059 INFO     Train loss at step 87900: 0.232109
2023-03-16 20:18:57,392 INFO     Train positive_sample_loss at step 88000: 0.365243
2023-03-16 20:18:57,393 INFO     Train negative_sample_loss at step 88000: 0.104133
2023-03-16 20:18:57,393 INFO     Train loss at step 88000: 0.234688
2023-03-16 20:19:16,722 INFO     Train positive_sample_loss at step 88100: 0.368828
2023-03-16 20:19:16,722 INFO     Train negative_sample_loss at step 88100: 0.104324
2023-03-16 20:19:16,722 INFO     Train loss at step 88100: 0.236576
2023-03-16 20:19:36,053 INFO     Train positive_sample_loss at step 88200: 0.370882
2023-03-16 20:19:36,054 INFO     Train negative_sample_loss at step 88200: 0.103863
2023-03-16 20:19:36,054 INFO     Train loss at step 88200: 0.237373
2023-03-16 20:20:02,497 INFO     Train positive_sample_loss at step 88300: 0.374784
2023-03-16 20:20:02,498 INFO     Train negative_sample_loss at step 88300: 0.103945
2023-03-16 20:20:02,498 INFO     Train loss at step 88300: 0.239365
2023-03-16 20:20:21,838 INFO     Train positive_sample_loss at step 88400: 0.377209
2023-03-16 20:20:21,839 INFO     Train negative_sample_loss at step 88400: 0.105044
2023-03-16 20:20:21,839 INFO     Train loss at step 88400: 0.241126
2023-03-16 20:20:41,175 INFO     Train positive_sample_loss at step 88500: 0.379901
2023-03-16 20:20:41,175 INFO     Train negative_sample_loss at step 88500: 0.105380
2023-03-16 20:20:41,175 INFO     Train loss at step 88500: 0.242641
2023-03-16 20:21:00,504 INFO     Train positive_sample_loss at step 88600: 0.381954
2023-03-16 20:21:00,505 INFO     Train negative_sample_loss at step 88600: 0.105237
2023-03-16 20:21:00,505 INFO     Train loss at step 88600: 0.243595
2023-03-16 20:21:19,828 INFO     Train positive_sample_loss at step 88700: 0.381587
2023-03-16 20:21:19,828 INFO     Train negative_sample_loss at step 88700: 0.105601
2023-03-16 20:21:19,828 INFO     Train loss at step 88700: 0.243594
2023-03-16 20:21:39,155 INFO     Train positive_sample_loss at step 88800: 0.383537
2023-03-16 20:21:39,155 INFO     Train negative_sample_loss at step 88800: 0.107051
2023-03-16 20:21:39,156 INFO     Train loss at step 88800: 0.245294
2023-03-16 20:21:58,485 INFO     Train positive_sample_loss at step 88900: 0.386248
2023-03-16 20:21:58,485 INFO     Train negative_sample_loss at step 88900: 0.105894
2023-03-16 20:21:58,486 INFO     Train loss at step 88900: 0.246071
2023-03-16 20:22:17,814 INFO     Train positive_sample_loss at step 89000: 0.387917
2023-03-16 20:22:17,814 INFO     Train negative_sample_loss at step 89000: 0.106920
2023-03-16 20:22:17,815 INFO     Train loss at step 89000: 0.247418
2023-03-16 20:22:37,149 INFO     Train positive_sample_loss at step 89100: 0.388837
2023-03-16 20:22:37,149 INFO     Train negative_sample_loss at step 89100: 0.106824
2023-03-16 20:22:37,149 INFO     Train loss at step 89100: 0.247830
2023-03-16 20:22:56,479 INFO     Train positive_sample_loss at step 89200: 0.388842
2023-03-16 20:22:56,479 INFO     Train negative_sample_loss at step 89200: 0.107495
2023-03-16 20:22:56,480 INFO     Train loss at step 89200: 0.248168
2023-03-16 20:23:22,597 INFO     Train positive_sample_loss at step 89300: 0.385703
2023-03-16 20:23:22,598 INFO     Train negative_sample_loss at step 89300: 0.107247
2023-03-16 20:23:22,598 INFO     Train loss at step 89300: 0.246475
2023-03-16 20:23:41,928 INFO     Train positive_sample_loss at step 89400: 0.388576
2023-03-16 20:23:41,928 INFO     Train negative_sample_loss at step 89400: 0.107313
2023-03-16 20:23:41,929 INFO     Train loss at step 89400: 0.247944
2023-03-16 20:24:01,257 INFO     Train positive_sample_loss at step 89500: 0.387994
2023-03-16 20:24:01,258 INFO     Train negative_sample_loss at step 89500: 0.108096
2023-03-16 20:24:01,258 INFO     Train loss at step 89500: 0.248045
2023-03-16 20:24:20,587 INFO     Train positive_sample_loss at step 89600: 0.388862
2023-03-16 20:24:20,588 INFO     Train negative_sample_loss at step 89600: 0.107730
2023-03-16 20:24:20,588 INFO     Train loss at step 89600: 0.248296
2023-03-16 20:24:39,917 INFO     Train positive_sample_loss at step 89700: 0.386940
2023-03-16 20:24:39,917 INFO     Train negative_sample_loss at step 89700: 0.108560
2023-03-16 20:24:39,917 INFO     Train loss at step 89700: 0.247750
2023-03-16 20:24:59,262 INFO     Train positive_sample_loss at step 89800: 0.386954
2023-03-16 20:24:59,262 INFO     Train negative_sample_loss at step 89800: 0.108559
2023-03-16 20:24:59,262 INFO     Train loss at step 89800: 0.247757
2023-03-16 20:25:18,604 INFO     Train positive_sample_loss at step 89900: 0.384725
2023-03-16 20:25:18,604 INFO     Train negative_sample_loss at step 89900: 0.108891
2023-03-16 20:25:18,604 INFO     Train loss at step 89900: 0.246808
2023-03-16 20:25:39,451 INFO     Train positive_sample_loss at step 90000: 0.384430
2023-03-16 20:25:39,452 INFO     Train negative_sample_loss at step 90000: 0.109234
2023-03-16 20:25:39,452 INFO     Train loss at step 90000: 0.246832
2023-03-16 20:25:39,452 INFO     Evaluating on Valid Dataset...
2023-03-16 20:25:40,469 INFO     Evaluating the model... (0/26842)
2023-03-16 20:25:42,002 INFO     Evaluating the model... (1000/26842)
2023-03-16 20:25:43,235 INFO     Evaluating the model... (2000/26842)
2023-03-16 20:25:44,463 INFO     Evaluating the model... (3000/26842)
2023-03-16 20:25:45,695 INFO     Evaluating the model... (4000/26842)
2023-03-16 20:25:46,925 INFO     Evaluating the model... (5000/26842)
2023-03-16 20:25:48,159 INFO     Evaluating the model... (6000/26842)
2023-03-16 20:25:49,395 INFO     Evaluating the model... (7000/26842)
2023-03-16 20:25:50,629 INFO     Evaluating the model... (8000/26842)
2023-03-16 20:25:51,870 INFO     Evaluating the model... (9000/26842)
2023-03-16 20:25:53,101 INFO     Evaluating the model... (10000/26842)
2023-03-16 20:25:54,332 INFO     Evaluating the model... (11000/26842)
2023-03-16 20:25:55,563 INFO     Evaluating the model... (12000/26842)
2023-03-16 20:25:56,790 INFO     Evaluating the model... (13000/26842)
2023-03-16 20:25:59,061 INFO     Evaluating the model... (14000/26842)
2023-03-16 20:26:00,533 INFO     Evaluating the model... (15000/26842)
2023-03-16 20:26:01,991 INFO     Evaluating the model... (16000/26842)
2023-03-16 20:26:03,453 INFO     Evaluating the model... (17000/26842)
2023-03-16 20:26:04,921 INFO     Evaluating the model... (18000/26842)
2023-03-16 20:26:06,377 INFO     Evaluating the model... (19000/26842)
2023-03-16 20:26:07,837 INFO     Evaluating the model... (20000/26842)
2023-03-16 20:26:09,302 INFO     Evaluating the model... (21000/26842)
2023-03-16 20:26:10,771 INFO     Evaluating the model... (22000/26842)
2023-03-16 20:26:12,237 INFO     Evaluating the model... (23000/26842)
2023-03-16 20:26:13,705 INFO     Evaluating the model... (24000/26842)
2023-03-16 20:26:15,169 INFO     Evaluating the model... (25000/26842)
2023-03-16 20:26:16,639 INFO     Evaluating the model... (26000/26842)
2023-03-16 20:26:18,201 INFO     Valid hits@1_list at step 90000: 0.588694
2023-03-16 20:26:18,202 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 20:26:18,202 INFO     Valid hits@3_list at step 90000: 0.680221
2023-03-16 20:26:18,202 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 20:26:18,202 INFO     Valid hits@10_list at step 90000: 0.765394
2023-03-16 20:26:18,202 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 20:26:18,202 INFO     Valid mrr_list at step 90000: 0.650588
2023-03-16 20:26:37,552 INFO     Train positive_sample_loss at step 90100: 0.383974
2023-03-16 20:26:37,552 INFO     Train negative_sample_loss at step 90100: 0.109603
2023-03-16 20:26:37,553 INFO     Train loss at step 90100: 0.246788
2023-03-16 20:26:56,897 INFO     Train positive_sample_loss at step 90200: 0.383786
2023-03-16 20:26:56,897 INFO     Train negative_sample_loss at step 90200: 0.109641
2023-03-16 20:26:56,898 INFO     Train loss at step 90200: 0.246714
2023-03-16 20:27:16,242 INFO     Train positive_sample_loss at step 90300: 0.382555
2023-03-16 20:27:16,243 INFO     Train negative_sample_loss at step 90300: 0.108840
2023-03-16 20:27:16,243 INFO     Train loss at step 90300: 0.245698
2023-03-16 20:27:42,562 INFO     Train positive_sample_loss at step 90400: 0.378549
2023-03-16 20:27:42,562 INFO     Train negative_sample_loss at step 90400: 0.109477
2023-03-16 20:27:42,562 INFO     Train loss at step 90400: 0.244013
funtion time use:38567ms
2023-03-16 20:28:07,769 INFO     Train positive_sample_loss at step 90500: 0.364383
2023-03-16 20:28:07,770 INFO     Train negative_sample_loss at step 90500: 0.109515
2023-03-16 20:28:07,770 INFO     Train loss at step 90500: 0.236949
2023-03-16 20:28:27,099 INFO     Train positive_sample_loss at step 90600: 0.310237
2023-03-16 20:28:27,099 INFO     Train negative_sample_loss at step 90600: 0.106654
2023-03-16 20:28:27,100 INFO     Train loss at step 90600: 0.208446
2023-03-16 20:28:46,427 INFO     Train positive_sample_loss at step 90700: 0.315204
2023-03-16 20:28:46,428 INFO     Train negative_sample_loss at step 90700: 0.105043
2023-03-16 20:28:46,428 INFO     Train loss at step 90700: 0.210124
2023-03-16 20:29:05,734 INFO     Train positive_sample_loss at step 90800: 0.316798
2023-03-16 20:29:05,734 INFO     Train negative_sample_loss at step 90800: 0.103795
2023-03-16 20:29:05,734 INFO     Train loss at step 90800: 0.210296
2023-03-16 20:29:25,055 INFO     Train positive_sample_loss at step 90900: 0.323491
2023-03-16 20:29:25,055 INFO     Train negative_sample_loss at step 90900: 0.103005
2023-03-16 20:29:25,056 INFO     Train loss at step 90900: 0.213248
2023-03-16 20:29:44,352 INFO     Train positive_sample_loss at step 91000: 0.324173
2023-03-16 20:29:44,352 INFO     Train negative_sample_loss at step 91000: 0.102951
2023-03-16 20:29:44,352 INFO     Train loss at step 91000: 0.213562
2023-03-16 20:30:11,168 INFO     Train positive_sample_loss at step 91100: 0.329358
2023-03-16 20:30:11,168 INFO     Train negative_sample_loss at step 91100: 0.102407
2023-03-16 20:30:11,169 INFO     Train loss at step 91100: 0.215882
2023-03-16 20:30:30,501 INFO     Train positive_sample_loss at step 91200: 0.334323
2023-03-16 20:30:30,501 INFO     Train negative_sample_loss at step 91200: 0.102872
2023-03-16 20:30:30,501 INFO     Train loss at step 91200: 0.218597
2023-03-16 20:30:49,835 INFO     Train positive_sample_loss at step 91300: 0.337685
2023-03-16 20:30:49,835 INFO     Train negative_sample_loss at step 91300: 0.102918
2023-03-16 20:30:49,836 INFO     Train loss at step 91300: 0.220302
2023-03-16 20:31:09,165 INFO     Train positive_sample_loss at step 91400: 0.343474
2023-03-16 20:31:09,166 INFO     Train negative_sample_loss at step 91400: 0.103131
2023-03-16 20:31:09,166 INFO     Train loss at step 91400: 0.223302
2023-03-16 20:31:28,485 INFO     Train positive_sample_loss at step 91500: 0.346712
2023-03-16 20:31:28,486 INFO     Train negative_sample_loss at step 91500: 0.103064
2023-03-16 20:31:28,486 INFO     Train loss at step 91500: 0.224888
2023-03-16 20:31:47,811 INFO     Train positive_sample_loss at step 91600: 0.350180
2023-03-16 20:31:47,812 INFO     Train negative_sample_loss at step 91600: 0.103765
2023-03-16 20:31:47,812 INFO     Train loss at step 91600: 0.226973
2023-03-16 20:32:07,142 INFO     Train positive_sample_loss at step 91700: 0.354162
2023-03-16 20:32:07,143 INFO     Train negative_sample_loss at step 91700: 0.103535
2023-03-16 20:32:07,143 INFO     Train loss at step 91700: 0.228849
2023-03-16 20:32:26,484 INFO     Train positive_sample_loss at step 91800: 0.357969
2023-03-16 20:32:26,484 INFO     Train negative_sample_loss at step 91800: 0.103768
2023-03-16 20:32:26,485 INFO     Train loss at step 91800: 0.230868
2023-03-16 20:32:45,818 INFO     Train positive_sample_loss at step 91900: 0.363367
2023-03-16 20:32:45,818 INFO     Train negative_sample_loss at step 91900: 0.103732
2023-03-16 20:32:45,818 INFO     Train loss at step 91900: 0.233549
2023-03-16 20:33:05,152 INFO     Train positive_sample_loss at step 92000: 0.366754
2023-03-16 20:33:05,152 INFO     Train negative_sample_loss at step 92000: 0.104526
2023-03-16 20:33:05,152 INFO     Train loss at step 92000: 0.235640
2023-03-16 20:33:24,492 INFO     Train positive_sample_loss at step 92100: 0.369975
2023-03-16 20:33:24,493 INFO     Train negative_sample_loss at step 92100: 0.104477
2023-03-16 20:33:24,493 INFO     Train loss at step 92100: 0.237226
2023-03-16 20:33:50,844 INFO     Train positive_sample_loss at step 92200: 0.374009
2023-03-16 20:33:50,845 INFO     Train negative_sample_loss at step 92200: 0.105018
2023-03-16 20:33:50,845 INFO     Train loss at step 92200: 0.239514
2023-03-16 20:34:10,173 INFO     Train positive_sample_loss at step 92300: 0.377487
2023-03-16 20:34:10,173 INFO     Train negative_sample_loss at step 92300: 0.105359
2023-03-16 20:34:10,174 INFO     Train loss at step 92300: 0.241423
2023-03-16 20:34:29,503 INFO     Train positive_sample_loss at step 92400: 0.376803
2023-03-16 20:34:29,503 INFO     Train negative_sample_loss at step 92400: 0.105041
2023-03-16 20:34:29,503 INFO     Train loss at step 92400: 0.240922
2023-03-16 20:34:48,830 INFO     Train positive_sample_loss at step 92500: 0.381196
2023-03-16 20:34:48,830 INFO     Train negative_sample_loss at step 92500: 0.104955
2023-03-16 20:34:48,830 INFO     Train loss at step 92500: 0.243076
2023-03-16 20:35:08,157 INFO     Train positive_sample_loss at step 92600: 0.382443
2023-03-16 20:35:08,157 INFO     Train negative_sample_loss at step 92600: 0.105513
2023-03-16 20:35:08,157 INFO     Train loss at step 92600: 0.243978
2023-03-16 20:35:27,485 INFO     Train positive_sample_loss at step 92700: 0.385431
2023-03-16 20:35:27,485 INFO     Train negative_sample_loss at step 92700: 0.106440
2023-03-16 20:35:27,485 INFO     Train loss at step 92700: 0.245935
2023-03-16 20:35:46,817 INFO     Train positive_sample_loss at step 92800: 0.387206
2023-03-16 20:35:46,818 INFO     Train negative_sample_loss at step 92800: 0.106273
2023-03-16 20:35:46,818 INFO     Train loss at step 92800: 0.246740
2023-03-16 20:36:06,147 INFO     Train positive_sample_loss at step 92900: 0.386328
2023-03-16 20:36:06,148 INFO     Train negative_sample_loss at step 92900: 0.107127
2023-03-16 20:36:06,148 INFO     Train loss at step 92900: 0.246728
2023-03-16 20:36:25,471 INFO     Train positive_sample_loss at step 93000: 0.391635
2023-03-16 20:36:25,471 INFO     Train negative_sample_loss at step 93000: 0.107360
2023-03-16 20:36:25,472 INFO     Train loss at step 93000: 0.249498
2023-03-16 20:36:44,794 INFO     Train positive_sample_loss at step 93100: 0.389392
2023-03-16 20:36:44,794 INFO     Train negative_sample_loss at step 93100: 0.106092
2023-03-16 20:36:44,795 INFO     Train loss at step 93100: 0.247742
2023-03-16 20:37:10,982 INFO     Train positive_sample_loss at step 93200: 0.387382
2023-03-16 20:37:10,983 INFO     Train negative_sample_loss at step 93200: 0.107174
2023-03-16 20:37:10,983 INFO     Train loss at step 93200: 0.247278
2023-03-16 20:37:30,320 INFO     Train positive_sample_loss at step 93300: 0.389596
2023-03-16 20:37:30,320 INFO     Train negative_sample_loss at step 93300: 0.107129
2023-03-16 20:37:30,321 INFO     Train loss at step 93300: 0.248363
2023-03-16 20:37:49,653 INFO     Train positive_sample_loss at step 93400: 0.387975
2023-03-16 20:37:49,654 INFO     Train negative_sample_loss at step 93400: 0.107956
2023-03-16 20:37:49,654 INFO     Train loss at step 93400: 0.247966
2023-03-16 20:38:08,990 INFO     Train positive_sample_loss at step 93500: 0.389109
2023-03-16 20:38:08,990 INFO     Train negative_sample_loss at step 93500: 0.107909
2023-03-16 20:38:08,990 INFO     Train loss at step 93500: 0.248509
2023-03-16 20:38:28,324 INFO     Train positive_sample_loss at step 93600: 0.389042
2023-03-16 20:38:28,324 INFO     Train negative_sample_loss at step 93600: 0.108925
2023-03-16 20:38:28,324 INFO     Train loss at step 93600: 0.248984
2023-03-16 20:38:47,664 INFO     Train positive_sample_loss at step 93700: 0.388132
2023-03-16 20:38:47,664 INFO     Train negative_sample_loss at step 93700: 0.107892
2023-03-16 20:38:47,665 INFO     Train loss at step 93700: 0.248012
2023-03-16 20:39:07,003 INFO     Train positive_sample_loss at step 93800: 0.387483
2023-03-16 20:39:07,004 INFO     Train negative_sample_loss at step 93800: 0.108421
2023-03-16 20:39:07,004 INFO     Train loss at step 93800: 0.247952
2023-03-16 20:39:26,339 INFO     Train positive_sample_loss at step 93900: 0.384685
2023-03-16 20:39:26,339 INFO     Train negative_sample_loss at step 93900: 0.108951
2023-03-16 20:39:26,339 INFO     Train loss at step 93900: 0.246818
2023-03-16 20:39:45,668 INFO     Train positive_sample_loss at step 94000: 0.384136
2023-03-16 20:39:45,669 INFO     Train negative_sample_loss at step 94000: 0.108977
2023-03-16 20:39:45,669 INFO     Train loss at step 94000: 0.246556
2023-03-16 20:40:04,995 INFO     Train positive_sample_loss at step 94100: 0.382256
2023-03-16 20:40:04,995 INFO     Train negative_sample_loss at step 94100: 0.109146
2023-03-16 20:40:04,996 INFO     Train loss at step 94100: 0.245701
2023-03-16 20:40:24,329 INFO     Train positive_sample_loss at step 94200: 0.382407
2023-03-16 20:40:24,329 INFO     Train negative_sample_loss at step 94200: 0.109445
2023-03-16 20:40:24,329 INFO     Train loss at step 94200: 0.245926
2023-03-16 20:40:50,700 INFO     Train positive_sample_loss at step 94300: 0.381212
2023-03-16 20:40:50,700 INFO     Train negative_sample_loss at step 94300: 0.109746
2023-03-16 20:40:50,700 INFO     Train loss at step 94300: 0.245479
2023-03-16 20:41:11,888 INFO     Train positive_sample_loss at step 94400: 0.378085
2023-03-16 20:41:11,888 INFO     Train negative_sample_loss at step 94400: 0.110392
2023-03-16 20:41:11,888 INFO     Train loss at step 94400: 0.244238
2023-03-16 20:41:35,239 INFO     Train positive_sample_loss at step 94500: 0.318056
2023-03-16 20:41:35,240 INFO     Train negative_sample_loss at step 94500: 0.107854
2023-03-16 20:41:35,240 INFO     Train loss at step 94500: 0.212955
2023-03-16 20:41:54,555 INFO     Train positive_sample_loss at step 94600: 0.313149
2023-03-16 20:41:54,555 INFO     Train negative_sample_loss at step 94600: 0.104575
2023-03-16 20:41:54,555 INFO     Train loss at step 94600: 0.208862
2023-03-16 20:42:13,860 INFO     Train positive_sample_loss at step 94700: 0.315653
2023-03-16 20:42:13,861 INFO     Train negative_sample_loss at step 94700: 0.103885
2023-03-16 20:42:13,861 INFO     Train loss at step 94700: 0.209769
2023-03-16 20:42:33,166 INFO     Train positive_sample_loss at step 94800: 0.317616
2023-03-16 20:42:33,166 INFO     Train negative_sample_loss at step 94800: 0.103387
2023-03-16 20:42:33,166 INFO     Train loss at step 94800: 0.210502
2023-03-16 20:42:52,482 INFO     Train positive_sample_loss at step 94900: 0.324242
2023-03-16 20:42:52,482 INFO     Train negative_sample_loss at step 94900: 0.103228
2023-03-16 20:42:52,482 INFO     Train loss at step 94900: 0.213735
2023-03-16 20:43:19,360 INFO     Train positive_sample_loss at step 95000: 0.327127
2023-03-16 20:43:19,361 INFO     Train negative_sample_loss at step 95000: 0.102572
2023-03-16 20:43:19,361 INFO     Train loss at step 95000: 0.214850
2023-03-16 20:43:38,677 INFO     Train positive_sample_loss at step 95100: 0.332205
2023-03-16 20:43:38,677 INFO     Train negative_sample_loss at step 95100: 0.103060
2023-03-16 20:43:38,677 INFO     Train loss at step 95100: 0.217632
2023-03-16 20:43:57,999 INFO     Train positive_sample_loss at step 95200: 0.335777
2023-03-16 20:43:57,999 INFO     Train negative_sample_loss at step 95200: 0.102573
2023-03-16 20:43:57,999 INFO     Train loss at step 95200: 0.219175
2023-03-16 20:44:17,300 INFO     Train positive_sample_loss at step 95300: 0.341035
2023-03-16 20:44:17,300 INFO     Train negative_sample_loss at step 95300: 0.102531
2023-03-16 20:44:17,300 INFO     Train loss at step 95300: 0.221783
2023-03-16 20:44:36,601 INFO     Train positive_sample_loss at step 95400: 0.343515
2023-03-16 20:44:36,602 INFO     Train negative_sample_loss at step 95400: 0.103205
2023-03-16 20:44:36,602 INFO     Train loss at step 95400: 0.223360
2023-03-16 20:44:55,903 INFO     Train positive_sample_loss at step 95500: 0.350144
2023-03-16 20:44:55,904 INFO     Train negative_sample_loss at step 95500: 0.103001
2023-03-16 20:44:55,904 INFO     Train loss at step 95500: 0.226572
2023-03-16 20:45:15,215 INFO     Train positive_sample_loss at step 95600: 0.351784
2023-03-16 20:45:15,215 INFO     Train negative_sample_loss at step 95600: 0.103630
2023-03-16 20:45:15,215 INFO     Train loss at step 95600: 0.227707
2023-03-16 20:45:34,541 INFO     Train positive_sample_loss at step 95700: 0.356210
2023-03-16 20:45:34,542 INFO     Train negative_sample_loss at step 95700: 0.104230
2023-03-16 20:45:34,542 INFO     Train loss at step 95700: 0.230220
2023-03-16 20:45:53,873 INFO     Train positive_sample_loss at step 95800: 0.361337
2023-03-16 20:45:53,873 INFO     Train negative_sample_loss at step 95800: 0.103951
2023-03-16 20:45:53,873 INFO     Train loss at step 95800: 0.232644
2023-03-16 20:46:13,250 INFO     Train positive_sample_loss at step 95900: 0.366108
2023-03-16 20:46:13,250 INFO     Train negative_sample_loss at step 95900: 0.103892
2023-03-16 20:46:13,250 INFO     Train loss at step 95900: 0.235000
2023-03-16 20:46:32,627 INFO     Train positive_sample_loss at step 96000: 0.367853
2023-03-16 20:46:32,627 INFO     Train negative_sample_loss at step 96000: 0.104669
2023-03-16 20:46:32,627 INFO     Train loss at step 96000: 0.236261
2023-03-16 20:46:58,972 INFO     Train positive_sample_loss at step 96100: 0.371888
2023-03-16 20:46:58,972 INFO     Train negative_sample_loss at step 96100: 0.103785
2023-03-16 20:46:58,972 INFO     Train loss at step 96100: 0.237836
2023-03-16 20:47:18,393 INFO     Train positive_sample_loss at step 96200: 0.374988
2023-03-16 20:47:18,393 INFO     Train negative_sample_loss at step 96200: 0.105051
2023-03-16 20:47:18,393 INFO     Train loss at step 96200: 0.240019
2023-03-16 20:47:37,807 INFO     Train positive_sample_loss at step 96300: 0.379261
2023-03-16 20:47:37,807 INFO     Train negative_sample_loss at step 96300: 0.104766
2023-03-16 20:47:37,808 INFO     Train loss at step 96300: 0.242014
2023-03-16 20:47:57,246 INFO     Train positive_sample_loss at step 96400: 0.379360
2023-03-16 20:47:57,247 INFO     Train negative_sample_loss at step 96400: 0.105314
2023-03-16 20:47:57,247 INFO     Train loss at step 96400: 0.242337
2023-03-16 20:48:16,676 INFO     Train positive_sample_loss at step 96500: 0.381359
2023-03-16 20:48:16,677 INFO     Train negative_sample_loss at step 96500: 0.106000
2023-03-16 20:48:16,677 INFO     Train loss at step 96500: 0.243680
2023-03-16 20:48:36,110 INFO     Train positive_sample_loss at step 96600: 0.382528
2023-03-16 20:48:36,110 INFO     Train negative_sample_loss at step 96600: 0.106180
2023-03-16 20:48:36,110 INFO     Train loss at step 96600: 0.244354
2023-03-16 20:48:55,544 INFO     Train positive_sample_loss at step 96700: 0.386634
2023-03-16 20:48:55,544 INFO     Train negative_sample_loss at step 96700: 0.105809
2023-03-16 20:48:55,544 INFO     Train loss at step 96700: 0.246222
2023-03-16 20:49:14,964 INFO     Train positive_sample_loss at step 96800: 0.385259
2023-03-16 20:49:14,964 INFO     Train negative_sample_loss at step 96800: 0.105871
2023-03-16 20:49:14,964 INFO     Train loss at step 96800: 0.245565
2023-03-16 20:49:34,402 INFO     Train positive_sample_loss at step 96900: 0.388007
2023-03-16 20:49:34,403 INFO     Train negative_sample_loss at step 96900: 0.106978
2023-03-16 20:49:34,403 INFO     Train loss at step 96900: 0.247492
2023-03-16 20:49:53,848 INFO     Train positive_sample_loss at step 97000: 0.386462
2023-03-16 20:49:53,848 INFO     Train negative_sample_loss at step 97000: 0.106923
2023-03-16 20:49:53,849 INFO     Train loss at step 97000: 0.246692
2023-03-16 20:50:13,283 INFO     Train positive_sample_loss at step 97100: 0.388290
2023-03-16 20:50:13,283 INFO     Train negative_sample_loss at step 97100: 0.107552
2023-03-16 20:50:13,283 INFO     Train loss at step 97100: 0.247921
2023-03-16 20:50:39,814 INFO     Train positive_sample_loss at step 97200: 0.388303
2023-03-16 20:50:39,814 INFO     Train negative_sample_loss at step 97200: 0.107745
2023-03-16 20:50:39,815 INFO     Train loss at step 97200: 0.248024
2023-03-16 20:50:59,282 INFO     Train positive_sample_loss at step 97300: 0.389448
2023-03-16 20:50:59,282 INFO     Train negative_sample_loss at step 97300: 0.107533
2023-03-16 20:50:59,282 INFO     Train loss at step 97300: 0.248491
2023-03-16 20:51:18,715 INFO     Train positive_sample_loss at step 97400: 0.388584
2023-03-16 20:51:18,715 INFO     Train negative_sample_loss at step 97400: 0.107828
2023-03-16 20:51:18,715 INFO     Train loss at step 97400: 0.248206
2023-03-16 20:51:38,139 INFO     Train positive_sample_loss at step 97500: 0.387520
2023-03-16 20:51:38,140 INFO     Train negative_sample_loss at step 97500: 0.108328
2023-03-16 20:51:38,140 INFO     Train loss at step 97500: 0.247924
2023-03-16 20:51:57,570 INFO     Train positive_sample_loss at step 97600: 0.387522
2023-03-16 20:51:57,570 INFO     Train negative_sample_loss at step 97600: 0.108366
2023-03-16 20:51:57,570 INFO     Train loss at step 97600: 0.247944
2023-03-16 20:52:16,990 INFO     Train positive_sample_loss at step 97700: 0.385410
2023-03-16 20:52:16,991 INFO     Train negative_sample_loss at step 97700: 0.108804
2023-03-16 20:52:16,991 INFO     Train loss at step 97700: 0.247107
2023-03-16 20:52:36,433 INFO     Train positive_sample_loss at step 97800: 0.388524
2023-03-16 20:52:36,434 INFO     Train negative_sample_loss at step 97800: 0.108916
2023-03-16 20:52:36,434 INFO     Train loss at step 97800: 0.248720
2023-03-16 20:52:55,876 INFO     Train positive_sample_loss at step 97900: 0.384217
2023-03-16 20:52:55,877 INFO     Train negative_sample_loss at step 97900: 0.108939
2023-03-16 20:52:55,877 INFO     Train loss at step 97900: 0.246578
2023-03-16 20:53:15,312 INFO     Train positive_sample_loss at step 98000: 0.385770
2023-03-16 20:53:15,312 INFO     Train negative_sample_loss at step 98000: 0.109421
2023-03-16 20:53:15,312 INFO     Train loss at step 98000: 0.247596
2023-03-16 20:53:34,757 INFO     Train positive_sample_loss at step 98100: 0.382538
2023-03-16 20:53:34,758 INFO     Train negative_sample_loss at step 98100: 0.109230
2023-03-16 20:53:34,758 INFO     Train loss at step 98100: 0.245884
2023-03-16 20:54:01,116 INFO     Train positive_sample_loss at step 98200: 0.381036
2023-03-16 20:54:01,117 INFO     Train negative_sample_loss at step 98200: 0.109751
2023-03-16 20:54:01,117 INFO     Train loss at step 98200: 0.245393
2023-03-16 20:54:20,544 INFO     Train positive_sample_loss at step 98300: 0.381616
2023-03-16 20:54:20,544 INFO     Train negative_sample_loss at step 98300: 0.109538
2023-03-16 20:54:20,544 INFO     Train loss at step 98300: 0.245577
2023-03-16 20:54:45,846 INFO     Train positive_sample_loss at step 98400: 0.341725
2023-03-16 20:54:45,847 INFO     Train negative_sample_loss at step 98400: 0.108792
2023-03-16 20:54:45,847 INFO     Train loss at step 98400: 0.225259
2023-03-16 20:55:05,181 INFO     Train positive_sample_loss at step 98500: 0.311834
2023-03-16 20:55:05,181 INFO     Train negative_sample_loss at step 98500: 0.105488
2023-03-16 20:55:05,181 INFO     Train loss at step 98500: 0.208661
2023-03-16 20:55:24,516 INFO     Train positive_sample_loss at step 98600: 0.314840
2023-03-16 20:55:24,516 INFO     Train negative_sample_loss at step 98600: 0.104513
2023-03-16 20:55:24,516 INFO     Train loss at step 98600: 0.209677
2023-03-16 20:55:43,839 INFO     Train positive_sample_loss at step 98700: 0.319322
2023-03-16 20:55:43,839 INFO     Train negative_sample_loss at step 98700: 0.103617
2023-03-16 20:55:43,839 INFO     Train loss at step 98700: 0.211470
2023-03-16 20:56:03,162 INFO     Train positive_sample_loss at step 98800: 0.323024
2023-03-16 20:56:03,162 INFO     Train negative_sample_loss at step 98800: 0.103684
2023-03-16 20:56:03,162 INFO     Train loss at step 98800: 0.213354
2023-03-16 20:56:22,490 INFO     Train positive_sample_loss at step 98900: 0.327135
2023-03-16 20:56:22,490 INFO     Train negative_sample_loss at step 98900: 0.102834
2023-03-16 20:56:22,490 INFO     Train loss at step 98900: 0.214984
2023-03-16 20:56:49,408 INFO     Train positive_sample_loss at step 99000: 0.330749
2023-03-16 20:56:49,409 INFO     Train negative_sample_loss at step 99000: 0.103285
2023-03-16 20:56:49,409 INFO     Train loss at step 99000: 0.217017
2023-03-16 20:57:08,792 INFO     Train positive_sample_loss at step 99100: 0.332275
2023-03-16 20:57:08,793 INFO     Train negative_sample_loss at step 99100: 0.102888
2023-03-16 20:57:08,793 INFO     Train loss at step 99100: 0.217582
2023-03-16 20:57:28,175 INFO     Train positive_sample_loss at step 99200: 0.341413
2023-03-16 20:57:28,176 INFO     Train negative_sample_loss at step 99200: 0.103016
2023-03-16 20:57:28,176 INFO     Train loss at step 99200: 0.222214
2023-03-16 20:57:47,572 INFO     Train positive_sample_loss at step 99300: 0.342084
2023-03-16 20:57:47,572 INFO     Train negative_sample_loss at step 99300: 0.102493
2023-03-16 20:57:47,572 INFO     Train loss at step 99300: 0.222289
2023-03-16 20:58:06,969 INFO     Train positive_sample_loss at step 99400: 0.347359
2023-03-16 20:58:06,969 INFO     Train negative_sample_loss at step 99400: 0.103500
2023-03-16 20:58:06,969 INFO     Train loss at step 99400: 0.225430
2023-03-16 20:58:26,377 INFO     Train positive_sample_loss at step 99500: 0.352707
2023-03-16 20:58:26,378 INFO     Train negative_sample_loss at step 99500: 0.102885
2023-03-16 20:58:26,378 INFO     Train loss at step 99500: 0.227796
2023-03-16 20:58:45,778 INFO     Train positive_sample_loss at step 99600: 0.356456
2023-03-16 20:58:45,778 INFO     Train negative_sample_loss at step 99600: 0.102976
2023-03-16 20:58:45,778 INFO     Train loss at step 99600: 0.229716
2023-03-16 20:59:05,186 INFO     Train positive_sample_loss at step 99700: 0.359311
2023-03-16 20:59:05,186 INFO     Train negative_sample_loss at step 99700: 0.104022
2023-03-16 20:59:05,186 INFO     Train loss at step 99700: 0.231667
2023-03-16 20:59:24,584 INFO     Train positive_sample_loss at step 99800: 0.363503
2023-03-16 20:59:24,584 INFO     Train negative_sample_loss at step 99800: 0.104104
2023-03-16 20:59:24,584 INFO     Train loss at step 99800: 0.233803
2023-03-16 20:59:43,996 INFO     Train positive_sample_loss at step 99900: 0.366483
2023-03-16 20:59:43,996 INFO     Train negative_sample_loss at step 99900: 0.104004
2023-03-16 20:59:43,997 INFO     Train loss at step 99900: 0.235244
2023-03-16 21:00:12,160 INFO     Train positive_sample_loss at step 100000: 0.369218
2023-03-16 21:00:12,161 INFO     Train negative_sample_loss at step 100000: 0.104432
2023-03-16 21:00:12,161 INFO     Train loss at step 100000: 0.236825
2023-03-16 21:00:12,161 INFO     Evaluating on Valid Dataset...
2023-03-16 21:00:13,146 INFO     Evaluating the model... (0/26842)
2023-03-16 21:00:14,801 INFO     Evaluating the model... (1000/26842)
2023-03-16 21:00:16,046 INFO     Evaluating the model... (2000/26842)
2023-03-16 21:00:17,288 INFO     Evaluating the model... (3000/26842)
2023-03-16 21:00:18,530 INFO     Evaluating the model... (4000/26842)
2023-03-16 21:00:19,779 INFO     Evaluating the model... (5000/26842)
2023-03-16 21:00:21,029 INFO     Evaluating the model... (6000/26842)
2023-03-16 21:00:22,279 INFO     Evaluating the model... (7000/26842)
2023-03-16 21:00:23,525 INFO     Evaluating the model... (8000/26842)
2023-03-16 21:00:24,776 INFO     Evaluating the model... (9000/26842)
2023-03-16 21:00:26,030 INFO     Evaluating the model... (10000/26842)
2023-03-16 21:00:27,276 INFO     Evaluating the model... (11000/26842)
2023-03-16 21:00:28,515 INFO     Evaluating the model... (12000/26842)
2023-03-16 21:00:29,757 INFO     Evaluating the model... (13000/26842)
2023-03-16 21:00:32,039 INFO     Evaluating the model... (14000/26842)
2023-03-16 21:00:33,524 INFO     Evaluating the model... (15000/26842)
2023-03-16 21:00:35,008 INFO     Evaluating the model... (16000/26842)
2023-03-16 21:00:36,489 INFO     Evaluating the model... (17000/26842)
2023-03-16 21:00:37,981 INFO     Evaluating the model... (18000/26842)
2023-03-16 21:00:39,463 INFO     Evaluating the model... (19000/26842)
2023-03-16 21:00:40,939 INFO     Evaluating the model... (20000/26842)
2023-03-16 21:00:42,419 INFO     Evaluating the model... (21000/26842)
2023-03-16 21:00:43,900 INFO     Evaluating the model... (22000/26842)
2023-03-16 21:00:45,378 INFO     Evaluating the model... (23000/26842)
2023-03-16 21:00:46,855 INFO     Evaluating the model... (24000/26842)
2023-03-16 21:00:48,332 INFO     Evaluating the model... (25000/26842)
2023-03-16 21:00:49,815 INFO     Evaluating the model... (26000/26842)
2023-03-16 21:00:51,394 INFO     Valid hits@1_list at step 100000: 0.591936
2023-03-16 21:00:51,394 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 21:00:51,394 INFO     Valid hits@3_list at step 100000: 0.681750
2023-03-16 21:00:51,394 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 21:00:51,394 INFO     Valid hits@10_list at step 100000: 0.766154
2023-03-16 21:00:51,394 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 21:00:51,394 INFO     Valid mrr_list at step 100000: 0.652938
2023-03-16 21:01:10,812 INFO     Train positive_sample_loss at step 100100: 0.376088
2023-03-16 21:01:10,813 INFO     Train negative_sample_loss at step 100100: 0.104385
2023-03-16 21:01:10,813 INFO     Train loss at step 100100: 0.240236
2023-03-16 21:01:30,249 INFO     Train positive_sample_loss at step 100200: 0.377092
2023-03-16 21:01:30,250 INFO     Train negative_sample_loss at step 100200: 0.104596
2023-03-16 21:01:30,250 INFO     Train loss at step 100200: 0.240844
2023-03-16 21:01:49,675 INFO     Train positive_sample_loss at step 100300: 0.379196
2023-03-16 21:01:49,675 INFO     Train negative_sample_loss at step 100300: 0.105690
2023-03-16 21:01:49,675 INFO     Train loss at step 100300: 0.242443
2023-03-16 21:02:09,104 INFO     Train positive_sample_loss at step 100400: 0.381477
2023-03-16 21:02:09,104 INFO     Train negative_sample_loss at step 100400: 0.105198
2023-03-16 21:02:09,104 INFO     Train loss at step 100400: 0.243337
2023-03-16 21:02:28,531 INFO     Train positive_sample_loss at step 100500: 0.382930
2023-03-16 21:02:28,532 INFO     Train negative_sample_loss at step 100500: 0.105931
2023-03-16 21:02:28,532 INFO     Train loss at step 100500: 0.244430
2023-03-16 21:02:47,970 INFO     Train positive_sample_loss at step 100600: 0.385704
2023-03-16 21:02:47,970 INFO     Train negative_sample_loss at step 100600: 0.105733
2023-03-16 21:02:47,970 INFO     Train loss at step 100600: 0.245718
2023-03-16 21:03:07,393 INFO     Train positive_sample_loss at step 100700: 0.386379
2023-03-16 21:03:07,394 INFO     Train negative_sample_loss at step 100700: 0.106139
2023-03-16 21:03:07,394 INFO     Train loss at step 100700: 0.246259
2023-03-16 21:03:26,803 INFO     Train positive_sample_loss at step 100800: 0.385928
2023-03-16 21:03:26,804 INFO     Train negative_sample_loss at step 100800: 0.106613
2023-03-16 21:03:26,804 INFO     Train loss at step 100800: 0.246270
2023-03-16 21:03:46,225 INFO     Train positive_sample_loss at step 100900: 0.386474
2023-03-16 21:03:46,226 INFO     Train negative_sample_loss at step 100900: 0.106262
2023-03-16 21:03:46,226 INFO     Train loss at step 100900: 0.246368
2023-03-16 21:04:05,647 INFO     Train positive_sample_loss at step 101000: 0.390175
2023-03-16 21:04:05,648 INFO     Train negative_sample_loss at step 101000: 0.106990
2023-03-16 21:04:05,648 INFO     Train loss at step 101000: 0.248583
2023-03-16 21:04:31,997 INFO     Train positive_sample_loss at step 101100: 0.388369
2023-03-16 21:04:31,997 INFO     Train negative_sample_loss at step 101100: 0.107873
2023-03-16 21:04:31,997 INFO     Train loss at step 101100: 0.248121
2023-03-16 21:04:51,423 INFO     Train positive_sample_loss at step 101200: 0.388456
2023-03-16 21:04:51,424 INFO     Train negative_sample_loss at step 101200: 0.108097
2023-03-16 21:04:51,424 INFO     Train loss at step 101200: 0.248276
2023-03-16 21:05:10,846 INFO     Train positive_sample_loss at step 101300: 0.389454
2023-03-16 21:05:10,846 INFO     Train negative_sample_loss at step 101300: 0.107918
2023-03-16 21:05:10,846 INFO     Train loss at step 101300: 0.248686
2023-03-16 21:05:30,278 INFO     Train positive_sample_loss at step 101400: 0.388100
2023-03-16 21:05:30,278 INFO     Train negative_sample_loss at step 101400: 0.107641
2023-03-16 21:05:30,278 INFO     Train loss at step 101400: 0.247871
2023-03-16 21:05:49,700 INFO     Train positive_sample_loss at step 101500: 0.387308
2023-03-16 21:05:49,700 INFO     Train negative_sample_loss at step 101500: 0.107714
2023-03-16 21:05:49,700 INFO     Train loss at step 101500: 0.247511
2023-03-16 21:06:09,117 INFO     Train positive_sample_loss at step 101600: 0.385638
2023-03-16 21:06:09,117 INFO     Train negative_sample_loss at step 101600: 0.108568
2023-03-16 21:06:09,118 INFO     Train loss at step 101600: 0.247103
2023-03-16 21:06:28,541 INFO     Train positive_sample_loss at step 101700: 0.384364
2023-03-16 21:06:28,542 INFO     Train negative_sample_loss at step 101700: 0.108725
2023-03-16 21:06:28,542 INFO     Train loss at step 101700: 0.246544
2023-03-16 21:06:47,957 INFO     Train positive_sample_loss at step 101800: 0.384902
2023-03-16 21:06:47,958 INFO     Train negative_sample_loss at step 101800: 0.108398
2023-03-16 21:06:47,958 INFO     Train loss at step 101800: 0.246650
2023-03-16 21:07:07,378 INFO     Train positive_sample_loss at step 101900: 0.385310
2023-03-16 21:07:07,378 INFO     Train negative_sample_loss at step 101900: 0.108973
2023-03-16 21:07:07,379 INFO     Train loss at step 101900: 0.247141
2023-03-16 21:07:26,808 INFO     Train positive_sample_loss at step 102000: 0.381785
2023-03-16 21:07:26,808 INFO     Train negative_sample_loss at step 102000: 0.109110
2023-03-16 21:07:26,809 INFO     Train loss at step 102000: 0.245447
2023-03-16 21:07:46,237 INFO     Train positive_sample_loss at step 102100: 0.381468
2023-03-16 21:07:46,237 INFO     Train negative_sample_loss at step 102100: 0.108927
2023-03-16 21:07:46,237 INFO     Train loss at step 102100: 0.245197
2023-03-16 21:08:12,709 INFO     Train positive_sample_loss at step 102200: 0.378845
2023-03-16 21:08:12,710 INFO     Train negative_sample_loss at step 102200: 0.109252
2023-03-16 21:08:12,710 INFO     Train loss at step 102200: 0.244048
funtion time use:39053ms
2023-03-16 21:08:38,242 INFO     Train positive_sample_loss at step 102300: 0.365101
2023-03-16 21:08:38,242 INFO     Train negative_sample_loss at step 102300: 0.109794
2023-03-16 21:08:38,243 INFO     Train loss at step 102300: 0.237447
2023-03-16 21:08:57,584 INFO     Train positive_sample_loss at step 102400: 0.309177
2023-03-16 21:08:57,585 INFO     Train negative_sample_loss at step 102400: 0.105866
2023-03-16 21:08:57,585 INFO     Train loss at step 102400: 0.207521
2023-03-16 21:09:16,922 INFO     Train positive_sample_loss at step 102500: 0.312951
2023-03-16 21:09:16,922 INFO     Train negative_sample_loss at step 102500: 0.104611
2023-03-16 21:09:16,923 INFO     Train loss at step 102500: 0.208781
2023-03-16 21:09:36,248 INFO     Train positive_sample_loss at step 102600: 0.316534
2023-03-16 21:09:36,249 INFO     Train negative_sample_loss at step 102600: 0.103379
2023-03-16 21:09:36,249 INFO     Train loss at step 102600: 0.209956
2023-03-16 21:09:55,588 INFO     Train positive_sample_loss at step 102700: 0.319432
2023-03-16 21:09:55,588 INFO     Train negative_sample_loss at step 102700: 0.102964
2023-03-16 21:09:55,589 INFO     Train loss at step 102700: 0.211198
2023-03-16 21:10:14,926 INFO     Train positive_sample_loss at step 102800: 0.322235
2023-03-16 21:10:14,927 INFO     Train negative_sample_loss at step 102800: 0.102530
2023-03-16 21:10:14,927 INFO     Train loss at step 102800: 0.212383
2023-03-16 21:10:41,859 INFO     Train positive_sample_loss at step 102900: 0.329669
2023-03-16 21:10:41,859 INFO     Train negative_sample_loss at step 102900: 0.102618
2023-03-16 21:10:41,859 INFO     Train loss at step 102900: 0.216144
2023-03-16 21:11:01,239 INFO     Train positive_sample_loss at step 103000: 0.332951
2023-03-16 21:11:01,239 INFO     Train negative_sample_loss at step 103000: 0.102904
2023-03-16 21:11:01,240 INFO     Train loss at step 103000: 0.217927
2023-03-16 21:11:20,627 INFO     Train positive_sample_loss at step 103100: 0.339663
2023-03-16 21:11:20,628 INFO     Train negative_sample_loss at step 103100: 0.103310
2023-03-16 21:11:20,628 INFO     Train loss at step 103100: 0.221487
2023-03-16 21:11:40,025 INFO     Train positive_sample_loss at step 103200: 0.342710
2023-03-16 21:11:40,026 INFO     Train negative_sample_loss at step 103200: 0.102813
2023-03-16 21:11:40,026 INFO     Train loss at step 103200: 0.222761
2023-03-16 21:11:59,420 INFO     Train positive_sample_loss at step 103300: 0.346631
2023-03-16 21:11:59,421 INFO     Train negative_sample_loss at step 103300: 0.103240
2023-03-16 21:11:59,421 INFO     Train loss at step 103300: 0.224935
2023-03-16 21:12:18,829 INFO     Train positive_sample_loss at step 103400: 0.352500
2023-03-16 21:12:18,829 INFO     Train negative_sample_loss at step 103400: 0.102712
2023-03-16 21:12:18,829 INFO     Train loss at step 103400: 0.227606
2023-03-16 21:12:38,234 INFO     Train positive_sample_loss at step 103500: 0.354228
2023-03-16 21:12:38,235 INFO     Train negative_sample_loss at step 103500: 0.103013
2023-03-16 21:12:38,235 INFO     Train loss at step 103500: 0.228621
2023-03-16 21:12:57,644 INFO     Train positive_sample_loss at step 103600: 0.357935
2023-03-16 21:12:57,644 INFO     Train negative_sample_loss at step 103600: 0.103301
2023-03-16 21:12:57,644 INFO     Train loss at step 103600: 0.230618
2023-03-16 21:13:17,052 INFO     Train positive_sample_loss at step 103700: 0.362953
2023-03-16 21:13:17,052 INFO     Train negative_sample_loss at step 103700: 0.103626
2023-03-16 21:13:17,053 INFO     Train loss at step 103700: 0.233289
2023-03-16 21:13:36,464 INFO     Train positive_sample_loss at step 103800: 0.365700
2023-03-16 21:13:36,464 INFO     Train negative_sample_loss at step 103800: 0.103675
2023-03-16 21:13:36,465 INFO     Train loss at step 103800: 0.234687
2023-03-16 21:14:02,590 INFO     Train positive_sample_loss at step 103900: 0.369679
2023-03-16 21:14:02,590 INFO     Train negative_sample_loss at step 103900: 0.104088
2023-03-16 21:14:02,603 INFO     Train loss at step 103900: 0.236884
2023-03-16 21:14:22,324 INFO     Train positive_sample_loss at step 104000: 0.371638
2023-03-16 21:14:22,324 INFO     Train negative_sample_loss at step 104000: 0.105046
2023-03-16 21:14:22,324 INFO     Train loss at step 104000: 0.238342
2023-03-16 21:14:41,741 INFO     Train positive_sample_loss at step 104100: 0.377767
2023-03-16 21:14:41,742 INFO     Train negative_sample_loss at step 104100: 0.104887
2023-03-16 21:14:41,742 INFO     Train loss at step 104100: 0.241327
2023-03-16 21:15:01,156 INFO     Train positive_sample_loss at step 104200: 0.379647
2023-03-16 21:15:01,156 INFO     Train negative_sample_loss at step 104200: 0.104649
2023-03-16 21:15:01,156 INFO     Train loss at step 104200: 0.242148
2023-03-16 21:15:20,570 INFO     Train positive_sample_loss at step 104300: 0.380893
2023-03-16 21:15:20,571 INFO     Train negative_sample_loss at step 104300: 0.105559
2023-03-16 21:15:20,571 INFO     Train loss at step 104300: 0.243226
2023-03-16 21:15:39,990 INFO     Train positive_sample_loss at step 104400: 0.385103
2023-03-16 21:15:39,990 INFO     Train negative_sample_loss at step 104400: 0.104800
2023-03-16 21:15:39,990 INFO     Train loss at step 104400: 0.244952
2023-03-16 21:15:59,409 INFO     Train positive_sample_loss at step 104500: 0.384456
2023-03-16 21:15:59,409 INFO     Train negative_sample_loss at step 104500: 0.105349
2023-03-16 21:15:59,410 INFO     Train loss at step 104500: 0.244903
2023-03-16 21:16:18,827 INFO     Train positive_sample_loss at step 104600: 0.384068
2023-03-16 21:16:18,828 INFO     Train negative_sample_loss at step 104600: 0.105901
2023-03-16 21:16:18,828 INFO     Train loss at step 104600: 0.244985
2023-03-16 21:16:38,245 INFO     Train positive_sample_loss at step 104700: 0.387345
2023-03-16 21:16:38,245 INFO     Train negative_sample_loss at step 104700: 0.107133
2023-03-16 21:16:38,246 INFO     Train loss at step 104700: 0.247239
2023-03-16 21:16:57,673 INFO     Train positive_sample_loss at step 104800: 0.387733
2023-03-16 21:16:57,674 INFO     Train negative_sample_loss at step 104800: 0.106269
2023-03-16 21:16:57,674 INFO     Train loss at step 104800: 0.247001
2023-03-16 21:17:17,097 INFO     Train positive_sample_loss at step 104900: 0.391090
2023-03-16 21:17:17,098 INFO     Train negative_sample_loss at step 104900: 0.106908
2023-03-16 21:17:17,098 INFO     Train loss at step 104900: 0.248999
2023-03-16 21:17:43,510 INFO     Train positive_sample_loss at step 105000: 0.390169
2023-03-16 21:17:43,511 INFO     Train negative_sample_loss at step 105000: 0.107221
2023-03-16 21:17:43,511 INFO     Train loss at step 105000: 0.248695
2023-03-16 21:18:02,916 INFO     Train positive_sample_loss at step 105100: 0.389599
2023-03-16 21:18:02,916 INFO     Train negative_sample_loss at step 105100: 0.108050
2023-03-16 21:18:02,916 INFO     Train loss at step 105100: 0.248824
2023-03-16 21:18:22,328 INFO     Train positive_sample_loss at step 105200: 0.388432
2023-03-16 21:18:22,328 INFO     Train negative_sample_loss at step 105200: 0.107668
2023-03-16 21:18:22,328 INFO     Train loss at step 105200: 0.248050
2023-03-16 21:18:41,752 INFO     Train positive_sample_loss at step 105300: 0.389322
2023-03-16 21:18:41,752 INFO     Train negative_sample_loss at step 105300: 0.107952
2023-03-16 21:18:41,753 INFO     Train loss at step 105300: 0.248637
2023-03-16 21:19:01,165 INFO     Train positive_sample_loss at step 105400: 0.388541
2023-03-16 21:19:01,165 INFO     Train negative_sample_loss at step 105400: 0.108128
2023-03-16 21:19:01,166 INFO     Train loss at step 105400: 0.248334
2023-03-16 21:19:20,579 INFO     Train positive_sample_loss at step 105500: 0.388671
2023-03-16 21:19:20,579 INFO     Train negative_sample_loss at step 105500: 0.108391
2023-03-16 21:19:20,580 INFO     Train loss at step 105500: 0.248531
2023-03-16 21:19:39,993 INFO     Train positive_sample_loss at step 105600: 0.388813
2023-03-16 21:19:39,994 INFO     Train negative_sample_loss at step 105600: 0.108787
2023-03-16 21:19:39,994 INFO     Train loss at step 105600: 0.248800
2023-03-16 21:19:59,406 INFO     Train positive_sample_loss at step 105700: 0.388548
2023-03-16 21:19:59,406 INFO     Train negative_sample_loss at step 105700: 0.108581
2023-03-16 21:19:59,406 INFO     Train loss at step 105700: 0.248565
2023-03-16 21:20:18,819 INFO     Train positive_sample_loss at step 105800: 0.384668
2023-03-16 21:20:18,819 INFO     Train negative_sample_loss at step 105800: 0.108903
2023-03-16 21:20:18,819 INFO     Train loss at step 105800: 0.246785
2023-03-16 21:20:38,242 INFO     Train positive_sample_loss at step 105900: 0.385021
2023-03-16 21:20:38,243 INFO     Train negative_sample_loss at step 105900: 0.109214
2023-03-16 21:20:38,243 INFO     Train loss at step 105900: 0.247117
2023-03-16 21:20:57,660 INFO     Train positive_sample_loss at step 106000: 0.381136
2023-03-16 21:20:57,660 INFO     Train negative_sample_loss at step 106000: 0.109313
2023-03-16 21:20:57,660 INFO     Train loss at step 106000: 0.245224
2023-03-16 21:21:25,934 INFO     Train positive_sample_loss at step 106100: 0.380638
2023-03-16 21:21:25,934 INFO     Train negative_sample_loss at step 106100: 0.109100
2023-03-16 21:21:25,934 INFO     Train loss at step 106100: 0.244869
2023-03-16 21:21:46,296 INFO     Train positive_sample_loss at step 106200: 0.378945
2023-03-16 21:21:46,297 INFO     Train negative_sample_loss at step 106200: 0.109105
2023-03-16 21:21:46,297 INFO     Train loss at step 106200: 0.244025
2023-03-16 21:22:10,645 INFO     Train positive_sample_loss at step 106300: 0.320082
2023-03-16 21:22:10,645 INFO     Train negative_sample_loss at step 106300: 0.107408
2023-03-16 21:22:10,646 INFO     Train loss at step 106300: 0.213745
2023-03-16 21:22:29,985 INFO     Train positive_sample_loss at step 106400: 0.311358
2023-03-16 21:22:29,986 INFO     Train negative_sample_loss at step 106400: 0.104627
2023-03-16 21:22:29,986 INFO     Train loss at step 106400: 0.207993
2023-03-16 21:22:49,317 INFO     Train positive_sample_loss at step 106500: 0.314467
2023-03-16 21:22:49,318 INFO     Train negative_sample_loss at step 106500: 0.104194
2023-03-16 21:22:49,318 INFO     Train loss at step 106500: 0.209331
2023-03-16 21:23:08,644 INFO     Train positive_sample_loss at step 106600: 0.318533
2023-03-16 21:23:08,645 INFO     Train negative_sample_loss at step 106600: 0.103161
2023-03-16 21:23:08,645 INFO     Train loss at step 106600: 0.210847
2023-03-16 21:23:27,973 INFO     Train positive_sample_loss at step 106700: 0.323107
2023-03-16 21:23:27,974 INFO     Train negative_sample_loss at step 106700: 0.102681
2023-03-16 21:23:27,974 INFO     Train loss at step 106700: 0.212894
2023-03-16 21:23:55,120 INFO     Train positive_sample_loss at step 106800: 0.327465
2023-03-16 21:23:55,120 INFO     Train negative_sample_loss at step 106800: 0.103195
2023-03-16 21:23:55,121 INFO     Train loss at step 106800: 0.215330
2023-03-16 21:24:14,489 INFO     Train positive_sample_loss at step 106900: 0.331203
2023-03-16 21:24:14,490 INFO     Train negative_sample_loss at step 106900: 0.102134
2023-03-16 21:24:14,490 INFO     Train loss at step 106900: 0.216669
2023-03-16 21:24:33,889 INFO     Train positive_sample_loss at step 107000: 0.336455
2023-03-16 21:24:33,889 INFO     Train negative_sample_loss at step 107000: 0.102804
2023-03-16 21:24:33,889 INFO     Train loss at step 107000: 0.219630
2023-03-16 21:24:53,283 INFO     Train positive_sample_loss at step 107100: 0.339233
2023-03-16 21:24:53,283 INFO     Train negative_sample_loss at step 107100: 0.102688
2023-03-16 21:24:53,283 INFO     Train loss at step 107100: 0.220960
2023-03-16 21:25:12,686 INFO     Train positive_sample_loss at step 107200: 0.345348
2023-03-16 21:25:12,686 INFO     Train negative_sample_loss at step 107200: 0.103080
2023-03-16 21:25:12,686 INFO     Train loss at step 107200: 0.224214
2023-03-16 21:25:32,096 INFO     Train positive_sample_loss at step 107300: 0.349263
2023-03-16 21:25:32,096 INFO     Train negative_sample_loss at step 107300: 0.103162
2023-03-16 21:25:32,096 INFO     Train loss at step 107300: 0.226213
2023-03-16 21:25:51,512 INFO     Train positive_sample_loss at step 107400: 0.353099
2023-03-16 21:25:51,512 INFO     Train negative_sample_loss at step 107400: 0.103302
2023-03-16 21:25:51,512 INFO     Train loss at step 107400: 0.228201
2023-03-16 21:26:10,919 INFO     Train positive_sample_loss at step 107500: 0.357013
2023-03-16 21:26:10,920 INFO     Train negative_sample_loss at step 107500: 0.104159
2023-03-16 21:26:10,920 INFO     Train loss at step 107500: 0.230586
2023-03-16 21:26:30,326 INFO     Train positive_sample_loss at step 107600: 0.362882
2023-03-16 21:26:30,326 INFO     Train negative_sample_loss at step 107600: 0.103746
2023-03-16 21:26:30,326 INFO     Train loss at step 107600: 0.233314
2023-03-16 21:26:49,744 INFO     Train positive_sample_loss at step 107700: 0.366302
2023-03-16 21:26:49,745 INFO     Train negative_sample_loss at step 107700: 0.103802
2023-03-16 21:26:49,745 INFO     Train loss at step 107700: 0.235052
2023-03-16 21:27:09,161 INFO     Train positive_sample_loss at step 107800: 0.369778
2023-03-16 21:27:09,162 INFO     Train negative_sample_loss at step 107800: 0.104289
2023-03-16 21:27:09,162 INFO     Train loss at step 107800: 0.237034
2023-03-16 21:27:35,457 INFO     Train positive_sample_loss at step 107900: 0.372291
2023-03-16 21:27:35,458 INFO     Train negative_sample_loss at step 107900: 0.103975
2023-03-16 21:27:35,458 INFO     Train loss at step 107900: 0.238133
2023-03-16 21:27:54,863 INFO     Train positive_sample_loss at step 108000: 0.374181
2023-03-16 21:27:54,863 INFO     Train negative_sample_loss at step 108000: 0.103863
2023-03-16 21:27:54,863 INFO     Train loss at step 108000: 0.239022
2023-03-16 21:28:14,271 INFO     Train positive_sample_loss at step 108100: 0.377280
2023-03-16 21:28:14,271 INFO     Train negative_sample_loss at step 108100: 0.104789
2023-03-16 21:28:14,271 INFO     Train loss at step 108100: 0.241034
2023-03-16 21:28:33,686 INFO     Train positive_sample_loss at step 108200: 0.378675
2023-03-16 21:28:33,687 INFO     Train negative_sample_loss at step 108200: 0.104917
2023-03-16 21:28:33,687 INFO     Train loss at step 108200: 0.241796
2023-03-16 21:28:53,109 INFO     Train positive_sample_loss at step 108300: 0.383089
2023-03-16 21:28:53,110 INFO     Train negative_sample_loss at step 108300: 0.105301
2023-03-16 21:28:53,110 INFO     Train loss at step 108300: 0.244195
2023-03-16 21:29:12,518 INFO     Train positive_sample_loss at step 108400: 0.381807
2023-03-16 21:29:12,518 INFO     Train negative_sample_loss at step 108400: 0.104669
2023-03-16 21:29:12,519 INFO     Train loss at step 108400: 0.243238
2023-03-16 21:29:31,937 INFO     Train positive_sample_loss at step 108500: 0.383556
2023-03-16 21:29:31,937 INFO     Train negative_sample_loss at step 108500: 0.105989
2023-03-16 21:29:31,938 INFO     Train loss at step 108500: 0.244773
2023-03-16 21:29:51,353 INFO     Train positive_sample_loss at step 108600: 0.386286
2023-03-16 21:29:51,354 INFO     Train negative_sample_loss at step 108600: 0.106093
2023-03-16 21:29:51,354 INFO     Train loss at step 108600: 0.246190
2023-03-16 21:30:10,769 INFO     Train positive_sample_loss at step 108700: 0.387281
2023-03-16 21:30:10,770 INFO     Train negative_sample_loss at step 108700: 0.106015
2023-03-16 21:30:10,770 INFO     Train loss at step 108700: 0.246648
2023-03-16 21:30:30,181 INFO     Train positive_sample_loss at step 108800: 0.389133
2023-03-16 21:30:30,182 INFO     Train negative_sample_loss at step 108800: 0.106982
2023-03-16 21:30:30,182 INFO     Train loss at step 108800: 0.248058
2023-03-16 21:30:56,428 INFO     Train positive_sample_loss at step 108900: 0.388628
2023-03-16 21:30:56,428 INFO     Train negative_sample_loss at step 108900: 0.106902
2023-03-16 21:30:56,429 INFO     Train loss at step 108900: 0.247765
2023-03-16 21:31:15,906 INFO     Train positive_sample_loss at step 109000: 0.389179
2023-03-16 21:31:15,906 INFO     Train negative_sample_loss at step 109000: 0.107555
2023-03-16 21:31:15,906 INFO     Train loss at step 109000: 0.248367
2023-03-16 21:31:35,329 INFO     Train positive_sample_loss at step 109100: 0.388107
2023-03-16 21:31:35,330 INFO     Train negative_sample_loss at step 109100: 0.107426
2023-03-16 21:31:35,330 INFO     Train loss at step 109100: 0.247766
2023-03-16 21:31:54,741 INFO     Train positive_sample_loss at step 109200: 0.387425
2023-03-16 21:31:54,742 INFO     Train negative_sample_loss at step 109200: 0.107595
2023-03-16 21:31:54,742 INFO     Train loss at step 109200: 0.247510
2023-03-16 21:32:14,154 INFO     Train positive_sample_loss at step 109300: 0.387356
2023-03-16 21:32:14,154 INFO     Train negative_sample_loss at step 109300: 0.108219
2023-03-16 21:32:14,154 INFO     Train loss at step 109300: 0.247788
2023-03-16 21:32:33,562 INFO     Train positive_sample_loss at step 109400: 0.388042
2023-03-16 21:32:33,563 INFO     Train negative_sample_loss at step 109400: 0.107649
2023-03-16 21:32:33,563 INFO     Train loss at step 109400: 0.247845
2023-03-16 21:32:52,983 INFO     Train positive_sample_loss at step 109500: 0.387510
2023-03-16 21:32:52,983 INFO     Train negative_sample_loss at step 109500: 0.108209
2023-03-16 21:32:52,983 INFO     Train loss at step 109500: 0.247860
2023-03-16 21:33:12,392 INFO     Train positive_sample_loss at step 109600: 0.384655
2023-03-16 21:33:12,393 INFO     Train negative_sample_loss at step 109600: 0.108213
2023-03-16 21:33:12,393 INFO     Train loss at step 109600: 0.246434
2023-03-16 21:33:31,794 INFO     Train positive_sample_loss at step 109700: 0.384268
2023-03-16 21:33:31,794 INFO     Train negative_sample_loss at step 109700: 0.108397
2023-03-16 21:33:31,794 INFO     Train loss at step 109700: 0.246332
2023-03-16 21:33:51,201 INFO     Train positive_sample_loss at step 109800: 0.383656
2023-03-16 21:33:51,202 INFO     Train negative_sample_loss at step 109800: 0.108663
2023-03-16 21:33:51,202 INFO     Train loss at step 109800: 0.246159
2023-03-16 21:34:10,628 INFO     Train positive_sample_loss at step 109900: 0.382445
2023-03-16 21:34:10,628 INFO     Train negative_sample_loss at step 109900: 0.108639
2023-03-16 21:34:10,629 INFO     Train loss at step 109900: 0.245542
2023-03-16 21:34:40,621 INFO     Train positive_sample_loss at step 110000: 0.381097
2023-03-16 21:34:40,621 INFO     Train negative_sample_loss at step 110000: 0.109450
2023-03-16 21:34:40,621 INFO     Train loss at step 110000: 0.245273
2023-03-16 21:34:40,621 INFO     Evaluating on Valid Dataset...
2023-03-16 21:34:41,598 INFO     Evaluating the model... (0/26842)
2023-03-16 21:34:43,116 INFO     Evaluating the model... (1000/26842)
2023-03-16 21:34:44,458 INFO     Evaluating the model... (2000/26842)
2023-03-16 21:34:45,680 INFO     Evaluating the model... (3000/26842)
2023-03-16 21:34:46,899 INFO     Evaluating the model... (4000/26842)
2023-03-16 21:34:48,117 INFO     Evaluating the model... (5000/26842)
2023-03-16 21:34:49,338 INFO     Evaluating the model... (6000/26842)
2023-03-16 21:34:50,559 INFO     Evaluating the model... (7000/26842)
2023-03-16 21:34:51,779 INFO     Evaluating the model... (8000/26842)
2023-03-16 21:34:53,018 INFO     Evaluating the model... (9000/26842)
2023-03-16 21:34:54,240 INFO     Evaluating the model... (10000/26842)
2023-03-16 21:34:55,467 INFO     Evaluating the model... (11000/26842)
2023-03-16 21:34:56,693 INFO     Evaluating the model... (12000/26842)
2023-03-16 21:34:57,917 INFO     Evaluating the model... (13000/26842)
2023-03-16 21:35:00,172 INFO     Evaluating the model... (14000/26842)
2023-03-16 21:35:01,656 INFO     Evaluating the model... (15000/26842)
2023-03-16 21:35:03,136 INFO     Evaluating the model... (16000/26842)
2023-03-16 21:35:04,612 INFO     Evaluating the model... (17000/26842)
2023-03-16 21:35:06,104 INFO     Evaluating the model... (18000/26842)
2023-03-16 21:35:07,586 INFO     Evaluating the model... (19000/26842)
2023-03-16 21:35:09,066 INFO     Evaluating the model... (20000/26842)
2023-03-16 21:35:10,553 INFO     Evaluating the model... (21000/26842)
2023-03-16 21:35:12,038 INFO     Evaluating the model... (22000/26842)
2023-03-16 21:35:13,522 INFO     Evaluating the model... (23000/26842)
2023-03-16 21:35:15,005 INFO     Evaluating the model... (24000/26842)
2023-03-16 21:35:16,484 INFO     Evaluating the model... (25000/26842)
2023-03-16 21:35:17,965 INFO     Evaluating the model... (26000/26842)
2023-03-16 21:35:19,546 INFO     Valid hits@1_list at step 110000: 0.588808
2023-03-16 21:35:19,546 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 21:35:19,547 INFO     Valid hits@3_list at step 110000: 0.679897
2023-03-16 21:35:19,547 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 21:35:19,547 INFO     Valid hits@10_list at step 110000: 0.764418
2023-03-16 21:35:19,547 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 21:35:19,547 INFO     Valid mrr_list at step 110000: 0.650354
2023-03-16 21:35:38,965 INFO     Train positive_sample_loss at step 110100: 0.380023
2023-03-16 21:35:38,965 INFO     Train negative_sample_loss at step 110100: 0.108896
2023-03-16 21:35:38,965 INFO     Train loss at step 110100: 0.244460
funtion time use:38746ms
2023-03-16 21:36:04,293 INFO     Train positive_sample_loss at step 110200: 0.342569
2023-03-16 21:36:04,293 INFO     Train negative_sample_loss at step 110200: 0.108241
2023-03-16 21:36:04,293 INFO     Train loss at step 110200: 0.225405
2023-03-16 21:36:23,641 INFO     Train positive_sample_loss at step 110300: 0.310113
2023-03-16 21:36:23,641 INFO     Train negative_sample_loss at step 110300: 0.105767
2023-03-16 21:36:23,642 INFO     Train loss at step 110300: 0.207940
2023-03-16 21:36:42,976 INFO     Train positive_sample_loss at step 110400: 0.314395
2023-03-16 21:36:42,976 INFO     Train negative_sample_loss at step 110400: 0.103832
2023-03-16 21:36:42,976 INFO     Train loss at step 110400: 0.209114
2023-03-16 21:37:02,309 INFO     Train positive_sample_loss at step 110500: 0.318884
2023-03-16 21:37:02,310 INFO     Train negative_sample_loss at step 110500: 0.102894
2023-03-16 21:37:02,310 INFO     Train loss at step 110500: 0.210889
2023-03-16 21:37:21,640 INFO     Train positive_sample_loss at step 110600: 0.322427
2023-03-16 21:37:21,641 INFO     Train negative_sample_loss at step 110600: 0.102776
2023-03-16 21:37:21,641 INFO     Train loss at step 110600: 0.212602
2023-03-16 21:37:48,536 INFO     Train positive_sample_loss at step 110700: 0.325745
2023-03-16 21:37:48,537 INFO     Train negative_sample_loss at step 110700: 0.102825
2023-03-16 21:37:48,537 INFO     Train loss at step 110700: 0.214285
2023-03-16 21:38:07,911 INFO     Train positive_sample_loss at step 110800: 0.329929
2023-03-16 21:38:07,911 INFO     Train negative_sample_loss at step 110800: 0.102542
2023-03-16 21:38:07,911 INFO     Train loss at step 110800: 0.216236
2023-03-16 21:38:27,301 INFO     Train positive_sample_loss at step 110900: 0.334329
2023-03-16 21:38:27,301 INFO     Train negative_sample_loss at step 110900: 0.102659
2023-03-16 21:38:27,301 INFO     Train loss at step 110900: 0.218494
2023-03-16 21:38:46,696 INFO     Train positive_sample_loss at step 111000: 0.341476
2023-03-16 21:38:46,697 INFO     Train negative_sample_loss at step 111000: 0.102944
2023-03-16 21:38:46,697 INFO     Train loss at step 111000: 0.222210
2023-03-16 21:39:06,095 INFO     Train positive_sample_loss at step 111100: 0.343518
2023-03-16 21:39:06,095 INFO     Train negative_sample_loss at step 111100: 0.102661
2023-03-16 21:39:06,096 INFO     Train loss at step 111100: 0.223090
2023-03-16 21:39:25,506 INFO     Train positive_sample_loss at step 111200: 0.345820
2023-03-16 21:39:25,506 INFO     Train negative_sample_loss at step 111200: 0.103093
2023-03-16 21:39:25,506 INFO     Train loss at step 111200: 0.224456
2023-03-16 21:39:44,916 INFO     Train positive_sample_loss at step 111300: 0.351894
2023-03-16 21:39:44,916 INFO     Train negative_sample_loss at step 111300: 0.102750
2023-03-16 21:39:44,917 INFO     Train loss at step 111300: 0.227322
2023-03-16 21:40:04,316 INFO     Train positive_sample_loss at step 111400: 0.354104
2023-03-16 21:40:04,316 INFO     Train negative_sample_loss at step 111400: 0.102807
2023-03-16 21:40:04,317 INFO     Train loss at step 111400: 0.228456
2023-03-16 21:40:23,721 INFO     Train positive_sample_loss at step 111500: 0.359334
2023-03-16 21:40:23,721 INFO     Train negative_sample_loss at step 111500: 0.103263
2023-03-16 21:40:23,721 INFO     Train loss at step 111500: 0.231298
2023-03-16 21:40:43,122 INFO     Train positive_sample_loss at step 111600: 0.362874
2023-03-16 21:40:43,122 INFO     Train negative_sample_loss at step 111600: 0.104190
2023-03-16 21:40:43,122 INFO     Train loss at step 111600: 0.233532
2023-03-16 21:41:02,533 INFO     Train positive_sample_loss at step 111700: 0.369085
2023-03-16 21:41:02,533 INFO     Train negative_sample_loss at step 111700: 0.103987
2023-03-16 21:41:02,533 INFO     Train loss at step 111700: 0.236536
2023-03-16 21:41:28,945 INFO     Train positive_sample_loss at step 111800: 0.371876
2023-03-16 21:41:28,945 INFO     Train negative_sample_loss at step 111800: 0.103897
2023-03-16 21:41:28,945 INFO     Train loss at step 111800: 0.237886
2023-03-16 21:41:48,348 INFO     Train positive_sample_loss at step 111900: 0.373821
2023-03-16 21:41:48,348 INFO     Train negative_sample_loss at step 111900: 0.104421
2023-03-16 21:41:48,348 INFO     Train loss at step 111900: 0.239121
2023-03-16 21:42:07,753 INFO     Train positive_sample_loss at step 112000: 0.378163
2023-03-16 21:42:07,753 INFO     Train negative_sample_loss at step 112000: 0.104454
2023-03-16 21:42:07,753 INFO     Train loss at step 112000: 0.241308
2023-03-16 21:42:27,164 INFO     Train positive_sample_loss at step 112100: 0.377926
2023-03-16 21:42:27,164 INFO     Train negative_sample_loss at step 112100: 0.104682
2023-03-16 21:42:27,164 INFO     Train loss at step 112100: 0.241304
2023-03-16 21:42:46,564 INFO     Train positive_sample_loss at step 112200: 0.380730
2023-03-16 21:42:46,565 INFO     Train negative_sample_loss at step 112200: 0.104934
2023-03-16 21:42:46,565 INFO     Train loss at step 112200: 0.242832
2023-03-16 21:43:05,976 INFO     Train positive_sample_loss at step 112300: 0.382691
2023-03-16 21:43:05,976 INFO     Train negative_sample_loss at step 112300: 0.105308
2023-03-16 21:43:05,976 INFO     Train loss at step 112300: 0.243999
2023-03-16 21:43:25,381 INFO     Train positive_sample_loss at step 112400: 0.383099
2023-03-16 21:43:25,382 INFO     Train negative_sample_loss at step 112400: 0.105841
2023-03-16 21:43:25,382 INFO     Train loss at step 112400: 0.244470
2023-03-16 21:43:44,796 INFO     Train positive_sample_loss at step 112500: 0.384888
2023-03-16 21:43:44,796 INFO     Train negative_sample_loss at step 112500: 0.106488
2023-03-16 21:43:44,796 INFO     Train loss at step 112500: 0.245688
2023-03-16 21:44:04,205 INFO     Train positive_sample_loss at step 112600: 0.387346
2023-03-16 21:44:04,205 INFO     Train negative_sample_loss at step 112600: 0.106636
2023-03-16 21:44:04,205 INFO     Train loss at step 112600: 0.246991
2023-03-16 21:44:23,624 INFO     Train positive_sample_loss at step 112700: 0.386589
2023-03-16 21:44:23,625 INFO     Train negative_sample_loss at step 112700: 0.106155
2023-03-16 21:44:23,625 INFO     Train loss at step 112700: 0.246372
2023-03-16 21:44:49,814 INFO     Train positive_sample_loss at step 112800: 0.387697
2023-03-16 21:44:49,815 INFO     Train negative_sample_loss at step 112800: 0.106525
2023-03-16 21:44:49,816 INFO     Train loss at step 112800: 0.247111
2023-03-16 21:45:09,436 INFO     Train positive_sample_loss at step 112900: 0.388729
2023-03-16 21:45:09,436 INFO     Train negative_sample_loss at step 112900: 0.107574
2023-03-16 21:45:09,436 INFO     Train loss at step 112900: 0.248151
2023-03-16 21:45:28,838 INFO     Train positive_sample_loss at step 113000: 0.390391
2023-03-16 21:45:28,839 INFO     Train negative_sample_loss at step 113000: 0.107800
2023-03-16 21:45:28,839 INFO     Train loss at step 113000: 0.249095
2023-03-16 21:45:48,246 INFO     Train positive_sample_loss at step 113100: 0.387513
2023-03-16 21:45:48,247 INFO     Train negative_sample_loss at step 113100: 0.107583
2023-03-16 21:45:48,247 INFO     Train loss at step 113100: 0.247548
2023-03-16 21:46:07,656 INFO     Train positive_sample_loss at step 113200: 0.389623
2023-03-16 21:46:07,657 INFO     Train negative_sample_loss at step 113200: 0.108254
2023-03-16 21:46:07,657 INFO     Train loss at step 113200: 0.248938
2023-03-16 21:46:27,074 INFO     Train positive_sample_loss at step 113300: 0.387039
2023-03-16 21:46:27,074 INFO     Train negative_sample_loss at step 113300: 0.107937
2023-03-16 21:46:27,075 INFO     Train loss at step 113300: 0.247488
2023-03-16 21:46:46,481 INFO     Train positive_sample_loss at step 113400: 0.386517
2023-03-16 21:46:46,482 INFO     Train negative_sample_loss at step 113400: 0.107873
2023-03-16 21:46:46,482 INFO     Train loss at step 113400: 0.247195
2023-03-16 21:47:05,879 INFO     Train positive_sample_loss at step 113500: 0.383609
2023-03-16 21:47:05,880 INFO     Train negative_sample_loss at step 113500: 0.108367
2023-03-16 21:47:05,880 INFO     Train loss at step 113500: 0.245988
2023-03-16 21:47:25,285 INFO     Train positive_sample_loss at step 113600: 0.385906
2023-03-16 21:47:25,286 INFO     Train negative_sample_loss at step 113600: 0.108279
2023-03-16 21:47:25,286 INFO     Train loss at step 113600: 0.247093
2023-03-16 21:47:44,680 INFO     Train positive_sample_loss at step 113700: 0.385170
2023-03-16 21:47:44,680 INFO     Train negative_sample_loss at step 113700: 0.109394
2023-03-16 21:47:44,680 INFO     Train loss at step 113700: 0.247282
2023-03-16 21:48:04,081 INFO     Train positive_sample_loss at step 113800: 0.381329
2023-03-16 21:48:04,081 INFO     Train negative_sample_loss at step 113800: 0.108668
2023-03-16 21:48:04,081 INFO     Train loss at step 113800: 0.244999
2023-03-16 21:48:30,523 INFO     Train positive_sample_loss at step 113900: 0.381418
2023-03-16 21:48:30,524 INFO     Train negative_sample_loss at step 113900: 0.109679
2023-03-16 21:48:30,524 INFO     Train loss at step 113900: 0.245548
2023-03-16 21:48:49,922 INFO     Train positive_sample_loss at step 114000: 0.380173
2023-03-16 21:48:49,923 INFO     Train negative_sample_loss at step 114000: 0.108818
2023-03-16 21:48:49,923 INFO     Train loss at step 114000: 0.244496
2023-03-16 21:49:15,452 INFO     Train positive_sample_loss at step 114100: 0.368562
2023-03-16 21:49:15,452 INFO     Train negative_sample_loss at step 114100: 0.108910
2023-03-16 21:49:15,452 INFO     Train loss at step 114100: 0.238736
2023-03-16 21:49:34,795 INFO     Train positive_sample_loss at step 114200: 0.309507
2023-03-16 21:49:34,796 INFO     Train negative_sample_loss at step 114200: 0.106106
2023-03-16 21:49:34,796 INFO     Train loss at step 114200: 0.207806
2023-03-16 21:49:54,133 INFO     Train positive_sample_loss at step 114300: 0.312897
2023-03-16 21:49:54,133 INFO     Train negative_sample_loss at step 114300: 0.104636
2023-03-16 21:49:54,133 INFO     Train loss at step 114300: 0.208767
2023-03-16 21:50:13,460 INFO     Train positive_sample_loss at step 114400: 0.316120
2023-03-16 21:50:13,461 INFO     Train negative_sample_loss at step 114400: 0.103163
2023-03-16 21:50:13,461 INFO     Train loss at step 114400: 0.209641
2023-03-16 21:50:32,806 INFO     Train positive_sample_loss at step 114500: 0.322935
2023-03-16 21:50:32,807 INFO     Train negative_sample_loss at step 114500: 0.103393
2023-03-16 21:50:32,807 INFO     Train loss at step 114500: 0.213164
2023-03-16 21:50:52,141 INFO     Train positive_sample_loss at step 114600: 0.324672
2023-03-16 21:50:52,141 INFO     Train negative_sample_loss at step 114600: 0.102446
2023-03-16 21:50:52,142 INFO     Train loss at step 114600: 0.213559
2023-03-16 21:51:19,031 INFO     Train positive_sample_loss at step 114700: 0.329428
2023-03-16 21:51:19,031 INFO     Train negative_sample_loss at step 114700: 0.102527
2023-03-16 21:51:19,031 INFO     Train loss at step 114700: 0.215977
2023-03-16 21:51:38,429 INFO     Train positive_sample_loss at step 114800: 0.333834
2023-03-16 21:51:38,430 INFO     Train negative_sample_loss at step 114800: 0.102524
2023-03-16 21:51:38,430 INFO     Train loss at step 114800: 0.218179
2023-03-16 21:51:57,825 INFO     Train positive_sample_loss at step 114900: 0.336006
2023-03-16 21:51:57,826 INFO     Train negative_sample_loss at step 114900: 0.102469
2023-03-16 21:51:57,826 INFO     Train loss at step 114900: 0.219238
2023-03-16 21:52:17,224 INFO     Train positive_sample_loss at step 115000: 0.342275
2023-03-16 21:52:17,225 INFO     Train negative_sample_loss at step 115000: 0.102934
2023-03-16 21:52:17,225 INFO     Train loss at step 115000: 0.222605
2023-03-16 21:52:36,629 INFO     Train positive_sample_loss at step 115100: 0.346020
2023-03-16 21:52:36,629 INFO     Train negative_sample_loss at step 115100: 0.102565
2023-03-16 21:52:36,629 INFO     Train loss at step 115100: 0.224293
2023-03-16 21:52:56,044 INFO     Train positive_sample_loss at step 115200: 0.350067
2023-03-16 21:52:56,044 INFO     Train negative_sample_loss at step 115200: 0.103227
2023-03-16 21:52:56,044 INFO     Train loss at step 115200: 0.226647
2023-03-16 21:53:15,443 INFO     Train positive_sample_loss at step 115300: 0.356467
2023-03-16 21:53:15,443 INFO     Train negative_sample_loss at step 115300: 0.103247
2023-03-16 21:53:15,443 INFO     Train loss at step 115300: 0.229857
2023-03-16 21:53:34,839 INFO     Train positive_sample_loss at step 115400: 0.358785
2023-03-16 21:53:34,840 INFO     Train negative_sample_loss at step 115400: 0.103029
2023-03-16 21:53:34,840 INFO     Train loss at step 115400: 0.230907
2023-03-16 21:53:54,234 INFO     Train positive_sample_loss at step 115500: 0.363285
2023-03-16 21:53:54,234 INFO     Train negative_sample_loss at step 115500: 0.103984
2023-03-16 21:53:54,234 INFO     Train loss at step 115500: 0.233634
2023-03-16 21:54:13,624 INFO     Train positive_sample_loss at step 115600: 0.365162
2023-03-16 21:54:13,625 INFO     Train negative_sample_loss at step 115600: 0.104150
2023-03-16 21:54:13,625 INFO     Train loss at step 115600: 0.234656
2023-03-16 21:54:39,843 INFO     Train positive_sample_loss at step 115700: 0.371421
2023-03-16 21:54:39,844 INFO     Train negative_sample_loss at step 115700: 0.104243
2023-03-16 21:54:39,844 INFO     Train loss at step 115700: 0.237832
2023-03-16 21:54:59,254 INFO     Train positive_sample_loss at step 115800: 0.373956
2023-03-16 21:54:59,255 INFO     Train negative_sample_loss at step 115800: 0.104275
2023-03-16 21:54:59,255 INFO     Train loss at step 115800: 0.239116
2023-03-16 21:55:18,655 INFO     Train positive_sample_loss at step 115900: 0.374323
2023-03-16 21:55:18,655 INFO     Train negative_sample_loss at step 115900: 0.104233
2023-03-16 21:55:18,655 INFO     Train loss at step 115900: 0.239278
2023-03-16 21:55:38,062 INFO     Train positive_sample_loss at step 116000: 0.378207
2023-03-16 21:55:38,063 INFO     Train negative_sample_loss at step 116000: 0.104349
2023-03-16 21:55:38,063 INFO     Train loss at step 116000: 0.241278
2023-03-16 21:55:57,480 INFO     Train positive_sample_loss at step 116100: 0.381296
2023-03-16 21:55:57,480 INFO     Train negative_sample_loss at step 116100: 0.105299
2023-03-16 21:55:57,480 INFO     Train loss at step 116100: 0.243298
2023-03-16 21:56:16,896 INFO     Train positive_sample_loss at step 116200: 0.381453
2023-03-16 21:56:16,897 INFO     Train negative_sample_loss at step 116200: 0.104863
2023-03-16 21:56:16,897 INFO     Train loss at step 116200: 0.243158
2023-03-16 21:56:36,334 INFO     Train positive_sample_loss at step 116300: 0.382080
2023-03-16 21:56:36,334 INFO     Train negative_sample_loss at step 116300: 0.105262
2023-03-16 21:56:36,334 INFO     Train loss at step 116300: 0.243671
2023-03-16 21:56:55,745 INFO     Train positive_sample_loss at step 116400: 0.384541
2023-03-16 21:56:55,746 INFO     Train negative_sample_loss at step 116400: 0.105740
2023-03-16 21:56:55,746 INFO     Train loss at step 116400: 0.245140
2023-03-16 21:57:15,160 INFO     Train positive_sample_loss at step 116500: 0.385701
2023-03-16 21:57:15,160 INFO     Train negative_sample_loss at step 116500: 0.105999
2023-03-16 21:57:15,160 INFO     Train loss at step 116500: 0.245850
2023-03-16 21:57:34,574 INFO     Train positive_sample_loss at step 116600: 0.388943
2023-03-16 21:57:34,575 INFO     Train negative_sample_loss at step 116600: 0.106717
2023-03-16 21:57:34,575 INFO     Train loss at step 116600: 0.247830
2023-03-16 21:57:54,003 INFO     Train positive_sample_loss at step 116700: 0.387363
2023-03-16 21:57:54,003 INFO     Train negative_sample_loss at step 116700: 0.106680
2023-03-16 21:57:54,003 INFO     Train loss at step 116700: 0.247021
2023-03-16 21:58:20,338 INFO     Train positive_sample_loss at step 116800: 0.387988
2023-03-16 21:58:20,339 INFO     Train negative_sample_loss at step 116800: 0.106136
2023-03-16 21:58:20,339 INFO     Train loss at step 116800: 0.247062
2023-03-16 21:58:39,745 INFO     Train positive_sample_loss at step 116900: 0.386371
2023-03-16 21:58:39,746 INFO     Train negative_sample_loss at step 116900: 0.107337
2023-03-16 21:58:39,746 INFO     Train loss at step 116900: 0.246854
2023-03-16 21:58:59,162 INFO     Train positive_sample_loss at step 117000: 0.387983
2023-03-16 21:58:59,163 INFO     Train negative_sample_loss at step 117000: 0.107370
2023-03-16 21:58:59,163 INFO     Train loss at step 117000: 0.247676
2023-03-16 21:59:18,578 INFO     Train positive_sample_loss at step 117100: 0.386205
2023-03-16 21:59:18,578 INFO     Train negative_sample_loss at step 117100: 0.108148
2023-03-16 21:59:18,578 INFO     Train loss at step 117100: 0.247177
2023-03-16 21:59:37,988 INFO     Train positive_sample_loss at step 117200: 0.386586
2023-03-16 21:59:37,989 INFO     Train negative_sample_loss at step 117200: 0.108236
2023-03-16 21:59:37,989 INFO     Train loss at step 117200: 0.247411
2023-03-16 21:59:57,408 INFO     Train positive_sample_loss at step 117300: 0.386476
2023-03-16 21:59:57,409 INFO     Train negative_sample_loss at step 117300: 0.107953
2023-03-16 21:59:57,409 INFO     Train loss at step 117300: 0.247215
2023-03-16 22:00:16,811 INFO     Train positive_sample_loss at step 117400: 0.387027
2023-03-16 22:00:16,812 INFO     Train negative_sample_loss at step 117400: 0.108927
2023-03-16 22:00:16,812 INFO     Train loss at step 117400: 0.247977
2023-03-16 22:00:36,222 INFO     Train positive_sample_loss at step 117500: 0.385633
2023-03-16 22:00:36,223 INFO     Train negative_sample_loss at step 117500: 0.108448
2023-03-16 22:00:36,223 INFO     Train loss at step 117500: 0.247040
2023-03-16 22:00:55,632 INFO     Train positive_sample_loss at step 117600: 0.385006
2023-03-16 22:00:55,632 INFO     Train negative_sample_loss at step 117600: 0.108466
2023-03-16 22:00:55,632 INFO     Train loss at step 117600: 0.246736
2023-03-16 22:01:15,035 INFO     Train positive_sample_loss at step 117700: 0.383440
2023-03-16 22:01:15,036 INFO     Train negative_sample_loss at step 117700: 0.108663
2023-03-16 22:01:15,036 INFO     Train loss at step 117700: 0.246051
2023-03-16 22:01:41,277 INFO     Train positive_sample_loss at step 117800: 0.381491
2023-03-16 22:01:41,278 INFO     Train negative_sample_loss at step 117800: 0.109422
2023-03-16 22:01:41,278 INFO     Train loss at step 117800: 0.245456
2023-03-16 22:02:00,684 INFO     Train positive_sample_loss at step 117900: 0.378427
2023-03-16 22:02:00,684 INFO     Train negative_sample_loss at step 117900: 0.108423
2023-03-16 22:02:00,684 INFO     Train loss at step 117900: 0.243425
2023-03-16 22:02:20,094 INFO     Train positive_sample_loss at step 118000: 0.380171
2023-03-16 22:02:20,094 INFO     Train negative_sample_loss at step 118000: 0.109108
2023-03-16 22:02:20,095 INFO     Train loss at step 118000: 0.244640
2023-03-16 22:02:45,416 INFO     Train positive_sample_loss at step 118100: 0.319791
2023-03-16 22:02:45,417 INFO     Train negative_sample_loss at step 118100: 0.106732
2023-03-16 22:02:45,417 INFO     Train loss at step 118100: 0.213261
2023-03-16 22:03:04,749 INFO     Train positive_sample_loss at step 118200: 0.311457
2023-03-16 22:03:04,749 INFO     Train negative_sample_loss at step 118200: 0.105331
2023-03-16 22:03:04,749 INFO     Train loss at step 118200: 0.208394
2023-03-16 22:03:24,077 INFO     Train positive_sample_loss at step 118300: 0.314993
2023-03-16 22:03:24,078 INFO     Train negative_sample_loss at step 118300: 0.102886
2023-03-16 22:03:24,078 INFO     Train loss at step 118300: 0.208940
2023-03-16 22:03:43,406 INFO     Train positive_sample_loss at step 118400: 0.319152
2023-03-16 22:03:43,406 INFO     Train negative_sample_loss at step 118400: 0.102205
2023-03-16 22:03:43,407 INFO     Train loss at step 118400: 0.210678
2023-03-16 22:04:02,739 INFO     Train positive_sample_loss at step 118500: 0.323255
2023-03-16 22:04:02,739 INFO     Train negative_sample_loss at step 118500: 0.102758
2023-03-16 22:04:02,739 INFO     Train loss at step 118500: 0.213007
2023-03-16 22:04:29,565 INFO     Train positive_sample_loss at step 118600: 0.327142
2023-03-16 22:04:29,566 INFO     Train negative_sample_loss at step 118600: 0.102662
2023-03-16 22:04:29,566 INFO     Train loss at step 118600: 0.214902
2023-03-16 22:04:48,926 INFO     Train positive_sample_loss at step 118700: 0.330199
2023-03-16 22:04:48,927 INFO     Train negative_sample_loss at step 118700: 0.102426
2023-03-16 22:04:48,927 INFO     Train loss at step 118700: 0.216313
2023-03-16 22:05:08,283 INFO     Train positive_sample_loss at step 118800: 0.338068
2023-03-16 22:05:08,284 INFO     Train negative_sample_loss at step 118800: 0.102150
2023-03-16 22:05:08,284 INFO     Train loss at step 118800: 0.220109
2023-03-16 22:05:27,642 INFO     Train positive_sample_loss at step 118900: 0.339051
2023-03-16 22:05:27,642 INFO     Train negative_sample_loss at step 118900: 0.102122
2023-03-16 22:05:27,642 INFO     Train loss at step 118900: 0.220586
2023-03-16 22:05:47,004 INFO     Train positive_sample_loss at step 119000: 0.345445
2023-03-16 22:05:47,005 INFO     Train negative_sample_loss at step 119000: 0.102695
2023-03-16 22:05:47,005 INFO     Train loss at step 119000: 0.224070
2023-03-16 22:06:06,360 INFO     Train positive_sample_loss at step 119100: 0.346598
2023-03-16 22:06:06,361 INFO     Train negative_sample_loss at step 119100: 0.101932
2023-03-16 22:06:06,361 INFO     Train loss at step 119100: 0.224265
2023-03-16 22:06:25,709 INFO     Train positive_sample_loss at step 119200: 0.351384
2023-03-16 22:06:25,709 INFO     Train negative_sample_loss at step 119200: 0.102963
2023-03-16 22:06:25,709 INFO     Train loss at step 119200: 0.227174
2023-03-16 22:06:45,064 INFO     Train positive_sample_loss at step 119300: 0.356891
2023-03-16 22:06:45,064 INFO     Train negative_sample_loss at step 119300: 0.102860
2023-03-16 22:06:45,064 INFO     Train loss at step 119300: 0.229876
2023-03-16 22:07:04,416 INFO     Train positive_sample_loss at step 119400: 0.360320
2023-03-16 22:07:04,416 INFO     Train negative_sample_loss at step 119400: 0.104045
2023-03-16 22:07:04,417 INFO     Train loss at step 119400: 0.232183
2023-03-16 22:07:23,762 INFO     Train positive_sample_loss at step 119500: 0.365023
2023-03-16 22:07:23,763 INFO     Train negative_sample_loss at step 119500: 0.103539
2023-03-16 22:07:23,763 INFO     Train loss at step 119500: 0.234281
2023-03-16 22:07:43,140 INFO     Train positive_sample_loss at step 119600: 0.369918
2023-03-16 22:07:43,141 INFO     Train negative_sample_loss at step 119600: 0.104078
2023-03-16 22:07:43,141 INFO     Train loss at step 119600: 0.236998
2023-03-16 22:08:09,541 INFO     Train positive_sample_loss at step 119700: 0.372546
2023-03-16 22:08:09,541 INFO     Train negative_sample_loss at step 119700: 0.104182
2023-03-16 22:08:09,541 INFO     Train loss at step 119700: 0.238364
2023-03-16 22:08:28,926 INFO     Train positive_sample_loss at step 119800: 0.375148
2023-03-16 22:08:28,926 INFO     Train negative_sample_loss at step 119800: 0.104591
2023-03-16 22:08:28,926 INFO     Train loss at step 119800: 0.239869
2023-03-16 22:08:48,326 INFO     Train positive_sample_loss at step 119900: 0.377839
2023-03-16 22:08:48,326 INFO     Train negative_sample_loss at step 119900: 0.104406
2023-03-16 22:08:48,326 INFO     Train loss at step 119900: 0.241123
2023-03-16 22:09:09,401 INFO     Train positive_sample_loss at step 120000: 0.380248
2023-03-16 22:09:09,401 INFO     Train negative_sample_loss at step 120000: 0.104687
2023-03-16 22:09:09,401 INFO     Train loss at step 120000: 0.242468
2023-03-16 22:09:09,401 INFO     Evaluating on Valid Dataset...
2023-03-16 22:09:10,398 INFO     Evaluating the model... (0/26842)
2023-03-16 22:09:11,938 INFO     Evaluating the model... (1000/26842)
2023-03-16 22:09:13,191 INFO     Evaluating the model... (2000/26842)
2023-03-16 22:09:14,441 INFO     Evaluating the model... (3000/26842)
2023-03-16 22:09:15,690 INFO     Evaluating the model... (4000/26842)
2023-03-16 22:09:16,937 INFO     Evaluating the model... (5000/26842)
2023-03-16 22:09:18,184 INFO     Evaluating the model... (6000/26842)
2023-03-16 22:09:19,436 INFO     Evaluating the model... (7000/26842)
2023-03-16 22:09:20,686 INFO     Evaluating the model... (8000/26842)
2023-03-16 22:09:21,939 INFO     Evaluating the model... (9000/26842)
2023-03-16 22:09:23,188 INFO     Evaluating the model... (10000/26842)
2023-03-16 22:09:24,445 INFO     Evaluating the model... (11000/26842)
2023-03-16 22:09:25,699 INFO     Evaluating the model... (12000/26842)
2023-03-16 22:09:26,950 INFO     Evaluating the model... (13000/26842)
2023-03-16 22:09:29,210 INFO     Evaluating the model... (14000/26842)
2023-03-16 22:09:30,697 INFO     Evaluating the model... (15000/26842)
2023-03-16 22:09:32,178 INFO     Evaluating the model... (16000/26842)
2023-03-16 22:09:33,660 INFO     Evaluating the model... (17000/26842)
2023-03-16 22:09:35,142 INFO     Evaluating the model... (18000/26842)
2023-03-16 22:09:36,624 INFO     Evaluating the model... (19000/26842)
2023-03-16 22:09:38,112 INFO     Evaluating the model... (20000/26842)
2023-03-16 22:09:39,605 INFO     Evaluating the model... (21000/26842)
2023-03-16 22:09:41,087 INFO     Evaluating the model... (22000/26842)
2023-03-16 22:09:42,565 INFO     Evaluating the model... (23000/26842)
2023-03-16 22:09:44,057 INFO     Evaluating the model... (24000/26842)
2023-03-16 22:09:45,544 INFO     Evaluating the model... (25000/26842)
2023-03-16 22:09:47,020 INFO     Evaluating the model... (26000/26842)
2023-03-16 22:09:48,577 INFO     Valid hits@1_list at step 120000: 0.591525
2023-03-16 22:09:48,577 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 22:09:48,577 INFO     Valid hits@3_list at step 120000: 0.681234
2023-03-16 22:09:48,578 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 22:09:48,578 INFO     Valid hits@10_list at step 120000: 0.765874
2023-03-16 22:09:48,578 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 22:09:48,578 INFO     Valid mrr_list at step 120000: 0.652514
2023-03-16 22:10:08,003 INFO     Train positive_sample_loss at step 120100: 0.382461
2023-03-16 22:10:08,003 INFO     Train negative_sample_loss at step 120100: 0.105125
2023-03-16 22:10:08,003 INFO     Train loss at step 120100: 0.243793
2023-03-16 22:10:27,414 INFO     Train positive_sample_loss at step 120200: 0.384383
2023-03-16 22:10:27,415 INFO     Train negative_sample_loss at step 120200: 0.105162
2023-03-16 22:10:27,415 INFO     Train loss at step 120200: 0.244772
2023-03-16 22:10:46,831 INFO     Train positive_sample_loss at step 120300: 0.385408
2023-03-16 22:10:46,832 INFO     Train negative_sample_loss at step 120300: 0.105745
2023-03-16 22:10:46,832 INFO     Train loss at step 120300: 0.245577
2023-03-16 22:11:06,242 INFO     Train positive_sample_loss at step 120400: 0.385061
2023-03-16 22:11:06,242 INFO     Train negative_sample_loss at step 120400: 0.105968
2023-03-16 22:11:06,242 INFO     Train loss at step 120400: 0.245514
2023-03-16 22:11:25,647 INFO     Train positive_sample_loss at step 120500: 0.386145
2023-03-16 22:11:25,648 INFO     Train negative_sample_loss at step 120500: 0.105453
2023-03-16 22:11:25,648 INFO     Train loss at step 120500: 0.245799
2023-03-16 22:11:45,050 INFO     Train positive_sample_loss at step 120600: 0.387006
2023-03-16 22:11:45,050 INFO     Train negative_sample_loss at step 120600: 0.106457
2023-03-16 22:11:45,050 INFO     Train loss at step 120600: 0.246732
2023-03-16 22:12:11,267 INFO     Train positive_sample_loss at step 120700: 0.387908
2023-03-16 22:12:11,267 INFO     Train negative_sample_loss at step 120700: 0.106706
2023-03-16 22:12:11,268 INFO     Train loss at step 120700: 0.247307
2023-03-16 22:12:30,650 INFO     Train positive_sample_loss at step 120800: 0.387574
2023-03-16 22:12:30,651 INFO     Train negative_sample_loss at step 120800: 0.107289
2023-03-16 22:12:30,651 INFO     Train loss at step 120800: 0.247431
2023-03-16 22:12:50,063 INFO     Train positive_sample_loss at step 120900: 0.388518
2023-03-16 22:12:50,063 INFO     Train negative_sample_loss at step 120900: 0.107289
2023-03-16 22:12:50,063 INFO     Train loss at step 120900: 0.247904
2023-03-16 22:13:09,471 INFO     Train positive_sample_loss at step 121000: 0.388174
2023-03-16 22:13:09,472 INFO     Train negative_sample_loss at step 121000: 0.107774
2023-03-16 22:13:09,472 INFO     Train loss at step 121000: 0.247974
2023-03-16 22:13:28,870 INFO     Train positive_sample_loss at step 121100: 0.387898
2023-03-16 22:13:28,870 INFO     Train negative_sample_loss at step 121100: 0.107944
2023-03-16 22:13:28,871 INFO     Train loss at step 121100: 0.247921
2023-03-16 22:13:48,278 INFO     Train positive_sample_loss at step 121200: 0.386827
2023-03-16 22:13:48,279 INFO     Train negative_sample_loss at step 121200: 0.108298
2023-03-16 22:13:48,279 INFO     Train loss at step 121200: 0.247562
2023-03-16 22:14:07,686 INFO     Train positive_sample_loss at step 121300: 0.387122
2023-03-16 22:14:07,686 INFO     Train negative_sample_loss at step 121300: 0.108285
2023-03-16 22:14:07,686 INFO     Train loss at step 121300: 0.247704
2023-03-16 22:14:27,098 INFO     Train positive_sample_loss at step 121400: 0.385495
2023-03-16 22:14:27,099 INFO     Train negative_sample_loss at step 121400: 0.107914
2023-03-16 22:14:27,099 INFO     Train loss at step 121400: 0.246705
2023-03-16 22:14:46,514 INFO     Train positive_sample_loss at step 121500: 0.383325
2023-03-16 22:14:46,515 INFO     Train negative_sample_loss at step 121500: 0.108710
2023-03-16 22:14:46,515 INFO     Train loss at step 121500: 0.246018
2023-03-16 22:15:05,926 INFO     Train positive_sample_loss at step 121600: 0.384437
2023-03-16 22:15:05,927 INFO     Train negative_sample_loss at step 121600: 0.108911
2023-03-16 22:15:05,927 INFO     Train loss at step 121600: 0.246674
2023-03-16 22:15:25,331 INFO     Train positive_sample_loss at step 121700: 0.381412
2023-03-16 22:15:25,332 INFO     Train negative_sample_loss at step 121700: 0.108974
2023-03-16 22:15:25,332 INFO     Train loss at step 121700: 0.245193
2023-03-16 22:15:55,029 INFO     Train positive_sample_loss at step 121800: 0.380870
2023-03-16 22:15:55,029 INFO     Train negative_sample_loss at step 121800: 0.108932
2023-03-16 22:15:55,029 INFO     Train loss at step 121800: 0.244901
2023-03-16 22:16:14,430 INFO     Train positive_sample_loss at step 121900: 0.379878
2023-03-16 22:16:14,431 INFO     Train negative_sample_loss at step 121900: 0.109092
2023-03-16 22:16:14,431 INFO     Train loss at step 121900: 0.244485
funtion time use:38998ms
2023-03-16 22:16:39,932 INFO     Train positive_sample_loss at step 122000: 0.345870
2023-03-16 22:16:39,932 INFO     Train negative_sample_loss at step 122000: 0.108472
2023-03-16 22:16:39,932 INFO     Train loss at step 122000: 0.227171
2023-03-16 22:16:59,292 INFO     Train positive_sample_loss at step 122100: 0.311015
2023-03-16 22:16:59,292 INFO     Train negative_sample_loss at step 122100: 0.105041
2023-03-16 22:16:59,292 INFO     Train loss at step 122100: 0.208028
2023-03-16 22:17:18,637 INFO     Train positive_sample_loss at step 122200: 0.313648
2023-03-16 22:17:18,638 INFO     Train negative_sample_loss at step 122200: 0.103383
2023-03-16 22:17:18,638 INFO     Train loss at step 122200: 0.208516
2023-03-16 22:17:37,970 INFO     Train positive_sample_loss at step 122300: 0.318294
2023-03-16 22:17:37,971 INFO     Train negative_sample_loss at step 122300: 0.103213
2023-03-16 22:17:37,971 INFO     Train loss at step 122300: 0.210754
2023-03-16 22:17:57,307 INFO     Train positive_sample_loss at step 122400: 0.321788
2023-03-16 22:17:57,307 INFO     Train negative_sample_loss at step 122400: 0.102461
2023-03-16 22:17:57,308 INFO     Train loss at step 122400: 0.212124
2023-03-16 22:18:24,222 INFO     Train positive_sample_loss at step 122500: 0.326592
2023-03-16 22:18:24,222 INFO     Train negative_sample_loss at step 122500: 0.102442
2023-03-16 22:18:24,222 INFO     Train loss at step 122500: 0.214517
2023-03-16 22:18:43,590 INFO     Train positive_sample_loss at step 122600: 0.329272
2023-03-16 22:18:43,590 INFO     Train negative_sample_loss at step 122600: 0.102302
2023-03-16 22:18:43,590 INFO     Train loss at step 122600: 0.215787
2023-03-16 22:19:02,969 INFO     Train positive_sample_loss at step 122700: 0.333879
2023-03-16 22:19:02,969 INFO     Train negative_sample_loss at step 122700: 0.102214
2023-03-16 22:19:02,969 INFO     Train loss at step 122700: 0.218046
2023-03-16 22:19:22,386 INFO     Train positive_sample_loss at step 122800: 0.338084
2023-03-16 22:19:22,387 INFO     Train negative_sample_loss at step 122800: 0.102757
2023-03-16 22:19:22,387 INFO     Train loss at step 122800: 0.220421
2023-03-16 22:19:41,789 INFO     Train positive_sample_loss at step 122900: 0.343235
2023-03-16 22:19:41,790 INFO     Train negative_sample_loss at step 122900: 0.102364
2023-03-16 22:19:41,790 INFO     Train loss at step 122900: 0.222799
2023-03-16 22:20:01,174 INFO     Train positive_sample_loss at step 123000: 0.346535
2023-03-16 22:20:01,174 INFO     Train negative_sample_loss at step 123000: 0.102480
2023-03-16 22:20:01,175 INFO     Train loss at step 123000: 0.224507
2023-03-16 22:20:20,565 INFO     Train positive_sample_loss at step 123100: 0.350777
2023-03-16 22:20:20,565 INFO     Train negative_sample_loss at step 123100: 0.103040
2023-03-16 22:20:20,565 INFO     Train loss at step 123100: 0.226908
2023-03-16 22:20:39,955 INFO     Train positive_sample_loss at step 123200: 0.355273
2023-03-16 22:20:39,956 INFO     Train negative_sample_loss at step 123200: 0.103075
2023-03-16 22:20:39,956 INFO     Train loss at step 123200: 0.229174
2023-03-16 22:20:59,347 INFO     Train positive_sample_loss at step 123300: 0.359188
2023-03-16 22:20:59,348 INFO     Train negative_sample_loss at step 123300: 0.102488
2023-03-16 22:20:59,348 INFO     Train loss at step 123300: 0.230838
2023-03-16 22:21:18,730 INFO     Train positive_sample_loss at step 123400: 0.362240
2023-03-16 22:21:18,730 INFO     Train negative_sample_loss at step 123400: 0.103212
2023-03-16 22:21:18,731 INFO     Train loss at step 123400: 0.232726
2023-03-16 22:21:38,126 INFO     Train positive_sample_loss at step 123500: 0.367105
2023-03-16 22:21:38,126 INFO     Train negative_sample_loss at step 123500: 0.104252
2023-03-16 22:21:38,127 INFO     Train loss at step 123500: 0.235678
2023-03-16 22:22:04,447 INFO     Train positive_sample_loss at step 123600: 0.372496
2023-03-16 22:22:04,448 INFO     Train negative_sample_loss at step 123600: 0.104062
2023-03-16 22:22:04,448 INFO     Train loss at step 123600: 0.238279
2023-03-16 22:22:23,838 INFO     Train positive_sample_loss at step 123700: 0.373820
2023-03-16 22:22:23,838 INFO     Train negative_sample_loss at step 123700: 0.104262
2023-03-16 22:22:23,838 INFO     Train loss at step 123700: 0.239041
2023-03-16 22:22:43,247 INFO     Train positive_sample_loss at step 123800: 0.375792
2023-03-16 22:22:43,247 INFO     Train negative_sample_loss at step 123800: 0.104828
2023-03-16 22:22:43,247 INFO     Train loss at step 123800: 0.240310
2023-03-16 22:23:02,641 INFO     Train positive_sample_loss at step 123900: 0.379890
2023-03-16 22:23:02,642 INFO     Train negative_sample_loss at step 123900: 0.104778
2023-03-16 22:23:02,642 INFO     Train loss at step 123900: 0.242334
2023-03-16 22:23:22,043 INFO     Train positive_sample_loss at step 124000: 0.380825
2023-03-16 22:23:22,043 INFO     Train negative_sample_loss at step 124000: 0.104559
2023-03-16 22:23:22,043 INFO     Train loss at step 124000: 0.242692
2023-03-16 22:23:41,452 INFO     Train positive_sample_loss at step 124100: 0.382929
2023-03-16 22:23:41,452 INFO     Train negative_sample_loss at step 124100: 0.105623
2023-03-16 22:23:41,452 INFO     Train loss at step 124100: 0.244276
2023-03-16 22:24:00,844 INFO     Train positive_sample_loss at step 124200: 0.385612
2023-03-16 22:24:00,844 INFO     Train negative_sample_loss at step 124200: 0.105683
2023-03-16 22:24:00,844 INFO     Train loss at step 124200: 0.245648
2023-03-16 22:24:20,229 INFO     Train positive_sample_loss at step 124300: 0.385132
2023-03-16 22:24:20,229 INFO     Train negative_sample_loss at step 124300: 0.105829
2023-03-16 22:24:20,229 INFO     Train loss at step 124300: 0.245480
2023-03-16 22:24:39,633 INFO     Train positive_sample_loss at step 124400: 0.386876
2023-03-16 22:24:39,634 INFO     Train negative_sample_loss at step 124400: 0.106159
2023-03-16 22:24:39,634 INFO     Train loss at step 124400: 0.246517
2023-03-16 22:24:59,040 INFO     Train positive_sample_loss at step 124500: 0.387078
2023-03-16 22:24:59,040 INFO     Train negative_sample_loss at step 124500: 0.106755
2023-03-16 22:24:59,040 INFO     Train loss at step 124500: 0.246916
2023-03-16 22:25:25,433 INFO     Train positive_sample_loss at step 124600: 0.388273
2023-03-16 22:25:25,434 INFO     Train negative_sample_loss at step 124600: 0.106821
2023-03-16 22:25:25,434 INFO     Train loss at step 124600: 0.247547
2023-03-16 22:25:44,840 INFO     Train positive_sample_loss at step 124700: 0.388300
2023-03-16 22:25:44,841 INFO     Train negative_sample_loss at step 124700: 0.107355
2023-03-16 22:25:44,841 INFO     Train loss at step 124700: 0.247827
2023-03-16 22:26:04,252 INFO     Train positive_sample_loss at step 124800: 0.389199
2023-03-16 22:26:04,252 INFO     Train negative_sample_loss at step 124800: 0.107091
2023-03-16 22:26:04,252 INFO     Train loss at step 124800: 0.248145
2023-03-16 22:26:23,654 INFO     Train positive_sample_loss at step 124900: 0.387839
2023-03-16 22:26:23,655 INFO     Train negative_sample_loss at step 124900: 0.107690
2023-03-16 22:26:23,655 INFO     Train loss at step 124900: 0.247764
2023-03-16 22:26:43,061 INFO     Train positive_sample_loss at step 125000: 0.389381
2023-03-16 22:26:43,061 INFO     Train negative_sample_loss at step 125000: 0.107393
2023-03-16 22:26:43,061 INFO     Train loss at step 125000: 0.248387
2023-03-16 22:27:02,463 INFO     Train positive_sample_loss at step 125100: 0.387904
2023-03-16 22:27:02,463 INFO     Train negative_sample_loss at step 125100: 0.107618
2023-03-16 22:27:02,463 INFO     Train loss at step 125100: 0.247761
2023-03-16 22:27:21,869 INFO     Train positive_sample_loss at step 125200: 0.388459
2023-03-16 22:27:21,869 INFO     Train negative_sample_loss at step 125200: 0.108609
2023-03-16 22:27:21,870 INFO     Train loss at step 125200: 0.248534
2023-03-16 22:27:41,266 INFO     Train positive_sample_loss at step 125300: 0.386297
2023-03-16 22:27:41,266 INFO     Train negative_sample_loss at step 125300: 0.108039
2023-03-16 22:27:41,266 INFO     Train loss at step 125300: 0.247168
2023-03-16 22:28:00,666 INFO     Train positive_sample_loss at step 125400: 0.383759
2023-03-16 22:28:00,666 INFO     Train negative_sample_loss at step 125400: 0.108114
2023-03-16 22:28:00,666 INFO     Train loss at step 125400: 0.245936
2023-03-16 22:28:20,083 INFO     Train positive_sample_loss at step 125500: 0.382794
2023-03-16 22:28:20,084 INFO     Train negative_sample_loss at step 125500: 0.108645
2023-03-16 22:28:20,084 INFO     Train loss at step 125500: 0.245719
2023-03-16 22:28:39,486 INFO     Train positive_sample_loss at step 125600: 0.384129
2023-03-16 22:28:39,487 INFO     Train negative_sample_loss at step 125600: 0.108556
2023-03-16 22:28:39,487 INFO     Train loss at step 125600: 0.246343
2023-03-16 22:29:05,855 INFO     Train positive_sample_loss at step 125700: 0.381741
2023-03-16 22:29:05,856 INFO     Train negative_sample_loss at step 125700: 0.109543
2023-03-16 22:29:05,856 INFO     Train loss at step 125700: 0.245642
2023-03-16 22:29:25,267 INFO     Train positive_sample_loss at step 125800: 0.380293
2023-03-16 22:29:25,267 INFO     Train negative_sample_loss at step 125800: 0.108658
2023-03-16 22:29:25,267 INFO     Train loss at step 125800: 0.244476
2023-03-16 22:29:50,742 INFO     Train positive_sample_loss at step 125900: 0.367281
2023-03-16 22:29:50,743 INFO     Train negative_sample_loss at step 125900: 0.109397
2023-03-16 22:29:50,743 INFO     Train loss at step 125900: 0.238339
2023-03-16 22:30:10,093 INFO     Train positive_sample_loss at step 126000: 0.309463
2023-03-16 22:30:10,093 INFO     Train negative_sample_loss at step 126000: 0.105609
2023-03-16 22:30:10,093 INFO     Train loss at step 126000: 0.207536
2023-03-16 22:30:29,457 INFO     Train positive_sample_loss at step 126100: 0.311954
2023-03-16 22:30:29,457 INFO     Train negative_sample_loss at step 126100: 0.103200
2023-03-16 22:30:29,458 INFO     Train loss at step 126100: 0.207577
2023-03-16 22:30:48,795 INFO     Train positive_sample_loss at step 126200: 0.314967
2023-03-16 22:30:48,795 INFO     Train negative_sample_loss at step 126200: 0.103678
2023-03-16 22:30:48,795 INFO     Train loss at step 126200: 0.209322
2023-03-16 22:31:08,122 INFO     Train positive_sample_loss at step 126300: 0.319581
2023-03-16 22:31:08,123 INFO     Train negative_sample_loss at step 126300: 0.102406
2023-03-16 22:31:08,123 INFO     Train loss at step 126300: 0.210993
2023-03-16 22:31:35,163 INFO     Train positive_sample_loss at step 126400: 0.324498
2023-03-16 22:31:35,163 INFO     Train negative_sample_loss at step 126400: 0.102745
2023-03-16 22:31:35,164 INFO     Train loss at step 126400: 0.213622
2023-03-16 22:31:54,530 INFO     Train positive_sample_loss at step 126500: 0.328907
2023-03-16 22:31:54,531 INFO     Train negative_sample_loss at step 126500: 0.102151
2023-03-16 22:31:54,531 INFO     Train loss at step 126500: 0.215529
2023-03-16 22:32:13,906 INFO     Train positive_sample_loss at step 126600: 0.331657
2023-03-16 22:32:13,906 INFO     Train negative_sample_loss at step 126600: 0.102771
2023-03-16 22:32:13,907 INFO     Train loss at step 126600: 0.217214
2023-03-16 22:32:33,295 INFO     Train positive_sample_loss at step 126700: 0.337763
2023-03-16 22:32:33,295 INFO     Train negative_sample_loss at step 126700: 0.102418
2023-03-16 22:32:33,295 INFO     Train loss at step 126700: 0.220091
2023-03-16 22:32:52,699 INFO     Train positive_sample_loss at step 126800: 0.340526
2023-03-16 22:32:52,699 INFO     Train negative_sample_loss at step 126800: 0.102535
2023-03-16 22:32:52,699 INFO     Train loss at step 126800: 0.221531
2023-03-16 22:33:12,091 INFO     Train positive_sample_loss at step 126900: 0.346177
2023-03-16 22:33:12,091 INFO     Train negative_sample_loss at step 126900: 0.102368
2023-03-16 22:33:12,091 INFO     Train loss at step 126900: 0.224272
2023-03-16 22:33:31,478 INFO     Train positive_sample_loss at step 127000: 0.348643
2023-03-16 22:33:31,479 INFO     Train negative_sample_loss at step 127000: 0.103233
2023-03-16 22:33:31,479 INFO     Train loss at step 127000: 0.225938
2023-03-16 22:33:50,871 INFO     Train positive_sample_loss at step 127100: 0.353801
2023-03-16 22:33:50,872 INFO     Train negative_sample_loss at step 127100: 0.103422
2023-03-16 22:33:50,872 INFO     Train loss at step 127100: 0.228611
2023-03-16 22:34:10,252 INFO     Train positive_sample_loss at step 127200: 0.357376
2023-03-16 22:34:10,253 INFO     Train negative_sample_loss at step 127200: 0.102775
2023-03-16 22:34:10,253 INFO     Train loss at step 127200: 0.230076
2023-03-16 22:34:29,641 INFO     Train positive_sample_loss at step 127300: 0.363128
2023-03-16 22:34:29,642 INFO     Train negative_sample_loss at step 127300: 0.103320
2023-03-16 22:34:29,642 INFO     Train loss at step 127300: 0.233224
2023-03-16 22:34:49,035 INFO     Train positive_sample_loss at step 127400: 0.367112
2023-03-16 22:34:49,036 INFO     Train negative_sample_loss at step 127400: 0.103975
2023-03-16 22:34:49,036 INFO     Train loss at step 127400: 0.235543
2023-03-16 22:35:15,316 INFO     Train positive_sample_loss at step 127500: 0.369369
2023-03-16 22:35:15,316 INFO     Train negative_sample_loss at step 127500: 0.103447
2023-03-16 22:35:15,316 INFO     Train loss at step 127500: 0.236408
2023-03-16 22:35:34,702 INFO     Train positive_sample_loss at step 127600: 0.372555
2023-03-16 22:35:34,703 INFO     Train negative_sample_loss at step 127600: 0.103828
2023-03-16 22:35:34,703 INFO     Train loss at step 127600: 0.238191
2023-03-16 22:35:54,102 INFO     Train positive_sample_loss at step 127700: 0.376544
2023-03-16 22:35:54,103 INFO     Train negative_sample_loss at step 127700: 0.104412
2023-03-16 22:35:54,103 INFO     Train loss at step 127700: 0.240478
2023-03-16 22:36:13,508 INFO     Train positive_sample_loss at step 127800: 0.375993
2023-03-16 22:36:13,509 INFO     Train negative_sample_loss at step 127800: 0.103629
2023-03-16 22:36:13,509 INFO     Train loss at step 127800: 0.239811
2023-03-16 22:36:32,908 INFO     Train positive_sample_loss at step 127900: 0.380128
2023-03-16 22:36:32,909 INFO     Train negative_sample_loss at step 127900: 0.104949
2023-03-16 22:36:32,909 INFO     Train loss at step 127900: 0.242538
2023-03-16 22:36:52,316 INFO     Train positive_sample_loss at step 128000: 0.382433
2023-03-16 22:36:52,317 INFO     Train negative_sample_loss at step 128000: 0.105018
2023-03-16 22:36:52,317 INFO     Train loss at step 128000: 0.243726
2023-03-16 22:37:11,717 INFO     Train positive_sample_loss at step 128100: 0.384053
2023-03-16 22:37:11,718 INFO     Train negative_sample_loss at step 128100: 0.105306
2023-03-16 22:37:11,718 INFO     Train loss at step 128100: 0.244679
2023-03-16 22:37:31,121 INFO     Train positive_sample_loss at step 128200: 0.386271
2023-03-16 22:37:31,122 INFO     Train negative_sample_loss at step 128200: 0.105625
2023-03-16 22:37:31,122 INFO     Train loss at step 128200: 0.245948
2023-03-16 22:37:50,526 INFO     Train positive_sample_loss at step 128300: 0.387603
2023-03-16 22:37:50,526 INFO     Train negative_sample_loss at step 128300: 0.105404
2023-03-16 22:37:50,526 INFO     Train loss at step 128300: 0.246504
2023-03-16 22:38:09,931 INFO     Train positive_sample_loss at step 128400: 0.386827
2023-03-16 22:38:09,931 INFO     Train negative_sample_loss at step 128400: 0.106155
2023-03-16 22:38:09,931 INFO     Train loss at step 128400: 0.246491
2023-03-16 22:38:29,330 INFO     Train positive_sample_loss at step 128500: 0.387470
2023-03-16 22:38:29,330 INFO     Train negative_sample_loss at step 128500: 0.106323
2023-03-16 22:38:29,330 INFO     Train loss at step 128500: 0.246897
2023-03-16 22:38:58,079 INFO     Train positive_sample_loss at step 128600: 0.387075
2023-03-16 22:38:58,080 INFO     Train negative_sample_loss at step 128600: 0.106535
2023-03-16 22:38:58,080 INFO     Train loss at step 128600: 0.246805
2023-03-16 22:39:17,472 INFO     Train positive_sample_loss at step 128700: 0.390010
2023-03-16 22:39:17,473 INFO     Train negative_sample_loss at step 128700: 0.107082
2023-03-16 22:39:17,473 INFO     Train loss at step 128700: 0.248546
2023-03-16 22:39:36,875 INFO     Train positive_sample_loss at step 128800: 0.387985
2023-03-16 22:39:36,876 INFO     Train negative_sample_loss at step 128800: 0.107647
2023-03-16 22:39:36,876 INFO     Train loss at step 128800: 0.247816
2023-03-16 22:39:56,259 INFO     Train positive_sample_loss at step 128900: 0.389505
2023-03-16 22:39:56,259 INFO     Train negative_sample_loss at step 128900: 0.107545
2023-03-16 22:39:56,259 INFO     Train loss at step 128900: 0.248525
2023-03-16 22:40:15,659 INFO     Train positive_sample_loss at step 129000: 0.386787
2023-03-16 22:40:15,659 INFO     Train negative_sample_loss at step 129000: 0.107696
2023-03-16 22:40:15,659 INFO     Train loss at step 129000: 0.247241
2023-03-16 22:40:35,049 INFO     Train positive_sample_loss at step 129100: 0.388360
2023-03-16 22:40:35,050 INFO     Train negative_sample_loss at step 129100: 0.107746
2023-03-16 22:40:35,050 INFO     Train loss at step 129100: 0.248053
2023-03-16 22:40:54,441 INFO     Train positive_sample_loss at step 129200: 0.384771
2023-03-16 22:40:54,442 INFO     Train negative_sample_loss at step 129200: 0.108060
2023-03-16 22:40:54,442 INFO     Train loss at step 129200: 0.246415
2023-03-16 22:41:13,849 INFO     Train positive_sample_loss at step 129300: 0.384737
2023-03-16 22:41:13,849 INFO     Train negative_sample_loss at step 129300: 0.108633
2023-03-16 22:41:13,849 INFO     Train loss at step 129300: 0.246685
2023-03-16 22:41:33,244 INFO     Train positive_sample_loss at step 129400: 0.383142
2023-03-16 22:41:33,245 INFO     Train negative_sample_loss at step 129400: 0.109570
2023-03-16 22:41:33,245 INFO     Train loss at step 129400: 0.246356
2023-03-16 22:41:52,656 INFO     Train positive_sample_loss at step 129500: 0.385448
2023-03-16 22:41:52,657 INFO     Train negative_sample_loss at step 129500: 0.108622
2023-03-16 22:41:52,657 INFO     Train loss at step 129500: 0.247035
2023-03-16 22:42:18,944 INFO     Train positive_sample_loss at step 129600: 0.383753
2023-03-16 22:42:18,945 INFO     Train negative_sample_loss at step 129600: 0.108228
2023-03-16 22:42:18,945 INFO     Train loss at step 129600: 0.245991
2023-03-16 22:42:38,340 INFO     Train positive_sample_loss at step 129700: 0.380157
2023-03-16 22:42:38,340 INFO     Train negative_sample_loss at step 129700: 0.108685
2023-03-16 22:42:38,340 INFO     Train loss at step 129700: 0.244421
2023-03-16 22:42:57,730 INFO     Train positive_sample_loss at step 129800: 0.379344
2023-03-16 22:42:57,730 INFO     Train negative_sample_loss at step 129800: 0.109258
2023-03-16 22:42:57,730 INFO     Train loss at step 129800: 0.244301
2023-03-16 22:43:23,169 INFO     Train positive_sample_loss at step 129900: 0.321386
2023-03-16 22:43:23,170 INFO     Train negative_sample_loss at step 129900: 0.107131
2023-03-16 22:43:23,170 INFO     Train loss at step 129900: 0.214258
2023-03-16 22:43:44,311 INFO     Train positive_sample_loss at step 130000: 0.312896
2023-03-16 22:43:44,312 INFO     Train negative_sample_loss at step 130000: 0.104572
2023-03-16 22:43:44,312 INFO     Train loss at step 130000: 0.208734
2023-03-16 22:43:44,312 INFO     Evaluating on Valid Dataset...
2023-03-16 22:43:45,305 INFO     Evaluating the model... (0/26842)
2023-03-16 22:43:46,993 INFO     Evaluating the model... (1000/26842)
2023-03-16 22:43:48,222 INFO     Evaluating the model... (2000/26842)
2023-03-16 22:43:49,448 INFO     Evaluating the model... (3000/26842)
2023-03-16 22:43:50,679 INFO     Evaluating the model... (4000/26842)
2023-03-16 22:43:51,917 INFO     Evaluating the model... (5000/26842)
2023-03-16 22:43:53,150 INFO     Evaluating the model... (6000/26842)
2023-03-16 22:43:54,387 INFO     Evaluating the model... (7000/26842)
2023-03-16 22:43:55,624 INFO     Evaluating the model... (8000/26842)
2023-03-16 22:43:56,859 INFO     Evaluating the model... (9000/26842)
2023-03-16 22:43:58,091 INFO     Evaluating the model... (10000/26842)
2023-03-16 22:43:59,331 INFO     Evaluating the model... (11000/26842)
2023-03-16 22:44:00,573 INFO     Evaluating the model... (12000/26842)
2023-03-16 22:44:01,810 INFO     Evaluating the model... (13000/26842)
2023-03-16 22:44:04,109 INFO     Evaluating the model... (14000/26842)
2023-03-16 22:44:05,596 INFO     Evaluating the model... (15000/26842)
2023-03-16 22:44:07,078 INFO     Evaluating the model... (16000/26842)
2023-03-16 22:44:08,559 INFO     Evaluating the model... (17000/26842)
2023-03-16 22:44:10,037 INFO     Evaluating the model... (18000/26842)
2023-03-16 22:44:11,524 INFO     Evaluating the model... (19000/26842)
2023-03-16 22:44:13,012 INFO     Evaluating the model... (20000/26842)
2023-03-16 22:44:14,487 INFO     Evaluating the model... (21000/26842)
2023-03-16 22:44:15,969 INFO     Evaluating the model... (22000/26842)
2023-03-16 22:44:17,449 INFO     Evaluating the model... (23000/26842)
2023-03-16 22:44:18,920 INFO     Evaluating the model... (24000/26842)
2023-03-16 22:44:20,415 INFO     Evaluating the model... (25000/26842)
2023-03-16 22:44:21,895 INFO     Evaluating the model... (26000/26842)
2023-03-16 22:44:23,455 INFO     Valid hits@1_list at step 130000: 0.590121
2023-03-16 22:44:23,455 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 22:44:23,456 INFO     Valid hits@3_list at step 130000: 0.681152
2023-03-16 22:44:23,456 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 22:44:23,456 INFO     Valid hits@10_list at step 130000: 0.766826
2023-03-16 22:44:23,456 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 22:44:23,456 INFO     Valid mrr_list at step 130000: 0.651933
2023-03-16 22:44:42,804 INFO     Train positive_sample_loss at step 130100: 0.316896
2023-03-16 22:44:42,804 INFO     Train negative_sample_loss at step 130100: 0.103016
2023-03-16 22:44:42,804 INFO     Train loss at step 130100: 0.209956
2023-03-16 22:45:02,145 INFO     Train positive_sample_loss at step 130200: 0.319101
2023-03-16 22:45:02,146 INFO     Train negative_sample_loss at step 130200: 0.102854
2023-03-16 22:45:02,146 INFO     Train loss at step 130200: 0.210978
2023-03-16 22:45:21,480 INFO     Train positive_sample_loss at step 130300: 0.322267
2023-03-16 22:45:21,480 INFO     Train negative_sample_loss at step 130300: 0.102134
2023-03-16 22:45:21,480 INFO     Train loss at step 130300: 0.212201
2023-03-16 22:45:48,653 INFO     Train positive_sample_loss at step 130400: 0.328884
2023-03-16 22:45:48,653 INFO     Train negative_sample_loss at step 130400: 0.102564
2023-03-16 22:45:48,653 INFO     Train loss at step 130400: 0.215724
2023-03-16 22:46:08,033 INFO     Train positive_sample_loss at step 130500: 0.331435
2023-03-16 22:46:08,033 INFO     Train negative_sample_loss at step 130500: 0.102655
2023-03-16 22:46:08,033 INFO     Train loss at step 130500: 0.217045
2023-03-16 22:46:27,419 INFO     Train positive_sample_loss at step 130600: 0.336558
2023-03-16 22:46:27,419 INFO     Train negative_sample_loss at step 130600: 0.102511
2023-03-16 22:46:27,419 INFO     Train loss at step 130600: 0.219535
2023-03-16 22:46:46,824 INFO     Train positive_sample_loss at step 130700: 0.339734
2023-03-16 22:46:46,824 INFO     Train negative_sample_loss at step 130700: 0.102683
2023-03-16 22:46:46,825 INFO     Train loss at step 130700: 0.221208
2023-03-16 22:47:06,226 INFO     Train positive_sample_loss at step 130800: 0.345081
2023-03-16 22:47:06,226 INFO     Train negative_sample_loss at step 130800: 0.102571
2023-03-16 22:47:06,227 INFO     Train loss at step 130800: 0.223826
2023-03-16 22:47:25,612 INFO     Train positive_sample_loss at step 130900: 0.349084
2023-03-16 22:47:25,613 INFO     Train negative_sample_loss at step 130900: 0.102857
2023-03-16 22:47:25,613 INFO     Train loss at step 130900: 0.225970
2023-03-16 22:47:45,011 INFO     Train positive_sample_loss at step 131000: 0.352709
2023-03-16 22:47:45,011 INFO     Train negative_sample_loss at step 131000: 0.102424
2023-03-16 22:47:45,011 INFO     Train loss at step 131000: 0.227567
2023-03-16 22:48:04,414 INFO     Train positive_sample_loss at step 131100: 0.354739
2023-03-16 22:48:04,414 INFO     Train negative_sample_loss at step 131100: 0.103213
2023-03-16 22:48:04,414 INFO     Train loss at step 131100: 0.228976
2023-03-16 22:48:23,825 INFO     Train positive_sample_loss at step 131200: 0.360939
2023-03-16 22:48:23,825 INFO     Train negative_sample_loss at step 131200: 0.103785
2023-03-16 22:48:23,825 INFO     Train loss at step 131200: 0.232362
2023-03-16 22:48:43,229 INFO     Train positive_sample_loss at step 131300: 0.363529
2023-03-16 22:48:43,229 INFO     Train negative_sample_loss at step 131300: 0.102876
2023-03-16 22:48:43,230 INFO     Train loss at step 131300: 0.233202
2023-03-16 22:49:09,622 INFO     Train positive_sample_loss at step 131400: 0.368605
2023-03-16 22:49:09,622 INFO     Train negative_sample_loss at step 131400: 0.103901
2023-03-16 22:49:09,622 INFO     Train loss at step 131400: 0.236253
2023-03-16 22:49:29,028 INFO     Train positive_sample_loss at step 131500: 0.370524
2023-03-16 22:49:29,028 INFO     Train negative_sample_loss at step 131500: 0.104156
2023-03-16 22:49:29,028 INFO     Train loss at step 131500: 0.237340
2023-03-16 22:49:48,428 INFO     Train positive_sample_loss at step 131600: 0.374631
2023-03-16 22:49:48,428 INFO     Train negative_sample_loss at step 131600: 0.103793
2023-03-16 22:49:48,428 INFO     Train loss at step 131600: 0.239212
2023-03-16 22:50:07,814 INFO     Train positive_sample_loss at step 131700: 0.375951
2023-03-16 22:50:07,815 INFO     Train negative_sample_loss at step 131700: 0.104666
2023-03-16 22:50:07,815 INFO     Train loss at step 131700: 0.240308
2023-03-16 22:50:27,198 INFO     Train positive_sample_loss at step 131800: 0.377930
2023-03-16 22:50:27,198 INFO     Train negative_sample_loss at step 131800: 0.104920
2023-03-16 22:50:27,199 INFO     Train loss at step 131800: 0.241425
2023-03-16 22:50:46,596 INFO     Train positive_sample_loss at step 131900: 0.381135
2023-03-16 22:50:46,596 INFO     Train negative_sample_loss at step 131900: 0.104552
2023-03-16 22:50:46,596 INFO     Train loss at step 131900: 0.242843
2023-03-16 22:51:05,993 INFO     Train positive_sample_loss at step 132000: 0.383357
2023-03-16 22:51:05,994 INFO     Train negative_sample_loss at step 132000: 0.106058
2023-03-16 22:51:05,994 INFO     Train loss at step 132000: 0.244708
2023-03-16 22:51:25,375 INFO     Train positive_sample_loss at step 132100: 0.385918
2023-03-16 22:51:25,375 INFO     Train negative_sample_loss at step 132100: 0.105695
2023-03-16 22:51:25,375 INFO     Train loss at step 132100: 0.245807
2023-03-16 22:51:44,774 INFO     Train positive_sample_loss at step 132200: 0.384547
2023-03-16 22:51:44,774 INFO     Train negative_sample_loss at step 132200: 0.105646
2023-03-16 22:51:44,775 INFO     Train loss at step 132200: 0.245096
2023-03-16 22:52:04,171 INFO     Train positive_sample_loss at step 132300: 0.385264
2023-03-16 22:52:04,172 INFO     Train negative_sample_loss at step 132300: 0.106539
2023-03-16 22:52:04,172 INFO     Train loss at step 132300: 0.245901
2023-03-16 22:52:23,562 INFO     Train positive_sample_loss at step 132400: 0.387542
2023-03-16 22:52:23,562 INFO     Train negative_sample_loss at step 132400: 0.106301
2023-03-16 22:52:23,562 INFO     Train loss at step 132400: 0.246921
2023-03-16 22:52:53,192 INFO     Train positive_sample_loss at step 132500: 0.387344
2023-03-16 22:52:53,193 INFO     Train negative_sample_loss at step 132500: 0.106857
2023-03-16 22:52:53,193 INFO     Train loss at step 132500: 0.247100
2023-03-16 22:53:12,590 INFO     Train positive_sample_loss at step 132600: 0.387091
2023-03-16 22:53:12,590 INFO     Train negative_sample_loss at step 132600: 0.106987
2023-03-16 22:53:12,590 INFO     Train loss at step 132600: 0.247039
2023-03-16 22:53:31,984 INFO     Train positive_sample_loss at step 132700: 0.389217
2023-03-16 22:53:31,985 INFO     Train negative_sample_loss at step 132700: 0.107376
2023-03-16 22:53:31,985 INFO     Train loss at step 132700: 0.248296
2023-03-16 22:53:51,381 INFO     Train positive_sample_loss at step 132800: 0.387891
2023-03-16 22:53:51,381 INFO     Train negative_sample_loss at step 132800: 0.106945
2023-03-16 22:53:51,381 INFO     Train loss at step 132800: 0.247418
2023-03-16 22:54:10,777 INFO     Train positive_sample_loss at step 132900: 0.387398
2023-03-16 22:54:10,778 INFO     Train negative_sample_loss at step 132900: 0.108007
2023-03-16 22:54:10,778 INFO     Train loss at step 132900: 0.247702
2023-03-16 22:54:30,182 INFO     Train positive_sample_loss at step 133000: 0.386050
2023-03-16 22:54:30,182 INFO     Train negative_sample_loss at step 133000: 0.107291
2023-03-16 22:54:30,182 INFO     Train loss at step 133000: 0.246671
2023-03-16 22:54:49,587 INFO     Train positive_sample_loss at step 133100: 0.386199
2023-03-16 22:54:49,588 INFO     Train negative_sample_loss at step 133100: 0.107566
2023-03-16 22:54:49,588 INFO     Train loss at step 133100: 0.246883
2023-03-16 22:55:08,985 INFO     Train positive_sample_loss at step 133200: 0.386831
2023-03-16 22:55:08,986 INFO     Train negative_sample_loss at step 133200: 0.108232
2023-03-16 22:55:08,986 INFO     Train loss at step 133200: 0.247532
2023-03-16 22:55:28,388 INFO     Train positive_sample_loss at step 133300: 0.383805
2023-03-16 22:55:28,388 INFO     Train negative_sample_loss at step 133300: 0.108478
2023-03-16 22:55:28,388 INFO     Train loss at step 133300: 0.246142
2023-03-16 22:55:47,810 INFO     Train positive_sample_loss at step 133400: 0.383287
2023-03-16 22:55:47,810 INFO     Train negative_sample_loss at step 133400: 0.108242
2023-03-16 22:55:47,810 INFO     Train loss at step 133400: 0.245765
2023-03-16 22:56:07,234 INFO     Train positive_sample_loss at step 133500: 0.379779
2023-03-16 22:56:07,234 INFO     Train negative_sample_loss at step 133500: 0.109342
2023-03-16 22:56:07,235 INFO     Train loss at step 133500: 0.244561
2023-03-16 22:56:33,519 INFO     Train positive_sample_loss at step 133600: 0.379347
2023-03-16 22:56:33,519 INFO     Train negative_sample_loss at step 133600: 0.109384
2023-03-16 22:56:33,519 INFO     Train loss at step 133600: 0.244365
2023-03-16 22:56:52,926 INFO     Train positive_sample_loss at step 133700: 0.380675
2023-03-16 22:56:52,926 INFO     Train negative_sample_loss at step 133700: 0.109035
2023-03-16 22:56:52,926 INFO     Train loss at step 133700: 0.244855
funtion time use:38964ms
2023-03-16 22:57:18,441 INFO     Train positive_sample_loss at step 133800: 0.346429
2023-03-16 22:57:18,441 INFO     Train negative_sample_loss at step 133800: 0.108538
2023-03-16 22:57:18,442 INFO     Train loss at step 133800: 0.227483
2023-03-16 22:57:37,803 INFO     Train positive_sample_loss at step 133900: 0.310927
2023-03-16 22:57:37,804 INFO     Train negative_sample_loss at step 133900: 0.104213
2023-03-16 22:57:37,804 INFO     Train loss at step 133900: 0.207570
2023-03-16 22:57:57,156 INFO     Train positive_sample_loss at step 134000: 0.314168
2023-03-16 22:57:57,156 INFO     Train negative_sample_loss at step 134000: 0.103778
2023-03-16 22:57:57,157 INFO     Train loss at step 134000: 0.208973
2023-03-16 22:58:16,497 INFO     Train positive_sample_loss at step 134100: 0.317194
2023-03-16 22:58:16,498 INFO     Train negative_sample_loss at step 134100: 0.103082
2023-03-16 22:58:16,498 INFO     Train loss at step 134100: 0.210138
2023-03-16 22:58:35,836 INFO     Train positive_sample_loss at step 134200: 0.322622
2023-03-16 22:58:35,837 INFO     Train negative_sample_loss at step 134200: 0.103000
2023-03-16 22:58:35,837 INFO     Train loss at step 134200: 0.212811
2023-03-16 22:59:02,776 INFO     Train positive_sample_loss at step 134300: 0.325963
2023-03-16 22:59:02,777 INFO     Train negative_sample_loss at step 134300: 0.102814
2023-03-16 22:59:02,777 INFO     Train loss at step 134300: 0.214389
2023-03-16 22:59:22,167 INFO     Train positive_sample_loss at step 134400: 0.329114
2023-03-16 22:59:22,167 INFO     Train negative_sample_loss at step 134400: 0.101737
2023-03-16 22:59:22,167 INFO     Train loss at step 134400: 0.215426
2023-03-16 22:59:41,553 INFO     Train positive_sample_loss at step 134500: 0.333038
2023-03-16 22:59:41,554 INFO     Train negative_sample_loss at step 134500: 0.102042
2023-03-16 22:59:41,554 INFO     Train loss at step 134500: 0.217540
2023-03-16 23:00:00,957 INFO     Train positive_sample_loss at step 134600: 0.338803
2023-03-16 23:00:00,957 INFO     Train negative_sample_loss at step 134600: 0.101888
2023-03-16 23:00:00,958 INFO     Train loss at step 134600: 0.220346
2023-03-16 23:00:20,344 INFO     Train positive_sample_loss at step 134700: 0.340959
2023-03-16 23:00:20,345 INFO     Train negative_sample_loss at step 134700: 0.101655
2023-03-16 23:00:20,345 INFO     Train loss at step 134700: 0.221307
2023-03-16 23:00:39,747 INFO     Train positive_sample_loss at step 134800: 0.345753
2023-03-16 23:00:39,747 INFO     Train negative_sample_loss at step 134800: 0.102484
2023-03-16 23:00:39,747 INFO     Train loss at step 134800: 0.224118
2023-03-16 23:00:59,143 INFO     Train positive_sample_loss at step 134900: 0.350948
2023-03-16 23:00:59,144 INFO     Train negative_sample_loss at step 134900: 0.101774
2023-03-16 23:00:59,144 INFO     Train loss at step 134900: 0.226361
2023-03-16 23:01:18,537 INFO     Train positive_sample_loss at step 135000: 0.354258
2023-03-16 23:01:18,538 INFO     Train negative_sample_loss at step 135000: 0.102540
2023-03-16 23:01:18,538 INFO     Train loss at step 135000: 0.228399
2023-03-16 23:01:37,929 INFO     Train positive_sample_loss at step 135100: 0.357784
2023-03-16 23:01:37,929 INFO     Train negative_sample_loss at step 135100: 0.102506
2023-03-16 23:01:37,929 INFO     Train loss at step 135100: 0.230145
2023-03-16 23:01:57,325 INFO     Train positive_sample_loss at step 135200: 0.362842
2023-03-16 23:01:57,325 INFO     Train negative_sample_loss at step 135200: 0.103527
2023-03-16 23:01:57,325 INFO     Train loss at step 135200: 0.233184
2023-03-16 23:02:23,681 INFO     Train positive_sample_loss at step 135300: 0.368338
2023-03-16 23:02:23,682 INFO     Train negative_sample_loss at step 135300: 0.104294
2023-03-16 23:02:23,682 INFO     Train loss at step 135300: 0.236316
2023-03-16 23:02:43,091 INFO     Train positive_sample_loss at step 135400: 0.371899
2023-03-16 23:02:43,092 INFO     Train negative_sample_loss at step 135400: 0.104247
2023-03-16 23:02:43,092 INFO     Train loss at step 135400: 0.238073
2023-03-16 23:03:02,484 INFO     Train positive_sample_loss at step 135500: 0.372406
2023-03-16 23:03:02,484 INFO     Train negative_sample_loss at step 135500: 0.104440
2023-03-16 23:03:02,484 INFO     Train loss at step 135500: 0.238423
2023-03-16 23:03:21,893 INFO     Train positive_sample_loss at step 135600: 0.377263
2023-03-16 23:03:21,894 INFO     Train negative_sample_loss at step 135600: 0.104925
2023-03-16 23:03:21,894 INFO     Train loss at step 135600: 0.241094
2023-03-16 23:03:41,283 INFO     Train positive_sample_loss at step 135700: 0.378131
2023-03-16 23:03:41,284 INFO     Train negative_sample_loss at step 135700: 0.104997
2023-03-16 23:03:41,284 INFO     Train loss at step 135700: 0.241564
2023-03-16 23:04:00,690 INFO     Train positive_sample_loss at step 135800: 0.380369
2023-03-16 23:04:00,690 INFO     Train negative_sample_loss at step 135800: 0.104536
2023-03-16 23:04:00,690 INFO     Train loss at step 135800: 0.242452
2023-03-16 23:04:20,095 INFO     Train positive_sample_loss at step 135900: 0.381319
2023-03-16 23:04:20,095 INFO     Train negative_sample_loss at step 135900: 0.105358
2023-03-16 23:04:20,096 INFO     Train loss at step 135900: 0.243338
2023-03-16 23:04:39,504 INFO     Train positive_sample_loss at step 136000: 0.385485
2023-03-16 23:04:39,504 INFO     Train negative_sample_loss at step 136000: 0.105677
2023-03-16 23:04:39,505 INFO     Train loss at step 136000: 0.245581
2023-03-16 23:04:58,892 INFO     Train positive_sample_loss at step 136100: 0.386322
2023-03-16 23:04:58,892 INFO     Train negative_sample_loss at step 136100: 0.105517
2023-03-16 23:04:58,892 INFO     Train loss at step 136100: 0.245919
2023-03-16 23:05:18,290 INFO     Train positive_sample_loss at step 136200: 0.386262
2023-03-16 23:05:18,290 INFO     Train negative_sample_loss at step 136200: 0.105888
2023-03-16 23:05:18,290 INFO     Train loss at step 136200: 0.246075
2023-03-16 23:05:37,697 INFO     Train positive_sample_loss at step 136300: 0.388855
2023-03-16 23:05:37,697 INFO     Train negative_sample_loss at step 136300: 0.106963
2023-03-16 23:05:37,697 INFO     Train loss at step 136300: 0.247909
2023-03-16 23:06:03,960 INFO     Train positive_sample_loss at step 136400: 0.387815
2023-03-16 23:06:03,961 INFO     Train negative_sample_loss at step 136400: 0.106325
2023-03-16 23:06:03,961 INFO     Train loss at step 136400: 0.247070
2023-03-16 23:06:23,368 INFO     Train positive_sample_loss at step 136500: 0.387972
2023-03-16 23:06:23,369 INFO     Train negative_sample_loss at step 136500: 0.106731
2023-03-16 23:06:23,369 INFO     Train loss at step 136500: 0.247352
2023-03-16 23:06:42,777 INFO     Train positive_sample_loss at step 136600: 0.387703
2023-03-16 23:06:42,778 INFO     Train negative_sample_loss at step 136600: 0.106849
2023-03-16 23:06:42,778 INFO     Train loss at step 136600: 0.247276
2023-03-16 23:07:02,189 INFO     Train positive_sample_loss at step 136700: 0.389266
2023-03-16 23:07:02,189 INFO     Train negative_sample_loss at step 136700: 0.107283
2023-03-16 23:07:02,189 INFO     Train loss at step 136700: 0.248275
2023-03-16 23:07:21,606 INFO     Train positive_sample_loss at step 136800: 0.388523
2023-03-16 23:07:21,606 INFO     Train negative_sample_loss at step 136800: 0.107534
2023-03-16 23:07:21,606 INFO     Train loss at step 136800: 0.248028
2023-03-16 23:07:41,033 INFO     Train positive_sample_loss at step 136900: 0.389215
2023-03-16 23:07:41,033 INFO     Train negative_sample_loss at step 136900: 0.108021
2023-03-16 23:07:41,033 INFO     Train loss at step 136900: 0.248618
2023-03-16 23:08:00,445 INFO     Train positive_sample_loss at step 137000: 0.388653
2023-03-16 23:08:00,446 INFO     Train negative_sample_loss at step 137000: 0.107773
2023-03-16 23:08:00,446 INFO     Train loss at step 137000: 0.248213
2023-03-16 23:08:19,877 INFO     Train positive_sample_loss at step 137100: 0.386428
2023-03-16 23:08:19,878 INFO     Train negative_sample_loss at step 137100: 0.107889
2023-03-16 23:08:19,878 INFO     Train loss at step 137100: 0.247159
2023-03-16 23:08:39,284 INFO     Train positive_sample_loss at step 137200: 0.385612
2023-03-16 23:08:39,285 INFO     Train negative_sample_loss at step 137200: 0.108180
2023-03-16 23:08:39,285 INFO     Train loss at step 137200: 0.246896
2023-03-16 23:08:58,685 INFO     Train positive_sample_loss at step 137300: 0.384350
2023-03-16 23:08:58,686 INFO     Train negative_sample_loss at step 137300: 0.108101
2023-03-16 23:08:58,686 INFO     Train loss at step 137300: 0.246226
2023-03-16 23:09:18,103 INFO     Train positive_sample_loss at step 137400: 0.382002
2023-03-16 23:09:18,103 INFO     Train negative_sample_loss at step 137400: 0.108260
2023-03-16 23:09:18,103 INFO     Train loss at step 137400: 0.245131
2023-03-16 23:09:44,429 INFO     Train positive_sample_loss at step 137500: 0.380711
2023-03-16 23:09:44,429 INFO     Train negative_sample_loss at step 137500: 0.108552
2023-03-16 23:09:44,429 INFO     Train loss at step 137500: 0.244632
2023-03-16 23:10:03,838 INFO     Train positive_sample_loss at step 137600: 0.379319
2023-03-16 23:10:03,839 INFO     Train negative_sample_loss at step 137600: 0.108566
2023-03-16 23:10:03,839 INFO     Train loss at step 137600: 0.243942
2023-03-16 23:10:29,431 INFO     Train positive_sample_loss at step 137700: 0.368763
2023-03-16 23:10:29,431 INFO     Train negative_sample_loss at step 137700: 0.108892
2023-03-16 23:10:29,431 INFO     Train loss at step 137700: 0.238827
2023-03-16 23:10:48,813 INFO     Train positive_sample_loss at step 137800: 0.307637
2023-03-16 23:10:48,813 INFO     Train negative_sample_loss at step 137800: 0.106055
2023-03-16 23:10:48,813 INFO     Train loss at step 137800: 0.206846
2023-03-16 23:11:08,175 INFO     Train positive_sample_loss at step 137900: 0.312977
2023-03-16 23:11:08,176 INFO     Train negative_sample_loss at step 137900: 0.104382
2023-03-16 23:11:08,176 INFO     Train loss at step 137900: 0.208679
2023-03-16 23:11:27,530 INFO     Train positive_sample_loss at step 138000: 0.318898
2023-03-16 23:11:27,531 INFO     Train negative_sample_loss at step 138000: 0.102990
2023-03-16 23:11:27,531 INFO     Train loss at step 138000: 0.210944
2023-03-16 23:11:46,870 INFO     Train positive_sample_loss at step 138100: 0.321906
2023-03-16 23:11:46,871 INFO     Train negative_sample_loss at step 138100: 0.102700
2023-03-16 23:11:46,871 INFO     Train loss at step 138100: 0.212303
2023-03-16 23:12:13,897 INFO     Train positive_sample_loss at step 138200: 0.323228
2023-03-16 23:12:13,898 INFO     Train negative_sample_loss at step 138200: 0.102379
2023-03-16 23:12:13,898 INFO     Train loss at step 138200: 0.212804
2023-03-16 23:12:33,279 INFO     Train positive_sample_loss at step 138300: 0.328477
2023-03-16 23:12:33,280 INFO     Train negative_sample_loss at step 138300: 0.102126
2023-03-16 23:12:33,280 INFO     Train loss at step 138300: 0.215302
2023-03-16 23:12:52,666 INFO     Train positive_sample_loss at step 138400: 0.331358
2023-03-16 23:12:52,667 INFO     Train negative_sample_loss at step 138400: 0.101529
2023-03-16 23:12:52,667 INFO     Train loss at step 138400: 0.216444
2023-03-16 23:13:12,054 INFO     Train positive_sample_loss at step 138500: 0.335086
2023-03-16 23:13:12,054 INFO     Train negative_sample_loss at step 138500: 0.102350
2023-03-16 23:13:12,054 INFO     Train loss at step 138500: 0.218718
2023-03-16 23:13:31,446 INFO     Train positive_sample_loss at step 138600: 0.340319
2023-03-16 23:13:31,446 INFO     Train negative_sample_loss at step 138600: 0.102547
2023-03-16 23:13:31,447 INFO     Train loss at step 138600: 0.221433
2023-03-16 23:13:50,836 INFO     Train positive_sample_loss at step 138700: 0.345489
2023-03-16 23:13:50,837 INFO     Train negative_sample_loss at step 138700: 0.103107
2023-03-16 23:13:50,837 INFO     Train loss at step 138700: 0.224298
2023-03-16 23:14:10,232 INFO     Train positive_sample_loss at step 138800: 0.349470
2023-03-16 23:14:10,233 INFO     Train negative_sample_loss at step 138800: 0.101662
2023-03-16 23:14:10,233 INFO     Train loss at step 138800: 0.225566
2023-03-16 23:14:29,629 INFO     Train positive_sample_loss at step 138900: 0.353898
2023-03-16 23:14:29,630 INFO     Train negative_sample_loss at step 138900: 0.102594
2023-03-16 23:14:29,630 INFO     Train loss at step 138900: 0.228246
2023-03-16 23:14:49,020 INFO     Train positive_sample_loss at step 139000: 0.358291
2023-03-16 23:14:49,021 INFO     Train negative_sample_loss at step 139000: 0.103132
2023-03-16 23:14:49,021 INFO     Train loss at step 139000: 0.230712
2023-03-16 23:15:08,422 INFO     Train positive_sample_loss at step 139100: 0.363013
2023-03-16 23:15:08,423 INFO     Train negative_sample_loss at step 139100: 0.103325
2023-03-16 23:15:08,423 INFO     Train loss at step 139100: 0.233169
2023-03-16 23:15:27,835 INFO     Train positive_sample_loss at step 139200: 0.365485
2023-03-16 23:15:27,836 INFO     Train negative_sample_loss at step 139200: 0.103683
2023-03-16 23:15:27,836 INFO     Train loss at step 139200: 0.234584
2023-03-16 23:15:54,404 INFO     Train positive_sample_loss at step 139300: 0.370478
2023-03-16 23:15:54,404 INFO     Train negative_sample_loss at step 139300: 0.103716
2023-03-16 23:15:54,404 INFO     Train loss at step 139300: 0.237097
2023-03-16 23:16:13,812 INFO     Train positive_sample_loss at step 139400: 0.372620
2023-03-16 23:16:13,812 INFO     Train negative_sample_loss at step 139400: 0.104313
2023-03-16 23:16:13,812 INFO     Train loss at step 139400: 0.238467
2023-03-16 23:16:33,205 INFO     Train positive_sample_loss at step 139500: 0.375142
2023-03-16 23:16:33,205 INFO     Train negative_sample_loss at step 139500: 0.103729
2023-03-16 23:16:33,206 INFO     Train loss at step 139500: 0.239435
2023-03-16 23:16:52,599 INFO     Train positive_sample_loss at step 139600: 0.375128
2023-03-16 23:16:52,599 INFO     Train negative_sample_loss at step 139600: 0.104513
2023-03-16 23:16:52,599 INFO     Train loss at step 139600: 0.239820
2023-03-16 23:17:12,005 INFO     Train positive_sample_loss at step 139700: 0.380799
2023-03-16 23:17:12,005 INFO     Train negative_sample_loss at step 139700: 0.105066
2023-03-16 23:17:12,005 INFO     Train loss at step 139700: 0.242933
2023-03-16 23:17:31,390 INFO     Train positive_sample_loss at step 139800: 0.382344
2023-03-16 23:17:31,391 INFO     Train negative_sample_loss at step 139800: 0.105275
2023-03-16 23:17:31,391 INFO     Train loss at step 139800: 0.243810
2023-03-16 23:17:50,795 INFO     Train positive_sample_loss at step 139900: 0.384060
2023-03-16 23:17:50,796 INFO     Train negative_sample_loss at step 139900: 0.105869
2023-03-16 23:17:50,796 INFO     Train loss at step 139900: 0.244964
2023-03-16 23:18:12,478 INFO     Train positive_sample_loss at step 140000: 0.385606
2023-03-16 23:18:12,479 INFO     Train negative_sample_loss at step 140000: 0.105389
2023-03-16 23:18:12,479 INFO     Train loss at step 140000: 0.245498
2023-03-16 23:18:12,479 INFO     Evaluating on Valid Dataset...
2023-03-16 23:18:13,538 INFO     Evaluating the model... (0/26842)
2023-03-16 23:18:15,078 INFO     Evaluating the model... (1000/26842)
2023-03-16 23:18:16,434 INFO     Evaluating the model... (2000/26842)
2023-03-16 23:18:17,665 INFO     Evaluating the model... (3000/26842)
2023-03-16 23:18:18,899 INFO     Evaluating the model... (4000/26842)
2023-03-16 23:18:20,132 INFO     Evaluating the model... (5000/26842)
2023-03-16 23:18:21,380 INFO     Evaluating the model... (6000/26842)
2023-03-16 23:18:22,610 INFO     Evaluating the model... (7000/26842)
2023-03-16 23:18:23,837 INFO     Evaluating the model... (8000/26842)
2023-03-16 23:18:25,065 INFO     Evaluating the model... (9000/26842)
2023-03-16 23:18:26,291 INFO     Evaluating the model... (10000/26842)
2023-03-16 23:18:27,527 INFO     Evaluating the model... (11000/26842)
2023-03-16 23:18:28,763 INFO     Evaluating the model... (12000/26842)
2023-03-16 23:18:29,998 INFO     Evaluating the model... (13000/26842)
2023-03-16 23:18:32,312 INFO     Evaluating the model... (14000/26842)
2023-03-16 23:18:33,803 INFO     Evaluating the model... (15000/26842)
2023-03-16 23:18:35,300 INFO     Evaluating the model... (16000/26842)
2023-03-16 23:18:36,796 INFO     Evaluating the model... (17000/26842)
2023-03-16 23:18:38,279 INFO     Evaluating the model... (18000/26842)
2023-03-16 23:18:39,758 INFO     Evaluating the model... (19000/26842)
2023-03-16 23:18:41,247 INFO     Evaluating the model... (20000/26842)
2023-03-16 23:18:42,733 INFO     Evaluating the model... (21000/26842)
2023-03-16 23:18:44,219 INFO     Evaluating the model... (22000/26842)
2023-03-16 23:18:45,718 INFO     Evaluating the model... (23000/26842)
2023-03-16 23:18:47,211 INFO     Evaluating the model... (24000/26842)
2023-03-16 23:18:48,695 INFO     Evaluating the model... (25000/26842)
2023-03-16 23:18:50,185 INFO     Evaluating the model... (26000/26842)
2023-03-16 23:18:51,770 INFO     Valid hits@1_list at step 140000: 0.591607
2023-03-16 23:18:51,770 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 23:18:51,771 INFO     Valid hits@3_list at step 140000: 0.681326
2023-03-16 23:18:51,771 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 23:18:51,771 INFO     Valid hits@10_list at step 140000: 0.765787
2023-03-16 23:18:51,771 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 23:18:51,771 INFO     Valid mrr_list at step 140000: 0.652594
2023-03-16 23:19:11,173 INFO     Train positive_sample_loss at step 140100: 0.386797
2023-03-16 23:19:11,173 INFO     Train negative_sample_loss at step 140100: 0.105987
2023-03-16 23:19:11,173 INFO     Train loss at step 140100: 0.246392
2023-03-16 23:19:30,574 INFO     Train positive_sample_loss at step 140200: 0.389408
2023-03-16 23:19:30,575 INFO     Train negative_sample_loss at step 140200: 0.106448
2023-03-16 23:19:30,575 INFO     Train loss at step 140200: 0.247928
2023-03-16 23:19:57,131 INFO     Train positive_sample_loss at step 140300: 0.386927
2023-03-16 23:19:57,131 INFO     Train negative_sample_loss at step 140300: 0.106375
2023-03-16 23:19:57,131 INFO     Train loss at step 140300: 0.246651
2023-03-16 23:20:16,539 INFO     Train positive_sample_loss at step 140400: 0.388358
2023-03-16 23:20:16,540 INFO     Train negative_sample_loss at step 140400: 0.106686
2023-03-16 23:20:16,540 INFO     Train loss at step 140400: 0.247522
2023-03-16 23:20:35,934 INFO     Train positive_sample_loss at step 140500: 0.389059
2023-03-16 23:20:35,934 INFO     Train negative_sample_loss at step 140500: 0.106544
2023-03-16 23:20:35,934 INFO     Train loss at step 140500: 0.247802
2023-03-16 23:20:55,336 INFO     Train positive_sample_loss at step 140600: 0.386178
2023-03-16 23:20:55,336 INFO     Train negative_sample_loss at step 140600: 0.106986
2023-03-16 23:20:55,336 INFO     Train loss at step 140600: 0.246582
2023-03-16 23:21:14,740 INFO     Train positive_sample_loss at step 140700: 0.387152
2023-03-16 23:21:14,741 INFO     Train negative_sample_loss at step 140700: 0.107528
2023-03-16 23:21:14,741 INFO     Train loss at step 140700: 0.247340
2023-03-16 23:21:34,139 INFO     Train positive_sample_loss at step 140800: 0.387246
2023-03-16 23:21:34,139 INFO     Train negative_sample_loss at step 140800: 0.107359
2023-03-16 23:21:34,139 INFO     Train loss at step 140800: 0.247303
2023-03-16 23:21:53,529 INFO     Train positive_sample_loss at step 140900: 0.384701
2023-03-16 23:21:53,530 INFO     Train negative_sample_loss at step 140900: 0.107809
2023-03-16 23:21:53,530 INFO     Train loss at step 140900: 0.246255
2023-03-16 23:22:12,928 INFO     Train positive_sample_loss at step 141000: 0.384848
2023-03-16 23:22:12,929 INFO     Train negative_sample_loss at step 141000: 0.107938
2023-03-16 23:22:12,929 INFO     Train loss at step 141000: 0.246393
2023-03-16 23:22:32,333 INFO     Train positive_sample_loss at step 141100: 0.384827
2023-03-16 23:22:32,334 INFO     Train negative_sample_loss at step 141100: 0.108958
2023-03-16 23:22:32,334 INFO     Train loss at step 141100: 0.246892
2023-03-16 23:22:51,735 INFO     Train positive_sample_loss at step 141200: 0.383595
2023-03-16 23:22:51,735 INFO     Train negative_sample_loss at step 141200: 0.108268
2023-03-16 23:22:51,736 INFO     Train loss at step 141200: 0.245931
2023-03-16 23:23:11,140 INFO     Train positive_sample_loss at step 141300: 0.381454
2023-03-16 23:23:11,141 INFO     Train negative_sample_loss at step 141300: 0.108145
2023-03-16 23:23:11,141 INFO     Train loss at step 141300: 0.244800
2023-03-16 23:23:37,547 INFO     Train positive_sample_loss at step 141400: 0.380805
2023-03-16 23:23:37,547 INFO     Train negative_sample_loss at step 141400: 0.108557
2023-03-16 23:23:37,547 INFO     Train loss at step 141400: 0.244681
2023-03-16 23:23:56,943 INFO     Train positive_sample_loss at step 141500: 0.380393
2023-03-16 23:23:56,944 INFO     Train negative_sample_loss at step 141500: 0.108109
2023-03-16 23:23:56,944 INFO     Train loss at step 141500: 0.244251
2023-03-16 23:24:16,351 INFO     Train positive_sample_loss at step 141600: 0.374851
2023-03-16 23:24:16,351 INFO     Train negative_sample_loss at step 141600: 0.108515
2023-03-16 23:24:16,351 INFO     Train loss at step 141600: 0.241683
funtion time use:39103ms
2023-03-16 23:24:41,753 INFO     Train positive_sample_loss at step 141700: 0.323355
2023-03-16 23:24:41,754 INFO     Train negative_sample_loss at step 141700: 0.107604
2023-03-16 23:24:41,754 INFO     Train loss at step 141700: 0.215479
2023-03-16 23:25:01,120 INFO     Train positive_sample_loss at step 141800: 0.310185
2023-03-16 23:25:01,121 INFO     Train negative_sample_loss at step 141800: 0.104035
2023-03-16 23:25:01,121 INFO     Train loss at step 141800: 0.207110
2023-03-16 23:25:20,482 INFO     Train positive_sample_loss at step 141900: 0.315179
2023-03-16 23:25:20,483 INFO     Train negative_sample_loss at step 141900: 0.103243
2023-03-16 23:25:20,483 INFO     Train loss at step 141900: 0.209211
2023-03-16 23:25:39,823 INFO     Train positive_sample_loss at step 142000: 0.317810
2023-03-16 23:25:39,824 INFO     Train negative_sample_loss at step 142000: 0.102711
2023-03-16 23:25:39,824 INFO     Train loss at step 142000: 0.210261
2023-03-16 23:26:06,996 INFO     Train positive_sample_loss at step 142100: 0.322414
2023-03-16 23:26:06,996 INFO     Train negative_sample_loss at step 142100: 0.102644
2023-03-16 23:26:06,996 INFO     Train loss at step 142100: 0.212529
2023-03-16 23:26:26,371 INFO     Train positive_sample_loss at step 142200: 0.326221
2023-03-16 23:26:26,372 INFO     Train negative_sample_loss at step 142200: 0.102030
2023-03-16 23:26:26,372 INFO     Train loss at step 142200: 0.214126
2023-03-16 23:26:45,763 INFO     Train positive_sample_loss at step 142300: 0.330942
2023-03-16 23:26:45,763 INFO     Train negative_sample_loss at step 142300: 0.101537
2023-03-16 23:26:45,764 INFO     Train loss at step 142300: 0.216239
2023-03-16 23:27:05,160 INFO     Train positive_sample_loss at step 142400: 0.335919
2023-03-16 23:27:05,161 INFO     Train negative_sample_loss at step 142400: 0.102200
2023-03-16 23:27:05,161 INFO     Train loss at step 142400: 0.219059
2023-03-16 23:27:24,542 INFO     Train positive_sample_loss at step 142500: 0.339243
2023-03-16 23:27:24,543 INFO     Train negative_sample_loss at step 142500: 0.102523
2023-03-16 23:27:24,543 INFO     Train loss at step 142500: 0.220883
2023-03-16 23:27:43,941 INFO     Train positive_sample_loss at step 142600: 0.344032
2023-03-16 23:27:43,942 INFO     Train negative_sample_loss at step 142600: 0.102026
2023-03-16 23:27:43,942 INFO     Train loss at step 142600: 0.223029
2023-03-16 23:28:03,334 INFO     Train positive_sample_loss at step 142700: 0.348088
2023-03-16 23:28:03,335 INFO     Train negative_sample_loss at step 142700: 0.102868
2023-03-16 23:28:03,335 INFO     Train loss at step 142700: 0.225478
2023-03-16 23:28:22,721 INFO     Train positive_sample_loss at step 142800: 0.352770
2023-03-16 23:28:22,721 INFO     Train negative_sample_loss at step 142800: 0.102130
2023-03-16 23:28:22,721 INFO     Train loss at step 142800: 0.227450
2023-03-16 23:28:42,111 INFO     Train positive_sample_loss at step 142900: 0.357702
2023-03-16 23:28:42,111 INFO     Train negative_sample_loss at step 142900: 0.102863
2023-03-16 23:28:42,111 INFO     Train loss at step 142900: 0.230283
2023-03-16 23:29:01,501 INFO     Train positive_sample_loss at step 143000: 0.360146
2023-03-16 23:29:01,501 INFO     Train negative_sample_loss at step 143000: 0.102887
2023-03-16 23:29:01,501 INFO     Train loss at step 143000: 0.231517
2023-03-16 23:29:20,895 INFO     Train positive_sample_loss at step 143100: 0.365241
2023-03-16 23:29:20,896 INFO     Train negative_sample_loss at step 143100: 0.103200
2023-03-16 23:29:20,896 INFO     Train loss at step 143100: 0.234221
2023-03-16 23:29:47,297 INFO     Train positive_sample_loss at step 143200: 0.367543
2023-03-16 23:29:47,298 INFO     Train negative_sample_loss at step 143200: 0.103441
2023-03-16 23:29:47,298 INFO     Train loss at step 143200: 0.235492
2023-03-16 23:30:06,698 INFO     Train positive_sample_loss at step 143300: 0.370888
2023-03-16 23:30:06,698 INFO     Train negative_sample_loss at step 143300: 0.103671
2023-03-16 23:30:06,698 INFO     Train loss at step 143300: 0.237279
2023-03-16 23:30:26,095 INFO     Train positive_sample_loss at step 143400: 0.374570
2023-03-16 23:30:26,095 INFO     Train negative_sample_loss at step 143400: 0.103875
2023-03-16 23:30:26,095 INFO     Train loss at step 143400: 0.239222
2023-03-16 23:30:45,528 INFO     Train positive_sample_loss at step 143500: 0.377411
2023-03-16 23:30:45,529 INFO     Train negative_sample_loss at step 143500: 0.104688
2023-03-16 23:30:45,529 INFO     Train loss at step 143500: 0.241050
2023-03-16 23:31:04,941 INFO     Train positive_sample_loss at step 143600: 0.380914
2023-03-16 23:31:04,942 INFO     Train negative_sample_loss at step 143600: 0.104904
2023-03-16 23:31:04,942 INFO     Train loss at step 143600: 0.242909
2023-03-16 23:31:24,361 INFO     Train positive_sample_loss at step 143700: 0.380230
2023-03-16 23:31:24,361 INFO     Train negative_sample_loss at step 143700: 0.104844
2023-03-16 23:31:24,361 INFO     Train loss at step 143700: 0.242537
2023-03-16 23:31:43,791 INFO     Train positive_sample_loss at step 143800: 0.384205
2023-03-16 23:31:43,791 INFO     Train negative_sample_loss at step 143800: 0.105621
2023-03-16 23:31:43,791 INFO     Train loss at step 143800: 0.244913
2023-03-16 23:32:03,206 INFO     Train positive_sample_loss at step 143900: 0.385791
2023-03-16 23:32:03,207 INFO     Train negative_sample_loss at step 143900: 0.105967
2023-03-16 23:32:03,207 INFO     Train loss at step 143900: 0.245879
2023-03-16 23:32:22,628 INFO     Train positive_sample_loss at step 144000: 0.386823
2023-03-16 23:32:22,629 INFO     Train negative_sample_loss at step 144000: 0.105470
2023-03-16 23:32:22,629 INFO     Train loss at step 144000: 0.246146
2023-03-16 23:32:42,053 INFO     Train positive_sample_loss at step 144100: 0.386852
2023-03-16 23:32:42,053 INFO     Train negative_sample_loss at step 144100: 0.106668
2023-03-16 23:32:42,053 INFO     Train loss at step 144100: 0.246760
2023-03-16 23:33:08,337 INFO     Train positive_sample_loss at step 144200: 0.389253
2023-03-16 23:33:08,338 INFO     Train negative_sample_loss at step 144200: 0.106128
2023-03-16 23:33:08,338 INFO     Train loss at step 144200: 0.247690
2023-03-16 23:33:27,749 INFO     Train positive_sample_loss at step 144300: 0.389783
2023-03-16 23:33:27,749 INFO     Train negative_sample_loss at step 144300: 0.106348
2023-03-16 23:33:27,749 INFO     Train loss at step 144300: 0.248066
2023-03-16 23:33:47,154 INFO     Train positive_sample_loss at step 144400: 0.388879
2023-03-16 23:33:47,155 INFO     Train negative_sample_loss at step 144400: 0.106859
2023-03-16 23:33:47,155 INFO     Train loss at step 144400: 0.247869
2023-03-16 23:34:06,563 INFO     Train positive_sample_loss at step 144500: 0.389568
2023-03-16 23:34:06,563 INFO     Train negative_sample_loss at step 144500: 0.107026
2023-03-16 23:34:06,563 INFO     Train loss at step 144500: 0.248297
2023-03-16 23:34:25,978 INFO     Train positive_sample_loss at step 144600: 0.387936
2023-03-16 23:34:25,979 INFO     Train negative_sample_loss at step 144600: 0.107151
2023-03-16 23:34:25,979 INFO     Train loss at step 144600: 0.247544
2023-03-16 23:34:45,383 INFO     Train positive_sample_loss at step 144700: 0.387256
2023-03-16 23:34:45,384 INFO     Train negative_sample_loss at step 144700: 0.107814
2023-03-16 23:34:45,384 INFO     Train loss at step 144700: 0.247535
2023-03-16 23:35:04,797 INFO     Train positive_sample_loss at step 144800: 0.385015
2023-03-16 23:35:04,797 INFO     Train negative_sample_loss at step 144800: 0.107659
2023-03-16 23:35:04,798 INFO     Train loss at step 144800: 0.246337
2023-03-16 23:35:24,217 INFO     Train positive_sample_loss at step 144900: 0.387294
2023-03-16 23:35:24,218 INFO     Train negative_sample_loss at step 144900: 0.108224
2023-03-16 23:35:24,218 INFO     Train loss at step 144900: 0.247759
2023-03-16 23:35:43,623 INFO     Train positive_sample_loss at step 145000: 0.386082
2023-03-16 23:35:43,623 INFO     Train negative_sample_loss at step 145000: 0.108436
2023-03-16 23:35:43,624 INFO     Train loss at step 145000: 0.247259
2023-03-16 23:36:03,023 INFO     Train positive_sample_loss at step 145100: 0.383904
2023-03-16 23:36:03,024 INFO     Train negative_sample_loss at step 145100: 0.108473
2023-03-16 23:36:03,024 INFO     Train loss at step 145100: 0.246188
2023-03-16 23:36:22,433 INFO     Train positive_sample_loss at step 145200: 0.382574
2023-03-16 23:36:22,434 INFO     Train negative_sample_loss at step 145200: 0.108448
2023-03-16 23:36:22,434 INFO     Train loss at step 145200: 0.245511
2023-03-16 23:36:48,974 INFO     Train positive_sample_loss at step 145300: 0.383440
2023-03-16 23:36:48,974 INFO     Train negative_sample_loss at step 145300: 0.108647
2023-03-16 23:36:48,975 INFO     Train loss at step 145300: 0.246044
2023-03-16 23:37:08,384 INFO     Train positive_sample_loss at step 145400: 0.379184
2023-03-16 23:37:08,384 INFO     Train negative_sample_loss at step 145400: 0.108172
2023-03-16 23:37:08,385 INFO     Train loss at step 145400: 0.243678
2023-03-16 23:37:27,797 INFO     Train positive_sample_loss at step 145500: 0.379159
2023-03-16 23:37:27,798 INFO     Train negative_sample_loss at step 145500: 0.109039
2023-03-16 23:37:27,798 INFO     Train loss at step 145500: 0.244099
2023-03-16 23:37:53,190 INFO     Train positive_sample_loss at step 145600: 0.346983
2023-03-16 23:37:53,191 INFO     Train negative_sample_loss at step 145600: 0.108366
2023-03-16 23:37:53,191 INFO     Train loss at step 145600: 0.227675
2023-03-16 23:38:12,533 INFO     Train positive_sample_loss at step 145700: 0.307293
2023-03-16 23:38:12,533 INFO     Train negative_sample_loss at step 145700: 0.104649
2023-03-16 23:38:12,533 INFO     Train loss at step 145700: 0.205971
2023-03-16 23:38:31,865 INFO     Train positive_sample_loss at step 145800: 0.311771
2023-03-16 23:38:31,865 INFO     Train negative_sample_loss at step 145800: 0.103691
2023-03-16 23:38:31,865 INFO     Train loss at step 145800: 0.207731
2023-03-16 23:38:51,195 INFO     Train positive_sample_loss at step 145900: 0.318539
2023-03-16 23:38:51,196 INFO     Train negative_sample_loss at step 145900: 0.102311
2023-03-16 23:38:51,196 INFO     Train loss at step 145900: 0.210425
2023-03-16 23:39:18,189 INFO     Train positive_sample_loss at step 146000: 0.321319
2023-03-16 23:39:18,190 INFO     Train negative_sample_loss at step 146000: 0.102451
2023-03-16 23:39:18,190 INFO     Train loss at step 146000: 0.211885
2023-03-16 23:39:37,537 INFO     Train positive_sample_loss at step 146100: 0.324912
2023-03-16 23:39:37,537 INFO     Train negative_sample_loss at step 146100: 0.102474
2023-03-16 23:39:37,537 INFO     Train loss at step 146100: 0.213693
2023-03-16 23:39:56,874 INFO     Train positive_sample_loss at step 146200: 0.330001
2023-03-16 23:39:56,874 INFO     Train negative_sample_loss at step 146200: 0.102244
2023-03-16 23:39:56,874 INFO     Train loss at step 146200: 0.216123
2023-03-16 23:40:16,225 INFO     Train positive_sample_loss at step 146300: 0.332081
2023-03-16 23:40:16,225 INFO     Train negative_sample_loss at step 146300: 0.101525
2023-03-16 23:40:16,225 INFO     Train loss at step 146300: 0.216803
2023-03-16 23:40:35,575 INFO     Train positive_sample_loss at step 146400: 0.336935
2023-03-16 23:40:35,575 INFO     Train negative_sample_loss at step 146400: 0.101800
2023-03-16 23:40:35,575 INFO     Train loss at step 146400: 0.219368
2023-03-16 23:40:54,920 INFO     Train positive_sample_loss at step 146500: 0.341286
2023-03-16 23:40:54,920 INFO     Train negative_sample_loss at step 146500: 0.102121
2023-03-16 23:40:54,920 INFO     Train loss at step 146500: 0.221704
2023-03-16 23:41:14,263 INFO     Train positive_sample_loss at step 146600: 0.346930
2023-03-16 23:41:14,263 INFO     Train negative_sample_loss at step 146600: 0.103005
2023-03-16 23:41:14,263 INFO     Train loss at step 146600: 0.224967
2023-03-16 23:41:33,603 INFO     Train positive_sample_loss at step 146700: 0.349220
2023-03-16 23:41:33,603 INFO     Train negative_sample_loss at step 146700: 0.102924
2023-03-16 23:41:33,604 INFO     Train loss at step 146700: 0.226072
2023-03-16 23:41:52,944 INFO     Train positive_sample_loss at step 146800: 0.355331
2023-03-16 23:41:52,944 INFO     Train negative_sample_loss at step 146800: 0.102015
2023-03-16 23:41:52,944 INFO     Train loss at step 146800: 0.228673
2023-03-16 23:42:12,301 INFO     Train positive_sample_loss at step 146900: 0.357975
2023-03-16 23:42:12,302 INFO     Train negative_sample_loss at step 146900: 0.103526
2023-03-16 23:42:12,302 INFO     Train loss at step 146900: 0.230751
2023-03-16 23:42:31,648 INFO     Train positive_sample_loss at step 147000: 0.362485
2023-03-16 23:42:31,649 INFO     Train negative_sample_loss at step 147000: 0.103441
2023-03-16 23:42:31,649 INFO     Train loss at step 147000: 0.232963
2023-03-16 23:43:00,597 INFO     Train positive_sample_loss at step 147100: 0.366765
2023-03-16 23:43:00,598 INFO     Train negative_sample_loss at step 147100: 0.103407
2023-03-16 23:43:00,598 INFO     Train loss at step 147100: 0.235086
2023-03-16 23:43:19,966 INFO     Train positive_sample_loss at step 147200: 0.370565
2023-03-16 23:43:19,966 INFO     Train negative_sample_loss at step 147200: 0.103206
2023-03-16 23:43:19,967 INFO     Train loss at step 147200: 0.236886
2023-03-16 23:43:39,348 INFO     Train positive_sample_loss at step 147300: 0.371961
2023-03-16 23:43:39,349 INFO     Train negative_sample_loss at step 147300: 0.103442
2023-03-16 23:43:39,349 INFO     Train loss at step 147300: 0.237702
2023-03-16 23:43:58,738 INFO     Train positive_sample_loss at step 147400: 0.375899
2023-03-16 23:43:58,738 INFO     Train negative_sample_loss at step 147400: 0.103878
2023-03-16 23:43:58,739 INFO     Train loss at step 147400: 0.239889
2023-03-16 23:44:18,126 INFO     Train positive_sample_loss at step 147500: 0.376993
2023-03-16 23:44:18,127 INFO     Train negative_sample_loss at step 147500: 0.103797
2023-03-16 23:44:18,127 INFO     Train loss at step 147500: 0.240395
2023-03-16 23:44:37,525 INFO     Train positive_sample_loss at step 147600: 0.379604
2023-03-16 23:44:37,525 INFO     Train negative_sample_loss at step 147600: 0.105691
2023-03-16 23:44:37,526 INFO     Train loss at step 147600: 0.242647
2023-03-16 23:44:56,929 INFO     Train positive_sample_loss at step 147700: 0.383197
2023-03-16 23:44:56,929 INFO     Train negative_sample_loss at step 147700: 0.104983
2023-03-16 23:44:56,929 INFO     Train loss at step 147700: 0.244090
2023-03-16 23:45:16,322 INFO     Train positive_sample_loss at step 147800: 0.384927
2023-03-16 23:45:16,323 INFO     Train negative_sample_loss at step 147800: 0.105426
2023-03-16 23:45:16,323 INFO     Train loss at step 147800: 0.245176
2023-03-16 23:45:35,724 INFO     Train positive_sample_loss at step 147900: 0.384777
2023-03-16 23:45:35,725 INFO     Train negative_sample_loss at step 147900: 0.105523
2023-03-16 23:45:35,725 INFO     Train loss at step 147900: 0.245150
2023-03-16 23:45:55,154 INFO     Train positive_sample_loss at step 148000: 0.385472
2023-03-16 23:45:55,154 INFO     Train negative_sample_loss at step 148000: 0.105286
2023-03-16 23:45:55,155 INFO     Train loss at step 148000: 0.245379
2023-03-16 23:46:14,578 INFO     Train positive_sample_loss at step 148100: 0.389048
2023-03-16 23:46:14,578 INFO     Train negative_sample_loss at step 148100: 0.106326
2023-03-16 23:46:14,578 INFO     Train loss at step 148100: 0.247687
2023-03-16 23:46:40,979 INFO     Train positive_sample_loss at step 148200: 0.386007
2023-03-16 23:46:40,980 INFO     Train negative_sample_loss at step 148200: 0.106367
2023-03-16 23:46:40,980 INFO     Train loss at step 148200: 0.246187
2023-03-16 23:47:00,394 INFO     Train positive_sample_loss at step 148300: 0.387268
2023-03-16 23:47:00,394 INFO     Train negative_sample_loss at step 148300: 0.106642
2023-03-16 23:47:00,395 INFO     Train loss at step 148300: 0.246955
2023-03-16 23:47:19,800 INFO     Train positive_sample_loss at step 148400: 0.387980
2023-03-16 23:47:19,800 INFO     Train negative_sample_loss at step 148400: 0.106280
2023-03-16 23:47:19,800 INFO     Train loss at step 148400: 0.247130
2023-03-16 23:47:39,209 INFO     Train positive_sample_loss at step 148500: 0.388909
2023-03-16 23:47:39,209 INFO     Train negative_sample_loss at step 148500: 0.107567
2023-03-16 23:47:39,209 INFO     Train loss at step 148500: 0.248238
2023-03-16 23:47:58,621 INFO     Train positive_sample_loss at step 148600: 0.387700
2023-03-16 23:47:58,621 INFO     Train negative_sample_loss at step 148600: 0.107641
2023-03-16 23:47:58,622 INFO     Train loss at step 148600: 0.247670
2023-03-16 23:48:18,046 INFO     Train positive_sample_loss at step 148700: 0.387613
2023-03-16 23:48:18,046 INFO     Train negative_sample_loss at step 148700: 0.107819
2023-03-16 23:48:18,046 INFO     Train loss at step 148700: 0.247716
2023-03-16 23:48:37,467 INFO     Train positive_sample_loss at step 148800: 0.386335
2023-03-16 23:48:37,467 INFO     Train negative_sample_loss at step 148800: 0.108031
2023-03-16 23:48:37,468 INFO     Train loss at step 148800: 0.247183
2023-03-16 23:48:56,882 INFO     Train positive_sample_loss at step 148900: 0.386193
2023-03-16 23:48:56,882 INFO     Train negative_sample_loss at step 148900: 0.108008
2023-03-16 23:48:56,883 INFO     Train loss at step 148900: 0.247101
2023-03-16 23:49:16,284 INFO     Train positive_sample_loss at step 149000: 0.386973
2023-03-16 23:49:16,284 INFO     Train negative_sample_loss at step 149000: 0.108417
2023-03-16 23:49:16,284 INFO     Train loss at step 149000: 0.247695
2023-03-16 23:49:35,698 INFO     Train positive_sample_loss at step 149100: 0.382071
2023-03-16 23:49:35,698 INFO     Train negative_sample_loss at step 149100: 0.108492
2023-03-16 23:49:35,699 INFO     Train loss at step 149100: 0.245282
2023-03-16 23:50:02,158 INFO     Train positive_sample_loss at step 149200: 0.383356
2023-03-16 23:50:02,159 INFO     Train negative_sample_loss at step 149200: 0.108414
2023-03-16 23:50:02,159 INFO     Train loss at step 149200: 0.245885
2023-03-16 23:50:21,562 INFO     Train positive_sample_loss at step 149300: 0.381646
2023-03-16 23:50:21,562 INFO     Train negative_sample_loss at step 149300: 0.109203
2023-03-16 23:50:21,562 INFO     Train loss at step 149300: 0.245425
2023-03-16 23:50:40,962 INFO     Train positive_sample_loss at step 149400: 0.379644
2023-03-16 23:50:40,962 INFO     Train negative_sample_loss at step 149400: 0.108614
2023-03-16 23:50:40,962 INFO     Train loss at step 149400: 0.244129
2023-03-16 23:51:06,434 INFO     Train positive_sample_loss at step 149500: 0.374106
2023-03-16 23:51:06,435 INFO     Train negative_sample_loss at step 149500: 0.108967
2023-03-16 23:51:06,435 INFO     Train loss at step 149500: 0.241536
2023-03-16 23:51:25,779 INFO     Train positive_sample_loss at step 149600: 0.310939
2023-03-16 23:51:25,779 INFO     Train negative_sample_loss at step 149600: 0.106363
2023-03-16 23:51:25,779 INFO     Train loss at step 149600: 0.208651
2023-03-16 23:51:45,125 INFO     Train positive_sample_loss at step 149700: 0.313671
2023-03-16 23:51:45,126 INFO     Train negative_sample_loss at step 149700: 0.103066
2023-03-16 23:51:45,126 INFO     Train loss at step 149700: 0.208369
2023-03-16 23:52:04,463 INFO     Train positive_sample_loss at step 149800: 0.315233
2023-03-16 23:52:04,463 INFO     Train negative_sample_loss at step 149800: 0.102711
2023-03-16 23:52:04,463 INFO     Train loss at step 149800: 0.208972
2023-03-16 23:52:23,793 INFO     Train positive_sample_loss at step 149900: 0.318971
2023-03-16 23:52:23,793 INFO     Train negative_sample_loss at step 149900: 0.102331
2023-03-16 23:52:23,793 INFO     Train loss at step 149900: 0.210651
2023-03-16 23:52:50,990 INFO     Change learning_rate to 0.000100 at step 150000
2023-03-16 23:52:52,982 INFO     Train positive_sample_loss at step 150000: 0.322922
2023-03-16 23:52:52,982 INFO     Train negative_sample_loss at step 150000: 0.102224
2023-03-16 23:52:52,982 INFO     Train loss at step 150000: 0.212573
2023-03-16 23:52:52,982 INFO     Evaluating on Valid Dataset...
2023-03-16 23:52:53,999 INFO     Evaluating the model... (0/26842)
2023-03-16 23:52:55,235 INFO     Evaluating the model... (1000/26842)
2023-03-16 23:52:56,461 INFO     Evaluating the model... (2000/26842)
2023-03-16 23:52:57,684 INFO     Evaluating the model... (3000/26842)
2023-03-16 23:52:58,914 INFO     Evaluating the model... (4000/26842)
2023-03-16 23:53:00,148 INFO     Evaluating the model... (5000/26842)
2023-03-16 23:53:01,379 INFO     Evaluating the model... (6000/26842)
2023-03-16 23:53:02,608 INFO     Evaluating the model... (7000/26842)
2023-03-16 23:53:03,848 INFO     Evaluating the model... (8000/26842)
2023-03-16 23:53:05,090 INFO     Evaluating the model... (9000/26842)
2023-03-16 23:53:06,343 INFO     Evaluating the model... (10000/26842)
2023-03-16 23:53:07,599 INFO     Evaluating the model... (11000/26842)
2023-03-16 23:53:08,843 INFO     Evaluating the model... (12000/26842)
2023-03-16 23:53:10,090 INFO     Evaluating the model... (13000/26842)
2023-03-16 23:53:12,352 INFO     Evaluating the model... (14000/26842)
2023-03-16 23:53:13,849 INFO     Evaluating the model... (15000/26842)
2023-03-16 23:53:15,340 INFO     Evaluating the model... (16000/26842)
2023-03-16 23:53:16,830 INFO     Evaluating the model... (17000/26842)
2023-03-16 23:53:18,318 INFO     Evaluating the model... (18000/26842)
2023-03-16 23:53:19,822 INFO     Evaluating the model... (19000/26842)
2023-03-16 23:53:21,308 INFO     Evaluating the model... (20000/26842)
2023-03-16 23:53:22,794 INFO     Evaluating the model... (21000/26842)
2023-03-16 23:53:24,283 INFO     Evaluating the model... (22000/26842)
2023-03-16 23:53:25,770 INFO     Evaluating the model... (23000/26842)
2023-03-16 23:53:27,257 INFO     Evaluating the model... (24000/26842)
2023-03-16 23:53:28,741 INFO     Evaluating the model... (25000/26842)
2023-03-16 23:53:30,223 INFO     Evaluating the model... (26000/26842)
2023-03-16 23:53:31,782 INFO     Valid hits@1_list at step 150000: 0.593485
2023-03-16 23:53:31,782 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-16 23:53:31,783 INFO     Valid hits@3_list at step 150000: 0.683379
2023-03-16 23:53:31,783 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-16 23:53:31,783 INFO     Valid hits@10_list at step 150000: 0.768876
2023-03-16 23:53:31,783 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-16 23:53:31,783 INFO     Valid mrr_list at step 150000: 0.654670
2023-03-16 23:53:51,199 INFO     Train positive_sample_loss at step 150100: 0.327891
2023-03-16 23:53:51,199 INFO     Train negative_sample_loss at step 150100: 0.099898
2023-03-16 23:53:51,199 INFO     Train loss at step 150100: 0.213894
2023-03-16 23:54:10,603 INFO     Train positive_sample_loss at step 150200: 0.324196
2023-03-16 23:54:10,603 INFO     Train negative_sample_loss at step 150200: 0.096540
2023-03-16 23:54:10,603 INFO     Train loss at step 150200: 0.210368
2023-03-16 23:54:30,011 INFO     Train positive_sample_loss at step 150300: 0.316157
2023-03-16 23:54:30,012 INFO     Train negative_sample_loss at step 150300: 0.095873
2023-03-16 23:54:30,012 INFO     Train loss at step 150300: 0.206015
2023-03-16 23:54:49,416 INFO     Train positive_sample_loss at step 150400: 0.306942
2023-03-16 23:54:49,417 INFO     Train negative_sample_loss at step 150400: 0.094985
2023-03-16 23:54:49,417 INFO     Train loss at step 150400: 0.200963
2023-03-16 23:55:08,813 INFO     Train positive_sample_loss at step 150500: 0.296241
2023-03-16 23:55:08,814 INFO     Train negative_sample_loss at step 150500: 0.095279
2023-03-16 23:55:08,814 INFO     Train loss at step 150500: 0.195760
2023-03-16 23:55:28,207 INFO     Train positive_sample_loss at step 150600: 0.286286
2023-03-16 23:55:28,207 INFO     Train negative_sample_loss at step 150600: 0.096239
2023-03-16 23:55:28,207 INFO     Train loss at step 150600: 0.191262
2023-03-16 23:55:47,606 INFO     Train positive_sample_loss at step 150700: 0.276297
2023-03-16 23:55:47,606 INFO     Train negative_sample_loss at step 150700: 0.096084
2023-03-16 23:55:47,606 INFO     Train loss at step 150700: 0.186191
2023-03-16 23:56:07,005 INFO     Train positive_sample_loss at step 150800: 0.267322
2023-03-16 23:56:07,006 INFO     Train negative_sample_loss at step 150800: 0.096480
2023-03-16 23:56:07,006 INFO     Train loss at step 150800: 0.181901
2023-03-16 23:56:26,406 INFO     Train positive_sample_loss at step 150900: 0.257952
2023-03-16 23:56:26,406 INFO     Train negative_sample_loss at step 150900: 0.097662
2023-03-16 23:56:26,406 INFO     Train loss at step 150900: 0.177807
2023-03-16 23:56:52,744 INFO     Train positive_sample_loss at step 151000: 0.248600
2023-03-16 23:56:52,745 INFO     Train negative_sample_loss at step 151000: 0.098082
2023-03-16 23:56:52,745 INFO     Train loss at step 151000: 0.173341
2023-03-16 23:57:12,152 INFO     Train positive_sample_loss at step 151100: 0.239664
2023-03-16 23:57:12,152 INFO     Train negative_sample_loss at step 151100: 0.098552
2023-03-16 23:57:12,152 INFO     Train loss at step 151100: 0.169108
2023-03-16 23:57:31,563 INFO     Train positive_sample_loss at step 151200: 0.231361
2023-03-16 23:57:31,564 INFO     Train negative_sample_loss at step 151200: 0.097623
2023-03-16 23:57:31,564 INFO     Train loss at step 151200: 0.164492
2023-03-16 23:57:50,975 INFO     Train positive_sample_loss at step 151300: 0.225565
2023-03-16 23:57:50,975 INFO     Train negative_sample_loss at step 151300: 0.099255
2023-03-16 23:57:50,976 INFO     Train loss at step 151300: 0.162410
2023-03-16 23:58:10,386 INFO     Train positive_sample_loss at step 151400: 0.218628
2023-03-16 23:58:10,387 INFO     Train negative_sample_loss at step 151400: 0.098937
2023-03-16 23:58:10,387 INFO     Train loss at step 151400: 0.158783
2023-03-16 23:58:29,792 INFO     Train positive_sample_loss at step 151500: 0.211814
2023-03-16 23:58:29,793 INFO     Train negative_sample_loss at step 151500: 0.099779
2023-03-16 23:58:29,793 INFO     Train loss at step 151500: 0.155797
2023-03-16 23:58:49,206 INFO     Train positive_sample_loss at step 151600: 0.205713
2023-03-16 23:58:49,207 INFO     Train negative_sample_loss at step 151600: 0.098933
2023-03-16 23:58:49,207 INFO     Train loss at step 151600: 0.152323
2023-03-16 23:59:08,623 INFO     Train positive_sample_loss at step 151700: 0.199448
2023-03-16 23:59:08,623 INFO     Train negative_sample_loss at step 151700: 0.099502
2023-03-16 23:59:08,623 INFO     Train loss at step 151700: 0.149475
2023-03-16 23:59:28,039 INFO     Train positive_sample_loss at step 151800: 0.195000
2023-03-16 23:59:28,040 INFO     Train negative_sample_loss at step 151800: 0.099908
2023-03-16 23:59:28,040 INFO     Train loss at step 151800: 0.147454
2023-03-16 23:59:47,461 INFO     Train positive_sample_loss at step 151900: 0.188771
2023-03-16 23:59:47,462 INFO     Train negative_sample_loss at step 151900: 0.099420
2023-03-16 23:59:47,462 INFO     Train loss at step 151900: 0.144095
2023-03-17 00:00:06,879 INFO     Train positive_sample_loss at step 152000: 0.184280
2023-03-17 00:00:06,880 INFO     Train negative_sample_loss at step 152000: 0.100933
2023-03-17 00:00:06,880 INFO     Train loss at step 152000: 0.142606
2023-03-17 00:00:33,217 INFO     Train positive_sample_loss at step 152100: 0.179696
2023-03-17 00:00:33,217 INFO     Train negative_sample_loss at step 152100: 0.100186
2023-03-17 00:00:33,218 INFO     Train loss at step 152100: 0.139941
2023-03-17 00:00:52,635 INFO     Train positive_sample_loss at step 152200: 0.175524
2023-03-17 00:00:52,636 INFO     Train negative_sample_loss at step 152200: 0.101057
2023-03-17 00:00:52,636 INFO     Train loss at step 152200: 0.138290
2023-03-17 00:01:12,042 INFO     Train positive_sample_loss at step 152300: 0.171158
2023-03-17 00:01:12,042 INFO     Train negative_sample_loss at step 152300: 0.100251
2023-03-17 00:01:12,043 INFO     Train loss at step 152300: 0.135704
2023-03-17 00:01:31,450 INFO     Train positive_sample_loss at step 152400: 0.168488
2023-03-17 00:01:31,451 INFO     Train negative_sample_loss at step 152400: 0.099961
2023-03-17 00:01:31,451 INFO     Train loss at step 152400: 0.134224
2023-03-17 00:01:50,857 INFO     Train positive_sample_loss at step 152500: 0.164397
2023-03-17 00:01:50,858 INFO     Train negative_sample_loss at step 152500: 0.100659
2023-03-17 00:01:50,858 INFO     Train loss at step 152500: 0.132528
2023-03-17 00:02:10,272 INFO     Train positive_sample_loss at step 152600: 0.160220
2023-03-17 00:02:10,272 INFO     Train negative_sample_loss at step 152600: 0.100432
2023-03-17 00:02:10,272 INFO     Train loss at step 152600: 0.130326
2023-03-17 00:02:29,681 INFO     Train positive_sample_loss at step 152700: 0.157570
2023-03-17 00:02:29,681 INFO     Train negative_sample_loss at step 152700: 0.100784
2023-03-17 00:02:29,681 INFO     Train loss at step 152700: 0.129177
2023-03-17 00:02:49,078 INFO     Train positive_sample_loss at step 152800: 0.154352
2023-03-17 00:02:49,078 INFO     Train negative_sample_loss at step 152800: 0.101033
2023-03-17 00:02:49,078 INFO     Train loss at step 152800: 0.127693
2023-03-17 00:03:08,467 INFO     Train positive_sample_loss at step 152900: 0.150447
2023-03-17 00:03:08,468 INFO     Train negative_sample_loss at step 152900: 0.100092
2023-03-17 00:03:08,468 INFO     Train loss at step 152900: 0.125270
2023-03-17 00:03:27,874 INFO     Train positive_sample_loss at step 153000: 0.148765
2023-03-17 00:03:27,875 INFO     Train negative_sample_loss at step 153000: 0.100769
2023-03-17 00:03:27,875 INFO     Train loss at step 153000: 0.124767
2023-03-17 00:03:47,268 INFO     Train positive_sample_loss at step 153100: 0.145588
2023-03-17 00:03:47,269 INFO     Train negative_sample_loss at step 153100: 0.100083
2023-03-17 00:03:47,269 INFO     Train loss at step 153100: 0.122835
2023-03-17 00:04:16,465 INFO     Train positive_sample_loss at step 153200: 0.142782
2023-03-17 00:04:16,465 INFO     Train negative_sample_loss at step 153200: 0.099939
2023-03-17 00:04:16,466 INFO     Train loss at step 153200: 0.121361
2023-03-17 00:04:35,862 INFO     Train positive_sample_loss at step 153300: 0.140083
2023-03-17 00:04:35,863 INFO     Train negative_sample_loss at step 153300: 0.100362
2023-03-17 00:04:35,863 INFO     Train loss at step 153300: 0.120223
2023-03-17 00:04:55,276 INFO     Train positive_sample_loss at step 153400: 0.138197
2023-03-17 00:04:55,277 INFO     Train negative_sample_loss at step 153400: 0.099543
2023-03-17 00:04:55,277 INFO     Train loss at step 153400: 0.118870
funtion time use:38618ms
2023-03-17 00:05:20,856 INFO     Train positive_sample_loss at step 153500: 0.113238
2023-03-17 00:05:20,857 INFO     Train negative_sample_loss at step 153500: 0.099566
2023-03-17 00:05:20,857 INFO     Train loss at step 153500: 0.106402
2023-03-17 00:05:40,204 INFO     Train positive_sample_loss at step 153600: 0.106308
2023-03-17 00:05:40,204 INFO     Train negative_sample_loss at step 153600: 0.098537
2023-03-17 00:05:40,204 INFO     Train loss at step 153600: 0.102422
2023-03-17 00:05:59,548 INFO     Train positive_sample_loss at step 153700: 0.106464
2023-03-17 00:05:59,549 INFO     Train negative_sample_loss at step 153700: 0.096927
2023-03-17 00:05:59,549 INFO     Train loss at step 153700: 0.101695
2023-03-17 00:06:18,897 INFO     Train positive_sample_loss at step 153800: 0.106767
2023-03-17 00:06:18,898 INFO     Train negative_sample_loss at step 153800: 0.097427
2023-03-17 00:06:18,898 INFO     Train loss at step 153800: 0.102097
2023-03-17 00:06:45,923 INFO     Train positive_sample_loss at step 153900: 0.107226
2023-03-17 00:06:45,924 INFO     Train negative_sample_loss at step 153900: 0.095976
2023-03-17 00:06:45,924 INFO     Train loss at step 153900: 0.101601
2023-03-17 00:07:05,299 INFO     Train positive_sample_loss at step 154000: 0.107000
2023-03-17 00:07:05,300 INFO     Train negative_sample_loss at step 154000: 0.095694
2023-03-17 00:07:05,300 INFO     Train loss at step 154000: 0.101347
2023-03-17 00:07:24,706 INFO     Train positive_sample_loss at step 154100: 0.106391
2023-03-17 00:07:24,706 INFO     Train negative_sample_loss at step 154100: 0.094927
2023-03-17 00:07:24,707 INFO     Train loss at step 154100: 0.100659
2023-03-17 00:07:44,107 INFO     Train positive_sample_loss at step 154200: 0.106964
2023-03-17 00:07:44,107 INFO     Train negative_sample_loss at step 154200: 0.094411
2023-03-17 00:07:44,108 INFO     Train loss at step 154200: 0.100688
2023-03-17 00:08:03,514 INFO     Train positive_sample_loss at step 154300: 0.106486
2023-03-17 00:08:03,514 INFO     Train negative_sample_loss at step 154300: 0.093704
2023-03-17 00:08:03,514 INFO     Train loss at step 154300: 0.100095
2023-03-17 00:08:22,922 INFO     Train positive_sample_loss at step 154400: 0.106719
2023-03-17 00:08:22,923 INFO     Train negative_sample_loss at step 154400: 0.093307
2023-03-17 00:08:22,923 INFO     Train loss at step 154400: 0.100013
2023-03-17 00:08:42,335 INFO     Train positive_sample_loss at step 154500: 0.106196
2023-03-17 00:08:42,336 INFO     Train negative_sample_loss at step 154500: 0.093359
2023-03-17 00:08:42,336 INFO     Train loss at step 154500: 0.099778
2023-03-17 00:09:01,749 INFO     Train positive_sample_loss at step 154600: 0.106345
2023-03-17 00:09:01,749 INFO     Train negative_sample_loss at step 154600: 0.092807
2023-03-17 00:09:01,750 INFO     Train loss at step 154600: 0.099576
2023-03-17 00:09:21,151 INFO     Train positive_sample_loss at step 154700: 0.105657
2023-03-17 00:09:21,152 INFO     Train negative_sample_loss at step 154700: 0.092563
2023-03-17 00:09:21,152 INFO     Train loss at step 154700: 0.099110
2023-03-17 00:09:40,544 INFO     Train positive_sample_loss at step 154800: 0.105635
2023-03-17 00:09:40,544 INFO     Train negative_sample_loss at step 154800: 0.092415
2023-03-17 00:09:40,544 INFO     Train loss at step 154800: 0.099025
2023-03-17 00:10:06,959 INFO     Train positive_sample_loss at step 154900: 0.105545
2023-03-17 00:10:06,959 INFO     Train negative_sample_loss at step 154900: 0.091603
2023-03-17 00:10:06,959 INFO     Train loss at step 154900: 0.098574
2023-03-17 00:10:26,357 INFO     Train positive_sample_loss at step 155000: 0.104919
2023-03-17 00:10:26,358 INFO     Train negative_sample_loss at step 155000: 0.091461
2023-03-17 00:10:26,358 INFO     Train loss at step 155000: 0.098190
2023-03-17 00:10:45,760 INFO     Train positive_sample_loss at step 155100: 0.104885
2023-03-17 00:10:45,761 INFO     Train negative_sample_loss at step 155100: 0.091392
2023-03-17 00:10:45,761 INFO     Train loss at step 155100: 0.098138
2023-03-17 00:11:05,170 INFO     Train positive_sample_loss at step 155200: 0.104606
2023-03-17 00:11:05,171 INFO     Train negative_sample_loss at step 155200: 0.090980
2023-03-17 00:11:05,171 INFO     Train loss at step 155200: 0.097793
2023-03-17 00:11:24,576 INFO     Train positive_sample_loss at step 155300: 0.104072
2023-03-17 00:11:24,576 INFO     Train negative_sample_loss at step 155300: 0.090436
2023-03-17 00:11:24,576 INFO     Train loss at step 155300: 0.097254
2023-03-17 00:11:43,978 INFO     Train positive_sample_loss at step 155400: 0.103818
2023-03-17 00:11:43,978 INFO     Train negative_sample_loss at step 155400: 0.090967
2023-03-17 00:11:43,978 INFO     Train loss at step 155400: 0.097393
2023-03-17 00:12:03,380 INFO     Train positive_sample_loss at step 155500: 0.103470
2023-03-17 00:12:03,381 INFO     Train negative_sample_loss at step 155500: 0.090556
2023-03-17 00:12:03,381 INFO     Train loss at step 155500: 0.097013
2023-03-17 00:12:22,783 INFO     Train positive_sample_loss at step 155600: 0.103639
2023-03-17 00:12:22,783 INFO     Train negative_sample_loss at step 155600: 0.090309
2023-03-17 00:12:22,784 INFO     Train loss at step 155600: 0.096974
2023-03-17 00:12:42,195 INFO     Train positive_sample_loss at step 155700: 0.103223
2023-03-17 00:12:42,196 INFO     Train negative_sample_loss at step 155700: 0.090376
2023-03-17 00:12:42,196 INFO     Train loss at step 155700: 0.096800
2023-03-17 00:13:01,602 INFO     Train positive_sample_loss at step 155800: 0.102512
2023-03-17 00:13:01,603 INFO     Train negative_sample_loss at step 155800: 0.089404
2023-03-17 00:13:01,603 INFO     Train loss at step 155800: 0.095958
2023-03-17 00:13:21,016 INFO     Train positive_sample_loss at step 155900: 0.101896
2023-03-17 00:13:21,017 INFO     Train negative_sample_loss at step 155900: 0.088750
2023-03-17 00:13:21,017 INFO     Train loss at step 155900: 0.095323
2023-03-17 00:13:47,381 INFO     Train positive_sample_loss at step 156000: 0.101647
2023-03-17 00:13:47,381 INFO     Train negative_sample_loss at step 156000: 0.089586
2023-03-17 00:13:47,382 INFO     Train loss at step 156000: 0.095616
2023-03-17 00:14:06,801 INFO     Train positive_sample_loss at step 156100: 0.101365
2023-03-17 00:14:06,802 INFO     Train negative_sample_loss at step 156100: 0.088587
2023-03-17 00:14:06,802 INFO     Train loss at step 156100: 0.094976
2023-03-17 00:14:26,226 INFO     Train positive_sample_loss at step 156200: 0.101132
2023-03-17 00:14:26,226 INFO     Train negative_sample_loss at step 156200: 0.089206
2023-03-17 00:14:26,226 INFO     Train loss at step 156200: 0.095169
2023-03-17 00:14:45,633 INFO     Train positive_sample_loss at step 156300: 0.100625
2023-03-17 00:14:45,634 INFO     Train negative_sample_loss at step 156300: 0.088846
2023-03-17 00:14:45,634 INFO     Train loss at step 156300: 0.094735
2023-03-17 00:15:05,048 INFO     Train positive_sample_loss at step 156400: 0.099911
2023-03-17 00:15:05,049 INFO     Train negative_sample_loss at step 156400: 0.088195
2023-03-17 00:15:05,049 INFO     Train loss at step 156400: 0.094053
2023-03-17 00:15:24,460 INFO     Train positive_sample_loss at step 156500: 0.099780
2023-03-17 00:15:24,460 INFO     Train negative_sample_loss at step 156500: 0.087801
2023-03-17 00:15:24,460 INFO     Train loss at step 156500: 0.093790
2023-03-17 00:15:43,881 INFO     Train positive_sample_loss at step 156600: 0.099111
2023-03-17 00:15:43,881 INFO     Train negative_sample_loss at step 156600: 0.087830
2023-03-17 00:15:43,881 INFO     Train loss at step 156600: 0.093471
2023-03-17 00:16:03,294 INFO     Train positive_sample_loss at step 156700: 0.098935
2023-03-17 00:16:03,294 INFO     Train negative_sample_loss at step 156700: 0.088129
2023-03-17 00:16:03,294 INFO     Train loss at step 156700: 0.093532
2023-03-17 00:16:22,709 INFO     Train positive_sample_loss at step 156800: 0.098527
2023-03-17 00:16:22,710 INFO     Train negative_sample_loss at step 156800: 0.087670
2023-03-17 00:16:22,710 INFO     Train loss at step 156800: 0.093098
2023-03-17 00:16:42,125 INFO     Train positive_sample_loss at step 156900: 0.098231
2023-03-17 00:16:42,125 INFO     Train negative_sample_loss at step 156900: 0.087829
2023-03-17 00:16:42,125 INFO     Train loss at step 156900: 0.093030
2023-03-17 00:17:01,526 INFO     Train positive_sample_loss at step 157000: 0.097501
2023-03-17 00:17:01,526 INFO     Train negative_sample_loss at step 157000: 0.086987
2023-03-17 00:17:01,527 INFO     Train loss at step 157000: 0.092244
2023-03-17 00:17:27,963 INFO     Train positive_sample_loss at step 157100: 0.097586
2023-03-17 00:17:27,964 INFO     Train negative_sample_loss at step 157100: 0.087602
2023-03-17 00:17:27,964 INFO     Train loss at step 157100: 0.092594
2023-03-17 00:17:47,365 INFO     Train positive_sample_loss at step 157200: 0.097052
2023-03-17 00:17:47,365 INFO     Train negative_sample_loss at step 157200: 0.086394
2023-03-17 00:17:47,365 INFO     Train loss at step 157200: 0.091723
2023-03-17 00:18:06,758 INFO     Train positive_sample_loss at step 157300: 0.096791
2023-03-17 00:18:06,758 INFO     Train negative_sample_loss at step 157300: 0.086602
2023-03-17 00:18:06,758 INFO     Train loss at step 157300: 0.091696
2023-03-17 00:18:32,310 INFO     Train positive_sample_loss at step 157400: 0.089472
2023-03-17 00:18:32,311 INFO     Train negative_sample_loss at step 157400: 0.085969
2023-03-17 00:18:32,311 INFO     Train loss at step 157400: 0.087720
2023-03-17 00:18:51,657 INFO     Train positive_sample_loss at step 157500: 0.081527
2023-03-17 00:18:51,657 INFO     Train negative_sample_loss at step 157500: 0.085053
2023-03-17 00:18:51,657 INFO     Train loss at step 157500: 0.083290
2023-03-17 00:19:10,999 INFO     Train positive_sample_loss at step 157600: 0.082282
2023-03-17 00:19:11,000 INFO     Train negative_sample_loss at step 157600: 0.084541
2023-03-17 00:19:11,000 INFO     Train loss at step 157600: 0.083411
2023-03-17 00:19:30,337 INFO     Train positive_sample_loss at step 157700: 0.083068
2023-03-17 00:19:30,337 INFO     Train negative_sample_loss at step 157700: 0.083282
2023-03-17 00:19:30,337 INFO     Train loss at step 157700: 0.083175
2023-03-17 00:19:57,471 INFO     Train positive_sample_loss at step 157800: 0.083439
2023-03-17 00:19:57,472 INFO     Train negative_sample_loss at step 157800: 0.082983
2023-03-17 00:19:57,472 INFO     Train loss at step 157800: 0.083211
2023-03-17 00:20:16,840 INFO     Train positive_sample_loss at step 157900: 0.084189
2023-03-17 00:20:16,841 INFO     Train negative_sample_loss at step 157900: 0.082875
2023-03-17 00:20:16,841 INFO     Train loss at step 157900: 0.083532
2023-03-17 00:20:36,218 INFO     Train positive_sample_loss at step 158000: 0.085155
2023-03-17 00:20:36,219 INFO     Train negative_sample_loss at step 158000: 0.082886
2023-03-17 00:20:36,219 INFO     Train loss at step 158000: 0.084020
2023-03-17 00:20:55,606 INFO     Train positive_sample_loss at step 158100: 0.085346
2023-03-17 00:20:55,607 INFO     Train negative_sample_loss at step 158100: 0.082829
2023-03-17 00:20:55,607 INFO     Train loss at step 158100: 0.084087
2023-03-17 00:21:14,990 INFO     Train positive_sample_loss at step 158200: 0.085588
2023-03-17 00:21:14,990 INFO     Train negative_sample_loss at step 158200: 0.081937
2023-03-17 00:21:14,990 INFO     Train loss at step 158200: 0.083763
2023-03-17 00:21:34,376 INFO     Train positive_sample_loss at step 158300: 0.086053
2023-03-17 00:21:34,377 INFO     Train negative_sample_loss at step 158300: 0.081455
2023-03-17 00:21:34,377 INFO     Train loss at step 158300: 0.083754
2023-03-17 00:21:53,758 INFO     Train positive_sample_loss at step 158400: 0.086290
2023-03-17 00:21:53,759 INFO     Train negative_sample_loss at step 158400: 0.081348
2023-03-17 00:21:53,759 INFO     Train loss at step 158400: 0.083819
2023-03-17 00:22:13,138 INFO     Train positive_sample_loss at step 158500: 0.086834
2023-03-17 00:22:13,138 INFO     Train negative_sample_loss at step 158500: 0.081443
2023-03-17 00:22:13,138 INFO     Train loss at step 158500: 0.084139
2023-03-17 00:22:32,516 INFO     Train positive_sample_loss at step 158600: 0.086823
2023-03-17 00:22:32,517 INFO     Train negative_sample_loss at step 158600: 0.081393
2023-03-17 00:22:32,517 INFO     Train loss at step 158600: 0.084108
2023-03-17 00:22:51,899 INFO     Train positive_sample_loss at step 158700: 0.087379
2023-03-17 00:22:51,900 INFO     Train negative_sample_loss at step 158700: 0.080625
2023-03-17 00:22:51,900 INFO     Train loss at step 158700: 0.084002
2023-03-17 00:23:11,295 INFO     Train positive_sample_loss at step 158800: 0.087159
2023-03-17 00:23:11,295 INFO     Train negative_sample_loss at step 158800: 0.080624
2023-03-17 00:23:11,296 INFO     Train loss at step 158800: 0.083892
2023-03-17 00:23:37,731 INFO     Train positive_sample_loss at step 158900: 0.087549
2023-03-17 00:23:37,732 INFO     Train negative_sample_loss at step 158900: 0.079791
2023-03-17 00:23:37,732 INFO     Train loss at step 158900: 0.083670
2023-03-17 00:23:57,140 INFO     Train positive_sample_loss at step 159000: 0.087569
2023-03-17 00:23:57,141 INFO     Train negative_sample_loss at step 159000: 0.080458
2023-03-17 00:23:57,141 INFO     Train loss at step 159000: 0.084013
2023-03-17 00:24:16,537 INFO     Train positive_sample_loss at step 159100: 0.087481
2023-03-17 00:24:16,538 INFO     Train negative_sample_loss at step 159100: 0.080323
2023-03-17 00:24:16,538 INFO     Train loss at step 159100: 0.083902
2023-03-17 00:24:35,919 INFO     Train positive_sample_loss at step 159200: 0.087275
2023-03-17 00:24:35,919 INFO     Train negative_sample_loss at step 159200: 0.080219
2023-03-17 00:24:35,920 INFO     Train loss at step 159200: 0.083747
2023-03-17 00:24:55,314 INFO     Train positive_sample_loss at step 159300: 0.087602
2023-03-17 00:24:55,315 INFO     Train negative_sample_loss at step 159300: 0.079897
2023-03-17 00:24:55,315 INFO     Train loss at step 159300: 0.083749
2023-03-17 00:25:14,707 INFO     Train positive_sample_loss at step 159400: 0.087773
2023-03-17 00:25:14,707 INFO     Train negative_sample_loss at step 159400: 0.079932
2023-03-17 00:25:14,707 INFO     Train loss at step 159400: 0.083853
2023-03-17 00:25:34,097 INFO     Train positive_sample_loss at step 159500: 0.088082
2023-03-17 00:25:34,097 INFO     Train negative_sample_loss at step 159500: 0.079781
2023-03-17 00:25:34,097 INFO     Train loss at step 159500: 0.083932
2023-03-17 00:25:53,499 INFO     Train positive_sample_loss at step 159600: 0.088154
2023-03-17 00:25:53,500 INFO     Train negative_sample_loss at step 159600: 0.079678
2023-03-17 00:25:53,500 INFO     Train loss at step 159600: 0.083916
2023-03-17 00:26:12,898 INFO     Train positive_sample_loss at step 159700: 0.087919
2023-03-17 00:26:12,898 INFO     Train negative_sample_loss at step 159700: 0.078840
2023-03-17 00:26:12,898 INFO     Train loss at step 159700: 0.083380
2023-03-17 00:26:32,292 INFO     Train positive_sample_loss at step 159800: 0.087632
2023-03-17 00:26:32,292 INFO     Train negative_sample_loss at step 159800: 0.079592
2023-03-17 00:26:32,292 INFO     Train loss at step 159800: 0.083612
2023-03-17 00:26:58,740 INFO     Train positive_sample_loss at step 159900: 0.087506
2023-03-17 00:26:58,740 INFO     Train negative_sample_loss at step 159900: 0.079440
2023-03-17 00:26:58,740 INFO     Train loss at step 159900: 0.083473
2023-03-17 00:27:19,880 INFO     Train positive_sample_loss at step 160000: 0.087408
2023-03-17 00:27:19,881 INFO     Train negative_sample_loss at step 160000: 0.079943
2023-03-17 00:27:19,881 INFO     Train loss at step 160000: 0.083675
2023-03-17 00:27:19,881 INFO     Evaluating on Valid Dataset...
2023-03-17 00:27:20,905 INFO     Evaluating the model... (0/26842)
2023-03-17 00:27:22,630 INFO     Evaluating the model... (1000/26842)
2023-03-17 00:27:23,879 INFO     Evaluating the model... (2000/26842)
2023-03-17 00:27:25,141 INFO     Evaluating the model... (3000/26842)
2023-03-17 00:27:26,393 INFO     Evaluating the model... (4000/26842)
2023-03-17 00:27:27,650 INFO     Evaluating the model... (5000/26842)
2023-03-17 00:27:28,895 INFO     Evaluating the model... (6000/26842)
2023-03-17 00:27:30,140 INFO     Evaluating the model... (7000/26842)
2023-03-17 00:27:31,395 INFO     Evaluating the model... (8000/26842)
2023-03-17 00:27:32,648 INFO     Evaluating the model... (9000/26842)
2023-03-17 00:27:33,893 INFO     Evaluating the model... (10000/26842)
2023-03-17 00:27:35,143 INFO     Evaluating the model... (11000/26842)
2023-03-17 00:27:36,385 INFO     Evaluating the model... (12000/26842)
2023-03-17 00:27:37,624 INFO     Evaluating the model... (13000/26842)
2023-03-17 00:27:39,962 INFO     Evaluating the model... (14000/26842)
2023-03-17 00:27:41,446 INFO     Evaluating the model... (15000/26842)
2023-03-17 00:27:42,927 INFO     Evaluating the model... (16000/26842)
2023-03-17 00:27:44,418 INFO     Evaluating the model... (17000/26842)
2023-03-17 00:27:45,903 INFO     Evaluating the model... (18000/26842)
2023-03-17 00:27:47,386 INFO     Evaluating the model... (19000/26842)
2023-03-17 00:27:48,873 INFO     Evaluating the model... (20000/26842)
2023-03-17 00:27:50,362 INFO     Evaluating the model... (21000/26842)
2023-03-17 00:27:51,846 INFO     Evaluating the model... (22000/26842)
2023-03-17 00:27:53,334 INFO     Evaluating the model... (23000/26842)
2023-03-17 00:27:54,828 INFO     Evaluating the model... (24000/26842)
2023-03-17 00:27:56,315 INFO     Evaluating the model... (25000/26842)
2023-03-17 00:27:57,795 INFO     Evaluating the model... (26000/26842)
2023-03-17 00:27:59,367 INFO     Valid hits@1_list at step 160000: 0.636262
2023-03-17 00:27:59,367 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 00:27:59,367 INFO     Valid hits@3_list at step 160000: 0.730486
2023-03-17 00:27:59,367 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 00:27:59,367 INFO     Valid hits@10_list at step 160000: 0.822581
2023-03-17 00:27:59,367 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 00:27:59,367 INFO     Valid mrr_list at step 160000: 0.700019
2023-03-17 00:28:18,771 INFO     Train positive_sample_loss at step 160100: 0.087937
2023-03-17 00:28:18,771 INFO     Train negative_sample_loss at step 160100: 0.079636
2023-03-17 00:28:18,771 INFO     Train loss at step 160100: 0.083786
2023-03-17 00:28:38,163 INFO     Train positive_sample_loss at step 160200: 0.087813
2023-03-17 00:28:38,163 INFO     Train negative_sample_loss at step 160200: 0.078726
2023-03-17 00:28:38,163 INFO     Train loss at step 160200: 0.083269
2023-03-17 00:28:57,560 INFO     Train positive_sample_loss at step 160300: 0.087753
2023-03-17 00:28:57,561 INFO     Train negative_sample_loss at step 160300: 0.078428
2023-03-17 00:28:57,561 INFO     Train loss at step 160300: 0.083091
2023-03-17 00:29:16,970 INFO     Train positive_sample_loss at step 160400: 0.087785
2023-03-17 00:29:16,971 INFO     Train negative_sample_loss at step 160400: 0.078540
2023-03-17 00:29:16,971 INFO     Train loss at step 160400: 0.083162
2023-03-17 00:29:36,374 INFO     Train positive_sample_loss at step 160500: 0.087333
2023-03-17 00:29:36,374 INFO     Train negative_sample_loss at step 160500: 0.078097
2023-03-17 00:29:36,375 INFO     Train loss at step 160500: 0.082715
2023-03-17 00:29:55,774 INFO     Train positive_sample_loss at step 160600: 0.087683
2023-03-17 00:29:55,775 INFO     Train negative_sample_loss at step 160600: 0.078863
2023-03-17 00:29:55,775 INFO     Train loss at step 160600: 0.083273
2023-03-17 00:30:15,176 INFO     Train positive_sample_loss at step 160700: 0.087384
2023-03-17 00:30:15,177 INFO     Train negative_sample_loss at step 160700: 0.077878
2023-03-17 00:30:15,177 INFO     Train loss at step 160700: 0.082631
2023-03-17 00:30:34,584 INFO     Train positive_sample_loss at step 160800: 0.087124
2023-03-17 00:30:34,585 INFO     Train negative_sample_loss at step 160800: 0.077368
2023-03-17 00:30:34,585 INFO     Train loss at step 160800: 0.082246
2023-03-17 00:30:53,985 INFO     Train positive_sample_loss at step 160900: 0.086817
2023-03-17 00:30:53,985 INFO     Train negative_sample_loss at step 160900: 0.077395
2023-03-17 00:30:53,986 INFO     Train loss at step 160900: 0.082106
2023-03-17 00:31:20,409 INFO     Train positive_sample_loss at step 161000: 0.086968
2023-03-17 00:31:20,409 INFO     Train negative_sample_loss at step 161000: 0.078051
2023-03-17 00:31:20,409 INFO     Train loss at step 161000: 0.082510
2023-03-17 00:31:39,810 INFO     Train positive_sample_loss at step 161100: 0.086798
2023-03-17 00:31:39,811 INFO     Train negative_sample_loss at step 161100: 0.077404
2023-03-17 00:31:39,811 INFO     Train loss at step 161100: 0.082101
2023-03-17 00:31:59,213 INFO     Train positive_sample_loss at step 161200: 0.086753
2023-03-17 00:31:59,213 INFO     Train negative_sample_loss at step 161200: 0.077635
2023-03-17 00:31:59,214 INFO     Train loss at step 161200: 0.082194
funtion time use:39306ms
2023-03-17 00:32:24,920 INFO     Train positive_sample_loss at step 161300: 0.085399
2023-03-17 00:32:24,920 INFO     Train negative_sample_loss at step 161300: 0.077489
2023-03-17 00:32:24,921 INFO     Train loss at step 161300: 0.081444
2023-03-17 00:32:44,287 INFO     Train positive_sample_loss at step 161400: 0.073263
2023-03-17 00:32:44,287 INFO     Train negative_sample_loss at step 161400: 0.076053
2023-03-17 00:32:44,287 INFO     Train loss at step 161400: 0.074658
2023-03-17 00:33:03,648 INFO     Train positive_sample_loss at step 161500: 0.074396
2023-03-17 00:33:03,648 INFO     Train negative_sample_loss at step 161500: 0.075906
2023-03-17 00:33:03,648 INFO     Train loss at step 161500: 0.075151
2023-03-17 00:33:22,997 INFO     Train positive_sample_loss at step 161600: 0.075333
2023-03-17 00:33:22,998 INFO     Train negative_sample_loss at step 161600: 0.075242
2023-03-17 00:33:22,998 INFO     Train loss at step 161600: 0.075287
2023-03-17 00:33:50,339 INFO     Train positive_sample_loss at step 161700: 0.076216
2023-03-17 00:33:50,340 INFO     Train negative_sample_loss at step 161700: 0.074839
2023-03-17 00:33:50,340 INFO     Train loss at step 161700: 0.075528
2023-03-17 00:34:09,729 INFO     Train positive_sample_loss at step 161800: 0.076533
2023-03-17 00:34:09,730 INFO     Train negative_sample_loss at step 161800: 0.074570
2023-03-17 00:34:09,730 INFO     Train loss at step 161800: 0.075551
2023-03-17 00:34:29,131 INFO     Train positive_sample_loss at step 161900: 0.077496
2023-03-17 00:34:29,131 INFO     Train negative_sample_loss at step 161900: 0.074325
2023-03-17 00:34:29,131 INFO     Train loss at step 161900: 0.075911
2023-03-17 00:34:48,532 INFO     Train positive_sample_loss at step 162000: 0.077678
2023-03-17 00:34:48,533 INFO     Train negative_sample_loss at step 162000: 0.073985
2023-03-17 00:34:48,533 INFO     Train loss at step 162000: 0.075832
2023-03-17 00:35:07,939 INFO     Train positive_sample_loss at step 162100: 0.078225
2023-03-17 00:35:07,939 INFO     Train negative_sample_loss at step 162100: 0.074013
2023-03-17 00:35:07,939 INFO     Train loss at step 162100: 0.076119
2023-03-17 00:35:27,347 INFO     Train positive_sample_loss at step 162200: 0.078881
2023-03-17 00:35:27,348 INFO     Train negative_sample_loss at step 162200: 0.073580
2023-03-17 00:35:27,348 INFO     Train loss at step 162200: 0.076230
2023-03-17 00:35:46,755 INFO     Train positive_sample_loss at step 162300: 0.079172
2023-03-17 00:35:46,756 INFO     Train negative_sample_loss at step 162300: 0.073124
2023-03-17 00:35:46,756 INFO     Train loss at step 162300: 0.076148
2023-03-17 00:36:06,150 INFO     Train positive_sample_loss at step 162400: 0.079571
2023-03-17 00:36:06,151 INFO     Train negative_sample_loss at step 162400: 0.073770
2023-03-17 00:36:06,151 INFO     Train loss at step 162400: 0.076670
2023-03-17 00:36:25,553 INFO     Train positive_sample_loss at step 162500: 0.079501
2023-03-17 00:36:25,553 INFO     Train negative_sample_loss at step 162500: 0.073270
2023-03-17 00:36:25,553 INFO     Train loss at step 162500: 0.076385
2023-03-17 00:36:44,955 INFO     Train positive_sample_loss at step 162600: 0.080108
2023-03-17 00:36:44,956 INFO     Train negative_sample_loss at step 162600: 0.073306
2023-03-17 00:36:44,956 INFO     Train loss at step 162600: 0.076707
2023-03-17 00:37:04,363 INFO     Train positive_sample_loss at step 162700: 0.080450
2023-03-17 00:37:04,364 INFO     Train negative_sample_loss at step 162700: 0.073196
2023-03-17 00:37:04,364 INFO     Train loss at step 162700: 0.076823
2023-03-17 00:37:30,856 INFO     Train positive_sample_loss at step 162800: 0.080758
2023-03-17 00:37:30,856 INFO     Train negative_sample_loss at step 162800: 0.073622
2023-03-17 00:37:30,856 INFO     Train loss at step 162800: 0.077190
2023-03-17 00:37:50,255 INFO     Train positive_sample_loss at step 162900: 0.080776
2023-03-17 00:37:50,255 INFO     Train negative_sample_loss at step 162900: 0.072389
2023-03-17 00:37:50,255 INFO     Train loss at step 162900: 0.076583
2023-03-17 00:38:09,664 INFO     Train positive_sample_loss at step 163000: 0.080880
2023-03-17 00:38:09,664 INFO     Train negative_sample_loss at step 163000: 0.073029
2023-03-17 00:38:09,664 INFO     Train loss at step 163000: 0.076954
2023-03-17 00:38:29,057 INFO     Train positive_sample_loss at step 163100: 0.081096
2023-03-17 00:38:29,058 INFO     Train negative_sample_loss at step 163100: 0.072220
2023-03-17 00:38:29,058 INFO     Train loss at step 163100: 0.076658
2023-03-17 00:38:48,461 INFO     Train positive_sample_loss at step 163200: 0.081210
2023-03-17 00:38:48,462 INFO     Train negative_sample_loss at step 163200: 0.073422
2023-03-17 00:38:48,462 INFO     Train loss at step 163200: 0.077316
2023-03-17 00:39:07,860 INFO     Train positive_sample_loss at step 163300: 0.081316
2023-03-17 00:39:07,860 INFO     Train negative_sample_loss at step 163300: 0.072585
2023-03-17 00:39:07,860 INFO     Train loss at step 163300: 0.076950
2023-03-17 00:39:27,270 INFO     Train positive_sample_loss at step 163400: 0.081476
2023-03-17 00:39:27,270 INFO     Train negative_sample_loss at step 163400: 0.072477
2023-03-17 00:39:27,270 INFO     Train loss at step 163400: 0.076976
2023-03-17 00:39:46,666 INFO     Train positive_sample_loss at step 163500: 0.081607
2023-03-17 00:39:46,667 INFO     Train negative_sample_loss at step 163500: 0.072282
2023-03-17 00:39:46,667 INFO     Train loss at step 163500: 0.076945
2023-03-17 00:40:06,073 INFO     Train positive_sample_loss at step 163600: 0.081466
2023-03-17 00:40:06,074 INFO     Train negative_sample_loss at step 163600: 0.072566
2023-03-17 00:40:06,074 INFO     Train loss at step 163600: 0.077016
2023-03-17 00:40:25,499 INFO     Train positive_sample_loss at step 163700: 0.081548
2023-03-17 00:40:25,499 INFO     Train negative_sample_loss at step 163700: 0.073080
2023-03-17 00:40:25,499 INFO     Train loss at step 163700: 0.077314
2023-03-17 00:40:51,880 INFO     Train positive_sample_loss at step 163800: 0.081900
2023-03-17 00:40:51,880 INFO     Train negative_sample_loss at step 163800: 0.073116
2023-03-17 00:40:51,880 INFO     Train loss at step 163800: 0.077508
2023-03-17 00:41:11,274 INFO     Train positive_sample_loss at step 163900: 0.081892
2023-03-17 00:41:11,275 INFO     Train negative_sample_loss at step 163900: 0.073031
2023-03-17 00:41:11,275 INFO     Train loss at step 163900: 0.077461
2023-03-17 00:41:30,675 INFO     Train positive_sample_loss at step 164000: 0.081910
2023-03-17 00:41:30,676 INFO     Train negative_sample_loss at step 164000: 0.073036
2023-03-17 00:41:30,676 INFO     Train loss at step 164000: 0.077473
2023-03-17 00:41:50,068 INFO     Train positive_sample_loss at step 164100: 0.081791
2023-03-17 00:41:50,069 INFO     Train negative_sample_loss at step 164100: 0.072546
2023-03-17 00:41:50,069 INFO     Train loss at step 164100: 0.077168
2023-03-17 00:42:09,470 INFO     Train positive_sample_loss at step 164200: 0.081659
2023-03-17 00:42:09,471 INFO     Train negative_sample_loss at step 164200: 0.072535
2023-03-17 00:42:09,471 INFO     Train loss at step 164200: 0.077097
2023-03-17 00:42:28,868 INFO     Train positive_sample_loss at step 164300: 0.081730
2023-03-17 00:42:28,868 INFO     Train negative_sample_loss at step 164300: 0.071775
2023-03-17 00:42:28,868 INFO     Train loss at step 164300: 0.076753
2023-03-17 00:42:48,274 INFO     Train positive_sample_loss at step 164400: 0.081649
2023-03-17 00:42:48,275 INFO     Train negative_sample_loss at step 164400: 0.071824
2023-03-17 00:42:48,275 INFO     Train loss at step 164400: 0.076737
2023-03-17 00:43:07,680 INFO     Train positive_sample_loss at step 164500: 0.081742
2023-03-17 00:43:07,681 INFO     Train negative_sample_loss at step 164500: 0.072086
2023-03-17 00:43:07,681 INFO     Train loss at step 164500: 0.076914
2023-03-17 00:43:27,069 INFO     Train positive_sample_loss at step 164600: 0.081747
2023-03-17 00:43:27,070 INFO     Train negative_sample_loss at step 164600: 0.072654
2023-03-17 00:43:27,070 INFO     Train loss at step 164600: 0.077200
2023-03-17 00:43:46,472 INFO     Train positive_sample_loss at step 164700: 0.081353
2023-03-17 00:43:46,473 INFO     Train negative_sample_loss at step 164700: 0.072057
2023-03-17 00:43:46,473 INFO     Train loss at step 164700: 0.076705
2023-03-17 00:44:05,873 INFO     Train positive_sample_loss at step 164800: 0.081631
2023-03-17 00:44:05,873 INFO     Train negative_sample_loss at step 164800: 0.072175
2023-03-17 00:44:05,873 INFO     Train loss at step 164800: 0.076903
2023-03-17 00:44:32,524 INFO     Train positive_sample_loss at step 164900: 0.081324
2023-03-17 00:44:32,524 INFO     Train negative_sample_loss at step 164900: 0.072439
2023-03-17 00:44:32,525 INFO     Train loss at step 164900: 0.076881
2023-03-17 00:44:51,936 INFO     Train positive_sample_loss at step 165000: 0.081538
2023-03-17 00:44:51,937 INFO     Train negative_sample_loss at step 165000: 0.072686
2023-03-17 00:44:51,937 INFO     Train loss at step 165000: 0.077112
2023-03-17 00:45:11,332 INFO     Train positive_sample_loss at step 165100: 0.081276
2023-03-17 00:45:11,333 INFO     Train negative_sample_loss at step 165100: 0.071983
2023-03-17 00:45:11,333 INFO     Train loss at step 165100: 0.076629
2023-03-17 00:45:30,728 INFO     Train positive_sample_loss at step 165200: 0.081631
2023-03-17 00:45:30,728 INFO     Train negative_sample_loss at step 165200: 0.072229
2023-03-17 00:45:30,728 INFO     Train loss at step 165200: 0.076930
2023-03-17 00:45:56,469 INFO     Train positive_sample_loss at step 165300: 0.072479
2023-03-17 00:45:56,469 INFO     Train negative_sample_loss at step 165300: 0.071942
2023-03-17 00:45:56,469 INFO     Train loss at step 165300: 0.072210
2023-03-17 00:46:15,831 INFO     Train positive_sample_loss at step 165400: 0.070261
2023-03-17 00:46:15,831 INFO     Train negative_sample_loss at step 165400: 0.071151
2023-03-17 00:46:15,832 INFO     Train loss at step 165400: 0.070706
2023-03-17 00:46:35,182 INFO     Train positive_sample_loss at step 165500: 0.071076
2023-03-17 00:46:35,183 INFO     Train negative_sample_loss at step 165500: 0.070689
2023-03-17 00:46:35,183 INFO     Train loss at step 165500: 0.070882
2023-03-17 00:47:02,526 INFO     Train positive_sample_loss at step 165600: 0.071598
2023-03-17 00:47:02,526 INFO     Train negative_sample_loss at step 165600: 0.069452
2023-03-17 00:47:02,526 INFO     Train loss at step 165600: 0.070525
2023-03-17 00:47:21,907 INFO     Train positive_sample_loss at step 165700: 0.072571
2023-03-17 00:47:21,908 INFO     Train negative_sample_loss at step 165700: 0.070173
2023-03-17 00:47:21,908 INFO     Train loss at step 165700: 0.071372
2023-03-17 00:47:41,295 INFO     Train positive_sample_loss at step 165800: 0.073008
2023-03-17 00:47:41,295 INFO     Train negative_sample_loss at step 165800: 0.068864
2023-03-17 00:47:41,295 INFO     Train loss at step 165800: 0.070936
2023-03-17 00:48:00,674 INFO     Train positive_sample_loss at step 165900: 0.073603
2023-03-17 00:48:00,674 INFO     Train negative_sample_loss at step 165900: 0.069812
2023-03-17 00:48:00,674 INFO     Train loss at step 165900: 0.071708
2023-03-17 00:48:20,073 INFO     Train positive_sample_loss at step 166000: 0.074088
2023-03-17 00:48:20,074 INFO     Train negative_sample_loss at step 166000: 0.069030
2023-03-17 00:48:20,074 INFO     Train loss at step 166000: 0.071559
2023-03-17 00:48:39,460 INFO     Train positive_sample_loss at step 166100: 0.074259
2023-03-17 00:48:39,461 INFO     Train negative_sample_loss at step 166100: 0.068623
2023-03-17 00:48:39,461 INFO     Train loss at step 166100: 0.071441
2023-03-17 00:48:58,845 INFO     Train positive_sample_loss at step 166200: 0.075022
2023-03-17 00:48:58,845 INFO     Train negative_sample_loss at step 166200: 0.069533
2023-03-17 00:48:58,845 INFO     Train loss at step 166200: 0.072278
2023-03-17 00:49:18,233 INFO     Train positive_sample_loss at step 166300: 0.075233
2023-03-17 00:49:18,234 INFO     Train negative_sample_loss at step 166300: 0.069418
2023-03-17 00:49:18,234 INFO     Train loss at step 166300: 0.072326
2023-03-17 00:49:37,633 INFO     Train positive_sample_loss at step 166400: 0.075612
2023-03-17 00:49:37,633 INFO     Train negative_sample_loss at step 166400: 0.068980
2023-03-17 00:49:37,633 INFO     Train loss at step 166400: 0.072296
2023-03-17 00:49:57,034 INFO     Train positive_sample_loss at step 166500: 0.075891
2023-03-17 00:49:57,034 INFO     Train negative_sample_loss at step 166500: 0.068808
2023-03-17 00:49:57,034 INFO     Train loss at step 166500: 0.072349
2023-03-17 00:50:16,432 INFO     Train positive_sample_loss at step 166600: 0.076000
2023-03-17 00:50:16,433 INFO     Train negative_sample_loss at step 166600: 0.069058
2023-03-17 00:50:16,433 INFO     Train loss at step 166600: 0.072529
2023-03-17 00:50:42,975 INFO     Train positive_sample_loss at step 166700: 0.076380
2023-03-17 00:50:42,975 INFO     Train negative_sample_loss at step 166700: 0.068992
2023-03-17 00:50:42,975 INFO     Train loss at step 166700: 0.072686
2023-03-17 00:51:02,377 INFO     Train positive_sample_loss at step 166800: 0.076816
2023-03-17 00:51:02,378 INFO     Train negative_sample_loss at step 166800: 0.068356
2023-03-17 00:51:02,378 INFO     Train loss at step 166800: 0.072586
2023-03-17 00:51:21,777 INFO     Train positive_sample_loss at step 166900: 0.077034
2023-03-17 00:51:21,777 INFO     Train negative_sample_loss at step 166900: 0.068789
2023-03-17 00:51:21,778 INFO     Train loss at step 166900: 0.072912
2023-03-17 00:51:41,174 INFO     Train positive_sample_loss at step 167000: 0.077141
2023-03-17 00:51:41,175 INFO     Train negative_sample_loss at step 167000: 0.068568
2023-03-17 00:51:41,175 INFO     Train loss at step 167000: 0.072854
2023-03-17 00:52:00,580 INFO     Train positive_sample_loss at step 167100: 0.077215
2023-03-17 00:52:00,581 INFO     Train negative_sample_loss at step 167100: 0.068861
2023-03-17 00:52:00,581 INFO     Train loss at step 167100: 0.073038
2023-03-17 00:52:19,975 INFO     Train positive_sample_loss at step 167200: 0.077467
2023-03-17 00:52:19,975 INFO     Train negative_sample_loss at step 167200: 0.067988
2023-03-17 00:52:19,975 INFO     Train loss at step 167200: 0.072727
2023-03-17 00:52:39,374 INFO     Train positive_sample_loss at step 167300: 0.077670
2023-03-17 00:52:39,375 INFO     Train negative_sample_loss at step 167300: 0.068890
2023-03-17 00:52:39,375 INFO     Train loss at step 167300: 0.073280
2023-03-17 00:52:58,784 INFO     Train positive_sample_loss at step 167400: 0.077820
2023-03-17 00:52:58,785 INFO     Train negative_sample_loss at step 167400: 0.068536
2023-03-17 00:52:58,785 INFO     Train loss at step 167400: 0.073178
2023-03-17 00:53:18,187 INFO     Train positive_sample_loss at step 167500: 0.077923
2023-03-17 00:53:18,188 INFO     Train negative_sample_loss at step 167500: 0.069090
2023-03-17 00:53:18,188 INFO     Train loss at step 167500: 0.073506
2023-03-17 00:53:37,587 INFO     Train positive_sample_loss at step 167600: 0.077741
2023-03-17 00:53:37,587 INFO     Train negative_sample_loss at step 167600: 0.068710
2023-03-17 00:53:37,587 INFO     Train loss at step 167600: 0.073226
2023-03-17 00:53:56,991 INFO     Train positive_sample_loss at step 167700: 0.078086
2023-03-17 00:53:56,992 INFO     Train negative_sample_loss at step 167700: 0.068936
2023-03-17 00:53:56,992 INFO     Train loss at step 167700: 0.073511
2023-03-17 00:54:23,435 INFO     Train positive_sample_loss at step 167800: 0.078114
2023-03-17 00:54:23,435 INFO     Train negative_sample_loss at step 167800: 0.068973
2023-03-17 00:54:23,436 INFO     Train loss at step 167800: 0.073543
2023-03-17 00:54:42,833 INFO     Train positive_sample_loss at step 167900: 0.078142
2023-03-17 00:54:42,834 INFO     Train negative_sample_loss at step 167900: 0.068876
2023-03-17 00:54:42,834 INFO     Train loss at step 167900: 0.073509
2023-03-17 00:55:02,235 INFO     Train positive_sample_loss at step 168000: 0.078072
2023-03-17 00:55:02,235 INFO     Train negative_sample_loss at step 168000: 0.068328
2023-03-17 00:55:02,236 INFO     Train loss at step 168000: 0.073200
2023-03-17 00:55:21,632 INFO     Train positive_sample_loss at step 168100: 0.078209
2023-03-17 00:55:21,633 INFO     Train negative_sample_loss at step 168100: 0.068407
2023-03-17 00:55:21,633 INFO     Train loss at step 168100: 0.073308
2023-03-17 00:55:41,027 INFO     Train positive_sample_loss at step 168200: 0.078239
2023-03-17 00:55:41,027 INFO     Train negative_sample_loss at step 168200: 0.068392
2023-03-17 00:55:41,027 INFO     Train loss at step 168200: 0.073315
2023-03-17 00:56:00,424 INFO     Train positive_sample_loss at step 168300: 0.078237
2023-03-17 00:56:00,425 INFO     Train negative_sample_loss at step 168300: 0.068782
2023-03-17 00:56:00,425 INFO     Train loss at step 168300: 0.073510
2023-03-17 00:56:19,826 INFO     Train positive_sample_loss at step 168400: 0.078312
2023-03-17 00:56:19,826 INFO     Train negative_sample_loss at step 168400: 0.069558
2023-03-17 00:56:19,826 INFO     Train loss at step 168400: 0.073935
2023-03-17 00:56:39,228 INFO     Train positive_sample_loss at step 168500: 0.078091
2023-03-17 00:56:39,229 INFO     Train negative_sample_loss at step 168500: 0.069423
2023-03-17 00:56:39,229 INFO     Train loss at step 168500: 0.073757
2023-03-17 00:56:58,631 INFO     Train positive_sample_loss at step 168600: 0.078016
2023-03-17 00:56:58,631 INFO     Train negative_sample_loss at step 168600: 0.068882
2023-03-17 00:56:58,632 INFO     Train loss at step 168600: 0.073449
2023-03-17 00:57:18,053 INFO     Train positive_sample_loss at step 168700: 0.078171
2023-03-17 00:57:18,053 INFO     Train negative_sample_loss at step 168700: 0.068572
2023-03-17 00:57:18,053 INFO     Train loss at step 168700: 0.073371
2023-03-17 00:57:44,482 INFO     Train positive_sample_loss at step 168800: 0.078231
2023-03-17 00:57:44,483 INFO     Train negative_sample_loss at step 168800: 0.068891
2023-03-17 00:57:44,483 INFO     Train loss at step 168800: 0.073561
2023-03-17 00:58:03,906 INFO     Train positive_sample_loss at step 168900: 0.078179
2023-03-17 00:58:03,907 INFO     Train negative_sample_loss at step 168900: 0.068727
2023-03-17 00:58:03,907 INFO     Train loss at step 168900: 0.073453
2023-03-17 00:58:23,329 INFO     Train positive_sample_loss at step 169000: 0.078078
2023-03-17 00:58:23,329 INFO     Train negative_sample_loss at step 169000: 0.068732
2023-03-17 00:58:23,330 INFO     Train loss at step 169000: 0.073405
2023-03-17 00:58:42,741 INFO     Train positive_sample_loss at step 169100: 0.078132
2023-03-17 00:58:42,741 INFO     Train negative_sample_loss at step 169100: 0.068655
2023-03-17 00:58:42,741 INFO     Train loss at step 169100: 0.073394
2023-03-17 00:59:08,283 INFO     Train positive_sample_loss at step 169200: 0.073256
2023-03-17 00:59:08,283 INFO     Train negative_sample_loss at step 169200: 0.068313
2023-03-17 00:59:08,284 INFO     Train loss at step 169200: 0.070784
2023-03-17 00:59:27,640 INFO     Train positive_sample_loss at step 169300: 0.067164
2023-03-17 00:59:27,640 INFO     Train negative_sample_loss at step 169300: 0.068367
2023-03-17 00:59:27,640 INFO     Train loss at step 169300: 0.067766
2023-03-17 00:59:46,986 INFO     Train positive_sample_loss at step 169400: 0.068120
2023-03-17 00:59:46,987 INFO     Train negative_sample_loss at step 169400: 0.067770
2023-03-17 00:59:46,987 INFO     Train loss at step 169400: 0.067945
2023-03-17 01:00:06,319 INFO     Train positive_sample_loss at step 169500: 0.068941
2023-03-17 01:00:06,319 INFO     Train negative_sample_loss at step 169500: 0.066635
2023-03-17 01:00:06,319 INFO     Train loss at step 169500: 0.067788
2023-03-17 01:00:33,640 INFO     Train positive_sample_loss at step 169600: 0.069508
2023-03-17 01:00:33,640 INFO     Train negative_sample_loss at step 169600: 0.066520
2023-03-17 01:00:33,641 INFO     Train loss at step 169600: 0.068014
2023-03-17 01:00:53,027 INFO     Train positive_sample_loss at step 169700: 0.070307
2023-03-17 01:00:53,027 INFO     Train negative_sample_loss at step 169700: 0.066670
2023-03-17 01:00:53,027 INFO     Train loss at step 169700: 0.068488
2023-03-17 01:01:12,415 INFO     Train positive_sample_loss at step 169800: 0.070814
2023-03-17 01:01:12,415 INFO     Train negative_sample_loss at step 169800: 0.067050
2023-03-17 01:01:12,415 INFO     Train loss at step 169800: 0.068932
2023-03-17 01:01:31,822 INFO     Train positive_sample_loss at step 169900: 0.071107
2023-03-17 01:01:31,822 INFO     Train negative_sample_loss at step 169900: 0.066098
2023-03-17 01:01:31,822 INFO     Train loss at step 169900: 0.068602
2023-03-17 01:01:53,095 INFO     Train positive_sample_loss at step 170000: 0.071568
2023-03-17 01:01:53,095 INFO     Train negative_sample_loss at step 170000: 0.065650
2023-03-17 01:01:53,095 INFO     Train loss at step 170000: 0.068609
2023-03-17 01:01:53,095 INFO     Evaluating on Valid Dataset...
2023-03-17 01:01:54,107 INFO     Evaluating the model... (0/26842)
2023-03-17 01:01:55,633 INFO     Evaluating the model... (1000/26842)
2023-03-17 01:01:56,983 INFO     Evaluating the model... (2000/26842)
2023-03-17 01:01:58,202 INFO     Evaluating the model... (3000/26842)
2023-03-17 01:01:59,423 INFO     Evaluating the model... (4000/26842)
2023-03-17 01:02:00,644 INFO     Evaluating the model... (5000/26842)
2023-03-17 01:02:01,869 INFO     Evaluating the model... (6000/26842)
2023-03-17 01:02:03,091 INFO     Evaluating the model... (7000/26842)
2023-03-17 01:02:04,321 INFO     Evaluating the model... (8000/26842)
2023-03-17 01:02:05,552 INFO     Evaluating the model... (9000/26842)
2023-03-17 01:02:06,786 INFO     Evaluating the model... (10000/26842)
2023-03-17 01:02:08,016 INFO     Evaluating the model... (11000/26842)
2023-03-17 01:02:09,256 INFO     Evaluating the model... (12000/26842)
2023-03-17 01:02:10,508 INFO     Evaluating the model... (13000/26842)
2023-03-17 01:02:12,816 INFO     Evaluating the model... (14000/26842)
2023-03-17 01:02:14,303 INFO     Evaluating the model... (15000/26842)
2023-03-17 01:02:15,783 INFO     Evaluating the model... (16000/26842)
2023-03-17 01:02:17,254 INFO     Evaluating the model... (17000/26842)
2023-03-17 01:02:18,740 INFO     Evaluating the model... (18000/26842)
2023-03-17 01:02:20,212 INFO     Evaluating the model... (19000/26842)
2023-03-17 01:02:21,688 INFO     Evaluating the model... (20000/26842)
2023-03-17 01:02:23,164 INFO     Evaluating the model... (21000/26842)
2023-03-17 01:02:24,636 INFO     Evaluating the model... (22000/26842)
2023-03-17 01:02:26,110 INFO     Evaluating the model... (23000/26842)
2023-03-17 01:02:27,583 INFO     Evaluating the model... (24000/26842)
2023-03-17 01:02:29,061 INFO     Evaluating the model... (25000/26842)
2023-03-17 01:02:30,552 INFO     Evaluating the model... (26000/26842)
2023-03-17 01:02:32,139 INFO     Valid hits@1_list at step 170000: 0.645562
2023-03-17 01:02:32,140 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 01:02:32,140 INFO     Valid hits@3_list at step 170000: 0.738807
2023-03-17 01:02:32,140 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 01:02:32,140 INFO     Valid hits@10_list at step 170000: 0.830368
2023-03-17 01:02:32,140 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 01:02:32,140 INFO     Valid mrr_list at step 170000: 0.708645
2023-03-17 01:02:51,543 INFO     Train positive_sample_loss at step 170100: 0.072319
2023-03-17 01:02:51,544 INFO     Train negative_sample_loss at step 170100: 0.066148
2023-03-17 01:02:51,544 INFO     Train loss at step 170100: 0.069233
2023-03-17 01:03:10,933 INFO     Train positive_sample_loss at step 170200: 0.072520
2023-03-17 01:03:10,933 INFO     Train negative_sample_loss at step 170200: 0.065545
2023-03-17 01:03:10,933 INFO     Train loss at step 170200: 0.069032
2023-03-17 01:03:30,324 INFO     Train positive_sample_loss at step 170300: 0.072833
2023-03-17 01:03:30,324 INFO     Train negative_sample_loss at step 170300: 0.066057
2023-03-17 01:03:30,324 INFO     Train loss at step 170300: 0.069445
2023-03-17 01:03:49,721 INFO     Train positive_sample_loss at step 170400: 0.073156
2023-03-17 01:03:49,721 INFO     Train negative_sample_loss at step 170400: 0.065653
2023-03-17 01:03:49,721 INFO     Train loss at step 170400: 0.069404
2023-03-17 01:04:09,131 INFO     Train positive_sample_loss at step 170500: 0.073389
2023-03-17 01:04:09,131 INFO     Train negative_sample_loss at step 170500: 0.066178
2023-03-17 01:04:09,131 INFO     Train loss at step 170500: 0.069784
2023-03-17 01:04:35,584 INFO     Train positive_sample_loss at step 170600: 0.073771
2023-03-17 01:04:35,584 INFO     Train negative_sample_loss at step 170600: 0.065501
2023-03-17 01:04:35,584 INFO     Train loss at step 170600: 0.069636
2023-03-17 01:04:54,994 INFO     Train positive_sample_loss at step 170700: 0.074029
2023-03-17 01:04:54,994 INFO     Train negative_sample_loss at step 170700: 0.066028
2023-03-17 01:04:54,994 INFO     Train loss at step 170700: 0.070029
2023-03-17 01:05:14,413 INFO     Train positive_sample_loss at step 170800: 0.074471
2023-03-17 01:05:14,413 INFO     Train negative_sample_loss at step 170800: 0.066463
2023-03-17 01:05:14,413 INFO     Train loss at step 170800: 0.070467
2023-03-17 01:05:33,823 INFO     Train positive_sample_loss at step 170900: 0.074601
2023-03-17 01:05:33,823 INFO     Train negative_sample_loss at step 170900: 0.065912
2023-03-17 01:05:33,823 INFO     Train loss at step 170900: 0.070256
2023-03-17 01:05:53,231 INFO     Train positive_sample_loss at step 171000: 0.074615
2023-03-17 01:05:53,232 INFO     Train negative_sample_loss at step 171000: 0.066775
2023-03-17 01:05:53,232 INFO     Train loss at step 171000: 0.070695
2023-03-17 01:06:12,640 INFO     Train positive_sample_loss at step 171100: 0.074951
2023-03-17 01:06:12,640 INFO     Train negative_sample_loss at step 171100: 0.066477
2023-03-17 01:06:12,640 INFO     Train loss at step 171100: 0.070714
2023-03-17 01:06:32,048 INFO     Train positive_sample_loss at step 171200: 0.075230
2023-03-17 01:06:32,048 INFO     Train negative_sample_loss at step 171200: 0.066615
2023-03-17 01:06:32,048 INFO     Train loss at step 171200: 0.070923
2023-03-17 01:06:51,466 INFO     Train positive_sample_loss at step 171300: 0.075429
2023-03-17 01:06:51,467 INFO     Train negative_sample_loss at step 171300: 0.066200
2023-03-17 01:06:51,467 INFO     Train loss at step 171300: 0.070814
2023-03-17 01:07:10,875 INFO     Train positive_sample_loss at step 171400: 0.075318
2023-03-17 01:07:10,876 INFO     Train negative_sample_loss at step 171400: 0.065844
2023-03-17 01:07:10,876 INFO     Train loss at step 171400: 0.070581
2023-03-17 01:07:30,279 INFO     Train positive_sample_loss at step 171500: 0.075382
2023-03-17 01:07:30,279 INFO     Train negative_sample_loss at step 171500: 0.066165
2023-03-17 01:07:30,279 INFO     Train loss at step 171500: 0.070773
2023-03-17 01:07:49,704 INFO     Train positive_sample_loss at step 171600: 0.075666
2023-03-17 01:07:49,705 INFO     Train negative_sample_loss at step 171600: 0.066293
2023-03-17 01:07:49,705 INFO     Train loss at step 171600: 0.070979
2023-03-17 01:08:16,100 INFO     Train positive_sample_loss at step 171700: 0.075597
2023-03-17 01:08:16,100 INFO     Train negative_sample_loss at step 171700: 0.066748
2023-03-17 01:08:16,100 INFO     Train loss at step 171700: 0.071172
2023-03-17 01:08:35,490 INFO     Train positive_sample_loss at step 171800: 0.075626
2023-03-17 01:08:35,490 INFO     Train negative_sample_loss at step 171800: 0.066325
2023-03-17 01:08:35,490 INFO     Train loss at step 171800: 0.070976
2023-03-17 01:08:54,876 INFO     Train positive_sample_loss at step 171900: 0.075758
2023-03-17 01:08:54,877 INFO     Train negative_sample_loss at step 171900: 0.065917
2023-03-17 01:08:54,877 INFO     Train loss at step 171900: 0.070838
2023-03-17 01:09:14,273 INFO     Train positive_sample_loss at step 172000: 0.075856
2023-03-17 01:09:14,273 INFO     Train negative_sample_loss at step 172000: 0.066509
2023-03-17 01:09:14,273 INFO     Train loss at step 172000: 0.071182
2023-03-17 01:09:33,668 INFO     Train positive_sample_loss at step 172100: 0.075767
2023-03-17 01:09:33,669 INFO     Train negative_sample_loss at step 172100: 0.066535
2023-03-17 01:09:33,669 INFO     Train loss at step 172100: 0.071151
2023-03-17 01:09:53,065 INFO     Train positive_sample_loss at step 172200: 0.075802
2023-03-17 01:09:53,065 INFO     Train negative_sample_loss at step 172200: 0.066024
2023-03-17 01:09:53,065 INFO     Train loss at step 172200: 0.070913
2023-03-17 01:10:12,457 INFO     Train positive_sample_loss at step 172300: 0.075927
2023-03-17 01:10:12,457 INFO     Train negative_sample_loss at step 172300: 0.066059
2023-03-17 01:10:12,457 INFO     Train loss at step 172300: 0.070993
2023-03-17 01:10:31,861 INFO     Train positive_sample_loss at step 172400: 0.076002
2023-03-17 01:10:31,861 INFO     Train negative_sample_loss at step 172400: 0.066736
2023-03-17 01:10:31,861 INFO     Train loss at step 172400: 0.071369
2023-03-17 01:10:51,256 INFO     Train positive_sample_loss at step 172500: 0.075969
2023-03-17 01:10:51,256 INFO     Train negative_sample_loss at step 172500: 0.066027
2023-03-17 01:10:51,256 INFO     Train loss at step 172500: 0.070998
2023-03-17 01:11:10,646 INFO     Train positive_sample_loss at step 172600: 0.075970
2023-03-17 01:11:10,646 INFO     Train negative_sample_loss at step 172600: 0.067112
2023-03-17 01:11:10,646 INFO     Train loss at step 172600: 0.071541
2023-03-17 01:11:30,041 INFO     Train positive_sample_loss at step 172700: 0.075715
2023-03-17 01:11:30,042 INFO     Train negative_sample_loss at step 172700: 0.066826
2023-03-17 01:11:30,042 INFO     Train loss at step 172700: 0.071270
2023-03-17 01:11:56,357 INFO     Train positive_sample_loss at step 172800: 0.075988
2023-03-17 01:11:56,357 INFO     Train negative_sample_loss at step 172800: 0.066175
2023-03-17 01:11:56,357 INFO     Train loss at step 172800: 0.071082
2023-03-17 01:12:15,753 INFO     Train positive_sample_loss at step 172900: 0.075794
2023-03-17 01:12:15,754 INFO     Train negative_sample_loss at step 172900: 0.066412
2023-03-17 01:12:15,754 INFO     Train loss at step 172900: 0.071103
2023-03-17 01:12:35,143 INFO     Train positive_sample_loss at step 173000: 0.075787
2023-03-17 01:12:35,143 INFO     Train negative_sample_loss at step 173000: 0.067391
2023-03-17 01:12:35,144 INFO     Train loss at step 173000: 0.071589
funtion time use:38851ms
2023-03-17 01:13:00,395 INFO     Train positive_sample_loss at step 173100: 0.075252
2023-03-17 01:13:00,395 INFO     Train negative_sample_loss at step 173100: 0.065849
2023-03-17 01:13:00,395 INFO     Train loss at step 173100: 0.070551
2023-03-17 01:13:19,754 INFO     Train positive_sample_loss at step 173200: 0.065082
2023-03-17 01:13:19,755 INFO     Train negative_sample_loss at step 173200: 0.065537
2023-03-17 01:13:19,755 INFO     Train loss at step 173200: 0.065309
2023-03-17 01:13:39,111 INFO     Train positive_sample_loss at step 173300: 0.066119
2023-03-17 01:13:39,112 INFO     Train negative_sample_loss at step 173300: 0.065359
2023-03-17 01:13:39,112 INFO     Train loss at step 173300: 0.065739
2023-03-17 01:13:58,445 INFO     Train positive_sample_loss at step 173400: 0.067125
2023-03-17 01:13:58,446 INFO     Train negative_sample_loss at step 173400: 0.065159
2023-03-17 01:13:58,446 INFO     Train loss at step 173400: 0.066142
2023-03-17 01:14:25,652 INFO     Train positive_sample_loss at step 173500: 0.067544
2023-03-17 01:14:25,653 INFO     Train negative_sample_loss at step 173500: 0.064588
2023-03-17 01:14:25,653 INFO     Train loss at step 173500: 0.066066
2023-03-17 01:14:45,029 INFO     Train positive_sample_loss at step 173600: 0.068303
2023-03-17 01:14:45,030 INFO     Train negative_sample_loss at step 173600: 0.063733
2023-03-17 01:14:45,030 INFO     Train loss at step 173600: 0.066018
2023-03-17 01:15:04,411 INFO     Train positive_sample_loss at step 173700: 0.068773
2023-03-17 01:15:04,411 INFO     Train negative_sample_loss at step 173700: 0.064194
2023-03-17 01:15:04,411 INFO     Train loss at step 173700: 0.066483
2023-03-17 01:15:23,806 INFO     Train positive_sample_loss at step 173800: 0.069563
2023-03-17 01:15:23,807 INFO     Train negative_sample_loss at step 173800: 0.064534
2023-03-17 01:15:23,807 INFO     Train loss at step 173800: 0.067048
2023-03-17 01:15:43,199 INFO     Train positive_sample_loss at step 173900: 0.069766
2023-03-17 01:15:43,200 INFO     Train negative_sample_loss at step 173900: 0.064743
2023-03-17 01:15:43,200 INFO     Train loss at step 173900: 0.067254
2023-03-17 01:16:02,594 INFO     Train positive_sample_loss at step 174000: 0.070353
2023-03-17 01:16:02,594 INFO     Train negative_sample_loss at step 174000: 0.063949
2023-03-17 01:16:02,594 INFO     Train loss at step 174000: 0.067151
2023-03-17 01:16:21,991 INFO     Train positive_sample_loss at step 174100: 0.070687
2023-03-17 01:16:21,991 INFO     Train negative_sample_loss at step 174100: 0.064446
2023-03-17 01:16:21,991 INFO     Train loss at step 174100: 0.067566
2023-03-17 01:16:41,392 INFO     Train positive_sample_loss at step 174200: 0.070901
2023-03-17 01:16:41,393 INFO     Train negative_sample_loss at step 174200: 0.063794
2023-03-17 01:16:41,393 INFO     Train loss at step 174200: 0.067347
2023-03-17 01:17:00,787 INFO     Train positive_sample_loss at step 174300: 0.071250
2023-03-17 01:17:00,788 INFO     Train negative_sample_loss at step 174300: 0.064655
2023-03-17 01:17:00,788 INFO     Train loss at step 174300: 0.067952
2023-03-17 01:17:20,198 INFO     Train positive_sample_loss at step 174400: 0.071462
2023-03-17 01:17:20,199 INFO     Train negative_sample_loss at step 174400: 0.064343
2023-03-17 01:17:20,199 INFO     Train loss at step 174400: 0.067902
2023-03-17 01:17:46,580 INFO     Train positive_sample_loss at step 174500: 0.071956
2023-03-17 01:17:46,581 INFO     Train negative_sample_loss at step 174500: 0.063565
2023-03-17 01:17:46,581 INFO     Train loss at step 174500: 0.067760
2023-03-17 01:18:05,978 INFO     Train positive_sample_loss at step 174600: 0.072120
2023-03-17 01:18:05,979 INFO     Train negative_sample_loss at step 174600: 0.064474
2023-03-17 01:18:05,979 INFO     Train loss at step 174600: 0.068297
2023-03-17 01:18:25,386 INFO     Train positive_sample_loss at step 174700: 0.072673
2023-03-17 01:18:25,386 INFO     Train negative_sample_loss at step 174700: 0.064148
2023-03-17 01:18:25,386 INFO     Train loss at step 174700: 0.068410
2023-03-17 01:18:44,799 INFO     Train positive_sample_loss at step 174800: 0.072725
2023-03-17 01:18:44,800 INFO     Train negative_sample_loss at step 174800: 0.063976
2023-03-17 01:18:44,800 INFO     Train loss at step 174800: 0.068351
2023-03-17 01:19:04,208 INFO     Train positive_sample_loss at step 174900: 0.072823
2023-03-17 01:19:04,209 INFO     Train negative_sample_loss at step 174900: 0.064158
2023-03-17 01:19:04,209 INFO     Train loss at step 174900: 0.068490
2023-03-17 01:19:23,613 INFO     Train positive_sample_loss at step 175000: 0.073060
2023-03-17 01:19:23,613 INFO     Train negative_sample_loss at step 175000: 0.064019
2023-03-17 01:19:23,613 INFO     Train loss at step 175000: 0.068540
2023-03-17 01:19:43,030 INFO     Train positive_sample_loss at step 175100: 0.073476
2023-03-17 01:19:43,030 INFO     Train negative_sample_loss at step 175100: 0.064713
2023-03-17 01:19:43,030 INFO     Train loss at step 175100: 0.069095
2023-03-17 01:20:02,435 INFO     Train positive_sample_loss at step 175200: 0.073378
2023-03-17 01:20:02,435 INFO     Train negative_sample_loss at step 175200: 0.064277
2023-03-17 01:20:02,435 INFO     Train loss at step 175200: 0.068828
2023-03-17 01:20:21,835 INFO     Train positive_sample_loss at step 175300: 0.073618
2023-03-17 01:20:21,835 INFO     Train negative_sample_loss at step 175300: 0.064648
2023-03-17 01:20:21,835 INFO     Train loss at step 175300: 0.069133
2023-03-17 01:20:41,240 INFO     Train positive_sample_loss at step 175400: 0.073807
2023-03-17 01:20:41,241 INFO     Train negative_sample_loss at step 175400: 0.064251
2023-03-17 01:20:41,241 INFO     Train loss at step 175400: 0.069029
2023-03-17 01:21:00,644 INFO     Train positive_sample_loss at step 175500: 0.073772
2023-03-17 01:21:00,644 INFO     Train negative_sample_loss at step 175500: 0.064221
2023-03-17 01:21:00,644 INFO     Train loss at step 175500: 0.068997
2023-03-17 01:21:27,083 INFO     Train positive_sample_loss at step 175600: 0.073860
2023-03-17 01:21:27,083 INFO     Train negative_sample_loss at step 175600: 0.064534
2023-03-17 01:21:27,084 INFO     Train loss at step 175600: 0.069197
2023-03-17 01:21:46,475 INFO     Train positive_sample_loss at step 175700: 0.074163
2023-03-17 01:21:46,476 INFO     Train negative_sample_loss at step 175700: 0.064396
2023-03-17 01:21:46,476 INFO     Train loss at step 175700: 0.069279
2023-03-17 01:22:05,869 INFO     Train positive_sample_loss at step 175800: 0.074181
2023-03-17 01:22:05,870 INFO     Train negative_sample_loss at step 175800: 0.064662
2023-03-17 01:22:05,870 INFO     Train loss at step 175800: 0.069421
2023-03-17 01:22:25,258 INFO     Train positive_sample_loss at step 175900: 0.074011
2023-03-17 01:22:25,258 INFO     Train negative_sample_loss at step 175900: 0.063937
2023-03-17 01:22:25,258 INFO     Train loss at step 175900: 0.068974
2023-03-17 01:22:44,647 INFO     Train positive_sample_loss at step 176000: 0.074264
2023-03-17 01:22:44,648 INFO     Train negative_sample_loss at step 176000: 0.064438
2023-03-17 01:22:44,648 INFO     Train loss at step 176000: 0.069351
2023-03-17 01:23:04,044 INFO     Train positive_sample_loss at step 176100: 0.074187
2023-03-17 01:23:04,045 INFO     Train negative_sample_loss at step 176100: 0.064584
2023-03-17 01:23:04,045 INFO     Train loss at step 176100: 0.069386
2023-03-17 01:23:23,444 INFO     Train positive_sample_loss at step 176200: 0.074219
2023-03-17 01:23:23,444 INFO     Train negative_sample_loss at step 176200: 0.064971
2023-03-17 01:23:23,445 INFO     Train loss at step 176200: 0.069595
2023-03-17 01:23:42,827 INFO     Train positive_sample_loss at step 176300: 0.074228
2023-03-17 01:23:42,827 INFO     Train negative_sample_loss at step 176300: 0.065056
2023-03-17 01:23:42,827 INFO     Train loss at step 176300: 0.069642
2023-03-17 01:24:02,221 INFO     Train positive_sample_loss at step 176400: 0.073970
2023-03-17 01:24:02,221 INFO     Train negative_sample_loss at step 176400: 0.064440
2023-03-17 01:24:02,221 INFO     Train loss at step 176400: 0.069205
2023-03-17 01:24:21,617 INFO     Train positive_sample_loss at step 176500: 0.074149
2023-03-17 01:24:21,618 INFO     Train negative_sample_loss at step 176500: 0.064689
2023-03-17 01:24:21,618 INFO     Train loss at step 176500: 0.069419
2023-03-17 01:24:41,009 INFO     Train positive_sample_loss at step 176600: 0.074471
2023-03-17 01:24:41,010 INFO     Train negative_sample_loss at step 176600: 0.065085
2023-03-17 01:24:41,010 INFO     Train loss at step 176600: 0.069778
2023-03-17 01:25:07,272 INFO     Train positive_sample_loss at step 176700: 0.074476
2023-03-17 01:25:07,272 INFO     Train negative_sample_loss at step 176700: 0.065548
2023-03-17 01:25:07,272 INFO     Train loss at step 176700: 0.070012
2023-03-17 01:25:26,671 INFO     Train positive_sample_loss at step 176800: 0.074124
2023-03-17 01:25:26,672 INFO     Train negative_sample_loss at step 176800: 0.065091
2023-03-17 01:25:26,672 INFO     Train loss at step 176800: 0.069607
2023-03-17 01:25:46,066 INFO     Train positive_sample_loss at step 176900: 0.073966
2023-03-17 01:25:46,066 INFO     Train negative_sample_loss at step 176900: 0.064631
2023-03-17 01:25:46,066 INFO     Train loss at step 176900: 0.069298
2023-03-17 01:26:05,465 INFO     Train positive_sample_loss at step 177000: 0.074151
2023-03-17 01:26:05,466 INFO     Train negative_sample_loss at step 177000: 0.064908
2023-03-17 01:26:05,466 INFO     Train loss at step 177000: 0.069529
2023-03-17 01:26:30,825 INFO     Train positive_sample_loss at step 177100: 0.066721
2023-03-17 01:26:30,825 INFO     Train negative_sample_loss at step 177100: 0.064142
2023-03-17 01:26:30,826 INFO     Train loss at step 177100: 0.065431
2023-03-17 01:26:50,167 INFO     Train positive_sample_loss at step 177200: 0.064740
2023-03-17 01:26:50,167 INFO     Train negative_sample_loss at step 177200: 0.064618
2023-03-17 01:26:50,168 INFO     Train loss at step 177200: 0.064679
2023-03-17 01:27:09,510 INFO     Train positive_sample_loss at step 177300: 0.065392
2023-03-17 01:27:09,510 INFO     Train negative_sample_loss at step 177300: 0.063429
2023-03-17 01:27:09,510 INFO     Train loss at step 177300: 0.064411
2023-03-17 01:27:36,784 INFO     Train positive_sample_loss at step 177400: 0.065958
2023-03-17 01:27:36,784 INFO     Train negative_sample_loss at step 177400: 0.063197
2023-03-17 01:27:36,784 INFO     Train loss at step 177400: 0.064577
2023-03-17 01:27:56,145 INFO     Train positive_sample_loss at step 177500: 0.066823
2023-03-17 01:27:56,145 INFO     Train negative_sample_loss at step 177500: 0.063162
2023-03-17 01:27:56,145 INFO     Train loss at step 177500: 0.064993
2023-03-17 01:28:15,533 INFO     Train positive_sample_loss at step 177600: 0.067289
2023-03-17 01:28:15,533 INFO     Train negative_sample_loss at step 177600: 0.062658
2023-03-17 01:28:15,533 INFO     Train loss at step 177600: 0.064973
2023-03-17 01:28:34,913 INFO     Train positive_sample_loss at step 177700: 0.068115
2023-03-17 01:28:34,913 INFO     Train negative_sample_loss at step 177700: 0.062419
2023-03-17 01:28:34,913 INFO     Train loss at step 177700: 0.065267
2023-03-17 01:28:54,316 INFO     Train positive_sample_loss at step 177800: 0.068403
2023-03-17 01:28:54,317 INFO     Train negative_sample_loss at step 177800: 0.063350
2023-03-17 01:28:54,317 INFO     Train loss at step 177800: 0.065877
2023-03-17 01:29:13,713 INFO     Train positive_sample_loss at step 177900: 0.068718
2023-03-17 01:29:13,714 INFO     Train negative_sample_loss at step 177900: 0.062848
2023-03-17 01:29:13,714 INFO     Train loss at step 177900: 0.065783
2023-03-17 01:29:33,106 INFO     Train positive_sample_loss at step 178000: 0.069277
2023-03-17 01:29:33,106 INFO     Train negative_sample_loss at step 178000: 0.062615
2023-03-17 01:29:33,106 INFO     Train loss at step 178000: 0.065946
2023-03-17 01:29:52,497 INFO     Train positive_sample_loss at step 178100: 0.069572
2023-03-17 01:29:52,497 INFO     Train negative_sample_loss at step 178100: 0.062047
2023-03-17 01:29:52,497 INFO     Train loss at step 178100: 0.065809
2023-03-17 01:30:11,893 INFO     Train positive_sample_loss at step 178200: 0.069876
2023-03-17 01:30:11,894 INFO     Train negative_sample_loss at step 178200: 0.062509
2023-03-17 01:30:11,894 INFO     Train loss at step 178200: 0.066192
2023-03-17 01:30:31,301 INFO     Train positive_sample_loss at step 178300: 0.070278
2023-03-17 01:30:31,301 INFO     Train negative_sample_loss at step 178300: 0.062917
2023-03-17 01:30:31,301 INFO     Train loss at step 178300: 0.066598
2023-03-17 01:30:50,693 INFO     Train positive_sample_loss at step 178400: 0.070517
2023-03-17 01:30:50,693 INFO     Train negative_sample_loss at step 178400: 0.062581
2023-03-17 01:30:50,693 INFO     Train loss at step 178400: 0.066549
2023-03-17 01:31:17,021 INFO     Train positive_sample_loss at step 178500: 0.071019
2023-03-17 01:31:17,022 INFO     Train negative_sample_loss at step 178500: 0.062736
2023-03-17 01:31:17,022 INFO     Train loss at step 178500: 0.066877
2023-03-17 01:31:36,426 INFO     Train positive_sample_loss at step 178600: 0.071035
2023-03-17 01:31:36,426 INFO     Train negative_sample_loss at step 178600: 0.062651
2023-03-17 01:31:36,426 INFO     Train loss at step 178600: 0.066843
2023-03-17 01:31:55,824 INFO     Train positive_sample_loss at step 178700: 0.071262
2023-03-17 01:31:55,824 INFO     Train negative_sample_loss at step 178700: 0.062902
2023-03-17 01:31:55,824 INFO     Train loss at step 178700: 0.067082
2023-03-17 01:32:15,227 INFO     Train positive_sample_loss at step 178800: 0.071281
2023-03-17 01:32:15,228 INFO     Train negative_sample_loss at step 178800: 0.062725
2023-03-17 01:32:15,228 INFO     Train loss at step 178800: 0.067003
2023-03-17 01:32:34,630 INFO     Train positive_sample_loss at step 178900: 0.071811
2023-03-17 01:32:34,630 INFO     Train negative_sample_loss at step 178900: 0.062770
2023-03-17 01:32:34,631 INFO     Train loss at step 178900: 0.067290
2023-03-17 01:32:54,045 INFO     Train positive_sample_loss at step 179000: 0.071937
2023-03-17 01:32:54,046 INFO     Train negative_sample_loss at step 179000: 0.062504
2023-03-17 01:32:54,046 INFO     Train loss at step 179000: 0.067220
2023-03-17 01:33:13,460 INFO     Train positive_sample_loss at step 179100: 0.072088
2023-03-17 01:33:13,460 INFO     Train negative_sample_loss at step 179100: 0.062883
2023-03-17 01:33:13,461 INFO     Train loss at step 179100: 0.067486
2023-03-17 01:33:32,878 INFO     Train positive_sample_loss at step 179200: 0.072196
2023-03-17 01:33:32,878 INFO     Train negative_sample_loss at step 179200: 0.063222
2023-03-17 01:33:32,879 INFO     Train loss at step 179200: 0.067709
2023-03-17 01:33:52,283 INFO     Train positive_sample_loss at step 179300: 0.072453
2023-03-17 01:33:52,284 INFO     Train negative_sample_loss at step 179300: 0.063120
2023-03-17 01:33:52,284 INFO     Train loss at step 179300: 0.067787
2023-03-17 01:34:11,698 INFO     Train positive_sample_loss at step 179400: 0.072432
2023-03-17 01:34:11,698 INFO     Train negative_sample_loss at step 179400: 0.063287
2023-03-17 01:34:11,698 INFO     Train loss at step 179400: 0.067860
2023-03-17 01:34:38,039 INFO     Train positive_sample_loss at step 179500: 0.072473
2023-03-17 01:34:38,040 INFO     Train negative_sample_loss at step 179500: 0.062991
2023-03-17 01:34:38,040 INFO     Train loss at step 179500: 0.067732
2023-03-17 01:34:57,463 INFO     Train positive_sample_loss at step 179600: 0.072621
2023-03-17 01:34:57,464 INFO     Train negative_sample_loss at step 179600: 0.062904
2023-03-17 01:34:57,464 INFO     Train loss at step 179600: 0.067762
2023-03-17 01:35:16,869 INFO     Train positive_sample_loss at step 179700: 0.072562
2023-03-17 01:35:16,870 INFO     Train negative_sample_loss at step 179700: 0.063034
2023-03-17 01:35:16,870 INFO     Train loss at step 179700: 0.067798
2023-03-17 01:35:36,268 INFO     Train positive_sample_loss at step 179800: 0.072616
2023-03-17 01:35:36,268 INFO     Train negative_sample_loss at step 179800: 0.062908
2023-03-17 01:35:36,268 INFO     Train loss at step 179800: 0.067762
2023-03-17 01:35:55,679 INFO     Train positive_sample_loss at step 179900: 0.072720
2023-03-17 01:35:55,679 INFO     Train negative_sample_loss at step 179900: 0.063283
2023-03-17 01:35:55,679 INFO     Train loss at step 179900: 0.068002
2023-03-17 01:36:16,960 INFO     Train positive_sample_loss at step 180000: 0.072752
2023-03-17 01:36:16,961 INFO     Train negative_sample_loss at step 180000: 0.062629
2023-03-17 01:36:16,961 INFO     Train loss at step 180000: 0.067690
2023-03-17 01:36:16,961 INFO     Evaluating on Valid Dataset...
2023-03-17 01:36:17,933 INFO     Evaluating the model... (0/26842)
2023-03-17 01:36:19,494 INFO     Evaluating the model... (1000/26842)
2023-03-17 01:36:20,741 INFO     Evaluating the model... (2000/26842)
2023-03-17 01:36:21,977 INFO     Evaluating the model... (3000/26842)
2023-03-17 01:36:23,212 INFO     Evaluating the model... (4000/26842)
2023-03-17 01:36:24,449 INFO     Evaluating the model... (5000/26842)
2023-03-17 01:36:25,682 INFO     Evaluating the model... (6000/26842)
2023-03-17 01:36:26,917 INFO     Evaluating the model... (7000/26842)
2023-03-17 01:36:28,149 INFO     Evaluating the model... (8000/26842)
2023-03-17 01:36:29,376 INFO     Evaluating the model... (9000/26842)
2023-03-17 01:36:30,625 INFO     Evaluating the model... (10000/26842)
2023-03-17 01:36:31,858 INFO     Evaluating the model... (11000/26842)
2023-03-17 01:36:33,099 INFO     Evaluating the model... (12000/26842)
2023-03-17 01:36:34,356 INFO     Evaluating the model... (13000/26842)
2023-03-17 01:36:36,683 INFO     Evaluating the model... (14000/26842)
2023-03-17 01:36:38,167 INFO     Evaluating the model... (15000/26842)
2023-03-17 01:36:39,638 INFO     Evaluating the model... (16000/26842)
2023-03-17 01:36:41,114 INFO     Evaluating the model... (17000/26842)
2023-03-17 01:36:42,594 INFO     Evaluating the model... (18000/26842)
2023-03-17 01:36:44,083 INFO     Evaluating the model... (19000/26842)
2023-03-17 01:36:45,566 INFO     Evaluating the model... (20000/26842)
2023-03-17 01:36:47,052 INFO     Evaluating the model... (21000/26842)
2023-03-17 01:36:48,531 INFO     Evaluating the model... (22000/26842)
2023-03-17 01:36:50,007 INFO     Evaluating the model... (23000/26842)
2023-03-17 01:36:51,498 INFO     Evaluating the model... (24000/26842)
2023-03-17 01:36:52,988 INFO     Evaluating the model... (25000/26842)
2023-03-17 01:36:54,466 INFO     Evaluating the model... (26000/26842)
2023-03-17 01:36:56,057 INFO     Valid hits@1_list at step 180000: 0.649284
2023-03-17 01:36:56,057 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 01:36:56,057 INFO     Valid hits@3_list at step 180000: 0.741845
2023-03-17 01:36:56,057 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 01:36:56,057 INFO     Valid hits@10_list at step 180000: 0.832340
2023-03-17 01:36:56,057 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 01:36:56,057 INFO     Valid mrr_list at step 180000: 0.711830
2023-03-17 01:37:15,459 INFO     Train positive_sample_loss at step 180100: 0.072777
2023-03-17 01:37:15,459 INFO     Train negative_sample_loss at step 180100: 0.063429
2023-03-17 01:37:15,460 INFO     Train loss at step 180100: 0.068103
2023-03-17 01:37:34,861 INFO     Train positive_sample_loss at step 180200: 0.072715
2023-03-17 01:37:34,861 INFO     Train negative_sample_loss at step 180200: 0.063165
2023-03-17 01:37:34,861 INFO     Train loss at step 180200: 0.067940
2023-03-17 01:37:54,266 INFO     Train positive_sample_loss at step 180300: 0.072938
2023-03-17 01:37:54,267 INFO     Train negative_sample_loss at step 180300: 0.063248
2023-03-17 01:37:54,267 INFO     Train loss at step 180300: 0.068093
2023-03-17 01:38:13,669 INFO     Train positive_sample_loss at step 180400: 0.073008
2023-03-17 01:38:13,670 INFO     Train negative_sample_loss at step 180400: 0.064028
2023-03-17 01:38:13,670 INFO     Train loss at step 180400: 0.068518
2023-03-17 01:38:33,070 INFO     Train positive_sample_loss at step 180500: 0.072863
2023-03-17 01:38:33,070 INFO     Train negative_sample_loss at step 180500: 0.063626
2023-03-17 01:38:33,070 INFO     Train loss at step 180500: 0.068245
2023-03-17 01:38:59,345 INFO     Train positive_sample_loss at step 180600: 0.073064
2023-03-17 01:38:59,345 INFO     Train negative_sample_loss at step 180600: 0.063730
2023-03-17 01:38:59,346 INFO     Train loss at step 180600: 0.068397
2023-03-17 01:39:18,753 INFO     Train positive_sample_loss at step 180700: 0.072875
2023-03-17 01:39:18,753 INFO     Train negative_sample_loss at step 180700: 0.063259
2023-03-17 01:39:18,754 INFO     Train loss at step 180700: 0.068067
2023-03-17 01:39:38,156 INFO     Train positive_sample_loss at step 180800: 0.072913
2023-03-17 01:39:38,156 INFO     Train negative_sample_loss at step 180800: 0.063904
2023-03-17 01:39:38,156 INFO     Train loss at step 180800: 0.068408
2023-03-17 01:39:57,569 INFO     Train positive_sample_loss at step 180900: 0.072865
2023-03-17 01:39:57,569 INFO     Train negative_sample_loss at step 180900: 0.063534
2023-03-17 01:39:57,570 INFO     Train loss at step 180900: 0.068199
funtion time use:38910ms
2023-03-17 01:40:22,938 INFO     Train positive_sample_loss at step 181000: 0.069027
2023-03-17 01:40:22,939 INFO     Train negative_sample_loss at step 181000: 0.063216
2023-03-17 01:40:22,939 INFO     Train loss at step 181000: 0.066122
2023-03-17 01:40:42,291 INFO     Train positive_sample_loss at step 181100: 0.063223
2023-03-17 01:40:42,291 INFO     Train negative_sample_loss at step 181100: 0.062513
2023-03-17 01:40:42,291 INFO     Train loss at step 181100: 0.062868
2023-03-17 01:41:01,629 INFO     Train positive_sample_loss at step 181200: 0.064113
2023-03-17 01:41:01,630 INFO     Train negative_sample_loss at step 181200: 0.062611
2023-03-17 01:41:01,630 INFO     Train loss at step 181200: 0.063362
2023-03-17 01:41:28,902 INFO     Train positive_sample_loss at step 181300: 0.064849
2023-03-17 01:41:28,902 INFO     Train negative_sample_loss at step 181300: 0.062000
2023-03-17 01:41:28,902 INFO     Train loss at step 181300: 0.063425
2023-03-17 01:41:48,269 INFO     Train positive_sample_loss at step 181400: 0.065428
2023-03-17 01:41:48,270 INFO     Train negative_sample_loss at step 181400: 0.061883
2023-03-17 01:41:48,270 INFO     Train loss at step 181400: 0.063655
2023-03-17 01:42:07,655 INFO     Train positive_sample_loss at step 181500: 0.066040
2023-03-17 01:42:07,656 INFO     Train negative_sample_loss at step 181500: 0.061395
2023-03-17 01:42:07,656 INFO     Train loss at step 181500: 0.063718
2023-03-17 01:42:27,051 INFO     Train positive_sample_loss at step 181600: 0.066523
2023-03-17 01:42:27,052 INFO     Train negative_sample_loss at step 181600: 0.061100
2023-03-17 01:42:27,052 INFO     Train loss at step 181600: 0.063812
2023-03-17 01:42:46,448 INFO     Train positive_sample_loss at step 181700: 0.067210
2023-03-17 01:42:46,448 INFO     Train negative_sample_loss at step 181700: 0.061775
2023-03-17 01:42:46,448 INFO     Train loss at step 181700: 0.064492
2023-03-17 01:43:05,835 INFO     Train positive_sample_loss at step 181800: 0.067398
2023-03-17 01:43:05,836 INFO     Train negative_sample_loss at step 181800: 0.061986
2023-03-17 01:43:05,836 INFO     Train loss at step 181800: 0.064692
2023-03-17 01:43:25,246 INFO     Train positive_sample_loss at step 181900: 0.068113
2023-03-17 01:43:25,246 INFO     Train negative_sample_loss at step 181900: 0.061322
2023-03-17 01:43:25,247 INFO     Train loss at step 181900: 0.064718
2023-03-17 01:43:44,638 INFO     Train positive_sample_loss at step 182000: 0.068331
2023-03-17 01:43:44,638 INFO     Train negative_sample_loss at step 182000: 0.061249
2023-03-17 01:43:44,639 INFO     Train loss at step 182000: 0.064790
2023-03-17 01:44:04,041 INFO     Train positive_sample_loss at step 182100: 0.068732
2023-03-17 01:44:04,041 INFO     Train negative_sample_loss at step 182100: 0.061538
2023-03-17 01:44:04,041 INFO     Train loss at step 182100: 0.065135
2023-03-17 01:44:23,428 INFO     Train positive_sample_loss at step 182200: 0.069156
2023-03-17 01:44:23,429 INFO     Train negative_sample_loss at step 182200: 0.062100
2023-03-17 01:44:23,429 INFO     Train loss at step 182200: 0.065628
2023-03-17 01:44:42,821 INFO     Train positive_sample_loss at step 182300: 0.069583
2023-03-17 01:44:42,821 INFO     Train negative_sample_loss at step 182300: 0.061979
2023-03-17 01:44:42,822 INFO     Train loss at step 182300: 0.065781
2023-03-17 01:45:09,126 INFO     Train positive_sample_loss at step 182400: 0.069593
2023-03-17 01:45:09,126 INFO     Train negative_sample_loss at step 182400: 0.061780
2023-03-17 01:45:09,127 INFO     Train loss at step 182400: 0.065686
2023-03-17 01:45:28,511 INFO     Train positive_sample_loss at step 182500: 0.069633
2023-03-17 01:45:28,512 INFO     Train negative_sample_loss at step 182500: 0.061009
2023-03-17 01:45:28,512 INFO     Train loss at step 182500: 0.065321
2023-03-17 01:45:47,906 INFO     Train positive_sample_loss at step 182600: 0.070166
2023-03-17 01:45:47,906 INFO     Train negative_sample_loss at step 182600: 0.061435
2023-03-17 01:45:47,906 INFO     Train loss at step 182600: 0.065801
2023-03-17 01:46:07,299 INFO     Train positive_sample_loss at step 182700: 0.070388
2023-03-17 01:46:07,299 INFO     Train negative_sample_loss at step 182700: 0.061481
2023-03-17 01:46:07,299 INFO     Train loss at step 182700: 0.065934
2023-03-17 01:46:26,699 INFO     Train positive_sample_loss at step 182800: 0.070614
2023-03-17 01:46:26,699 INFO     Train negative_sample_loss at step 182800: 0.061387
2023-03-17 01:46:26,699 INFO     Train loss at step 182800: 0.066001
2023-03-17 01:46:46,100 INFO     Train positive_sample_loss at step 182900: 0.070793
2023-03-17 01:46:46,100 INFO     Train negative_sample_loss at step 182900: 0.061667
2023-03-17 01:46:46,100 INFO     Train loss at step 182900: 0.066230
2023-03-17 01:47:05,497 INFO     Train positive_sample_loss at step 183000: 0.071185
2023-03-17 01:47:05,497 INFO     Train negative_sample_loss at step 183000: 0.062011
2023-03-17 01:47:05,497 INFO     Train loss at step 183000: 0.066598
2023-03-17 01:47:24,896 INFO     Train positive_sample_loss at step 183100: 0.070886
2023-03-17 01:47:24,897 INFO     Train negative_sample_loss at step 183100: 0.061515
2023-03-17 01:47:24,897 INFO     Train loss at step 183100: 0.066201
2023-03-17 01:47:44,306 INFO     Train positive_sample_loss at step 183200: 0.071107
2023-03-17 01:47:44,306 INFO     Train negative_sample_loss at step 183200: 0.061252
2023-03-17 01:47:44,306 INFO     Train loss at step 183200: 0.066179
2023-03-17 01:48:03,702 INFO     Train positive_sample_loss at step 183300: 0.071528
2023-03-17 01:48:03,703 INFO     Train negative_sample_loss at step 183300: 0.062075
2023-03-17 01:48:03,703 INFO     Train loss at step 183300: 0.066802
2023-03-17 01:48:30,146 INFO     Train positive_sample_loss at step 183400: 0.071322
2023-03-17 01:48:30,146 INFO     Train negative_sample_loss at step 183400: 0.061977
2023-03-17 01:48:30,147 INFO     Train loss at step 183400: 0.066649
2023-03-17 01:48:49,564 INFO     Train positive_sample_loss at step 183500: 0.071639
2023-03-17 01:48:49,565 INFO     Train negative_sample_loss at step 183500: 0.061819
2023-03-17 01:48:49,565 INFO     Train loss at step 183500: 0.066729
2023-03-17 01:49:08,964 INFO     Train positive_sample_loss at step 183600: 0.071770
2023-03-17 01:49:08,965 INFO     Train negative_sample_loss at step 183600: 0.062471
2023-03-17 01:49:08,965 INFO     Train loss at step 183600: 0.067121
2023-03-17 01:49:28,380 INFO     Train positive_sample_loss at step 183700: 0.071839
2023-03-17 01:49:28,380 INFO     Train negative_sample_loss at step 183700: 0.061776
2023-03-17 01:49:28,381 INFO     Train loss at step 183700: 0.066807
2023-03-17 01:49:47,785 INFO     Train positive_sample_loss at step 183800: 0.071643
2023-03-17 01:49:47,786 INFO     Train negative_sample_loss at step 183800: 0.061822
2023-03-17 01:49:47,786 INFO     Train loss at step 183800: 0.066732
2023-03-17 01:50:07,200 INFO     Train positive_sample_loss at step 183900: 0.071708
2023-03-17 01:50:07,200 INFO     Train negative_sample_loss at step 183900: 0.061451
2023-03-17 01:50:07,200 INFO     Train loss at step 183900: 0.066580
2023-03-17 01:50:26,604 INFO     Train positive_sample_loss at step 184000: 0.071686
2023-03-17 01:50:26,604 INFO     Train negative_sample_loss at step 184000: 0.061740
2023-03-17 01:50:26,605 INFO     Train loss at step 184000: 0.066713
2023-03-17 01:50:46,005 INFO     Train positive_sample_loss at step 184100: 0.071894
2023-03-17 01:50:46,005 INFO     Train negative_sample_loss at step 184100: 0.063150
2023-03-17 01:50:46,005 INFO     Train loss at step 184100: 0.067522
2023-03-17 01:51:05,406 INFO     Train positive_sample_loss at step 184200: 0.072042
2023-03-17 01:51:05,407 INFO     Train negative_sample_loss at step 184200: 0.061891
2023-03-17 01:51:05,407 INFO     Train loss at step 184200: 0.066967
2023-03-17 01:51:24,823 INFO     Train positive_sample_loss at step 184300: 0.071885
2023-03-17 01:51:24,824 INFO     Train negative_sample_loss at step 184300: 0.062432
2023-03-17 01:51:24,824 INFO     Train loss at step 184300: 0.067159
2023-03-17 01:51:44,230 INFO     Train positive_sample_loss at step 184400: 0.071754
2023-03-17 01:51:44,230 INFO     Train negative_sample_loss at step 184400: 0.062233
2023-03-17 01:51:44,230 INFO     Train loss at step 184400: 0.066994
2023-03-17 01:52:13,261 INFO     Train positive_sample_loss at step 184500: 0.071867
2023-03-17 01:52:13,261 INFO     Train negative_sample_loss at step 184500: 0.061697
2023-03-17 01:52:13,262 INFO     Train loss at step 184500: 0.066782
2023-03-17 01:52:32,660 INFO     Train positive_sample_loss at step 184600: 0.071537
2023-03-17 01:52:32,661 INFO     Train negative_sample_loss at step 184600: 0.062796
2023-03-17 01:52:32,661 INFO     Train loss at step 184600: 0.067167
2023-03-17 01:52:52,060 INFO     Train positive_sample_loss at step 184700: 0.071732
2023-03-17 01:52:52,061 INFO     Train negative_sample_loss at step 184700: 0.062547
2023-03-17 01:52:52,061 INFO     Train loss at step 184700: 0.067139
2023-03-17 01:53:11,458 INFO     Train positive_sample_loss at step 184800: 0.071902
2023-03-17 01:53:11,459 INFO     Train negative_sample_loss at step 184800: 0.062539
2023-03-17 01:53:11,459 INFO     Train loss at step 184800: 0.067221
2023-03-17 01:53:37,140 INFO     Train positive_sample_loss at step 184900: 0.071464
2023-03-17 01:53:37,141 INFO     Train negative_sample_loss at step 184900: 0.062626
2023-03-17 01:53:37,141 INFO     Train loss at step 184900: 0.067045
2023-03-17 01:53:56,530 INFO     Train positive_sample_loss at step 185000: 0.062183
2023-03-17 01:53:56,531 INFO     Train negative_sample_loss at step 185000: 0.061824
2023-03-17 01:53:56,531 INFO     Train loss at step 185000: 0.062004
2023-03-17 01:54:15,902 INFO     Train positive_sample_loss at step 185100: 0.062898
2023-03-17 01:54:15,903 INFO     Train negative_sample_loss at step 185100: 0.061495
2023-03-17 01:54:15,903 INFO     Train loss at step 185100: 0.062196
2023-03-17 01:54:40,993 INFO     Train positive_sample_loss at step 185200: 0.063857
2023-03-17 01:54:40,993 INFO     Train negative_sample_loss at step 185200: 0.061779
2023-03-17 01:54:40,994 INFO     Train loss at step 185200: 0.062818
2023-03-17 01:55:06,084 INFO     Train positive_sample_loss at step 185300: 0.064505
2023-03-17 01:55:06,085 INFO     Train negative_sample_loss at step 185300: 0.060987
2023-03-17 01:55:06,085 INFO     Train loss at step 185300: 0.062746
2023-03-17 01:55:25,467 INFO     Train positive_sample_loss at step 185400: 0.065090
2023-03-17 01:55:25,468 INFO     Train negative_sample_loss at step 185400: 0.060522
2023-03-17 01:55:25,468 INFO     Train loss at step 185400: 0.062806
2023-03-17 01:55:44,856 INFO     Train positive_sample_loss at step 185500: 0.065865
2023-03-17 01:55:44,856 INFO     Train negative_sample_loss at step 185500: 0.060947
2023-03-17 01:55:44,856 INFO     Train loss at step 185500: 0.063406
2023-03-17 01:56:04,249 INFO     Train positive_sample_loss at step 185600: 0.066231
2023-03-17 01:56:04,249 INFO     Train negative_sample_loss at step 185600: 0.060290
2023-03-17 01:56:04,249 INFO     Train loss at step 185600: 0.063260
2023-03-17 01:56:23,654 INFO     Train positive_sample_loss at step 185700: 0.066471
2023-03-17 01:56:23,654 INFO     Train negative_sample_loss at step 185700: 0.060089
2023-03-17 01:56:23,654 INFO     Train loss at step 185700: 0.063280
2023-03-17 01:56:43,049 INFO     Train positive_sample_loss at step 185800: 0.067315
2023-03-17 01:56:43,050 INFO     Train negative_sample_loss at step 185800: 0.060700
2023-03-17 01:56:43,050 INFO     Train loss at step 185800: 0.064007
2023-03-17 01:57:02,449 INFO     Train positive_sample_loss at step 185900: 0.067336
2023-03-17 01:57:02,450 INFO     Train negative_sample_loss at step 185900: 0.060840
2023-03-17 01:57:02,450 INFO     Train loss at step 185900: 0.064088
2023-03-17 01:57:21,842 INFO     Train positive_sample_loss at step 186000: 0.067792
2023-03-17 01:57:21,842 INFO     Train negative_sample_loss at step 186000: 0.060748
2023-03-17 01:57:21,842 INFO     Train loss at step 186000: 0.064270
2023-03-17 01:57:41,242 INFO     Train positive_sample_loss at step 186100: 0.067966
2023-03-17 01:57:41,243 INFO     Train negative_sample_loss at step 186100: 0.060812
2023-03-17 01:57:41,243 INFO     Train loss at step 186100: 0.064389
2023-03-17 01:58:00,637 INFO     Train positive_sample_loss at step 186200: 0.068388
2023-03-17 01:58:00,638 INFO     Train negative_sample_loss at step 186200: 0.060155
2023-03-17 01:58:00,638 INFO     Train loss at step 186200: 0.064272
2023-03-17 01:58:27,056 INFO     Train positive_sample_loss at step 186300: 0.068770
2023-03-17 01:58:27,057 INFO     Train negative_sample_loss at step 186300: 0.060692
2023-03-17 01:58:27,057 INFO     Train loss at step 186300: 0.064731
2023-03-17 01:58:46,452 INFO     Train positive_sample_loss at step 186400: 0.068871
2023-03-17 01:58:46,452 INFO     Train negative_sample_loss at step 186400: 0.060510
2023-03-17 01:58:46,452 INFO     Train loss at step 186400: 0.064691
2023-03-17 01:59:05,861 INFO     Train positive_sample_loss at step 186500: 0.069401
2023-03-17 01:59:05,862 INFO     Train negative_sample_loss at step 186500: 0.060211
2023-03-17 01:59:05,862 INFO     Train loss at step 186500: 0.064806
2023-03-17 01:59:25,269 INFO     Train positive_sample_loss at step 186600: 0.069553
2023-03-17 01:59:25,270 INFO     Train negative_sample_loss at step 186600: 0.061153
2023-03-17 01:59:25,270 INFO     Train loss at step 186600: 0.065353
2023-03-17 01:59:44,691 INFO     Train positive_sample_loss at step 186700: 0.069336
2023-03-17 01:59:44,692 INFO     Train negative_sample_loss at step 186700: 0.060818
2023-03-17 01:59:44,692 INFO     Train loss at step 186700: 0.065077
2023-03-17 02:00:04,112 INFO     Train positive_sample_loss at step 186800: 0.069937
2023-03-17 02:00:04,113 INFO     Train negative_sample_loss at step 186800: 0.060742
2023-03-17 02:00:04,113 INFO     Train loss at step 186800: 0.065339
2023-03-17 02:00:23,521 INFO     Train positive_sample_loss at step 186900: 0.070114
2023-03-17 02:00:23,522 INFO     Train negative_sample_loss at step 186900: 0.061389
2023-03-17 02:00:23,522 INFO     Train loss at step 186900: 0.065752
2023-03-17 02:00:42,912 INFO     Train positive_sample_loss at step 187000: 0.070176
2023-03-17 02:00:42,912 INFO     Train negative_sample_loss at step 187000: 0.060832
2023-03-17 02:00:42,912 INFO     Train loss at step 187000: 0.065504
2023-03-17 02:01:02,315 INFO     Train positive_sample_loss at step 187100: 0.070184
2023-03-17 02:01:02,316 INFO     Train negative_sample_loss at step 187100: 0.060994
2023-03-17 02:01:02,316 INFO     Train loss at step 187100: 0.065589
2023-03-17 02:01:21,712 INFO     Train positive_sample_loss at step 187200: 0.070290
2023-03-17 02:01:21,712 INFO     Train negative_sample_loss at step 187200: 0.061100
2023-03-17 02:01:21,712 INFO     Train loss at step 187200: 0.065695
2023-03-17 02:01:41,121 INFO     Train positive_sample_loss at step 187300: 0.070425
2023-03-17 02:01:41,121 INFO     Train negative_sample_loss at step 187300: 0.060671
2023-03-17 02:01:41,121 INFO     Train loss at step 187300: 0.065548
2023-03-17 02:02:07,500 INFO     Train positive_sample_loss at step 187400: 0.070539
2023-03-17 02:02:07,500 INFO     Train negative_sample_loss at step 187400: 0.061314
2023-03-17 02:02:07,500 INFO     Train loss at step 187400: 0.065926
2023-03-17 02:02:26,903 INFO     Train positive_sample_loss at step 187500: 0.070663
2023-03-17 02:02:26,903 INFO     Train negative_sample_loss at step 187500: 0.061213
2023-03-17 02:02:26,903 INFO     Train loss at step 187500: 0.065938
2023-03-17 02:02:46,318 INFO     Train positive_sample_loss at step 187600: 0.070763
2023-03-17 02:02:46,319 INFO     Train negative_sample_loss at step 187600: 0.061410
2023-03-17 02:02:46,319 INFO     Train loss at step 187600: 0.066086
2023-03-17 02:03:05,728 INFO     Train positive_sample_loss at step 187700: 0.070652
2023-03-17 02:03:05,728 INFO     Train negative_sample_loss at step 187700: 0.061179
2023-03-17 02:03:05,728 INFO     Train loss at step 187700: 0.065915
2023-03-17 02:03:25,146 INFO     Train positive_sample_loss at step 187800: 0.070919
2023-03-17 02:03:25,146 INFO     Train negative_sample_loss at step 187800: 0.061573
2023-03-17 02:03:25,147 INFO     Train loss at step 187800: 0.066246
2023-03-17 02:03:44,550 INFO     Train positive_sample_loss at step 187900: 0.071077
2023-03-17 02:03:44,550 INFO     Train negative_sample_loss at step 187900: 0.061564
2023-03-17 02:03:44,550 INFO     Train loss at step 187900: 0.066321
2023-03-17 02:04:03,950 INFO     Train positive_sample_loss at step 188000: 0.071119
2023-03-17 02:04:03,950 INFO     Train negative_sample_loss at step 188000: 0.061783
2023-03-17 02:04:03,950 INFO     Train loss at step 188000: 0.066451
2023-03-17 02:04:23,358 INFO     Train positive_sample_loss at step 188100: 0.071107
2023-03-17 02:04:23,358 INFO     Train negative_sample_loss at step 188100: 0.061321
2023-03-17 02:04:23,358 INFO     Train loss at step 188100: 0.066214
2023-03-17 02:04:42,771 INFO     Train positive_sample_loss at step 188200: 0.070877
2023-03-17 02:04:42,772 INFO     Train negative_sample_loss at step 188200: 0.061016
2023-03-17 02:04:42,772 INFO     Train loss at step 188200: 0.065946
2023-03-17 02:05:02,187 INFO     Train positive_sample_loss at step 188300: 0.070687
2023-03-17 02:05:02,187 INFO     Train negative_sample_loss at step 188300: 0.061284
2023-03-17 02:05:02,188 INFO     Train loss at step 188300: 0.065986
2023-03-17 02:05:28,622 INFO     Train positive_sample_loss at step 188400: 0.070941
2023-03-17 02:05:28,623 INFO     Train negative_sample_loss at step 188400: 0.060992
2023-03-17 02:05:28,623 INFO     Train loss at step 188400: 0.065967
2023-03-17 02:05:48,025 INFO     Train positive_sample_loss at step 188500: 0.070998
2023-03-17 02:05:48,025 INFO     Train negative_sample_loss at step 188500: 0.061514
2023-03-17 02:05:48,026 INFO     Train loss at step 188500: 0.066256
2023-03-17 02:06:07,429 INFO     Train positive_sample_loss at step 188600: 0.071159
2023-03-17 02:06:07,430 INFO     Train negative_sample_loss at step 188600: 0.061557
2023-03-17 02:06:07,430 INFO     Train loss at step 188600: 0.066358
2023-03-17 02:06:26,830 INFO     Train positive_sample_loss at step 188700: 0.070925
2023-03-17 02:06:26,831 INFO     Train negative_sample_loss at step 188700: 0.061638
2023-03-17 02:06:26,831 INFO     Train loss at step 188700: 0.066281
2023-03-17 02:06:46,236 INFO     Train positive_sample_loss at step 188800: 0.070818
2023-03-17 02:06:46,236 INFO     Train negative_sample_loss at step 188800: 0.061384
2023-03-17 02:06:46,237 INFO     Train loss at step 188800: 0.066101
2023-03-17 02:07:11,848 INFO     Train positive_sample_loss at step 188900: 0.064249
2023-03-17 02:07:11,849 INFO     Train negative_sample_loss at step 188900: 0.061542
2023-03-17 02:07:11,849 INFO     Train loss at step 188900: 0.062896
2023-03-17 02:07:31,226 INFO     Train positive_sample_loss at step 189000: 0.062062
2023-03-17 02:07:31,227 INFO     Train negative_sample_loss at step 189000: 0.060883
2023-03-17 02:07:31,227 INFO     Train loss at step 189000: 0.061473
2023-03-17 02:07:50,584 INFO     Train positive_sample_loss at step 189100: 0.062827
2023-03-17 02:07:50,584 INFO     Train negative_sample_loss at step 189100: 0.060624
2023-03-17 02:07:50,584 INFO     Train loss at step 189100: 0.061725
2023-03-17 02:08:17,992 INFO     Train positive_sample_loss at step 189200: 0.063530
2023-03-17 02:08:17,993 INFO     Train negative_sample_loss at step 189200: 0.060238
2023-03-17 02:08:17,993 INFO     Train loss at step 189200: 0.061884
2023-03-17 02:08:37,376 INFO     Train positive_sample_loss at step 189300: 0.064124
2023-03-17 02:08:37,376 INFO     Train negative_sample_loss at step 189300: 0.060027
2023-03-17 02:08:37,376 INFO     Train loss at step 189300: 0.062075
2023-03-17 02:08:56,764 INFO     Train positive_sample_loss at step 189400: 0.064898
2023-03-17 02:08:56,765 INFO     Train negative_sample_loss at step 189400: 0.059932
2023-03-17 02:08:56,765 INFO     Train loss at step 189400: 0.062415
2023-03-17 02:09:16,157 INFO     Train positive_sample_loss at step 189500: 0.065184
2023-03-17 02:09:16,157 INFO     Train negative_sample_loss at step 189500: 0.059987
2023-03-17 02:09:16,158 INFO     Train loss at step 189500: 0.062586
2023-03-17 02:09:35,546 INFO     Train positive_sample_loss at step 189600: 0.065848
2023-03-17 02:09:35,547 INFO     Train negative_sample_loss at step 189600: 0.059992
2023-03-17 02:09:35,547 INFO     Train loss at step 189600: 0.062920
2023-03-17 02:09:54,938 INFO     Train positive_sample_loss at step 189700: 0.066029
2023-03-17 02:09:54,939 INFO     Train negative_sample_loss at step 189700: 0.059856
2023-03-17 02:09:54,939 INFO     Train loss at step 189700: 0.062942
2023-03-17 02:10:14,328 INFO     Train positive_sample_loss at step 189800: 0.066807
2023-03-17 02:10:14,328 INFO     Train negative_sample_loss at step 189800: 0.060168
2023-03-17 02:10:14,328 INFO     Train loss at step 189800: 0.063487
2023-03-17 02:10:33,723 INFO     Train positive_sample_loss at step 189900: 0.066880
2023-03-17 02:10:33,724 INFO     Train negative_sample_loss at step 189900: 0.059936
2023-03-17 02:10:33,724 INFO     Train loss at step 189900: 0.063408
2023-03-17 02:10:54,943 INFO     Train positive_sample_loss at step 190000: 0.067320
2023-03-17 02:10:54,944 INFO     Train negative_sample_loss at step 190000: 0.060066
2023-03-17 02:10:54,944 INFO     Train loss at step 190000: 0.063693
2023-03-17 02:10:54,944 INFO     Evaluating on Valid Dataset...
2023-03-17 02:10:56,002 INFO     Evaluating the model... (0/26842)
2023-03-17 02:10:57,730 INFO     Evaluating the model... (1000/26842)
2023-03-17 02:10:58,984 INFO     Evaluating the model... (2000/26842)
2023-03-17 02:11:00,230 INFO     Evaluating the model... (3000/26842)
2023-03-17 02:11:01,477 INFO     Evaluating the model... (4000/26842)
2023-03-17 02:11:02,722 INFO     Evaluating the model... (5000/26842)
2023-03-17 02:11:03,983 INFO     Evaluating the model... (6000/26842)
2023-03-17 02:11:05,235 INFO     Evaluating the model... (7000/26842)
2023-03-17 02:11:06,482 INFO     Evaluating the model... (8000/26842)
2023-03-17 02:11:07,732 INFO     Evaluating the model... (9000/26842)
2023-03-17 02:11:08,985 INFO     Evaluating the model... (10000/26842)
2023-03-17 02:11:10,239 INFO     Evaluating the model... (11000/26842)
2023-03-17 02:11:11,492 INFO     Evaluating the model... (12000/26842)
2023-03-17 02:11:12,753 INFO     Evaluating the model... (13000/26842)
2023-03-17 02:11:15,008 INFO     Evaluating the model... (14000/26842)
2023-03-17 02:11:16,501 INFO     Evaluating the model... (15000/26842)
2023-03-17 02:11:17,984 INFO     Evaluating the model... (16000/26842)
2023-03-17 02:11:19,468 INFO     Evaluating the model... (17000/26842)
2023-03-17 02:11:20,949 INFO     Evaluating the model... (18000/26842)
2023-03-17 02:11:22,438 INFO     Evaluating the model... (19000/26842)
2023-03-17 02:11:23,927 INFO     Evaluating the model... (20000/26842)
2023-03-17 02:11:25,421 INFO     Evaluating the model... (21000/26842)
2023-03-17 02:11:26,936 INFO     Evaluating the model... (22000/26842)
2023-03-17 02:11:28,416 INFO     Evaluating the model... (23000/26842)
2023-03-17 02:11:29,900 INFO     Evaluating the model... (24000/26842)
2023-03-17 02:11:31,391 INFO     Evaluating the model... (25000/26842)
2023-03-17 02:11:32,878 INFO     Evaluating the model... (26000/26842)
2023-03-17 02:11:34,460 INFO     Valid hits@1_list at step 190000: 0.650946
2023-03-17 02:11:34,461 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 02:11:34,461 INFO     Valid hits@3_list at step 190000: 0.742998
2023-03-17 02:11:34,461 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 02:11:34,461 INFO     Valid hits@10_list at step 190000: 0.833171
2023-03-17 02:11:34,461 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 02:11:34,461 INFO     Valid mrr_list at step 190000: 0.713316
2023-03-17 02:11:53,856 INFO     Train positive_sample_loss at step 190100: 0.067759
2023-03-17 02:11:53,856 INFO     Train negative_sample_loss at step 190100: 0.060368
2023-03-17 02:11:53,856 INFO     Train loss at step 190100: 0.064063
2023-03-17 02:12:19,861 INFO     Train positive_sample_loss at step 190200: 0.067970
2023-03-17 02:12:19,862 INFO     Train negative_sample_loss at step 190200: 0.060318
2023-03-17 02:12:19,862 INFO     Train loss at step 190200: 0.064144
2023-03-17 02:12:39,530 INFO     Train positive_sample_loss at step 190300: 0.068144
2023-03-17 02:12:39,530 INFO     Train negative_sample_loss at step 190300: 0.059649
2023-03-17 02:12:39,530 INFO     Train loss at step 190300: 0.063896
2023-03-17 02:12:58,932 INFO     Train positive_sample_loss at step 190400: 0.068358
2023-03-17 02:12:58,933 INFO     Train negative_sample_loss at step 190400: 0.059976
2023-03-17 02:12:58,933 INFO     Train loss at step 190400: 0.064167
2023-03-17 02:13:18,347 INFO     Train positive_sample_loss at step 190500: 0.068534
2023-03-17 02:13:18,348 INFO     Train negative_sample_loss at step 190500: 0.060220
2023-03-17 02:13:18,348 INFO     Train loss at step 190500: 0.064377
2023-03-17 02:13:37,758 INFO     Train positive_sample_loss at step 190600: 0.068718
2023-03-17 02:13:37,759 INFO     Train negative_sample_loss at step 190600: 0.059742
2023-03-17 02:13:37,759 INFO     Train loss at step 190600: 0.064230
2023-03-17 02:13:57,161 INFO     Train positive_sample_loss at step 190700: 0.069016
2023-03-17 02:13:57,162 INFO     Train negative_sample_loss at step 190700: 0.060226
2023-03-17 02:13:57,162 INFO     Train loss at step 190700: 0.064621
2023-03-17 02:14:16,561 INFO     Train positive_sample_loss at step 190800: 0.069251
2023-03-17 02:14:16,562 INFO     Train negative_sample_loss at step 190800: 0.059980
2023-03-17 02:14:16,562 INFO     Train loss at step 190800: 0.064615
2023-03-17 02:14:35,965 INFO     Train positive_sample_loss at step 190900: 0.069343
2023-03-17 02:14:35,966 INFO     Train negative_sample_loss at step 190900: 0.059679
2023-03-17 02:14:35,966 INFO     Train loss at step 190900: 0.064511
2023-03-17 02:14:55,367 INFO     Train positive_sample_loss at step 191000: 0.069630
2023-03-17 02:14:55,367 INFO     Train negative_sample_loss at step 191000: 0.059512
2023-03-17 02:14:55,367 INFO     Train loss at step 191000: 0.064571
2023-03-17 02:15:14,768 INFO     Train positive_sample_loss at step 191100: 0.069642
2023-03-17 02:15:14,768 INFO     Train negative_sample_loss at step 191100: 0.060595
2023-03-17 02:15:14,768 INFO     Train loss at step 191100: 0.065118
2023-03-17 02:15:34,171 INFO     Train positive_sample_loss at step 191200: 0.069911
2023-03-17 02:15:34,171 INFO     Train negative_sample_loss at step 191200: 0.060763
2023-03-17 02:15:34,172 INFO     Train loss at step 191200: 0.065337
2023-03-17 02:16:00,532 INFO     Train positive_sample_loss at step 191300: 0.069841
2023-03-17 02:16:00,533 INFO     Train negative_sample_loss at step 191300: 0.060411
2023-03-17 02:16:00,533 INFO     Train loss at step 191300: 0.065126
2023-03-17 02:16:19,922 INFO     Train positive_sample_loss at step 191400: 0.069894
2023-03-17 02:16:19,922 INFO     Train negative_sample_loss at step 191400: 0.060034
2023-03-17 02:16:19,922 INFO     Train loss at step 191400: 0.064964
2023-03-17 02:16:39,317 INFO     Train positive_sample_loss at step 191500: 0.069940
2023-03-17 02:16:39,317 INFO     Train negative_sample_loss at step 191500: 0.060077
2023-03-17 02:16:39,317 INFO     Train loss at step 191500: 0.065008
2023-03-17 02:16:58,702 INFO     Train positive_sample_loss at step 191600: 0.070062
2023-03-17 02:16:58,702 INFO     Train negative_sample_loss at step 191600: 0.059810
2023-03-17 02:16:58,702 INFO     Train loss at step 191600: 0.064936
2023-03-17 02:17:18,098 INFO     Train positive_sample_loss at step 191700: 0.070345
2023-03-17 02:17:18,098 INFO     Train negative_sample_loss at step 191700: 0.060643
2023-03-17 02:17:18,098 INFO     Train loss at step 191700: 0.065494
2023-03-17 02:17:37,504 INFO     Train positive_sample_loss at step 191800: 0.070073
2023-03-17 02:17:37,504 INFO     Train negative_sample_loss at step 191800: 0.060590
2023-03-17 02:17:37,504 INFO     Train loss at step 191800: 0.065331
2023-03-17 02:17:56,909 INFO     Train positive_sample_loss at step 191900: 0.070151
2023-03-17 02:17:56,909 INFO     Train negative_sample_loss at step 191900: 0.060873
2023-03-17 02:17:56,909 INFO     Train loss at step 191900: 0.065512
2023-03-17 02:18:16,329 INFO     Train positive_sample_loss at step 192000: 0.070314
2023-03-17 02:18:16,329 INFO     Train negative_sample_loss at step 192000: 0.060325
2023-03-17 02:18:16,329 INFO     Train loss at step 192000: 0.065320
2023-03-17 02:18:35,729 INFO     Train positive_sample_loss at step 192100: 0.070295
2023-03-17 02:18:35,730 INFO     Train negative_sample_loss at step 192100: 0.060586
2023-03-17 02:18:35,730 INFO     Train loss at step 192100: 0.065440
2023-03-17 02:18:55,145 INFO     Train positive_sample_loss at step 192200: 0.070458
2023-03-17 02:18:55,146 INFO     Train negative_sample_loss at step 192200: 0.060804
2023-03-17 02:18:55,146 INFO     Train loss at step 192200: 0.065631
2023-03-17 02:19:14,549 INFO     Train positive_sample_loss at step 192300: 0.070254
2023-03-17 02:19:14,549 INFO     Train negative_sample_loss at step 192300: 0.060864
2023-03-17 02:19:14,550 INFO     Train loss at step 192300: 0.065559
2023-03-17 02:19:43,390 INFO     Train positive_sample_loss at step 192400: 0.070420
2023-03-17 02:19:43,390 INFO     Train negative_sample_loss at step 192400: 0.060378
2023-03-17 02:19:43,390 INFO     Train loss at step 192400: 0.065399
2023-03-17 02:20:02,791 INFO     Train positive_sample_loss at step 192500: 0.070459
2023-03-17 02:20:02,792 INFO     Train negative_sample_loss at step 192500: 0.060552
2023-03-17 02:20:02,792 INFO     Train loss at step 192500: 0.065506
2023-03-17 02:20:22,197 INFO     Train positive_sample_loss at step 192600: 0.070145
2023-03-17 02:20:22,197 INFO     Train negative_sample_loss at step 192600: 0.060717
2023-03-17 02:20:22,197 INFO     Train loss at step 192600: 0.065431
2023-03-17 02:20:41,593 INFO     Train positive_sample_loss at step 192700: 0.070375
2023-03-17 02:20:41,594 INFO     Train negative_sample_loss at step 192700: 0.061670
2023-03-17 02:20:41,594 INFO     Train loss at step 192700: 0.066023
funtion time use:39335ms
2023-03-17 02:21:07,284 INFO     Train positive_sample_loss at step 192800: 0.066853
2023-03-17 02:21:07,284 INFO     Train negative_sample_loss at step 192800: 0.060590
2023-03-17 02:21:07,285 INFO     Train loss at step 192800: 0.063722
2023-03-17 02:21:26,650 INFO     Train positive_sample_loss at step 192900: 0.061286
2023-03-17 02:21:26,650 INFO     Train negative_sample_loss at step 192900: 0.060426
2023-03-17 02:21:26,650 INFO     Train loss at step 192900: 0.060856
2023-03-17 02:21:46,004 INFO     Train positive_sample_loss at step 193000: 0.062110
2023-03-17 02:21:46,005 INFO     Train negative_sample_loss at step 193000: 0.060045
2023-03-17 02:21:46,005 INFO     Train loss at step 193000: 0.061078
2023-03-17 02:22:13,282 INFO     Train positive_sample_loss at step 193100: 0.062686
2023-03-17 02:22:13,282 INFO     Train negative_sample_loss at step 193100: 0.059538
2023-03-17 02:22:13,282 INFO     Train loss at step 193100: 0.061112
2023-03-17 02:22:32,677 INFO     Train positive_sample_loss at step 193200: 0.063471
2023-03-17 02:22:32,677 INFO     Train negative_sample_loss at step 193200: 0.059369
2023-03-17 02:22:32,678 INFO     Train loss at step 193200: 0.061420
2023-03-17 02:22:52,067 INFO     Train positive_sample_loss at step 193300: 0.063901
2023-03-17 02:22:52,067 INFO     Train negative_sample_loss at step 193300: 0.058968
2023-03-17 02:22:52,067 INFO     Train loss at step 193300: 0.061435
2023-03-17 02:23:11,462 INFO     Train positive_sample_loss at step 193400: 0.064494
2023-03-17 02:23:11,463 INFO     Train negative_sample_loss at step 193400: 0.058937
2023-03-17 02:23:11,463 INFO     Train loss at step 193400: 0.061715
2023-03-17 02:23:30,863 INFO     Train positive_sample_loss at step 193500: 0.064875
2023-03-17 02:23:30,864 INFO     Train negative_sample_loss at step 193500: 0.059323
2023-03-17 02:23:30,864 INFO     Train loss at step 193500: 0.062099
2023-03-17 02:23:50,256 INFO     Train positive_sample_loss at step 193600: 0.065518
2023-03-17 02:23:50,256 INFO     Train negative_sample_loss at step 193600: 0.059089
2023-03-17 02:23:50,256 INFO     Train loss at step 193600: 0.062303
2023-03-17 02:24:09,658 INFO     Train positive_sample_loss at step 193700: 0.065750
2023-03-17 02:24:09,658 INFO     Train negative_sample_loss at step 193700: 0.058731
2023-03-17 02:24:09,658 INFO     Train loss at step 193700: 0.062241
2023-03-17 02:24:29,071 INFO     Train positive_sample_loss at step 193800: 0.066006
2023-03-17 02:24:29,072 INFO     Train negative_sample_loss at step 193800: 0.059681
2023-03-17 02:24:29,072 INFO     Train loss at step 193800: 0.062844
2023-03-17 02:24:48,494 INFO     Train positive_sample_loss at step 193900: 0.066727
2023-03-17 02:24:48,494 INFO     Train negative_sample_loss at step 193900: 0.058959
2023-03-17 02:24:48,495 INFO     Train loss at step 193900: 0.062843
2023-03-17 02:25:07,904 INFO     Train positive_sample_loss at step 194000: 0.066826
2023-03-17 02:25:07,904 INFO     Train negative_sample_loss at step 194000: 0.058657
2023-03-17 02:25:07,904 INFO     Train loss at step 194000: 0.062741
2023-03-17 02:25:27,329 INFO     Train positive_sample_loss at step 194100: 0.067266
2023-03-17 02:25:27,329 INFO     Train negative_sample_loss at step 194100: 0.059719
2023-03-17 02:25:27,329 INFO     Train loss at step 194100: 0.063493
2023-03-17 02:25:53,702 INFO     Train positive_sample_loss at step 194200: 0.067513
2023-03-17 02:25:53,702 INFO     Train negative_sample_loss at step 194200: 0.059237
2023-03-17 02:25:53,702 INFO     Train loss at step 194200: 0.063375
2023-03-17 02:26:13,106 INFO     Train positive_sample_loss at step 194300: 0.067792
2023-03-17 02:26:13,107 INFO     Train negative_sample_loss at step 194300: 0.059633
2023-03-17 02:26:13,107 INFO     Train loss at step 194300: 0.063713
2023-03-17 02:26:32,514 INFO     Train positive_sample_loss at step 194400: 0.067805
2023-03-17 02:26:32,515 INFO     Train negative_sample_loss at step 194400: 0.059140
2023-03-17 02:26:32,515 INFO     Train loss at step 194400: 0.063473
2023-03-17 02:26:51,916 INFO     Train positive_sample_loss at step 194500: 0.068099
2023-03-17 02:26:51,916 INFO     Train negative_sample_loss at step 194500: 0.059159
2023-03-17 02:26:51,916 INFO     Train loss at step 194500: 0.063629
2023-03-17 02:27:11,308 INFO     Train positive_sample_loss at step 194600: 0.068558
2023-03-17 02:27:11,308 INFO     Train negative_sample_loss at step 194600: 0.059222
2023-03-17 02:27:11,308 INFO     Train loss at step 194600: 0.063890
2023-03-17 02:27:30,702 INFO     Train positive_sample_loss at step 194700: 0.068466
2023-03-17 02:27:30,703 INFO     Train negative_sample_loss at step 194700: 0.059049
2023-03-17 02:27:30,703 INFO     Train loss at step 194700: 0.063758
2023-03-17 02:27:50,105 INFO     Train positive_sample_loss at step 194800: 0.068662
2023-03-17 02:27:50,106 INFO     Train negative_sample_loss at step 194800: 0.058981
2023-03-17 02:27:50,106 INFO     Train loss at step 194800: 0.063821
2023-03-17 02:28:09,509 INFO     Train positive_sample_loss at step 194900: 0.068975
2023-03-17 02:28:09,510 INFO     Train negative_sample_loss at step 194900: 0.059384
2023-03-17 02:28:09,510 INFO     Train loss at step 194900: 0.064180
2023-03-17 02:28:28,903 INFO     Train positive_sample_loss at step 195000: 0.069013
2023-03-17 02:28:28,904 INFO     Train negative_sample_loss at step 195000: 0.060059
2023-03-17 02:28:28,904 INFO     Train loss at step 195000: 0.064536
2023-03-17 02:28:48,294 INFO     Train positive_sample_loss at step 195100: 0.068896
2023-03-17 02:28:48,295 INFO     Train negative_sample_loss at step 195100: 0.059596
2023-03-17 02:28:48,295 INFO     Train loss at step 195100: 0.064246
2023-03-17 02:29:14,651 INFO     Train positive_sample_loss at step 195200: 0.069226
2023-03-17 02:29:14,652 INFO     Train negative_sample_loss at step 195200: 0.059758
2023-03-17 02:29:14,652 INFO     Train loss at step 195200: 0.064492
2023-03-17 02:29:34,058 INFO     Train positive_sample_loss at step 195300: 0.069463
2023-03-17 02:29:34,059 INFO     Train negative_sample_loss at step 195300: 0.059614
2023-03-17 02:29:34,059 INFO     Train loss at step 195300: 0.064538
2023-03-17 02:29:53,456 INFO     Train positive_sample_loss at step 195400: 0.069296
2023-03-17 02:29:53,457 INFO     Train negative_sample_loss at step 195400: 0.059429
2023-03-17 02:29:53,457 INFO     Train loss at step 195400: 0.064363
2023-03-17 02:30:12,852 INFO     Train positive_sample_loss at step 195500: 0.069380
2023-03-17 02:30:12,852 INFO     Train negative_sample_loss at step 195500: 0.060189
2023-03-17 02:30:12,852 INFO     Train loss at step 195500: 0.064785
2023-03-17 02:30:32,237 INFO     Train positive_sample_loss at step 195600: 0.069587
2023-03-17 02:30:32,237 INFO     Train negative_sample_loss at step 195600: 0.060278
2023-03-17 02:30:32,238 INFO     Train loss at step 195600: 0.064932
2023-03-17 02:30:51,636 INFO     Train positive_sample_loss at step 195700: 0.069534
2023-03-17 02:30:51,637 INFO     Train negative_sample_loss at step 195700: 0.059996
2023-03-17 02:30:51,637 INFO     Train loss at step 195700: 0.064765
2023-03-17 02:31:11,045 INFO     Train positive_sample_loss at step 195800: 0.069632
2023-03-17 02:31:11,045 INFO     Train negative_sample_loss at step 195800: 0.059890
2023-03-17 02:31:11,045 INFO     Train loss at step 195800: 0.064761
2023-03-17 02:31:30,467 INFO     Train positive_sample_loss at step 195900: 0.069568
2023-03-17 02:31:30,468 INFO     Train negative_sample_loss at step 195900: 0.060620
2023-03-17 02:31:30,468 INFO     Train loss at step 195900: 0.065094
2023-03-17 02:31:49,883 INFO     Train positive_sample_loss at step 196000: 0.069634
2023-03-17 02:31:49,883 INFO     Train negative_sample_loss at step 196000: 0.059716
2023-03-17 02:31:49,884 INFO     Train loss at step 196000: 0.064675
2023-03-17 02:32:09,302 INFO     Train positive_sample_loss at step 196100: 0.069581
2023-03-17 02:32:09,303 INFO     Train negative_sample_loss at step 196100: 0.060218
2023-03-17 02:32:09,303 INFO     Train loss at step 196100: 0.064899
2023-03-17 02:32:28,712 INFO     Train positive_sample_loss at step 196200: 0.069837
2023-03-17 02:32:28,713 INFO     Train negative_sample_loss at step 196200: 0.060409
2023-03-17 02:32:28,713 INFO     Train loss at step 196200: 0.065123
2023-03-17 02:32:57,595 INFO     Train positive_sample_loss at step 196300: 0.069829
2023-03-17 02:32:57,595 INFO     Train negative_sample_loss at step 196300: 0.059682
2023-03-17 02:32:57,595 INFO     Train loss at step 196300: 0.064755
2023-03-17 02:33:17,024 INFO     Train positive_sample_loss at step 196400: 0.069782
2023-03-17 02:33:17,024 INFO     Train negative_sample_loss at step 196400: 0.059699
2023-03-17 02:33:17,024 INFO     Train loss at step 196400: 0.064740
2023-03-17 02:33:36,444 INFO     Train positive_sample_loss at step 196500: 0.069870
2023-03-17 02:33:36,444 INFO     Train negative_sample_loss at step 196500: 0.060076
2023-03-17 02:33:36,444 INFO     Train loss at step 196500: 0.064973
2023-03-17 02:33:55,855 INFO     Train positive_sample_loss at step 196600: 0.069703
2023-03-17 02:33:55,855 INFO     Train negative_sample_loss at step 196600: 0.060341
2023-03-17 02:33:55,855 INFO     Train loss at step 196600: 0.065022
2023-03-17 02:34:19,186 INFO     Train positive_sample_loss at step 196700: 0.069615
2023-03-17 02:34:19,187 INFO     Train negative_sample_loss at step 196700: 0.060140
2023-03-17 02:34:19,187 INFO     Train loss at step 196700: 0.064877
2023-03-17 02:34:40,730 INFO     Train positive_sample_loss at step 196800: 0.060466
2023-03-17 02:34:40,731 INFO     Train negative_sample_loss at step 196800: 0.059876
2023-03-17 02:34:40,731 INFO     Train loss at step 196800: 0.060171
2023-03-17 02:35:00,096 INFO     Train positive_sample_loss at step 196900: 0.061380
2023-03-17 02:35:00,097 INFO     Train negative_sample_loss at step 196900: 0.059392
2023-03-17 02:35:00,097 INFO     Train loss at step 196900: 0.060386
2023-03-17 02:35:27,172 INFO     Train positive_sample_loss at step 197000: 0.061896
2023-03-17 02:35:27,173 INFO     Train negative_sample_loss at step 197000: 0.059486
2023-03-17 02:35:27,173 INFO     Train loss at step 197000: 0.060691
2023-03-17 02:35:46,532 INFO     Train positive_sample_loss at step 197100: 0.062786
2023-03-17 02:35:46,533 INFO     Train negative_sample_loss at step 197100: 0.059450
2023-03-17 02:35:46,533 INFO     Train loss at step 197100: 0.061118
2023-03-17 02:36:05,906 INFO     Train positive_sample_loss at step 197200: 0.063541
2023-03-17 02:36:05,907 INFO     Train negative_sample_loss at step 197200: 0.059149
2023-03-17 02:36:05,907 INFO     Train loss at step 197200: 0.061345
2023-03-17 02:36:25,290 INFO     Train positive_sample_loss at step 197300: 0.064064
2023-03-17 02:36:25,290 INFO     Train negative_sample_loss at step 197300: 0.059274
2023-03-17 02:36:25,291 INFO     Train loss at step 197300: 0.061669
2023-03-17 02:36:44,680 INFO     Train positive_sample_loss at step 197400: 0.064377
2023-03-17 02:36:44,680 INFO     Train negative_sample_loss at step 197400: 0.058855
2023-03-17 02:36:44,680 INFO     Train loss at step 197400: 0.061616
2023-03-17 02:37:04,076 INFO     Train positive_sample_loss at step 197500: 0.064799
2023-03-17 02:37:04,076 INFO     Train negative_sample_loss at step 197500: 0.058471
2023-03-17 02:37:04,076 INFO     Train loss at step 197500: 0.061635
2023-03-17 02:37:23,479 INFO     Train positive_sample_loss at step 197600: 0.064985
2023-03-17 02:37:23,479 INFO     Train negative_sample_loss at step 197600: 0.058204
2023-03-17 02:37:23,480 INFO     Train loss at step 197600: 0.061594
2023-03-17 02:37:42,868 INFO     Train positive_sample_loss at step 197700: 0.065696
2023-03-17 02:37:42,869 INFO     Train negative_sample_loss at step 197700: 0.058154
2023-03-17 02:37:42,869 INFO     Train loss at step 197700: 0.061925
2023-03-17 02:38:02,280 INFO     Train positive_sample_loss at step 197800: 0.065943
2023-03-17 02:38:02,281 INFO     Train negative_sample_loss at step 197800: 0.058999
2023-03-17 02:38:02,281 INFO     Train loss at step 197800: 0.062471
2023-03-17 02:38:21,679 INFO     Train positive_sample_loss at step 197900: 0.066431
2023-03-17 02:38:21,680 INFO     Train negative_sample_loss at step 197900: 0.058965
2023-03-17 02:38:21,680 INFO     Train loss at step 197900: 0.062698
2023-03-17 02:38:41,081 INFO     Train positive_sample_loss at step 198000: 0.066465
2023-03-17 02:38:41,081 INFO     Train negative_sample_loss at step 198000: 0.058401
2023-03-17 02:38:41,081 INFO     Train loss at step 198000: 0.062433
2023-03-17 02:39:07,633 INFO     Train positive_sample_loss at step 198100: 0.066735
2023-03-17 02:39:07,633 INFO     Train negative_sample_loss at step 198100: 0.058434
2023-03-17 02:39:07,633 INFO     Train loss at step 198100: 0.062584
2023-03-17 02:39:27,017 INFO     Train positive_sample_loss at step 198200: 0.067161
2023-03-17 02:39:27,018 INFO     Train negative_sample_loss at step 198200: 0.058848
2023-03-17 02:39:27,018 INFO     Train loss at step 198200: 0.063005
2023-03-17 02:39:46,413 INFO     Train positive_sample_loss at step 198300: 0.067389
2023-03-17 02:39:46,414 INFO     Train negative_sample_loss at step 198300: 0.058489
2023-03-17 02:39:46,414 INFO     Train loss at step 198300: 0.062939
2023-03-17 02:40:05,813 INFO     Train positive_sample_loss at step 198400: 0.067788
2023-03-17 02:40:05,814 INFO     Train negative_sample_loss at step 198400: 0.058729
2023-03-17 02:40:05,814 INFO     Train loss at step 198400: 0.063258
2023-03-17 02:40:25,213 INFO     Train positive_sample_loss at step 198500: 0.067847
2023-03-17 02:40:25,214 INFO     Train negative_sample_loss at step 198500: 0.059061
2023-03-17 02:40:25,214 INFO     Train loss at step 198500: 0.063454
2023-03-17 02:40:44,611 INFO     Train positive_sample_loss at step 198600: 0.067926
2023-03-17 02:40:44,611 INFO     Train negative_sample_loss at step 198600: 0.059075
2023-03-17 02:40:44,611 INFO     Train loss at step 198600: 0.063500
2023-03-17 02:41:04,003 INFO     Train positive_sample_loss at step 198700: 0.068272
2023-03-17 02:41:04,004 INFO     Train negative_sample_loss at step 198700: 0.058542
2023-03-17 02:41:04,004 INFO     Train loss at step 198700: 0.063407
2023-03-17 02:41:23,407 INFO     Train positive_sample_loss at step 198800: 0.068221
2023-03-17 02:41:23,407 INFO     Train negative_sample_loss at step 198800: 0.059502
2023-03-17 02:41:23,407 INFO     Train loss at step 198800: 0.063861
2023-03-17 02:41:42,809 INFO     Train positive_sample_loss at step 198900: 0.068461
2023-03-17 02:41:42,809 INFO     Train negative_sample_loss at step 198900: 0.059528
2023-03-17 02:41:42,810 INFO     Train loss at step 198900: 0.063994
2023-03-17 02:42:02,223 INFO     Train positive_sample_loss at step 199000: 0.068431
2023-03-17 02:42:02,223 INFO     Train negative_sample_loss at step 199000: 0.058574
2023-03-17 02:42:02,223 INFO     Train loss at step 199000: 0.063503
2023-03-17 02:42:28,246 INFO     Train positive_sample_loss at step 199100: 0.068726
2023-03-17 02:42:28,247 INFO     Train negative_sample_loss at step 199100: 0.058983
2023-03-17 02:42:28,247 INFO     Train loss at step 199100: 0.063854
2023-03-17 02:42:48,074 INFO     Train positive_sample_loss at step 199200: 0.068512
2023-03-17 02:42:48,074 INFO     Train negative_sample_loss at step 199200: 0.058985
2023-03-17 02:42:48,075 INFO     Train loss at step 199200: 0.063748
2023-03-17 02:43:07,477 INFO     Train positive_sample_loss at step 199300: 0.068822
2023-03-17 02:43:07,477 INFO     Train negative_sample_loss at step 199300: 0.059183
2023-03-17 02:43:07,477 INFO     Train loss at step 199300: 0.064003
2023-03-17 02:43:26,874 INFO     Train positive_sample_loss at step 199400: 0.068891
2023-03-17 02:43:26,875 INFO     Train negative_sample_loss at step 199400: 0.058899
2023-03-17 02:43:26,875 INFO     Train loss at step 199400: 0.063895
2023-03-17 02:43:46,281 INFO     Train positive_sample_loss at step 199500: 0.068657
2023-03-17 02:43:46,282 INFO     Train negative_sample_loss at step 199500: 0.059228
2023-03-17 02:43:46,282 INFO     Train loss at step 199500: 0.063943
2023-03-17 02:44:05,682 INFO     Train positive_sample_loss at step 199600: 0.068978
2023-03-17 02:44:05,683 INFO     Train negative_sample_loss at step 199600: 0.059149
2023-03-17 02:44:05,683 INFO     Train loss at step 199600: 0.064063
2023-03-17 02:44:25,093 INFO     Train positive_sample_loss at step 199700: 0.069090
2023-03-17 02:44:25,093 INFO     Train negative_sample_loss at step 199700: 0.059359
2023-03-17 02:44:25,094 INFO     Train loss at step 199700: 0.064225
2023-03-17 02:44:44,491 INFO     Train positive_sample_loss at step 199800: 0.069230
2023-03-17 02:44:44,492 INFO     Train negative_sample_loss at step 199800: 0.059543
2023-03-17 02:44:44,492 INFO     Train loss at step 199800: 0.064387
2023-03-17 02:45:03,890 INFO     Train positive_sample_loss at step 199900: 0.069249
2023-03-17 02:45:03,890 INFO     Train negative_sample_loss at step 199900: 0.059070
2023-03-17 02:45:03,890 INFO     Train loss at step 199900: 0.064160
2023-03-17 02:45:25,098 INFO     Train positive_sample_loss at step 200000: 0.068969
2023-03-17 02:45:25,098 INFO     Train negative_sample_loss at step 200000: 0.059599
2023-03-17 02:45:25,098 INFO     Train loss at step 200000: 0.064284
2023-03-17 02:45:25,098 INFO     Evaluating on Valid Dataset...
2023-03-17 02:45:26,357 INFO     Evaluating the model... (0/26842)
2023-03-17 02:45:27,623 INFO     Evaluating the model... (1000/26842)
2023-03-17 02:45:28,996 INFO     Evaluating the model... (2000/26842)
2023-03-17 02:45:30,236 INFO     Evaluating the model... (3000/26842)
2023-03-17 02:45:31,481 INFO     Evaluating the model... (4000/26842)
2023-03-17 02:45:32,725 INFO     Evaluating the model... (5000/26842)
2023-03-17 02:45:33,972 INFO     Evaluating the model... (6000/26842)
2023-03-17 02:45:35,215 INFO     Evaluating the model... (7000/26842)
2023-03-17 02:45:36,458 INFO     Evaluating the model... (8000/26842)
2023-03-17 02:45:37,704 INFO     Evaluating the model... (9000/26842)
2023-03-17 02:45:38,949 INFO     Evaluating the model... (10000/26842)
2023-03-17 02:45:40,198 INFO     Evaluating the model... (11000/26842)
2023-03-17 02:45:41,436 INFO     Evaluating the model... (12000/26842)
2023-03-17 02:45:42,680 INFO     Evaluating the model... (13000/26842)
2023-03-17 02:45:44,949 INFO     Evaluating the model... (14000/26842)
2023-03-17 02:45:46,444 INFO     Evaluating the model... (15000/26842)
2023-03-17 02:45:47,923 INFO     Evaluating the model... (16000/26842)
2023-03-17 02:45:49,400 INFO     Evaluating the model... (17000/26842)
2023-03-17 02:45:50,880 INFO     Evaluating the model... (18000/26842)
2023-03-17 02:45:52,359 INFO     Evaluating the model... (19000/26842)
2023-03-17 02:45:53,839 INFO     Evaluating the model... (20000/26842)
2023-03-17 02:45:55,316 INFO     Evaluating the model... (21000/26842)
2023-03-17 02:45:56,801 INFO     Evaluating the model... (22000/26842)
2023-03-17 02:45:58,295 INFO     Evaluating the model... (23000/26842)
2023-03-17 02:45:59,791 INFO     Evaluating the model... (24000/26842)
2023-03-17 02:46:01,283 INFO     Evaluating the model... (25000/26842)
2023-03-17 02:46:02,778 INFO     Evaluating the model... (26000/26842)
2023-03-17 02:46:04,358 INFO     Valid hits@1_list at step 200000: 0.653342
2023-03-17 02:46:04,358 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 02:46:04,358 INFO     Valid hits@3_list at step 200000: 0.744867
2023-03-17 02:46:04,358 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 02:46:04,358 INFO     Valid hits@10_list at step 200000: 0.835069
2023-03-17 02:46:04,358 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 02:46:04,358 INFO     Valid mrr_list at step 200000: 0.715319
2023-03-17 02:46:23,763 INFO     Train positive_sample_loss at step 200100: 0.069024
2023-03-17 02:46:23,763 INFO     Train negative_sample_loss at step 200100: 0.059829
2023-03-17 02:46:23,763 INFO     Train loss at step 200100: 0.064426
2023-03-17 02:46:50,190 INFO     Train positive_sample_loss at step 200200: 0.069442
2023-03-17 02:46:50,191 INFO     Train negative_sample_loss at step 200200: 0.059710
2023-03-17 02:46:50,191 INFO     Train loss at step 200200: 0.064576
2023-03-17 02:47:09,595 INFO     Train positive_sample_loss at step 200300: 0.069296
2023-03-17 02:47:09,595 INFO     Train negative_sample_loss at step 200300: 0.059851
2023-03-17 02:47:09,596 INFO     Train loss at step 200300: 0.064573
2023-03-17 02:47:28,986 INFO     Train positive_sample_loss at step 200400: 0.069147
2023-03-17 02:47:28,986 INFO     Train negative_sample_loss at step 200400: 0.059474
2023-03-17 02:47:28,986 INFO     Train loss at step 200400: 0.064311
2023-03-17 02:47:48,389 INFO     Train positive_sample_loss at step 200500: 0.068804
2023-03-17 02:47:48,390 INFO     Train negative_sample_loss at step 200500: 0.060102
2023-03-17 02:47:48,390 INFO     Train loss at step 200500: 0.064453
2023-03-17 02:48:07,794 INFO     Train positive_sample_loss at step 200600: 0.069213
2023-03-17 02:48:07,794 INFO     Train negative_sample_loss at step 200600: 0.059952
2023-03-17 02:48:07,794 INFO     Train loss at step 200600: 0.064583
funtion time use:39082ms
2023-03-17 02:48:33,338 INFO     Train positive_sample_loss at step 200700: 0.062851
2023-03-17 02:48:33,339 INFO     Train negative_sample_loss at step 200700: 0.059178
2023-03-17 02:48:33,339 INFO     Train loss at step 200700: 0.061014
2023-03-17 02:48:52,689 INFO     Train positive_sample_loss at step 200800: 0.060483
2023-03-17 02:48:52,689 INFO     Train negative_sample_loss at step 200800: 0.058852
2023-03-17 02:48:52,689 INFO     Train loss at step 200800: 0.059668
2023-03-17 02:49:19,949 INFO     Train positive_sample_loss at step 200900: 0.061415
2023-03-17 02:49:19,949 INFO     Train negative_sample_loss at step 200900: 0.058570
2023-03-17 02:49:19,949 INFO     Train loss at step 200900: 0.059992
2023-03-17 02:49:39,348 INFO     Train positive_sample_loss at step 201000: 0.062115
2023-03-17 02:49:39,348 INFO     Train negative_sample_loss at step 201000: 0.058572
2023-03-17 02:49:39,349 INFO     Train loss at step 201000: 0.060343
2023-03-17 02:49:58,757 INFO     Train positive_sample_loss at step 201100: 0.062779
2023-03-17 02:49:58,757 INFO     Train negative_sample_loss at step 201100: 0.058735
2023-03-17 02:49:58,757 INFO     Train loss at step 201100: 0.060757
2023-03-17 02:50:18,162 INFO     Train positive_sample_loss at step 201200: 0.063172
2023-03-17 02:50:18,163 INFO     Train negative_sample_loss at step 201200: 0.057865
2023-03-17 02:50:18,163 INFO     Train loss at step 201200: 0.060518
2023-03-17 02:50:37,568 INFO     Train positive_sample_loss at step 201300: 0.063871
2023-03-17 02:50:37,569 INFO     Train negative_sample_loss at step 201300: 0.058715
2023-03-17 02:50:37,569 INFO     Train loss at step 201300: 0.061293
2023-03-17 02:50:56,987 INFO     Train positive_sample_loss at step 201400: 0.064240
2023-03-17 02:50:56,987 INFO     Train negative_sample_loss at step 201400: 0.057878
2023-03-17 02:50:56,987 INFO     Train loss at step 201400: 0.061059
2023-03-17 02:51:16,401 INFO     Train positive_sample_loss at step 201500: 0.064705
2023-03-17 02:51:16,401 INFO     Train negative_sample_loss at step 201500: 0.058386
2023-03-17 02:51:16,401 INFO     Train loss at step 201500: 0.061545
2023-03-17 02:51:35,801 INFO     Train positive_sample_loss at step 201600: 0.065045
2023-03-17 02:51:35,802 INFO     Train negative_sample_loss at step 201600: 0.058141
2023-03-17 02:51:35,802 INFO     Train loss at step 201600: 0.061593
2023-03-17 02:51:55,207 INFO     Train positive_sample_loss at step 201700: 0.065377
2023-03-17 02:51:55,208 INFO     Train negative_sample_loss at step 201700: 0.057824
2023-03-17 02:51:55,208 INFO     Train loss at step 201700: 0.061600
2023-03-17 02:52:14,596 INFO     Train positive_sample_loss at step 201800: 0.065712
2023-03-17 02:52:14,597 INFO     Train negative_sample_loss at step 201800: 0.057727
2023-03-17 02:52:14,597 INFO     Train loss at step 201800: 0.061720
2023-03-17 02:52:33,988 INFO     Train positive_sample_loss at step 201900: 0.066013
2023-03-17 02:52:33,988 INFO     Train negative_sample_loss at step 201900: 0.058237
2023-03-17 02:52:33,988 INFO     Train loss at step 201900: 0.062125
2023-03-17 02:53:00,404 INFO     Train positive_sample_loss at step 202000: 0.066366
2023-03-17 02:53:00,404 INFO     Train negative_sample_loss at step 202000: 0.058507
2023-03-17 02:53:00,405 INFO     Train loss at step 202000: 0.062436
2023-03-17 02:53:19,802 INFO     Train positive_sample_loss at step 202100: 0.066672
2023-03-17 02:53:19,802 INFO     Train negative_sample_loss at step 202100: 0.059052
2023-03-17 02:53:19,802 INFO     Train loss at step 202100: 0.062862
2023-03-17 02:53:39,203 INFO     Train positive_sample_loss at step 202200: 0.066926
2023-03-17 02:53:39,203 INFO     Train negative_sample_loss at step 202200: 0.058365
2023-03-17 02:53:39,203 INFO     Train loss at step 202200: 0.062646
2023-03-17 02:53:58,594 INFO     Train positive_sample_loss at step 202300: 0.067110
2023-03-17 02:53:58,594 INFO     Train negative_sample_loss at step 202300: 0.058325
2023-03-17 02:53:58,594 INFO     Train loss at step 202300: 0.062718
2023-03-17 02:54:17,987 INFO     Train positive_sample_loss at step 202400: 0.067303
2023-03-17 02:54:17,988 INFO     Train negative_sample_loss at step 202400: 0.058574
2023-03-17 02:54:17,988 INFO     Train loss at step 202400: 0.062938
2023-03-17 02:54:37,393 INFO     Train positive_sample_loss at step 202500: 0.067630
2023-03-17 02:54:37,393 INFO     Train negative_sample_loss at step 202500: 0.058775
2023-03-17 02:54:37,393 INFO     Train loss at step 202500: 0.063203
2023-03-17 02:54:56,792 INFO     Train positive_sample_loss at step 202600: 0.067626
2023-03-17 02:54:56,792 INFO     Train negative_sample_loss at step 202600: 0.058630
2023-03-17 02:54:56,792 INFO     Train loss at step 202600: 0.063128
2023-03-17 02:55:16,186 INFO     Train positive_sample_loss at step 202700: 0.067884
2023-03-17 02:55:16,186 INFO     Train negative_sample_loss at step 202700: 0.058087
2023-03-17 02:55:16,187 INFO     Train loss at step 202700: 0.062986
2023-03-17 02:55:35,582 INFO     Train positive_sample_loss at step 202800: 0.067995
2023-03-17 02:55:35,582 INFO     Train negative_sample_loss at step 202800: 0.058443
2023-03-17 02:55:35,582 INFO     Train loss at step 202800: 0.063219
2023-03-17 02:55:54,983 INFO     Train positive_sample_loss at step 202900: 0.067990
2023-03-17 02:55:54,984 INFO     Train negative_sample_loss at step 202900: 0.058660
2023-03-17 02:55:54,984 INFO     Train loss at step 202900: 0.063325
2023-03-17 02:56:14,406 INFO     Train positive_sample_loss at step 203000: 0.068162
2023-03-17 02:56:14,407 INFO     Train negative_sample_loss at step 203000: 0.058892
2023-03-17 02:56:14,408 INFO     Train loss at step 203000: 0.063527
2023-03-17 02:56:40,857 INFO     Train positive_sample_loss at step 203100: 0.068349
2023-03-17 02:56:40,857 INFO     Train negative_sample_loss at step 203100: 0.058599
2023-03-17 02:56:40,857 INFO     Train loss at step 203100: 0.063474
2023-03-17 02:57:00,260 INFO     Train positive_sample_loss at step 203200: 0.068288
2023-03-17 02:57:00,261 INFO     Train negative_sample_loss at step 203200: 0.059236
2023-03-17 02:57:00,261 INFO     Train loss at step 203200: 0.063762
2023-03-17 02:57:19,664 INFO     Train positive_sample_loss at step 203300: 0.068599
2023-03-17 02:57:19,665 INFO     Train negative_sample_loss at step 203300: 0.058860
2023-03-17 02:57:19,665 INFO     Train loss at step 203300: 0.063730
2023-03-17 02:57:39,043 INFO     Train positive_sample_loss at step 203400: 0.068393
2023-03-17 02:57:39,043 INFO     Train negative_sample_loss at step 203400: 0.058581
2023-03-17 02:57:39,044 INFO     Train loss at step 203400: 0.063487
2023-03-17 02:57:58,439 INFO     Train positive_sample_loss at step 203500: 0.068446
2023-03-17 02:57:58,440 INFO     Train negative_sample_loss at step 203500: 0.058682
2023-03-17 02:57:58,440 INFO     Train loss at step 203500: 0.063564
2023-03-17 02:58:17,833 INFO     Train positive_sample_loss at step 203600: 0.068567
2023-03-17 02:58:17,834 INFO     Train negative_sample_loss at step 203600: 0.058793
2023-03-17 02:58:17,834 INFO     Train loss at step 203600: 0.063680
2023-03-17 02:58:37,243 INFO     Train positive_sample_loss at step 203700: 0.068736
2023-03-17 02:58:37,243 INFO     Train negative_sample_loss at step 203700: 0.059215
2023-03-17 02:58:37,243 INFO     Train loss at step 203700: 0.063976
2023-03-17 02:58:56,640 INFO     Train positive_sample_loss at step 203800: 0.068544
2023-03-17 02:58:56,641 INFO     Train negative_sample_loss at step 203800: 0.058681
2023-03-17 02:58:56,641 INFO     Train loss at step 203800: 0.063613
2023-03-17 02:59:16,042 INFO     Train positive_sample_loss at step 203900: 0.068646
2023-03-17 02:59:16,042 INFO     Train negative_sample_loss at step 203900: 0.059712
2023-03-17 02:59:16,042 INFO     Train loss at step 203900: 0.064179
2023-03-17 02:59:35,441 INFO     Train positive_sample_loss at step 204000: 0.068729
2023-03-17 02:59:35,442 INFO     Train negative_sample_loss at step 204000: 0.059344
2023-03-17 02:59:35,442 INFO     Train loss at step 204000: 0.064036
2023-03-17 03:00:01,747 INFO     Train positive_sample_loss at step 204100: 0.068620
2023-03-17 03:00:01,748 INFO     Train negative_sample_loss at step 204100: 0.059601
2023-03-17 03:00:01,748 INFO     Train loss at step 204100: 0.064111
2023-03-17 03:00:21,161 INFO     Train positive_sample_loss at step 204200: 0.068787
2023-03-17 03:00:21,161 INFO     Train negative_sample_loss at step 204200: 0.059203
2023-03-17 03:00:21,161 INFO     Train loss at step 204200: 0.063995
2023-03-17 03:00:40,581 INFO     Train positive_sample_loss at step 204300: 0.068695
2023-03-17 03:00:40,582 INFO     Train negative_sample_loss at step 204300: 0.059528
2023-03-17 03:00:40,582 INFO     Train loss at step 204300: 0.064111
2023-03-17 03:00:59,986 INFO     Train positive_sample_loss at step 204400: 0.068895
2023-03-17 03:00:59,986 INFO     Train negative_sample_loss at step 204400: 0.059643
2023-03-17 03:00:59,987 INFO     Train loss at step 204400: 0.064269
2023-03-17 03:01:19,405 INFO     Train positive_sample_loss at step 204500: 0.068461
2023-03-17 03:01:19,405 INFO     Train negative_sample_loss at step 204500: 0.059931
2023-03-17 03:01:19,405 INFO     Train loss at step 204500: 0.064196
2023-03-17 03:01:44,965 INFO     Train positive_sample_loss at step 204600: 0.065503
2023-03-17 03:01:44,966 INFO     Train negative_sample_loss at step 204600: 0.059359
2023-03-17 03:01:44,966 INFO     Train loss at step 204600: 0.062431
2023-03-17 03:02:04,330 INFO     Train positive_sample_loss at step 204700: 0.059925
2023-03-17 03:02:04,331 INFO     Train negative_sample_loss at step 204700: 0.058325
2023-03-17 03:02:04,331 INFO     Train loss at step 204700: 0.059125
2023-03-17 03:02:23,699 INFO     Train positive_sample_loss at step 204800: 0.060844
2023-03-17 03:02:23,700 INFO     Train negative_sample_loss at step 204800: 0.058149
2023-03-17 03:02:23,700 INFO     Train loss at step 204800: 0.059496
2023-03-17 03:02:51,276 INFO     Train positive_sample_loss at step 204900: 0.061596
2023-03-17 03:02:51,276 INFO     Train negative_sample_loss at step 204900: 0.058305
2023-03-17 03:02:51,276 INFO     Train loss at step 204900: 0.059950
2023-03-17 03:03:10,664 INFO     Train positive_sample_loss at step 205000: 0.062167
2023-03-17 03:03:10,664 INFO     Train negative_sample_loss at step 205000: 0.058337
2023-03-17 03:03:10,664 INFO     Train loss at step 205000: 0.060252
2023-03-17 03:03:30,055 INFO     Train positive_sample_loss at step 205100: 0.062546
2023-03-17 03:03:30,056 INFO     Train negative_sample_loss at step 205100: 0.057991
2023-03-17 03:03:30,056 INFO     Train loss at step 205100: 0.060269
2023-03-17 03:03:49,455 INFO     Train positive_sample_loss at step 205200: 0.063346
2023-03-17 03:03:49,455 INFO     Train negative_sample_loss at step 205200: 0.057685
2023-03-17 03:03:49,455 INFO     Train loss at step 205200: 0.060516
2023-03-17 03:04:08,849 INFO     Train positive_sample_loss at step 205300: 0.063672
2023-03-17 03:04:08,850 INFO     Train negative_sample_loss at step 205300: 0.057960
2023-03-17 03:04:08,850 INFO     Train loss at step 205300: 0.060816
2023-03-17 03:04:28,249 INFO     Train positive_sample_loss at step 205400: 0.064044
2023-03-17 03:04:28,250 INFO     Train negative_sample_loss at step 205400: 0.058249
2023-03-17 03:04:28,250 INFO     Train loss at step 205400: 0.061146
2023-03-17 03:04:47,656 INFO     Train positive_sample_loss at step 205500: 0.064644
2023-03-17 03:04:47,656 INFO     Train negative_sample_loss at step 205500: 0.058130
2023-03-17 03:04:47,656 INFO     Train loss at step 205500: 0.061387
2023-03-17 03:05:07,053 INFO     Train positive_sample_loss at step 205600: 0.064988
2023-03-17 03:05:07,053 INFO     Train negative_sample_loss at step 205600: 0.057803
2023-03-17 03:05:07,053 INFO     Train loss at step 205600: 0.061396
2023-03-17 03:05:26,461 INFO     Train positive_sample_loss at step 205700: 0.064849
2023-03-17 03:05:26,461 INFO     Train negative_sample_loss at step 205700: 0.056876
2023-03-17 03:05:26,461 INFO     Train loss at step 205700: 0.060862
2023-03-17 03:05:45,858 INFO     Train positive_sample_loss at step 205800: 0.065575
2023-03-17 03:05:45,858 INFO     Train negative_sample_loss at step 205800: 0.057585
2023-03-17 03:05:45,859 INFO     Train loss at step 205800: 0.061580
2023-03-17 03:06:12,224 INFO     Train positive_sample_loss at step 205900: 0.066051
2023-03-17 03:06:12,225 INFO     Train negative_sample_loss at step 205900: 0.057225
2023-03-17 03:06:12,225 INFO     Train loss at step 205900: 0.061638
2023-03-17 03:06:31,619 INFO     Train positive_sample_loss at step 206000: 0.066132
2023-03-17 03:06:31,619 INFO     Train negative_sample_loss at step 206000: 0.058522
2023-03-17 03:06:31,619 INFO     Train loss at step 206000: 0.062327
2023-03-17 03:06:51,022 INFO     Train positive_sample_loss at step 206100: 0.066392
2023-03-17 03:06:51,022 INFO     Train negative_sample_loss at step 206100: 0.057682
2023-03-17 03:06:51,022 INFO     Train loss at step 206100: 0.062037
2023-03-17 03:07:10,434 INFO     Train positive_sample_loss at step 206200: 0.066473
2023-03-17 03:07:10,435 INFO     Train negative_sample_loss at step 206200: 0.057700
2023-03-17 03:07:10,435 INFO     Train loss at step 206200: 0.062087
2023-03-17 03:07:29,844 INFO     Train positive_sample_loss at step 206300: 0.066672
2023-03-17 03:07:29,845 INFO     Train negative_sample_loss at step 206300: 0.058034
2023-03-17 03:07:29,845 INFO     Train loss at step 206300: 0.062353
2023-03-17 03:07:49,244 INFO     Train positive_sample_loss at step 206400: 0.066926
2023-03-17 03:07:49,244 INFO     Train negative_sample_loss at step 206400: 0.058555
2023-03-17 03:07:49,244 INFO     Train loss at step 206400: 0.062740
2023-03-17 03:08:08,634 INFO     Train positive_sample_loss at step 206500: 0.067336
2023-03-17 03:08:08,634 INFO     Train negative_sample_loss at step 206500: 0.058623
2023-03-17 03:08:08,634 INFO     Train loss at step 206500: 0.062980
2023-03-17 03:08:28,031 INFO     Train positive_sample_loss at step 206600: 0.067370
2023-03-17 03:08:28,031 INFO     Train negative_sample_loss at step 206600: 0.057935
2023-03-17 03:08:28,031 INFO     Train loss at step 206600: 0.062652
2023-03-17 03:08:47,424 INFO     Train positive_sample_loss at step 206700: 0.067400
2023-03-17 03:08:47,425 INFO     Train negative_sample_loss at step 206700: 0.058123
2023-03-17 03:08:47,425 INFO     Train loss at step 206700: 0.062761
2023-03-17 03:09:06,818 INFO     Train positive_sample_loss at step 206800: 0.067556
2023-03-17 03:09:06,819 INFO     Train negative_sample_loss at step 206800: 0.058341
2023-03-17 03:09:06,819 INFO     Train loss at step 206800: 0.062949
2023-03-17 03:09:26,219 INFO     Train positive_sample_loss at step 206900: 0.067589
2023-03-17 03:09:26,220 INFO     Train negative_sample_loss at step 206900: 0.057779
2023-03-17 03:09:26,220 INFO     Train loss at step 206900: 0.062684
2023-03-17 03:09:52,707 INFO     Train positive_sample_loss at step 207000: 0.067710
2023-03-17 03:09:52,708 INFO     Train negative_sample_loss at step 207000: 0.057948
2023-03-17 03:09:52,708 INFO     Train loss at step 207000: 0.062829
2023-03-17 03:10:12,095 INFO     Train positive_sample_loss at step 207100: 0.068009
2023-03-17 03:10:12,096 INFO     Train negative_sample_loss at step 207100: 0.058627
2023-03-17 03:10:12,096 INFO     Train loss at step 207100: 0.063318
2023-03-17 03:10:31,484 INFO     Train positive_sample_loss at step 207200: 0.068028
2023-03-17 03:10:31,484 INFO     Train negative_sample_loss at step 207200: 0.058681
2023-03-17 03:10:31,484 INFO     Train loss at step 207200: 0.063355
2023-03-17 03:10:50,884 INFO     Train positive_sample_loss at step 207300: 0.067801
2023-03-17 03:10:50,885 INFO     Train negative_sample_loss at step 207300: 0.058090
2023-03-17 03:10:50,885 INFO     Train loss at step 207300: 0.062946
2023-03-17 03:11:10,279 INFO     Train positive_sample_loss at step 207400: 0.068178
2023-03-17 03:11:10,280 INFO     Train negative_sample_loss at step 207400: 0.058292
2023-03-17 03:11:10,280 INFO     Train loss at step 207400: 0.063235
2023-03-17 03:11:29,676 INFO     Train positive_sample_loss at step 207500: 0.068189
2023-03-17 03:11:29,676 INFO     Train negative_sample_loss at step 207500: 0.058438
2023-03-17 03:11:29,677 INFO     Train loss at step 207500: 0.063314
2023-03-17 03:11:49,075 INFO     Train positive_sample_loss at step 207600: 0.068100
2023-03-17 03:11:49,076 INFO     Train negative_sample_loss at step 207600: 0.059266
2023-03-17 03:11:49,076 INFO     Train loss at step 207600: 0.063683
2023-03-17 03:12:08,468 INFO     Train positive_sample_loss at step 207700: 0.067947
2023-03-17 03:12:08,469 INFO     Train negative_sample_loss at step 207700: 0.058685
2023-03-17 03:12:08,469 INFO     Train loss at step 207700: 0.063316
2023-03-17 03:12:27,876 INFO     Train positive_sample_loss at step 207800: 0.068389
2023-03-17 03:12:27,876 INFO     Train negative_sample_loss at step 207800: 0.058318
2023-03-17 03:12:27,876 INFO     Train loss at step 207800: 0.063353
2023-03-17 03:12:47,283 INFO     Train positive_sample_loss at step 207900: 0.068210
2023-03-17 03:12:47,284 INFO     Train negative_sample_loss at step 207900: 0.058933
2023-03-17 03:12:47,284 INFO     Train loss at step 207900: 0.063572
2023-03-17 03:13:06,672 INFO     Train positive_sample_loss at step 208000: 0.068534
2023-03-17 03:13:06,672 INFO     Train negative_sample_loss at step 208000: 0.058287
2023-03-17 03:13:06,672 INFO     Train loss at step 208000: 0.063410
2023-03-17 03:13:32,982 INFO     Train positive_sample_loss at step 208100: 0.068343
2023-03-17 03:13:32,983 INFO     Train negative_sample_loss at step 208100: 0.058923
2023-03-17 03:13:32,983 INFO     Train loss at step 208100: 0.063633
2023-03-17 03:13:52,381 INFO     Train positive_sample_loss at step 208200: 0.068179
2023-03-17 03:13:52,381 INFO     Train negative_sample_loss at step 208200: 0.058550
2023-03-17 03:13:52,382 INFO     Train loss at step 208200: 0.063365
2023-03-17 03:14:11,788 INFO     Train positive_sample_loss at step 208300: 0.068234
2023-03-17 03:14:11,789 INFO     Train negative_sample_loss at step 208300: 0.058497
2023-03-17 03:14:11,789 INFO     Train loss at step 208300: 0.063366
2023-03-17 03:14:31,187 INFO     Train positive_sample_loss at step 208400: 0.068240
2023-03-17 03:14:31,188 INFO     Train negative_sample_loss at step 208400: 0.059017
2023-03-17 03:14:31,188 INFO     Train loss at step 208400: 0.063629
2023-03-17 03:14:52,433 INFO     Train positive_sample_loss at step 208500: 0.068507
2023-03-17 03:14:52,433 INFO     Train negative_sample_loss at step 208500: 0.058927
2023-03-17 03:14:52,433 INFO     Train loss at step 208500: 0.063717
2023-03-17 03:15:15,921 INFO     Train positive_sample_loss at step 208600: 0.059305
2023-03-17 03:15:15,921 INFO     Train negative_sample_loss at step 208600: 0.058715
2023-03-17 03:15:15,922 INFO     Train loss at step 208600: 0.059010
2023-03-17 03:15:35,264 INFO     Train positive_sample_loss at step 208700: 0.060179
2023-03-17 03:15:35,264 INFO     Train negative_sample_loss at step 208700: 0.058543
2023-03-17 03:15:35,264 INFO     Train loss at step 208700: 0.059361
2023-03-17 03:16:02,582 INFO     Train positive_sample_loss at step 208800: 0.060880
2023-03-17 03:16:02,583 INFO     Train negative_sample_loss at step 208800: 0.057574
2023-03-17 03:16:02,583 INFO     Train loss at step 208800: 0.059227
2023-03-17 03:16:21,971 INFO     Train positive_sample_loss at step 208900: 0.061523
2023-03-17 03:16:21,971 INFO     Train negative_sample_loss at step 208900: 0.057272
2023-03-17 03:16:21,971 INFO     Train loss at step 208900: 0.059398
2023-03-17 03:16:41,360 INFO     Train positive_sample_loss at step 209000: 0.062295
2023-03-17 03:16:41,360 INFO     Train negative_sample_loss at step 209000: 0.057761
2023-03-17 03:16:41,360 INFO     Train loss at step 209000: 0.060028
2023-03-17 03:17:00,750 INFO     Train positive_sample_loss at step 209100: 0.062582
2023-03-17 03:17:00,751 INFO     Train negative_sample_loss at step 209100: 0.057295
2023-03-17 03:17:00,751 INFO     Train loss at step 209100: 0.059938
2023-03-17 03:17:20,138 INFO     Train positive_sample_loss at step 209200: 0.063339
2023-03-17 03:17:20,139 INFO     Train negative_sample_loss at step 209200: 0.057740
2023-03-17 03:17:20,139 INFO     Train loss at step 209200: 0.060539
2023-03-17 03:17:39,530 INFO     Train positive_sample_loss at step 209300: 0.063586
2023-03-17 03:17:39,530 INFO     Train negative_sample_loss at step 209300: 0.057939
2023-03-17 03:17:39,530 INFO     Train loss at step 209300: 0.060763
2023-03-17 03:17:58,921 INFO     Train positive_sample_loss at step 209400: 0.064016
2023-03-17 03:17:58,922 INFO     Train negative_sample_loss at step 209400: 0.057410
2023-03-17 03:17:58,922 INFO     Train loss at step 209400: 0.060713
2023-03-17 03:18:18,316 INFO     Train positive_sample_loss at step 209500: 0.064252
2023-03-17 03:18:18,316 INFO     Train negative_sample_loss at step 209500: 0.057464
2023-03-17 03:18:18,316 INFO     Train loss at step 209500: 0.060858
2023-03-17 03:18:37,704 INFO     Train positive_sample_loss at step 209600: 0.064948
2023-03-17 03:18:37,704 INFO     Train negative_sample_loss at step 209600: 0.056951
2023-03-17 03:18:37,704 INFO     Train loss at step 209600: 0.060949
2023-03-17 03:18:57,091 INFO     Train positive_sample_loss at step 209700: 0.064915
2023-03-17 03:18:57,092 INFO     Train negative_sample_loss at step 209700: 0.057290
2023-03-17 03:18:57,092 INFO     Train loss at step 209700: 0.061102
2023-03-17 03:19:16,485 INFO     Train positive_sample_loss at step 209800: 0.065554
2023-03-17 03:19:16,485 INFO     Train negative_sample_loss at step 209800: 0.057430
2023-03-17 03:19:16,486 INFO     Train loss at step 209800: 0.061492
2023-03-17 03:19:42,954 INFO     Train positive_sample_loss at step 209900: 0.065795
2023-03-17 03:19:42,954 INFO     Train negative_sample_loss at step 209900: 0.057234
2023-03-17 03:19:42,954 INFO     Train loss at step 209900: 0.061514
2023-03-17 03:20:04,687 INFO     Train positive_sample_loss at step 210000: 0.065839
2023-03-17 03:20:04,688 INFO     Train negative_sample_loss at step 210000: 0.057512
2023-03-17 03:20:04,688 INFO     Train loss at step 210000: 0.061675
2023-03-17 03:20:04,688 INFO     Evaluating on Valid Dataset...
2023-03-17 03:20:05,647 INFO     Evaluating the model... (0/26842)
2023-03-17 03:20:07,178 INFO     Evaluating the model... (1000/26842)
2023-03-17 03:20:08,409 INFO     Evaluating the model... (2000/26842)
2023-03-17 03:20:09,647 INFO     Evaluating the model... (3000/26842)
2023-03-17 03:20:10,895 INFO     Evaluating the model... (4000/26842)
2023-03-17 03:20:12,130 INFO     Evaluating the model... (5000/26842)
2023-03-17 03:20:13,358 INFO     Evaluating the model... (6000/26842)
2023-03-17 03:20:14,592 INFO     Evaluating the model... (7000/26842)
2023-03-17 03:20:15,826 INFO     Evaluating the model... (8000/26842)
2023-03-17 03:20:17,055 INFO     Evaluating the model... (9000/26842)
2023-03-17 03:20:18,286 INFO     Evaluating the model... (10000/26842)
2023-03-17 03:20:19,519 INFO     Evaluating the model... (11000/26842)
2023-03-17 03:20:20,757 INFO     Evaluating the model... (12000/26842)
2023-03-17 03:20:21,996 INFO     Evaluating the model... (13000/26842)
2023-03-17 03:20:24,267 INFO     Evaluating the model... (14000/26842)
2023-03-17 03:20:25,755 INFO     Evaluating the model... (15000/26842)
2023-03-17 03:20:27,232 INFO     Evaluating the model... (16000/26842)
2023-03-17 03:20:28,713 INFO     Evaluating the model... (17000/26842)
2023-03-17 03:20:30,201 INFO     Evaluating the model... (18000/26842)
2023-03-17 03:20:31,693 INFO     Evaluating the model... (19000/26842)
2023-03-17 03:20:33,185 INFO     Evaluating the model... (20000/26842)
2023-03-17 03:20:34,692 INFO     Evaluating the model... (21000/26842)
2023-03-17 03:20:36,177 INFO     Evaluating the model... (22000/26842)
2023-03-17 03:20:37,663 INFO     Evaluating the model... (23000/26842)
2023-03-17 03:20:39,153 INFO     Evaluating the model... (24000/26842)
2023-03-17 03:20:40,644 INFO     Evaluating the model... (25000/26842)
2023-03-17 03:20:42,137 INFO     Evaluating the model... (26000/26842)
2023-03-17 03:20:43,719 INFO     Valid hits@1_list at step 210000: 0.653244
2023-03-17 03:20:43,719 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 03:20:43,720 INFO     Valid hits@3_list at step 210000: 0.744880
2023-03-17 03:20:43,720 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 03:20:43,720 INFO     Valid hits@10_list at step 210000: 0.834134
2023-03-17 03:20:43,720 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 03:20:43,720 INFO     Valid mrr_list at step 210000: 0.715109
2023-03-17 03:21:03,097 INFO     Train positive_sample_loss at step 210100: 0.066266
2023-03-17 03:21:03,098 INFO     Train negative_sample_loss at step 210100: 0.057454
2023-03-17 03:21:03,098 INFO     Train loss at step 210100: 0.061860
2023-03-17 03:21:22,490 INFO     Train positive_sample_loss at step 210200: 0.066408
2023-03-17 03:21:22,490 INFO     Train negative_sample_loss at step 210200: 0.057044
2023-03-17 03:21:22,490 INFO     Train loss at step 210200: 0.061726
2023-03-17 03:21:41,879 INFO     Train positive_sample_loss at step 210300: 0.066535
2023-03-17 03:21:41,879 INFO     Train negative_sample_loss at step 210300: 0.056927
2023-03-17 03:21:41,879 INFO     Train loss at step 210300: 0.061731
2023-03-17 03:22:01,273 INFO     Train positive_sample_loss at step 210400: 0.066714
2023-03-17 03:22:01,274 INFO     Train negative_sample_loss at step 210400: 0.057782
2023-03-17 03:22:01,274 INFO     Train loss at step 210400: 0.062248
2023-03-17 03:22:20,662 INFO     Train positive_sample_loss at step 210500: 0.066893
2023-03-17 03:22:20,663 INFO     Train negative_sample_loss at step 210500: 0.057498
2023-03-17 03:22:20,663 INFO     Train loss at step 210500: 0.062195
2023-03-17 03:22:40,051 INFO     Train positive_sample_loss at step 210600: 0.067150
2023-03-17 03:22:40,051 INFO     Train negative_sample_loss at step 210600: 0.057677
2023-03-17 03:22:40,051 INFO     Train loss at step 210600: 0.062414
2023-03-17 03:22:59,438 INFO     Train positive_sample_loss at step 210700: 0.067112
2023-03-17 03:22:59,438 INFO     Train negative_sample_loss at step 210700: 0.057551
2023-03-17 03:22:59,438 INFO     Train loss at step 210700: 0.062332
2023-03-17 03:23:18,827 INFO     Train positive_sample_loss at step 210800: 0.067149
2023-03-17 03:23:18,827 INFO     Train negative_sample_loss at step 210800: 0.057429
2023-03-17 03:23:18,827 INFO     Train loss at step 210800: 0.062289
2023-03-17 03:23:45,280 INFO     Train positive_sample_loss at step 210900: 0.067215
2023-03-17 03:23:45,280 INFO     Train negative_sample_loss at step 210900: 0.058277
2023-03-17 03:23:45,281 INFO     Train loss at step 210900: 0.062746
2023-03-17 03:24:04,673 INFO     Train positive_sample_loss at step 211000: 0.067448
2023-03-17 03:24:04,673 INFO     Train negative_sample_loss at step 211000: 0.058104
2023-03-17 03:24:04,673 INFO     Train loss at step 211000: 0.062776
2023-03-17 03:24:24,060 INFO     Train positive_sample_loss at step 211100: 0.067612
2023-03-17 03:24:24,060 INFO     Train negative_sample_loss at step 211100: 0.057767
2023-03-17 03:24:24,060 INFO     Train loss at step 211100: 0.062690
2023-03-17 03:24:43,448 INFO     Train positive_sample_loss at step 211200: 0.067640
2023-03-17 03:24:43,449 INFO     Train negative_sample_loss at step 211200: 0.058217
2023-03-17 03:24:43,449 INFO     Train loss at step 211200: 0.062929
2023-03-17 03:25:02,847 INFO     Train positive_sample_loss at step 211300: 0.067619
2023-03-17 03:25:02,848 INFO     Train negative_sample_loss at step 211300: 0.058505
2023-03-17 03:25:02,848 INFO     Train loss at step 211300: 0.063062
2023-03-17 03:25:22,236 INFO     Train positive_sample_loss at step 211400: 0.067770
2023-03-17 03:25:22,237 INFO     Train negative_sample_loss at step 211400: 0.058434
2023-03-17 03:25:22,237 INFO     Train loss at step 211400: 0.063102
2023-03-17 03:25:41,630 INFO     Train positive_sample_loss at step 211500: 0.067723
2023-03-17 03:25:41,630 INFO     Train negative_sample_loss at step 211500: 0.058047
2023-03-17 03:25:41,630 INFO     Train loss at step 211500: 0.062885
2023-03-17 03:26:01,024 INFO     Train positive_sample_loss at step 211600: 0.067904
2023-03-17 03:26:01,024 INFO     Train negative_sample_loss at step 211600: 0.058274
2023-03-17 03:26:01,024 INFO     Train loss at step 211600: 0.063089
2023-03-17 03:26:20,417 INFO     Train positive_sample_loss at step 211700: 0.067853
2023-03-17 03:26:20,418 INFO     Train negative_sample_loss at step 211700: 0.058817
2023-03-17 03:26:20,418 INFO     Train loss at step 211700: 0.063335
2023-03-17 03:26:39,810 INFO     Train positive_sample_loss at step 211800: 0.067884
2023-03-17 03:26:39,810 INFO     Train negative_sample_loss at step 211800: 0.058006
2023-03-17 03:26:39,811 INFO     Train loss at step 211800: 0.062945
2023-03-17 03:26:59,214 INFO     Train positive_sample_loss at step 211900: 0.068098
2023-03-17 03:26:59,214 INFO     Train negative_sample_loss at step 211900: 0.058939
2023-03-17 03:26:59,214 INFO     Train loss at step 211900: 0.063519
2023-03-17 03:27:25,520 INFO     Train positive_sample_loss at step 212000: 0.068089
2023-03-17 03:27:25,520 INFO     Train negative_sample_loss at step 212000: 0.058248
2023-03-17 03:27:25,520 INFO     Train loss at step 212000: 0.063168
2023-03-17 03:27:44,915 INFO     Train positive_sample_loss at step 212100: 0.067694
2023-03-17 03:27:44,915 INFO     Train negative_sample_loss at step 212100: 0.058215
2023-03-17 03:27:44,915 INFO     Train loss at step 212100: 0.062954
2023-03-17 03:28:04,318 INFO     Train positive_sample_loss at step 212200: 0.067896
2023-03-17 03:28:04,319 INFO     Train negative_sample_loss at step 212200: 0.058665
2023-03-17 03:28:04,319 INFO     Train loss at step 212200: 0.063280
2023-03-17 03:28:23,707 INFO     Train positive_sample_loss at step 212300: 0.067925
2023-03-17 03:28:23,707 INFO     Train negative_sample_loss at step 212300: 0.057984
2023-03-17 03:28:23,708 INFO     Train loss at step 212300: 0.062955
2023-03-17 03:28:43,102 INFO     Train positive_sample_loss at step 212400: 0.067962
2023-03-17 03:28:43,103 INFO     Train negative_sample_loss at step 212400: 0.058852
2023-03-17 03:28:43,103 INFO     Train loss at step 212400: 0.063407
funtion time use:38852ms
2023-03-17 03:29:08,808 INFO     Train positive_sample_loss at step 212500: 0.061999
2023-03-17 03:29:08,808 INFO     Train negative_sample_loss at step 212500: 0.058535
2023-03-17 03:29:08,808 INFO     Train loss at step 212500: 0.060267
2023-03-17 03:29:28,164 INFO     Train positive_sample_loss at step 212600: 0.059679
2023-03-17 03:29:28,164 INFO     Train negative_sample_loss at step 212600: 0.057933
2023-03-17 03:29:28,164 INFO     Train loss at step 212600: 0.058806
2023-03-17 03:29:55,646 INFO     Train positive_sample_loss at step 212700: 0.060502
2023-03-17 03:29:55,647 INFO     Train negative_sample_loss at step 212700: 0.057545
2023-03-17 03:29:55,647 INFO     Train loss at step 212700: 0.059023
2023-03-17 03:30:15,047 INFO     Train positive_sample_loss at step 212800: 0.061017
2023-03-17 03:30:15,048 INFO     Train negative_sample_loss at step 212800: 0.057503
2023-03-17 03:30:15,048 INFO     Train loss at step 212800: 0.059260
2023-03-17 03:30:34,428 INFO     Train positive_sample_loss at step 212900: 0.061542
2023-03-17 03:30:34,428 INFO     Train negative_sample_loss at step 212900: 0.057426
2023-03-17 03:30:34,428 INFO     Train loss at step 212900: 0.059484
2023-03-17 03:30:53,811 INFO     Train positive_sample_loss at step 213000: 0.062265
2023-03-17 03:30:53,811 INFO     Train negative_sample_loss at step 213000: 0.057315
2023-03-17 03:30:53,811 INFO     Train loss at step 213000: 0.059790
2023-03-17 03:31:13,204 INFO     Train positive_sample_loss at step 213100: 0.062728
2023-03-17 03:31:13,205 INFO     Train negative_sample_loss at step 213100: 0.056881
2023-03-17 03:31:13,205 INFO     Train loss at step 213100: 0.059805
2023-03-17 03:31:32,601 INFO     Train positive_sample_loss at step 213200: 0.063164
2023-03-17 03:31:32,601 INFO     Train negative_sample_loss at step 213200: 0.056717
2023-03-17 03:31:32,601 INFO     Train loss at step 213200: 0.059940
2023-03-17 03:31:51,992 INFO     Train positive_sample_loss at step 213300: 0.063525
2023-03-17 03:31:51,993 INFO     Train negative_sample_loss at step 213300: 0.057272
2023-03-17 03:31:51,993 INFO     Train loss at step 213300: 0.060399
2023-03-17 03:32:11,384 INFO     Train positive_sample_loss at step 213400: 0.063837
2023-03-17 03:32:11,385 INFO     Train negative_sample_loss at step 213400: 0.056602
2023-03-17 03:32:11,385 INFO     Train loss at step 213400: 0.060220
2023-03-17 03:32:30,774 INFO     Train positive_sample_loss at step 213500: 0.064524
2023-03-17 03:32:30,774 INFO     Train negative_sample_loss at step 213500: 0.056891
2023-03-17 03:32:30,774 INFO     Train loss at step 213500: 0.060707
2023-03-17 03:32:50,159 INFO     Train positive_sample_loss at step 213600: 0.064577
2023-03-17 03:32:50,159 INFO     Train negative_sample_loss at step 213600: 0.056925
2023-03-17 03:32:50,159 INFO     Train loss at step 213600: 0.060751
2023-03-17 03:33:09,542 INFO     Train positive_sample_loss at step 213700: 0.064974
2023-03-17 03:33:09,542 INFO     Train negative_sample_loss at step 213700: 0.056656
2023-03-17 03:33:09,542 INFO     Train loss at step 213700: 0.060815
2023-03-17 03:33:36,020 INFO     Train positive_sample_loss at step 213800: 0.065215
2023-03-17 03:33:36,020 INFO     Train negative_sample_loss at step 213800: 0.057864
2023-03-17 03:33:36,020 INFO     Train loss at step 213800: 0.061540
2023-03-17 03:33:55,416 INFO     Train positive_sample_loss at step 213900: 0.065364
2023-03-17 03:33:55,417 INFO     Train negative_sample_loss at step 213900: 0.056790
2023-03-17 03:33:55,417 INFO     Train loss at step 213900: 0.061077
2023-03-17 03:34:14,806 INFO     Train positive_sample_loss at step 214000: 0.065611
2023-03-17 03:34:14,806 INFO     Train negative_sample_loss at step 214000: 0.057199
2023-03-17 03:34:14,807 INFO     Train loss at step 214000: 0.061405
2023-03-17 03:34:34,193 INFO     Train positive_sample_loss at step 214100: 0.065927
2023-03-17 03:34:34,194 INFO     Train negative_sample_loss at step 214100: 0.057028
2023-03-17 03:34:34,194 INFO     Train loss at step 214100: 0.061478
2023-03-17 03:34:53,587 INFO     Train positive_sample_loss at step 214200: 0.066206
2023-03-17 03:34:53,587 INFO     Train negative_sample_loss at step 214200: 0.057058
2023-03-17 03:34:53,587 INFO     Train loss at step 214200: 0.061632
2023-03-17 03:35:12,989 INFO     Train positive_sample_loss at step 214300: 0.066624
2023-03-17 03:35:12,989 INFO     Train negative_sample_loss at step 214300: 0.057366
2023-03-17 03:35:12,990 INFO     Train loss at step 214300: 0.061995
2023-03-17 03:35:32,392 INFO     Train positive_sample_loss at step 214400: 0.066675
2023-03-17 03:35:32,393 INFO     Train negative_sample_loss at step 214400: 0.057947
2023-03-17 03:35:32,393 INFO     Train loss at step 214400: 0.062311
2023-03-17 03:35:51,783 INFO     Train positive_sample_loss at step 214500: 0.066650
2023-03-17 03:35:51,784 INFO     Train negative_sample_loss at step 214500: 0.057669
2023-03-17 03:35:51,784 INFO     Train loss at step 214500: 0.062160
2023-03-17 03:36:11,172 INFO     Train positive_sample_loss at step 214600: 0.066940
2023-03-17 03:36:11,173 INFO     Train negative_sample_loss at step 214600: 0.057590
2023-03-17 03:36:11,173 INFO     Train loss at step 214600: 0.062265
2023-03-17 03:36:30,557 INFO     Train positive_sample_loss at step 214700: 0.066859
2023-03-17 03:36:30,558 INFO     Train negative_sample_loss at step 214700: 0.057699
2023-03-17 03:36:30,558 INFO     Train loss at step 214700: 0.062279
2023-03-17 03:36:57,037 INFO     Train positive_sample_loss at step 214800: 0.067169
2023-03-17 03:36:57,038 INFO     Train negative_sample_loss at step 214800: 0.057943
2023-03-17 03:36:57,038 INFO     Train loss at step 214800: 0.062556
2023-03-17 03:37:16,435 INFO     Train positive_sample_loss at step 214900: 0.067212
2023-03-17 03:37:16,435 INFO     Train negative_sample_loss at step 214900: 0.057665
2023-03-17 03:37:16,436 INFO     Train loss at step 214900: 0.062438
2023-03-17 03:37:35,827 INFO     Train positive_sample_loss at step 215000: 0.067073
2023-03-17 03:37:35,827 INFO     Train negative_sample_loss at step 215000: 0.057819
2023-03-17 03:37:35,827 INFO     Train loss at step 215000: 0.062446
2023-03-17 03:37:55,218 INFO     Train positive_sample_loss at step 215100: 0.067184
2023-03-17 03:37:55,218 INFO     Train negative_sample_loss at step 215100: 0.057584
2023-03-17 03:37:55,218 INFO     Train loss at step 215100: 0.062384
2023-03-17 03:38:14,604 INFO     Train positive_sample_loss at step 215200: 0.067239
2023-03-17 03:38:14,605 INFO     Train negative_sample_loss at step 215200: 0.057955
2023-03-17 03:38:14,605 INFO     Train loss at step 215200: 0.062597
2023-03-17 03:38:34,005 INFO     Train positive_sample_loss at step 215300: 0.067319
2023-03-17 03:38:34,005 INFO     Train negative_sample_loss at step 215300: 0.057655
2023-03-17 03:38:34,005 INFO     Train loss at step 215300: 0.062487
2023-03-17 03:38:53,400 INFO     Train positive_sample_loss at step 215400: 0.067443
2023-03-17 03:38:53,401 INFO     Train negative_sample_loss at step 215400: 0.058211
2023-03-17 03:38:53,401 INFO     Train loss at step 215400: 0.062827
2023-03-17 03:39:12,792 INFO     Train positive_sample_loss at step 215500: 0.067601
2023-03-17 03:39:12,792 INFO     Train negative_sample_loss at step 215500: 0.058449
2023-03-17 03:39:12,792 INFO     Train loss at step 215500: 0.063025
2023-03-17 03:39:32,178 INFO     Train positive_sample_loss at step 215600: 0.067742
2023-03-17 03:39:32,178 INFO     Train negative_sample_loss at step 215600: 0.058176
2023-03-17 03:39:32,178 INFO     Train loss at step 215600: 0.062959
2023-03-17 03:39:51,570 INFO     Train positive_sample_loss at step 215700: 0.067639
2023-03-17 03:39:51,571 INFO     Train negative_sample_loss at step 215700: 0.057703
2023-03-17 03:39:51,571 INFO     Train loss at step 215700: 0.062671
2023-03-17 03:40:10,948 INFO     Train positive_sample_loss at step 215800: 0.067515
2023-03-17 03:40:10,949 INFO     Train negative_sample_loss at step 215800: 0.057972
2023-03-17 03:40:10,949 INFO     Train loss at step 215800: 0.062744
2023-03-17 03:40:37,259 INFO     Train positive_sample_loss at step 215900: 0.067532
2023-03-17 03:40:37,260 INFO     Train negative_sample_loss at step 215900: 0.058263
2023-03-17 03:40:37,260 INFO     Train loss at step 215900: 0.062897
2023-03-17 03:40:56,659 INFO     Train positive_sample_loss at step 216000: 0.067737
2023-03-17 03:40:56,660 INFO     Train negative_sample_loss at step 216000: 0.058666
2023-03-17 03:40:56,660 INFO     Train loss at step 216000: 0.063202
2023-03-17 03:41:16,053 INFO     Train positive_sample_loss at step 216100: 0.067607
2023-03-17 03:41:16,053 INFO     Train negative_sample_loss at step 216100: 0.058576
2023-03-17 03:41:16,053 INFO     Train loss at step 216100: 0.063092
2023-03-17 03:41:35,442 INFO     Train positive_sample_loss at step 216200: 0.067805
2023-03-17 03:41:35,443 INFO     Train negative_sample_loss at step 216200: 0.058260
2023-03-17 03:41:35,443 INFO     Train loss at step 216200: 0.063033
2023-03-17 03:41:54,840 INFO     Train positive_sample_loss at step 216300: 0.067787
2023-03-17 03:41:54,840 INFO     Train negative_sample_loss at step 216300: 0.058369
2023-03-17 03:41:54,840 INFO     Train loss at step 216300: 0.063078
2023-03-17 03:42:20,405 INFO     Train positive_sample_loss at step 216400: 0.064732
2023-03-17 03:42:20,406 INFO     Train negative_sample_loss at step 216400: 0.058427
2023-03-17 03:42:20,406 INFO     Train loss at step 216400: 0.061579
2023-03-17 03:42:39,791 INFO     Train positive_sample_loss at step 216500: 0.058947
2023-03-17 03:42:39,792 INFO     Train negative_sample_loss at step 216500: 0.057684
2023-03-17 03:42:39,792 INFO     Train loss at step 216500: 0.058316
2023-03-17 03:43:07,261 INFO     Train positive_sample_loss at step 216600: 0.059694
2023-03-17 03:43:07,261 INFO     Train negative_sample_loss at step 216600: 0.056982
2023-03-17 03:43:07,261 INFO     Train loss at step 216600: 0.058338
2023-03-17 03:43:26,645 INFO     Train positive_sample_loss at step 216700: 0.060732
2023-03-17 03:43:26,646 INFO     Train negative_sample_loss at step 216700: 0.057916
2023-03-17 03:43:26,646 INFO     Train loss at step 216700: 0.059324
2023-03-17 03:43:46,024 INFO     Train positive_sample_loss at step 216800: 0.061301
2023-03-17 03:43:46,024 INFO     Train negative_sample_loss at step 216800: 0.057676
2023-03-17 03:43:46,024 INFO     Train loss at step 216800: 0.059489
2023-03-17 03:44:05,412 INFO     Train positive_sample_loss at step 216900: 0.061720
2023-03-17 03:44:05,413 INFO     Train negative_sample_loss at step 216900: 0.057088
2023-03-17 03:44:05,413 INFO     Train loss at step 216900: 0.059404
2023-03-17 03:44:24,804 INFO     Train positive_sample_loss at step 217000: 0.062248
2023-03-17 03:44:24,804 INFO     Train negative_sample_loss at step 217000: 0.056581
2023-03-17 03:44:24,804 INFO     Train loss at step 217000: 0.059415
2023-03-17 03:44:44,197 INFO     Train positive_sample_loss at step 217100: 0.062857
2023-03-17 03:44:44,197 INFO     Train negative_sample_loss at step 217100: 0.057268
2023-03-17 03:44:44,198 INFO     Train loss at step 217100: 0.060063
2023-03-17 03:45:03,587 INFO     Train positive_sample_loss at step 217200: 0.063049
2023-03-17 03:45:03,588 INFO     Train negative_sample_loss at step 217200: 0.056308
2023-03-17 03:45:03,588 INFO     Train loss at step 217200: 0.059679
2023-03-17 03:45:22,976 INFO     Train positive_sample_loss at step 217300: 0.063426
2023-03-17 03:45:22,976 INFO     Train negative_sample_loss at step 217300: 0.056444
2023-03-17 03:45:22,976 INFO     Train loss at step 217300: 0.059935
2023-03-17 03:45:42,380 INFO     Train positive_sample_loss at step 217400: 0.063836
2023-03-17 03:45:42,381 INFO     Train negative_sample_loss at step 217400: 0.056419
2023-03-17 03:45:42,381 INFO     Train loss at step 217400: 0.060127
2023-03-17 03:46:01,762 INFO     Train positive_sample_loss at step 217500: 0.064338
2023-03-17 03:46:01,763 INFO     Train negative_sample_loss at step 217500: 0.056335
2023-03-17 03:46:01,763 INFO     Train loss at step 217500: 0.060336
2023-03-17 03:46:21,155 INFO     Train positive_sample_loss at step 217600: 0.064566
2023-03-17 03:46:21,155 INFO     Train negative_sample_loss at step 217600: 0.057330
2023-03-17 03:46:21,155 INFO     Train loss at step 217600: 0.060948
2023-03-17 03:46:47,593 INFO     Train positive_sample_loss at step 217700: 0.064926
2023-03-17 03:46:47,594 INFO     Train negative_sample_loss at step 217700: 0.057206
2023-03-17 03:46:47,594 INFO     Train loss at step 217700: 0.061066
2023-03-17 03:47:06,995 INFO     Train positive_sample_loss at step 217800: 0.065249
2023-03-17 03:47:06,996 INFO     Train negative_sample_loss at step 217800: 0.057145
2023-03-17 03:47:06,996 INFO     Train loss at step 217800: 0.061197
2023-03-17 03:47:26,400 INFO     Train positive_sample_loss at step 217900: 0.065401
2023-03-17 03:47:26,401 INFO     Train negative_sample_loss at step 217900: 0.057087
2023-03-17 03:47:26,401 INFO     Train loss at step 217900: 0.061244
2023-03-17 03:47:45,792 INFO     Train positive_sample_loss at step 218000: 0.065592
2023-03-17 03:47:45,792 INFO     Train negative_sample_loss at step 218000: 0.056906
2023-03-17 03:47:45,792 INFO     Train loss at step 218000: 0.061249
2023-03-17 03:48:05,196 INFO     Train positive_sample_loss at step 218100: 0.065706
2023-03-17 03:48:05,196 INFO     Train negative_sample_loss at step 218100: 0.056744
2023-03-17 03:48:05,196 INFO     Train loss at step 218100: 0.061225
2023-03-17 03:48:24,587 INFO     Train positive_sample_loss at step 218200: 0.066066
2023-03-17 03:48:24,587 INFO     Train negative_sample_loss at step 218200: 0.057793
2023-03-17 03:48:24,588 INFO     Train loss at step 218200: 0.061929
2023-03-17 03:48:43,979 INFO     Train positive_sample_loss at step 218300: 0.066281
2023-03-17 03:48:43,980 INFO     Train negative_sample_loss at step 218300: 0.056425
2023-03-17 03:48:43,980 INFO     Train loss at step 218300: 0.061353
2023-03-17 03:49:03,380 INFO     Train positive_sample_loss at step 218400: 0.066403
2023-03-17 03:49:03,380 INFO     Train negative_sample_loss at step 218400: 0.056807
2023-03-17 03:49:03,380 INFO     Train loss at step 218400: 0.061605
2023-03-17 03:49:22,773 INFO     Train positive_sample_loss at step 218500: 0.066426
2023-03-17 03:49:22,773 INFO     Train negative_sample_loss at step 218500: 0.057552
2023-03-17 03:49:22,773 INFO     Train loss at step 218500: 0.061989
2023-03-17 03:49:42,163 INFO     Train positive_sample_loss at step 218600: 0.066575
2023-03-17 03:49:42,163 INFO     Train negative_sample_loss at step 218600: 0.057524
2023-03-17 03:49:42,164 INFO     Train loss at step 218600: 0.062050
2023-03-17 03:50:01,557 INFO     Train positive_sample_loss at step 218700: 0.066848
2023-03-17 03:50:01,558 INFO     Train negative_sample_loss at step 218700: 0.057621
2023-03-17 03:50:01,558 INFO     Train loss at step 218700: 0.062234
2023-03-17 03:50:31,168 INFO     Train positive_sample_loss at step 218800: 0.066896
2023-03-17 03:50:31,169 INFO     Train negative_sample_loss at step 218800: 0.057472
2023-03-17 03:50:31,169 INFO     Train loss at step 218800: 0.062184
2023-03-17 03:50:50,568 INFO     Train positive_sample_loss at step 218900: 0.066996
2023-03-17 03:50:50,568 INFO     Train negative_sample_loss at step 218900: 0.056786
2023-03-17 03:50:50,568 INFO     Train loss at step 218900: 0.061891
2023-03-17 03:51:09,966 INFO     Train positive_sample_loss at step 219000: 0.067171
2023-03-17 03:51:09,966 INFO     Train negative_sample_loss at step 219000: 0.057723
2023-03-17 03:51:09,967 INFO     Train loss at step 219000: 0.062447
2023-03-17 03:51:29,376 INFO     Train positive_sample_loss at step 219100: 0.067026
2023-03-17 03:51:29,376 INFO     Train negative_sample_loss at step 219100: 0.057313
2023-03-17 03:51:29,377 INFO     Train loss at step 219100: 0.062170
2023-03-17 03:51:48,779 INFO     Train positive_sample_loss at step 219200: 0.067127
2023-03-17 03:51:48,780 INFO     Train negative_sample_loss at step 219200: 0.057647
2023-03-17 03:51:48,780 INFO     Train loss at step 219200: 0.062387
2023-03-17 03:52:08,205 INFO     Train positive_sample_loss at step 219300: 0.067120
2023-03-17 03:52:08,206 INFO     Train negative_sample_loss at step 219300: 0.058206
2023-03-17 03:52:08,206 INFO     Train loss at step 219300: 0.062663
2023-03-17 03:52:27,627 INFO     Train positive_sample_loss at step 219400: 0.067181
2023-03-17 03:52:27,628 INFO     Train negative_sample_loss at step 219400: 0.057312
2023-03-17 03:52:27,628 INFO     Train loss at step 219400: 0.062246
2023-03-17 03:52:47,052 INFO     Train positive_sample_loss at step 219500: 0.067079
2023-03-17 03:52:47,053 INFO     Train negative_sample_loss at step 219500: 0.057761
2023-03-17 03:52:47,053 INFO     Train loss at step 219500: 0.062420
2023-03-17 03:53:06,467 INFO     Train positive_sample_loss at step 219600: 0.067298
2023-03-17 03:53:06,467 INFO     Train negative_sample_loss at step 219600: 0.058563
2023-03-17 03:53:06,467 INFO     Train loss at step 219600: 0.062931
2023-03-17 03:53:25,883 INFO     Train positive_sample_loss at step 219700: 0.067151
2023-03-17 03:53:25,884 INFO     Train negative_sample_loss at step 219700: 0.057213
2023-03-17 03:53:25,884 INFO     Train loss at step 219700: 0.062182
2023-03-17 03:53:52,111 INFO     Train positive_sample_loss at step 219800: 0.067478
2023-03-17 03:53:52,111 INFO     Train negative_sample_loss at step 219800: 0.057908
2023-03-17 03:53:52,112 INFO     Train loss at step 219800: 0.062693
2023-03-17 03:54:11,539 INFO     Train positive_sample_loss at step 219900: 0.067435
2023-03-17 03:54:11,540 INFO     Train negative_sample_loss at step 219900: 0.058243
2023-03-17 03:54:11,540 INFO     Train loss at step 219900: 0.062839
2023-03-17 03:54:32,922 INFO     Train positive_sample_loss at step 220000: 0.067545
2023-03-17 03:54:32,922 INFO     Train negative_sample_loss at step 220000: 0.058657
2023-03-17 03:54:32,922 INFO     Train loss at step 220000: 0.063101
2023-03-17 03:54:32,923 INFO     Evaluating on Valid Dataset...
2023-03-17 03:54:33,882 INFO     Evaluating the model... (0/26842)
2023-03-17 03:54:35,548 INFO     Evaluating the model... (1000/26842)
2023-03-17 03:54:36,787 INFO     Evaluating the model... (2000/26842)
2023-03-17 03:54:38,018 INFO     Evaluating the model... (3000/26842)
2023-03-17 03:54:39,265 INFO     Evaluating the model... (4000/26842)
2023-03-17 03:54:40,505 INFO     Evaluating the model... (5000/26842)
2023-03-17 03:54:41,747 INFO     Evaluating the model... (6000/26842)
2023-03-17 03:54:42,989 INFO     Evaluating the model... (7000/26842)
2023-03-17 03:54:44,227 INFO     Evaluating the model... (8000/26842)
2023-03-17 03:54:45,461 INFO     Evaluating the model... (9000/26842)
2023-03-17 03:54:46,703 INFO     Evaluating the model... (10000/26842)
2023-03-17 03:54:47,945 INFO     Evaluating the model... (11000/26842)
2023-03-17 03:54:49,195 INFO     Evaluating the model... (12000/26842)
2023-03-17 03:54:50,438 INFO     Evaluating the model... (13000/26842)
2023-03-17 03:54:52,721 INFO     Evaluating the model... (14000/26842)
2023-03-17 03:54:54,213 INFO     Evaluating the model... (15000/26842)
2023-03-17 03:54:55,696 INFO     Evaluating the model... (16000/26842)
2023-03-17 03:54:57,175 INFO     Evaluating the model... (17000/26842)
2023-03-17 03:54:58,656 INFO     Evaluating the model... (18000/26842)
2023-03-17 03:55:00,135 INFO     Evaluating the model... (19000/26842)
2023-03-17 03:55:01,615 INFO     Evaluating the model... (20000/26842)
2023-03-17 03:55:03,116 INFO     Evaluating the model... (21000/26842)
2023-03-17 03:55:04,588 INFO     Evaluating the model... (22000/26842)
2023-03-17 03:55:06,061 INFO     Evaluating the model... (23000/26842)
2023-03-17 03:55:07,536 INFO     Evaluating the model... (24000/26842)
2023-03-17 03:55:09,004 INFO     Evaluating the model... (25000/26842)
2023-03-17 03:55:10,476 INFO     Evaluating the model... (26000/26842)
2023-03-17 03:55:12,040 INFO     Valid hits@1_list at step 220000: 0.654764
2023-03-17 03:55:12,040 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 03:55:12,040 INFO     Valid hits@3_list at step 220000: 0.745727
2023-03-17 03:55:12,040 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 03:55:12,041 INFO     Valid hits@10_list at step 220000: 0.835118
2023-03-17 03:55:12,041 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 03:55:12,041 INFO     Valid mrr_list at step 220000: 0.716367
2023-03-17 03:55:31,448 INFO     Train positive_sample_loss at step 220100: 0.067279
2023-03-17 03:55:31,449 INFO     Train negative_sample_loss at step 220100: 0.057893
2023-03-17 03:55:31,449 INFO     Train loss at step 220100: 0.062586
2023-03-17 03:55:50,863 INFO     Train positive_sample_loss at step 220200: 0.067428
2023-03-17 03:55:50,864 INFO     Train negative_sample_loss at step 220200: 0.058163
2023-03-17 03:55:50,864 INFO     Train loss at step 220200: 0.062795
2023-03-17 03:56:12,249 INFO     Train positive_sample_loss at step 220300: 0.067402
2023-03-17 03:56:12,250 INFO     Train negative_sample_loss at step 220300: 0.057515
2023-03-17 03:56:12,250 INFO     Train loss at step 220300: 0.062458
funtion time use:38939ms
2023-03-17 03:56:35,589 INFO     Train positive_sample_loss at step 220400: 0.058742
2023-03-17 03:56:35,589 INFO     Train negative_sample_loss at step 220400: 0.057453
2023-03-17 03:56:35,590 INFO     Train loss at step 220400: 0.058097
2023-03-17 03:57:02,869 INFO     Train positive_sample_loss at step 220500: 0.059155
2023-03-17 03:57:02,870 INFO     Train negative_sample_loss at step 220500: 0.056630
2023-03-17 03:57:02,870 INFO     Train loss at step 220500: 0.057893
2023-03-17 03:57:22,256 INFO     Train positive_sample_loss at step 220600: 0.060131
2023-03-17 03:57:22,256 INFO     Train negative_sample_loss at step 220600: 0.057132
2023-03-17 03:57:22,257 INFO     Train loss at step 220600: 0.058631
2023-03-17 03:57:41,656 INFO     Train positive_sample_loss at step 220700: 0.060676
2023-03-17 03:57:41,656 INFO     Train negative_sample_loss at step 220700: 0.057155
2023-03-17 03:57:41,656 INFO     Train loss at step 220700: 0.058916
2023-03-17 03:58:01,060 INFO     Train positive_sample_loss at step 220800: 0.061343
2023-03-17 03:58:01,060 INFO     Train negative_sample_loss at step 220800: 0.056567
2023-03-17 03:58:01,060 INFO     Train loss at step 220800: 0.058955
2023-03-17 03:58:20,461 INFO     Train positive_sample_loss at step 220900: 0.061920
2023-03-17 03:58:20,461 INFO     Train negative_sample_loss at step 220900: 0.057037
2023-03-17 03:58:20,461 INFO     Train loss at step 220900: 0.059478
2023-03-17 03:58:39,870 INFO     Train positive_sample_loss at step 221000: 0.062306
2023-03-17 03:58:39,870 INFO     Train negative_sample_loss at step 221000: 0.057028
2023-03-17 03:58:39,870 INFO     Train loss at step 221000: 0.059667
2023-03-17 03:58:59,272 INFO     Train positive_sample_loss at step 221100: 0.062890
2023-03-17 03:58:59,272 INFO     Train negative_sample_loss at step 221100: 0.056441
2023-03-17 03:58:59,272 INFO     Train loss at step 221100: 0.059666
2023-03-17 03:59:18,673 INFO     Train positive_sample_loss at step 221200: 0.063287
2023-03-17 03:59:18,673 INFO     Train negative_sample_loss at step 221200: 0.056719
2023-03-17 03:59:18,673 INFO     Train loss at step 221200: 0.060003
2023-03-17 03:59:38,073 INFO     Train positive_sample_loss at step 221300: 0.063500
2023-03-17 03:59:38,073 INFO     Train negative_sample_loss at step 221300: 0.056319
2023-03-17 03:59:38,073 INFO     Train loss at step 221300: 0.059909
2023-03-17 03:59:57,472 INFO     Train positive_sample_loss at step 221400: 0.063895
2023-03-17 03:59:57,472 INFO     Train negative_sample_loss at step 221400: 0.056107
2023-03-17 03:59:57,473 INFO     Train loss at step 221400: 0.060001
2023-03-17 04:00:16,876 INFO     Train positive_sample_loss at step 221500: 0.064206
2023-03-17 04:00:16,877 INFO     Train negative_sample_loss at step 221500: 0.056294
2023-03-17 04:00:16,877 INFO     Train loss at step 221500: 0.060250
2023-03-17 04:00:43,249 INFO     Train positive_sample_loss at step 221600: 0.064413
2023-03-17 04:00:43,250 INFO     Train negative_sample_loss at step 221600: 0.056698
2023-03-17 04:00:43,250 INFO     Train loss at step 221600: 0.060555
2023-03-17 04:01:02,637 INFO     Train positive_sample_loss at step 221700: 0.064812
2023-03-17 04:01:02,637 INFO     Train negative_sample_loss at step 221700: 0.056397
2023-03-17 04:01:02,637 INFO     Train loss at step 221700: 0.060604
2023-03-17 04:01:22,028 INFO     Train positive_sample_loss at step 221800: 0.065073
2023-03-17 04:01:22,029 INFO     Train negative_sample_loss at step 221800: 0.056598
2023-03-17 04:01:22,029 INFO     Train loss at step 221800: 0.060835
2023-03-17 04:01:41,410 INFO     Train positive_sample_loss at step 221900: 0.065294
2023-03-17 04:01:41,410 INFO     Train negative_sample_loss at step 221900: 0.057108
2023-03-17 04:01:41,410 INFO     Train loss at step 221900: 0.061201
2023-03-17 04:02:00,797 INFO     Train positive_sample_loss at step 222000: 0.065457
2023-03-17 04:02:00,797 INFO     Train negative_sample_loss at step 222000: 0.056694
2023-03-17 04:02:00,797 INFO     Train loss at step 222000: 0.061075
2023-03-17 04:02:20,184 INFO     Train positive_sample_loss at step 222100: 0.065655
2023-03-17 04:02:20,184 INFO     Train negative_sample_loss at step 222100: 0.056791
2023-03-17 04:02:20,185 INFO     Train loss at step 222100: 0.061223
2023-03-17 04:02:39,568 INFO     Train positive_sample_loss at step 222200: 0.065734
2023-03-17 04:02:39,569 INFO     Train negative_sample_loss at step 222200: 0.057419
2023-03-17 04:02:39,569 INFO     Train loss at step 222200: 0.061577
2023-03-17 04:02:58,948 INFO     Train positive_sample_loss at step 222300: 0.066151
2023-03-17 04:02:58,948 INFO     Train negative_sample_loss at step 222300: 0.057201
2023-03-17 04:02:58,949 INFO     Train loss at step 222300: 0.061676
2023-03-17 04:03:18,331 INFO     Train positive_sample_loss at step 222400: 0.066132
2023-03-17 04:03:18,332 INFO     Train negative_sample_loss at step 222400: 0.057171
2023-03-17 04:03:18,332 INFO     Train loss at step 222400: 0.061651
2023-03-17 04:03:37,704 INFO     Train positive_sample_loss at step 222500: 0.066372
2023-03-17 04:03:37,705 INFO     Train negative_sample_loss at step 222500: 0.056763
2023-03-17 04:03:37,705 INFO     Train loss at step 222500: 0.061568
2023-03-17 04:03:57,079 INFO     Train positive_sample_loss at step 222600: 0.066467
2023-03-17 04:03:57,080 INFO     Train negative_sample_loss at step 222600: 0.057514
2023-03-17 04:03:57,080 INFO     Train loss at step 222600: 0.061991
2023-03-17 04:04:25,583 INFO     Train positive_sample_loss at step 222700: 0.066414
2023-03-17 04:04:25,584 INFO     Train negative_sample_loss at step 222700: 0.056795
2023-03-17 04:04:25,584 INFO     Train loss at step 222700: 0.061604
2023-03-17 04:04:44,986 INFO     Train positive_sample_loss at step 222800: 0.066685
2023-03-17 04:04:44,986 INFO     Train negative_sample_loss at step 222800: 0.056484
2023-03-17 04:04:44,986 INFO     Train loss at step 222800: 0.061584
2023-03-17 04:05:04,378 INFO     Train positive_sample_loss at step 222900: 0.066908
2023-03-17 04:05:04,378 INFO     Train negative_sample_loss at step 222900: 0.057466
2023-03-17 04:05:04,378 INFO     Train loss at step 222900: 0.062187
2023-03-17 04:05:23,777 INFO     Train positive_sample_loss at step 223000: 0.066671
2023-03-17 04:05:23,778 INFO     Train negative_sample_loss at step 223000: 0.057425
2023-03-17 04:05:23,778 INFO     Train loss at step 223000: 0.062048
2023-03-17 04:05:43,183 INFO     Train positive_sample_loss at step 223100: 0.066848
2023-03-17 04:05:43,183 INFO     Train negative_sample_loss at step 223100: 0.056903
2023-03-17 04:05:43,183 INFO     Train loss at step 223100: 0.061875
2023-03-17 04:06:02,592 INFO     Train positive_sample_loss at step 223200: 0.066865
2023-03-17 04:06:02,592 INFO     Train negative_sample_loss at step 223200: 0.057200
2023-03-17 04:06:02,592 INFO     Train loss at step 223200: 0.062033
2023-03-17 04:06:21,999 INFO     Train positive_sample_loss at step 223300: 0.067089
2023-03-17 04:06:21,999 INFO     Train negative_sample_loss at step 223300: 0.057062
2023-03-17 04:06:21,999 INFO     Train loss at step 223300: 0.062075
2023-03-17 04:06:41,405 INFO     Train positive_sample_loss at step 223400: 0.067005
2023-03-17 04:06:41,405 INFO     Train negative_sample_loss at step 223400: 0.058033
2023-03-17 04:06:41,405 INFO     Train loss at step 223400: 0.062519
2023-03-17 04:07:00,829 INFO     Train positive_sample_loss at step 223500: 0.067027
2023-03-17 04:07:00,830 INFO     Train negative_sample_loss at step 223500: 0.056901
2023-03-17 04:07:00,830 INFO     Train loss at step 223500: 0.061964
2023-03-17 04:07:20,233 INFO     Train positive_sample_loss at step 223600: 0.067028
2023-03-17 04:07:20,233 INFO     Train negative_sample_loss at step 223600: 0.057586
2023-03-17 04:07:20,233 INFO     Train loss at step 223600: 0.062307
2023-03-17 04:07:46,518 INFO     Train positive_sample_loss at step 223700: 0.067170
2023-03-17 04:07:46,519 INFO     Train negative_sample_loss at step 223700: 0.057730
2023-03-17 04:07:46,519 INFO     Train loss at step 223700: 0.062450
2023-03-17 04:08:05,907 INFO     Train positive_sample_loss at step 223800: 0.067049
2023-03-17 04:08:05,907 INFO     Train negative_sample_loss at step 223800: 0.057803
2023-03-17 04:08:05,907 INFO     Train loss at step 223800: 0.062426
2023-03-17 04:08:25,305 INFO     Train positive_sample_loss at step 223900: 0.066950
2023-03-17 04:08:25,305 INFO     Train negative_sample_loss at step 223900: 0.057101
2023-03-17 04:08:25,306 INFO     Train loss at step 223900: 0.062026
2023-03-17 04:08:44,713 INFO     Train positive_sample_loss at step 224000: 0.067204
2023-03-17 04:08:44,714 INFO     Train negative_sample_loss at step 224000: 0.057817
2023-03-17 04:08:44,714 INFO     Train loss at step 224000: 0.062511
2023-03-17 04:09:04,117 INFO     Train positive_sample_loss at step 224100: 0.067188
2023-03-17 04:09:04,118 INFO     Train negative_sample_loss at step 224100: 0.057279
2023-03-17 04:09:04,118 INFO     Train loss at step 224100: 0.062234
2023-03-17 04:09:23,527 INFO     Train positive_sample_loss at step 224200: 0.067178
2023-03-17 04:09:23,528 INFO     Train negative_sample_loss at step 224200: 0.057559
2023-03-17 04:09:23,528 INFO     Train loss at step 224200: 0.062369
2023-03-17 04:09:48,901 INFO     Train positive_sample_loss at step 224300: 0.061387
2023-03-17 04:09:48,902 INFO     Train negative_sample_loss at step 224300: 0.057402
2023-03-17 04:09:48,902 INFO     Train loss at step 224300: 0.059395
2023-03-17 04:10:08,241 INFO     Train positive_sample_loss at step 224400: 0.058755
2023-03-17 04:10:08,242 INFO     Train negative_sample_loss at step 224400: 0.057360
2023-03-17 04:10:08,242 INFO     Train loss at step 224400: 0.058057
2023-03-17 04:10:35,524 INFO     Train positive_sample_loss at step 224500: 0.059552
2023-03-17 04:10:35,524 INFO     Train negative_sample_loss at step 224500: 0.057156
2023-03-17 04:10:35,524 INFO     Train loss at step 224500: 0.058354
2023-03-17 04:10:54,903 INFO     Train positive_sample_loss at step 224600: 0.060240
2023-03-17 04:10:54,904 INFO     Train negative_sample_loss at step 224600: 0.055929
2023-03-17 04:10:54,904 INFO     Train loss at step 224600: 0.058085
2023-03-17 04:11:14,289 INFO     Train positive_sample_loss at step 224700: 0.061117
2023-03-17 04:11:14,290 INFO     Train negative_sample_loss at step 224700: 0.055918
2023-03-17 04:11:14,290 INFO     Train loss at step 224700: 0.058518
2023-03-17 04:11:33,685 INFO     Train positive_sample_loss at step 224800: 0.061446
2023-03-17 04:11:33,685 INFO     Train negative_sample_loss at step 224800: 0.056577
2023-03-17 04:11:33,686 INFO     Train loss at step 224800: 0.059012
2023-03-17 04:11:53,099 INFO     Train positive_sample_loss at step 224900: 0.061914
2023-03-17 04:11:53,099 INFO     Train negative_sample_loss at step 224900: 0.056579
2023-03-17 04:11:53,099 INFO     Train loss at step 224900: 0.059246
2023-03-17 04:12:12,512 INFO     Train positive_sample_loss at step 225000: 0.062327
2023-03-17 04:12:12,513 INFO     Train negative_sample_loss at step 225000: 0.056216
2023-03-17 04:12:12,513 INFO     Train loss at step 225000: 0.059272
2023-03-17 04:12:31,908 INFO     Train positive_sample_loss at step 225100: 0.062816
2023-03-17 04:12:31,908 INFO     Train negative_sample_loss at step 225100: 0.056257
2023-03-17 04:12:31,908 INFO     Train loss at step 225100: 0.059537
2023-03-17 04:12:51,313 INFO     Train positive_sample_loss at step 225200: 0.063141
2023-03-17 04:12:51,314 INFO     Train negative_sample_loss at step 225200: 0.055689
2023-03-17 04:12:51,314 INFO     Train loss at step 225200: 0.059415
2023-03-17 04:13:10,713 INFO     Train positive_sample_loss at step 225300: 0.063342
2023-03-17 04:13:10,713 INFO     Train negative_sample_loss at step 225300: 0.055890
2023-03-17 04:13:10,713 INFO     Train loss at step 225300: 0.059616
2023-03-17 04:13:30,126 INFO     Train positive_sample_loss at step 225400: 0.063853
2023-03-17 04:13:30,126 INFO     Train negative_sample_loss at step 225400: 0.056402
2023-03-17 04:13:30,126 INFO     Train loss at step 225400: 0.060128
2023-03-17 04:13:56,701 INFO     Train positive_sample_loss at step 225500: 0.064268
2023-03-17 04:13:56,701 INFO     Train negative_sample_loss at step 225500: 0.055705
2023-03-17 04:13:56,701 INFO     Train loss at step 225500: 0.059987
2023-03-17 04:14:16,106 INFO     Train positive_sample_loss at step 225600: 0.064265
2023-03-17 04:14:16,107 INFO     Train negative_sample_loss at step 225600: 0.055821
2023-03-17 04:14:16,107 INFO     Train loss at step 225600: 0.060043
2023-03-17 04:14:35,512 INFO     Train positive_sample_loss at step 225700: 0.064845
2023-03-17 04:14:35,513 INFO     Train negative_sample_loss at step 225700: 0.056485
2023-03-17 04:14:35,513 INFO     Train loss at step 225700: 0.060665
2023-03-17 04:14:54,908 INFO     Train positive_sample_loss at step 225800: 0.064885
2023-03-17 04:14:54,909 INFO     Train negative_sample_loss at step 225800: 0.056275
2023-03-17 04:14:54,909 INFO     Train loss at step 225800: 0.060580
2023-03-17 04:15:14,315 INFO     Train positive_sample_loss at step 225900: 0.065157
2023-03-17 04:15:14,316 INFO     Train negative_sample_loss at step 225900: 0.056483
2023-03-17 04:15:14,316 INFO     Train loss at step 225900: 0.060820
2023-03-17 04:15:33,727 INFO     Train positive_sample_loss at step 226000: 0.065399
2023-03-17 04:15:33,727 INFO     Train negative_sample_loss at step 226000: 0.056442
2023-03-17 04:15:33,727 INFO     Train loss at step 226000: 0.060921
2023-03-17 04:15:53,143 INFO     Train positive_sample_loss at step 226100: 0.065553
2023-03-17 04:15:53,144 INFO     Train negative_sample_loss at step 226100: 0.056532
2023-03-17 04:15:53,144 INFO     Train loss at step 226100: 0.061042
2023-03-17 04:16:12,550 INFO     Train positive_sample_loss at step 226200: 0.065790
2023-03-17 04:16:12,551 INFO     Train negative_sample_loss at step 226200: 0.056737
2023-03-17 04:16:12,551 INFO     Train loss at step 226200: 0.061263
2023-03-17 04:16:31,958 INFO     Train positive_sample_loss at step 226300: 0.065859
2023-03-17 04:16:31,958 INFO     Train negative_sample_loss at step 226300: 0.056897
2023-03-17 04:16:31,958 INFO     Train loss at step 226300: 0.061378
2023-03-17 04:16:51,364 INFO     Train positive_sample_loss at step 226400: 0.066233
2023-03-17 04:16:51,364 INFO     Train negative_sample_loss at step 226400: 0.057287
2023-03-17 04:16:51,364 INFO     Train loss at step 226400: 0.061760
2023-03-17 04:17:10,784 INFO     Train positive_sample_loss at step 226500: 0.066053
2023-03-17 04:17:10,785 INFO     Train negative_sample_loss at step 226500: 0.056461
2023-03-17 04:17:10,785 INFO     Train loss at step 226500: 0.061257
2023-03-17 04:17:37,073 INFO     Train positive_sample_loss at step 226600: 0.066112
2023-03-17 04:17:37,073 INFO     Train negative_sample_loss at step 226600: 0.056596
2023-03-17 04:17:37,073 INFO     Train loss at step 226600: 0.061354
2023-03-17 04:17:56,483 INFO     Train positive_sample_loss at step 226700: 0.066254
2023-03-17 04:17:56,483 INFO     Train negative_sample_loss at step 226700: 0.056694
2023-03-17 04:17:56,483 INFO     Train loss at step 226700: 0.061474
2023-03-17 04:18:15,879 INFO     Train positive_sample_loss at step 226800: 0.066281
2023-03-17 04:18:15,880 INFO     Train negative_sample_loss at step 226800: 0.057526
2023-03-17 04:18:15,880 INFO     Train loss at step 226800: 0.061904
2023-03-17 04:18:35,273 INFO     Train positive_sample_loss at step 226900: 0.066597
2023-03-17 04:18:35,273 INFO     Train negative_sample_loss at step 226900: 0.056794
2023-03-17 04:18:35,273 INFO     Train loss at step 226900: 0.061696
2023-03-17 04:18:54,678 INFO     Train positive_sample_loss at step 227000: 0.066478
2023-03-17 04:18:54,679 INFO     Train negative_sample_loss at step 227000: 0.057311
2023-03-17 04:18:54,679 INFO     Train loss at step 227000: 0.061895
2023-03-17 04:19:14,082 INFO     Train positive_sample_loss at step 227100: 0.066693
2023-03-17 04:19:14,083 INFO     Train negative_sample_loss at step 227100: 0.057277
2023-03-17 04:19:14,083 INFO     Train loss at step 227100: 0.061985
2023-03-17 04:19:33,495 INFO     Train positive_sample_loss at step 227200: 0.066682
2023-03-17 04:19:33,496 INFO     Train negative_sample_loss at step 227200: 0.057311
2023-03-17 04:19:33,496 INFO     Train loss at step 227200: 0.061997
2023-03-17 04:19:52,892 INFO     Train positive_sample_loss at step 227300: 0.066766
2023-03-17 04:19:52,893 INFO     Train negative_sample_loss at step 227300: 0.057248
2023-03-17 04:19:52,893 INFO     Train loss at step 227300: 0.062007
2023-03-17 04:20:12,305 INFO     Train positive_sample_loss at step 227400: 0.066675
2023-03-17 04:20:12,305 INFO     Train negative_sample_loss at step 227400: 0.057325
2023-03-17 04:20:12,305 INFO     Train loss at step 227400: 0.062000
2023-03-17 04:20:31,706 INFO     Train positive_sample_loss at step 227500: 0.066799
2023-03-17 04:20:31,706 INFO     Train negative_sample_loss at step 227500: 0.057164
2023-03-17 04:20:31,706 INFO     Train loss at step 227500: 0.061981
2023-03-17 04:20:51,108 INFO     Train positive_sample_loss at step 227600: 0.066815
2023-03-17 04:20:51,108 INFO     Train negative_sample_loss at step 227600: 0.057385
2023-03-17 04:20:51,108 INFO     Train loss at step 227600: 0.062100
2023-03-17 04:21:17,481 INFO     Train positive_sample_loss at step 227700: 0.066923
2023-03-17 04:21:17,482 INFO     Train negative_sample_loss at step 227700: 0.057617
2023-03-17 04:21:17,482 INFO     Train loss at step 227700: 0.062270
2023-03-17 04:21:36,881 INFO     Train positive_sample_loss at step 227800: 0.066917
2023-03-17 04:21:36,882 INFO     Train negative_sample_loss at step 227800: 0.057592
2023-03-17 04:21:36,882 INFO     Train loss at step 227800: 0.062254
2023-03-17 04:21:56,279 INFO     Train positive_sample_loss at step 227900: 0.066663
2023-03-17 04:21:56,280 INFO     Train negative_sample_loss at step 227900: 0.057505
2023-03-17 04:21:56,280 INFO     Train loss at step 227900: 0.062084
2023-03-17 04:22:15,693 INFO     Train positive_sample_loss at step 228000: 0.066761
2023-03-17 04:22:15,694 INFO     Train negative_sample_loss at step 228000: 0.057422
2023-03-17 04:22:15,694 INFO     Train loss at step 228000: 0.062091
2023-03-17 04:22:35,106 INFO     Train positive_sample_loss at step 228100: 0.066991
2023-03-17 04:22:35,106 INFO     Train negative_sample_loss at step 228100: 0.058174
2023-03-17 04:22:35,106 INFO     Train loss at step 228100: 0.062582
2023-03-17 04:23:00,220 INFO     Train positive_sample_loss at step 228200: 0.064282
2023-03-17 04:23:00,221 INFO     Train negative_sample_loss at step 228200: 0.058008
2023-03-17 04:23:00,221 INFO     Train loss at step 228200: 0.061145
2023-03-17 04:23:19,581 INFO     Train positive_sample_loss at step 228300: 0.058282
2023-03-17 04:23:19,582 INFO     Train negative_sample_loss at step 228300: 0.056914
2023-03-17 04:23:19,582 INFO     Train loss at step 228300: 0.057598
2023-03-17 04:23:46,997 INFO     Train positive_sample_loss at step 228400: 0.059224
2023-03-17 04:23:46,997 INFO     Train negative_sample_loss at step 228400: 0.056772
2023-03-17 04:23:46,997 INFO     Train loss at step 228400: 0.057998
2023-03-17 04:24:06,379 INFO     Train positive_sample_loss at step 228500: 0.059885
2023-03-17 04:24:06,380 INFO     Train negative_sample_loss at step 228500: 0.056635
2023-03-17 04:24:06,380 INFO     Train loss at step 228500: 0.058260
2023-03-17 04:24:25,773 INFO     Train positive_sample_loss at step 228600: 0.060584
2023-03-17 04:24:25,774 INFO     Train negative_sample_loss at step 228600: 0.056573
2023-03-17 04:24:25,774 INFO     Train loss at step 228600: 0.058578
2023-03-17 04:24:45,170 INFO     Train positive_sample_loss at step 228700: 0.061127
2023-03-17 04:24:45,171 INFO     Train negative_sample_loss at step 228700: 0.055782
2023-03-17 04:24:45,171 INFO     Train loss at step 228700: 0.058455
2023-03-17 04:25:04,569 INFO     Train positive_sample_loss at step 228800: 0.061521
2023-03-17 04:25:04,569 INFO     Train negative_sample_loss at step 228800: 0.056287
2023-03-17 04:25:04,570 INFO     Train loss at step 228800: 0.058904
2023-03-17 04:25:23,973 INFO     Train positive_sample_loss at step 228900: 0.061962
2023-03-17 04:25:23,973 INFO     Train negative_sample_loss at step 228900: 0.056238
2023-03-17 04:25:23,973 INFO     Train loss at step 228900: 0.059100
2023-03-17 04:25:43,370 INFO     Train positive_sample_loss at step 229000: 0.062508
2023-03-17 04:25:43,370 INFO     Train negative_sample_loss at step 229000: 0.055821
2023-03-17 04:25:43,371 INFO     Train loss at step 229000: 0.059165
2023-03-17 04:26:02,768 INFO     Train positive_sample_loss at step 229100: 0.062912
2023-03-17 04:26:02,769 INFO     Train negative_sample_loss at step 229100: 0.055755
2023-03-17 04:26:02,769 INFO     Train loss at step 229100: 0.059334
2023-03-17 04:26:22,170 INFO     Train positive_sample_loss at step 229200: 0.063174
2023-03-17 04:26:22,171 INFO     Train negative_sample_loss at step 229200: 0.055542
2023-03-17 04:26:22,171 INFO     Train loss at step 229200: 0.059358
2023-03-17 04:26:41,576 INFO     Train positive_sample_loss at step 229300: 0.063499
2023-03-17 04:26:41,576 INFO     Train negative_sample_loss at step 229300: 0.056121
2023-03-17 04:26:41,576 INFO     Train loss at step 229300: 0.059810
2023-03-17 04:27:00,986 INFO     Train positive_sample_loss at step 229400: 0.063836
2023-03-17 04:27:00,987 INFO     Train negative_sample_loss at step 229400: 0.056001
2023-03-17 04:27:00,987 INFO     Train loss at step 229400: 0.059919
2023-03-17 04:27:27,426 INFO     Train positive_sample_loss at step 229500: 0.064319
2023-03-17 04:27:27,426 INFO     Train negative_sample_loss at step 229500: 0.056229
2023-03-17 04:27:27,426 INFO     Train loss at step 229500: 0.060274
2023-03-17 04:27:46,834 INFO     Train positive_sample_loss at step 229600: 0.064403
2023-03-17 04:27:46,835 INFO     Train negative_sample_loss at step 229600: 0.056231
2023-03-17 04:27:46,835 INFO     Train loss at step 229600: 0.060317
2023-03-17 04:28:06,247 INFO     Train positive_sample_loss at step 229700: 0.064833
2023-03-17 04:28:06,247 INFO     Train negative_sample_loss at step 229700: 0.056187
2023-03-17 04:28:06,247 INFO     Train loss at step 229700: 0.060510
2023-03-17 04:28:25,654 INFO     Train positive_sample_loss at step 229800: 0.065014
2023-03-17 04:28:25,654 INFO     Train negative_sample_loss at step 229800: 0.056616
2023-03-17 04:28:25,654 INFO     Train loss at step 229800: 0.060815
2023-03-17 04:28:45,051 INFO     Train positive_sample_loss at step 229900: 0.064991
2023-03-17 04:28:45,052 INFO     Train negative_sample_loss at step 229900: 0.056094
2023-03-17 04:28:45,052 INFO     Train loss at step 229900: 0.060542
2023-03-17 04:29:06,221 INFO     Train positive_sample_loss at step 230000: 0.065096
2023-03-17 04:29:06,221 INFO     Train negative_sample_loss at step 230000: 0.056314
2023-03-17 04:29:06,221 INFO     Train loss at step 230000: 0.060705
2023-03-17 04:29:06,221 INFO     Evaluating on Valid Dataset...
2023-03-17 04:29:07,590 INFO     Evaluating the model... (0/26842)
2023-03-17 04:29:08,852 INFO     Evaluating the model... (1000/26842)
2023-03-17 04:29:10,223 INFO     Evaluating the model... (2000/26842)
2023-03-17 04:29:11,461 INFO     Evaluating the model... (3000/26842)
2023-03-17 04:29:12,697 INFO     Evaluating the model... (4000/26842)
2023-03-17 04:29:13,930 INFO     Evaluating the model... (5000/26842)
2023-03-17 04:29:15,161 INFO     Evaluating the model... (6000/26842)
2023-03-17 04:29:16,409 INFO     Evaluating the model... (7000/26842)
2023-03-17 04:29:17,650 INFO     Evaluating the model... (8000/26842)
2023-03-17 04:29:18,897 INFO     Evaluating the model... (9000/26842)
2023-03-17 04:29:20,147 INFO     Evaluating the model... (10000/26842)
2023-03-17 04:29:21,389 INFO     Evaluating the model... (11000/26842)
2023-03-17 04:29:22,635 INFO     Evaluating the model... (12000/26842)
2023-03-17 04:29:23,883 INFO     Evaluating the model... (13000/26842)
2023-03-17 04:29:26,193 INFO     Evaluating the model... (14000/26842)
2023-03-17 04:29:27,676 INFO     Evaluating the model... (15000/26842)
2023-03-17 04:29:29,162 INFO     Evaluating the model... (16000/26842)
2023-03-17 04:29:30,643 INFO     Evaluating the model... (17000/26842)
2023-03-17 04:29:32,126 INFO     Evaluating the model... (18000/26842)
2023-03-17 04:29:33,606 INFO     Evaluating the model... (19000/26842)
2023-03-17 04:29:35,090 INFO     Evaluating the model... (20000/26842)
2023-03-17 04:29:36,569 INFO     Evaluating the model... (21000/26842)
2023-03-17 04:29:38,055 INFO     Evaluating the model... (22000/26842)
2023-03-17 04:29:39,546 INFO     Evaluating the model... (23000/26842)
2023-03-17 04:29:41,019 INFO     Evaluating the model... (24000/26842)
2023-03-17 04:29:42,486 INFO     Evaluating the model... (25000/26842)
2023-03-17 04:29:43,950 INFO     Evaluating the model... (26000/26842)
2023-03-17 04:29:45,505 INFO     Valid hits@1_list at step 230000: 0.654612
2023-03-17 04:29:45,505 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 04:29:45,505 INFO     Valid hits@3_list at step 230000: 0.745365
2023-03-17 04:29:45,505 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 04:29:45,505 INFO     Valid hits@10_list at step 230000: 0.834170
2023-03-17 04:29:45,505 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 04:29:45,505 INFO     Valid mrr_list at step 230000: 0.716036
2023-03-17 04:30:04,910 INFO     Train positive_sample_loss at step 230100: 0.065260
2023-03-17 04:30:04,911 INFO     Train negative_sample_loss at step 230100: 0.056143
2023-03-17 04:30:04,911 INFO     Train loss at step 230100: 0.060702
2023-03-17 04:30:24,308 INFO     Train positive_sample_loss at step 230200: 0.065641
2023-03-17 04:30:24,308 INFO     Train negative_sample_loss at step 230200: 0.056679
2023-03-17 04:30:24,308 INFO     Train loss at step 230200: 0.061160
2023-03-17 04:30:43,730 INFO     Train positive_sample_loss at step 230300: 0.065656
2023-03-17 04:30:43,730 INFO     Train negative_sample_loss at step 230300: 0.057235
2023-03-17 04:30:43,730 INFO     Train loss at step 230300: 0.061445
2023-03-17 04:31:03,135 INFO     Train positive_sample_loss at step 230400: 0.065956
2023-03-17 04:31:03,136 INFO     Train negative_sample_loss at step 230400: 0.056226
2023-03-17 04:31:03,136 INFO     Train loss at step 230400: 0.061091
2023-03-17 04:31:29,482 INFO     Train positive_sample_loss at step 230500: 0.065989
2023-03-17 04:31:29,482 INFO     Train negative_sample_loss at step 230500: 0.057021
2023-03-17 04:31:29,482 INFO     Train loss at step 230500: 0.061505
2023-03-17 04:31:48,894 INFO     Train positive_sample_loss at step 230600: 0.066023
2023-03-17 04:31:48,895 INFO     Train negative_sample_loss at step 230600: 0.056940
2023-03-17 04:31:48,895 INFO     Train loss at step 230600: 0.061482
2023-03-17 04:32:08,309 INFO     Train positive_sample_loss at step 230700: 0.066340
2023-03-17 04:32:08,310 INFO     Train negative_sample_loss at step 230700: 0.057005
2023-03-17 04:32:08,310 INFO     Train loss at step 230700: 0.061672
2023-03-17 04:32:27,697 INFO     Train positive_sample_loss at step 230800: 0.066213
2023-03-17 04:32:27,697 INFO     Train negative_sample_loss at step 230800: 0.056373
2023-03-17 04:32:27,697 INFO     Train loss at step 230800: 0.061293
2023-03-17 04:32:47,102 INFO     Train positive_sample_loss at step 230900: 0.066292
2023-03-17 04:32:47,103 INFO     Train negative_sample_loss at step 230900: 0.056652
2023-03-17 04:32:47,103 INFO     Train loss at step 230900: 0.061472
2023-03-17 04:33:06,487 INFO     Train positive_sample_loss at step 231000: 0.066448
2023-03-17 04:33:06,488 INFO     Train negative_sample_loss at step 231000: 0.056699
2023-03-17 04:33:06,488 INFO     Train loss at step 231000: 0.061573
2023-03-17 04:33:25,877 INFO     Train positive_sample_loss at step 231100: 0.066465
2023-03-17 04:33:25,878 INFO     Train negative_sample_loss at step 231100: 0.056585
2023-03-17 04:33:25,878 INFO     Train loss at step 231100: 0.061525
2023-03-17 04:33:45,272 INFO     Train positive_sample_loss at step 231200: 0.066247
2023-03-17 04:33:45,273 INFO     Train negative_sample_loss at step 231200: 0.056481
2023-03-17 04:33:45,273 INFO     Train loss at step 231200: 0.061364
2023-03-17 04:34:04,667 INFO     Train positive_sample_loss at step 231300: 0.066665
2023-03-17 04:34:04,668 INFO     Train negative_sample_loss at step 231300: 0.057237
2023-03-17 04:34:04,668 INFO     Train loss at step 231300: 0.061951
2023-03-17 04:34:24,065 INFO     Train positive_sample_loss at step 231400: 0.066582
2023-03-17 04:34:24,065 INFO     Train negative_sample_loss at step 231400: 0.056846
2023-03-17 04:34:24,066 INFO     Train loss at step 231400: 0.061714
2023-03-17 04:34:43,471 INFO     Train positive_sample_loss at step 231500: 0.066527
2023-03-17 04:34:43,471 INFO     Train negative_sample_loss at step 231500: 0.057467
2023-03-17 04:34:43,471 INFO     Train loss at step 231500: 0.061997
2023-03-17 04:35:09,900 INFO     Train positive_sample_loss at step 231600: 0.066693
2023-03-17 04:35:09,901 INFO     Train negative_sample_loss at step 231600: 0.057306
2023-03-17 04:35:09,901 INFO     Train loss at step 231600: 0.062000
2023-03-17 04:35:29,315 INFO     Train positive_sample_loss at step 231700: 0.066582
2023-03-17 04:35:29,316 INFO     Train negative_sample_loss at step 231700: 0.057458
2023-03-17 04:35:29,316 INFO     Train loss at step 231700: 0.062020
2023-03-17 04:35:48,735 INFO     Train positive_sample_loss at step 231800: 0.066542
2023-03-17 04:35:48,735 INFO     Train negative_sample_loss at step 231800: 0.057781
2023-03-17 04:35:48,736 INFO     Train loss at step 231800: 0.062162
2023-03-17 04:36:08,148 INFO     Train positive_sample_loss at step 231900: 0.066593
2023-03-17 04:36:08,149 INFO     Train negative_sample_loss at step 231900: 0.057382
2023-03-17 04:36:08,149 INFO     Train loss at step 231900: 0.061987
2023-03-17 04:36:27,555 INFO     Train positive_sample_loss at step 232000: 0.066665
2023-03-17 04:36:27,556 INFO     Train negative_sample_loss at step 232000: 0.056689
2023-03-17 04:36:27,556 INFO     Train loss at step 232000: 0.061677
2023-03-17 04:36:48,936 INFO     Train positive_sample_loss at step 232100: 0.066895
2023-03-17 04:36:48,936 INFO     Train negative_sample_loss at step 232100: 0.057357
2023-03-17 04:36:48,936 INFO     Train loss at step 232100: 0.062126
funtion time use:39104ms
2023-03-17 04:37:12,240 INFO     Train positive_sample_loss at step 232200: 0.058401
2023-03-17 04:37:12,241 INFO     Train negative_sample_loss at step 232200: 0.056896
2023-03-17 04:37:12,241 INFO     Train loss at step 232200: 0.057649
2023-03-17 04:37:39,559 INFO     Train positive_sample_loss at step 232300: 0.058812
2023-03-17 04:37:39,560 INFO     Train negative_sample_loss at step 232300: 0.056904
2023-03-17 04:37:39,560 INFO     Train loss at step 232300: 0.057858
2023-03-17 04:37:58,965 INFO     Train positive_sample_loss at step 232400: 0.059629
2023-03-17 04:37:58,965 INFO     Train negative_sample_loss at step 232400: 0.056458
2023-03-17 04:37:58,966 INFO     Train loss at step 232400: 0.058044
2023-03-17 04:38:18,365 INFO     Train positive_sample_loss at step 232500: 0.060186
2023-03-17 04:38:18,365 INFO     Train negative_sample_loss at step 232500: 0.056320
2023-03-17 04:38:18,366 INFO     Train loss at step 232500: 0.058253
2023-03-17 04:38:37,748 INFO     Train positive_sample_loss at step 232600: 0.060739
2023-03-17 04:38:37,748 INFO     Train negative_sample_loss at step 232600: 0.055855
2023-03-17 04:38:37,748 INFO     Train loss at step 232600: 0.058297
2023-03-17 04:38:57,128 INFO     Train positive_sample_loss at step 232700: 0.061133
2023-03-17 04:38:57,128 INFO     Train negative_sample_loss at step 232700: 0.055811
2023-03-17 04:38:57,129 INFO     Train loss at step 232700: 0.058472
2023-03-17 04:39:16,510 INFO     Train positive_sample_loss at step 232800: 0.061716
2023-03-17 04:39:16,511 INFO     Train negative_sample_loss at step 232800: 0.056438
2023-03-17 04:39:16,511 INFO     Train loss at step 232800: 0.059077
2023-03-17 04:39:35,912 INFO     Train positive_sample_loss at step 232900: 0.062131
2023-03-17 04:39:35,912 INFO     Train negative_sample_loss at step 232900: 0.056100
2023-03-17 04:39:35,912 INFO     Train loss at step 232900: 0.059116
2023-03-17 04:39:55,317 INFO     Train positive_sample_loss at step 233000: 0.062463
2023-03-17 04:39:55,317 INFO     Train negative_sample_loss at step 233000: 0.055961
2023-03-17 04:39:55,317 INFO     Train loss at step 233000: 0.059212
2023-03-17 04:40:14,726 INFO     Train positive_sample_loss at step 233100: 0.062981
2023-03-17 04:40:14,726 INFO     Train negative_sample_loss at step 233100: 0.056425
2023-03-17 04:40:14,726 INFO     Train loss at step 233100: 0.059703
2023-03-17 04:40:34,122 INFO     Train positive_sample_loss at step 233200: 0.063363
2023-03-17 04:40:34,123 INFO     Train negative_sample_loss at step 233200: 0.056261
2023-03-17 04:40:34,123 INFO     Train loss at step 233200: 0.059812
2023-03-17 04:40:53,517 INFO     Train positive_sample_loss at step 233300: 0.063701
2023-03-17 04:40:53,518 INFO     Train negative_sample_loss at step 233300: 0.056077
2023-03-17 04:40:53,518 INFO     Train loss at step 233300: 0.059889
2023-03-17 04:41:19,859 INFO     Train positive_sample_loss at step 233400: 0.063957
2023-03-17 04:41:19,859 INFO     Train negative_sample_loss at step 233400: 0.055560
2023-03-17 04:41:19,860 INFO     Train loss at step 233400: 0.059759
2023-03-17 04:41:39,260 INFO     Train positive_sample_loss at step 233500: 0.064238
2023-03-17 04:41:39,261 INFO     Train negative_sample_loss at step 233500: 0.056156
2023-03-17 04:41:39,261 INFO     Train loss at step 233500: 0.060197
2023-03-17 04:41:58,647 INFO     Train positive_sample_loss at step 233600: 0.064270
2023-03-17 04:41:58,647 INFO     Train negative_sample_loss at step 233600: 0.056063
2023-03-17 04:41:58,647 INFO     Train loss at step 233600: 0.060166
2023-03-17 04:42:18,039 INFO     Train positive_sample_loss at step 233700: 0.064644
2023-03-17 04:42:18,040 INFO     Train negative_sample_loss at step 233700: 0.056242
2023-03-17 04:42:18,040 INFO     Train loss at step 233700: 0.060443
2023-03-17 04:42:37,441 INFO     Train positive_sample_loss at step 233800: 0.064998
2023-03-17 04:42:37,441 INFO     Train negative_sample_loss at step 233800: 0.055938
2023-03-17 04:42:37,442 INFO     Train loss at step 233800: 0.060468
2023-03-17 04:42:56,851 INFO     Train positive_sample_loss at step 233900: 0.065109
2023-03-17 04:42:56,851 INFO     Train negative_sample_loss at step 233900: 0.055936
2023-03-17 04:42:56,851 INFO     Train loss at step 233900: 0.060523
2023-03-17 04:43:16,236 INFO     Train positive_sample_loss at step 234000: 0.065312
2023-03-17 04:43:16,237 INFO     Train negative_sample_loss at step 234000: 0.055941
2023-03-17 04:43:16,237 INFO     Train loss at step 234000: 0.060626
2023-03-17 04:43:35,632 INFO     Train positive_sample_loss at step 234100: 0.065255
2023-03-17 04:43:35,632 INFO     Train negative_sample_loss at step 234100: 0.055804
2023-03-17 04:43:35,632 INFO     Train loss at step 234100: 0.060529
2023-03-17 04:43:55,020 INFO     Train positive_sample_loss at step 234200: 0.065595
2023-03-17 04:43:55,021 INFO     Train negative_sample_loss at step 234200: 0.056680
2023-03-17 04:43:55,021 INFO     Train loss at step 234200: 0.061137
2023-03-17 04:44:14,426 INFO     Train positive_sample_loss at step 234300: 0.065463
2023-03-17 04:44:14,426 INFO     Train negative_sample_loss at step 234300: 0.056316
2023-03-17 04:44:14,426 INFO     Train loss at step 234300: 0.060889
2023-03-17 04:44:40,643 INFO     Train positive_sample_loss at step 234400: 0.065540
2023-03-17 04:44:40,643 INFO     Train negative_sample_loss at step 234400: 0.055774
2023-03-17 04:44:40,643 INFO     Train loss at step 234400: 0.060657
2023-03-17 04:45:00,041 INFO     Train positive_sample_loss at step 234500: 0.065810
2023-03-17 04:45:00,041 INFO     Train negative_sample_loss at step 234500: 0.056190
2023-03-17 04:45:00,041 INFO     Train loss at step 234500: 0.061000
2023-03-17 04:45:19,441 INFO     Train positive_sample_loss at step 234600: 0.065840
2023-03-17 04:45:19,441 INFO     Train negative_sample_loss at step 234600: 0.056522
2023-03-17 04:45:19,442 INFO     Train loss at step 234600: 0.061181
2023-03-17 04:45:38,839 INFO     Train positive_sample_loss at step 234700: 0.066130
2023-03-17 04:45:38,840 INFO     Train negative_sample_loss at step 234700: 0.056501
2023-03-17 04:45:38,840 INFO     Train loss at step 234700: 0.061316
2023-03-17 04:45:58,235 INFO     Train positive_sample_loss at step 234800: 0.066359
2023-03-17 04:45:58,236 INFO     Train negative_sample_loss at step 234800: 0.056023
2023-03-17 04:45:58,236 INFO     Train loss at step 234800: 0.061191
2023-03-17 04:46:17,641 INFO     Train positive_sample_loss at step 234900: 0.066015
2023-03-17 04:46:17,642 INFO     Train negative_sample_loss at step 234900: 0.057153
2023-03-17 04:46:17,642 INFO     Train loss at step 234900: 0.061584
2023-03-17 04:46:37,040 INFO     Train positive_sample_loss at step 235000: 0.066073
2023-03-17 04:46:37,040 INFO     Train negative_sample_loss at step 235000: 0.056778
2023-03-17 04:46:37,041 INFO     Train loss at step 235000: 0.061426
2023-03-17 04:46:56,444 INFO     Train positive_sample_loss at step 235100: 0.066216
2023-03-17 04:46:56,444 INFO     Train negative_sample_loss at step 235100: 0.056892
2023-03-17 04:46:56,444 INFO     Train loss at step 235100: 0.061554
2023-03-17 04:47:15,845 INFO     Train positive_sample_loss at step 235200: 0.066182
2023-03-17 04:47:15,845 INFO     Train negative_sample_loss at step 235200: 0.057312
2023-03-17 04:47:15,845 INFO     Train loss at step 235200: 0.061747
2023-03-17 04:47:35,245 INFO     Train positive_sample_loss at step 235300: 0.066489
2023-03-17 04:47:35,245 INFO     Train negative_sample_loss at step 235300: 0.056985
2023-03-17 04:47:35,245 INFO     Train loss at step 235300: 0.061737
2023-03-17 04:47:54,640 INFO     Train positive_sample_loss at step 235400: 0.066379
2023-03-17 04:47:54,640 INFO     Train negative_sample_loss at step 235400: 0.056846
2023-03-17 04:47:54,640 INFO     Train loss at step 235400: 0.061612
2023-03-17 04:48:20,990 INFO     Train positive_sample_loss at step 235500: 0.066463
2023-03-17 04:48:20,991 INFO     Train negative_sample_loss at step 235500: 0.057227
2023-03-17 04:48:20,991 INFO     Train loss at step 235500: 0.061845
2023-03-17 04:48:40,373 INFO     Train positive_sample_loss at step 235600: 0.066469
2023-03-17 04:48:40,373 INFO     Train negative_sample_loss at step 235600: 0.057373
2023-03-17 04:48:40,373 INFO     Train loss at step 235600: 0.061921
2023-03-17 04:48:59,751 INFO     Train positive_sample_loss at step 235700: 0.066263
2023-03-17 04:48:59,751 INFO     Train negative_sample_loss at step 235700: 0.056453
2023-03-17 04:48:59,751 INFO     Train loss at step 235700: 0.061358
2023-03-17 04:49:19,127 INFO     Train positive_sample_loss at step 235800: 0.066336
2023-03-17 04:49:19,128 INFO     Train negative_sample_loss at step 235800: 0.057407
2023-03-17 04:49:19,128 INFO     Train loss at step 235800: 0.061871
2023-03-17 04:49:38,503 INFO     Train positive_sample_loss at step 235900: 0.066312
2023-03-17 04:49:38,503 INFO     Train negative_sample_loss at step 235900: 0.056758
2023-03-17 04:49:38,503 INFO     Train loss at step 235900: 0.061535
2023-03-17 04:49:57,877 INFO     Train positive_sample_loss at step 236000: 0.066234
2023-03-17 04:49:57,877 INFO     Train negative_sample_loss at step 236000: 0.056720
2023-03-17 04:49:57,877 INFO     Train loss at step 236000: 0.061477
2023-03-17 04:50:22,849 INFO     Train positive_sample_loss at step 236100: 0.060967
2023-03-17 04:50:22,850 INFO     Train negative_sample_loss at step 236100: 0.057211
2023-03-17 04:50:22,850 INFO     Train loss at step 236100: 0.059089
2023-03-17 04:50:50,074 INFO     Train positive_sample_loss at step 236200: 0.058251
2023-03-17 04:50:50,075 INFO     Train negative_sample_loss at step 236200: 0.056511
2023-03-17 04:50:50,075 INFO     Train loss at step 236200: 0.057381
2023-03-17 04:51:09,398 INFO     Train positive_sample_loss at step 236300: 0.059034
2023-03-17 04:51:09,398 INFO     Train negative_sample_loss at step 236300: 0.056425
2023-03-17 04:51:09,399 INFO     Train loss at step 236300: 0.057730
2023-03-17 04:51:28,728 INFO     Train positive_sample_loss at step 236400: 0.059689
2023-03-17 04:51:28,729 INFO     Train negative_sample_loss at step 236400: 0.056323
2023-03-17 04:51:28,729 INFO     Train loss at step 236400: 0.058006
2023-03-17 04:51:48,060 INFO     Train positive_sample_loss at step 236500: 0.060396
2023-03-17 04:51:48,061 INFO     Train negative_sample_loss at step 236500: 0.056179
2023-03-17 04:51:48,061 INFO     Train loss at step 236500: 0.058287
2023-03-17 04:52:07,395 INFO     Train positive_sample_loss at step 236600: 0.061056
2023-03-17 04:52:07,396 INFO     Train negative_sample_loss at step 236600: 0.056012
2023-03-17 04:52:07,396 INFO     Train loss at step 236600: 0.058534
2023-03-17 04:52:26,721 INFO     Train positive_sample_loss at step 236700: 0.061306
2023-03-17 04:52:26,721 INFO     Train negative_sample_loss at step 236700: 0.055428
2023-03-17 04:52:26,721 INFO     Train loss at step 236700: 0.058367
2023-03-17 04:52:46,050 INFO     Train positive_sample_loss at step 236800: 0.061959
2023-03-17 04:52:46,051 INFO     Train negative_sample_loss at step 236800: 0.056349
2023-03-17 04:52:46,051 INFO     Train loss at step 236800: 0.059154
2023-03-17 04:53:05,383 INFO     Train positive_sample_loss at step 236900: 0.062142
2023-03-17 04:53:05,384 INFO     Train negative_sample_loss at step 236900: 0.055434
2023-03-17 04:53:05,384 INFO     Train loss at step 236900: 0.058788
2023-03-17 04:53:24,714 INFO     Train positive_sample_loss at step 237000: 0.062441
2023-03-17 04:53:24,714 INFO     Train negative_sample_loss at step 237000: 0.055346
2023-03-17 04:53:24,714 INFO     Train loss at step 237000: 0.058893
2023-03-17 04:53:44,041 INFO     Train positive_sample_loss at step 237100: 0.062998
2023-03-17 04:53:44,042 INFO     Train negative_sample_loss at step 237100: 0.056378
2023-03-17 04:53:44,042 INFO     Train loss at step 237100: 0.059688
2023-03-17 04:54:03,367 INFO     Train positive_sample_loss at step 237200: 0.063227
2023-03-17 04:54:03,368 INFO     Train negative_sample_loss at step 237200: 0.055831
2023-03-17 04:54:03,368 INFO     Train loss at step 237200: 0.059529
2023-03-17 04:54:29,589 INFO     Train positive_sample_loss at step 237300: 0.063528
2023-03-17 04:54:29,590 INFO     Train negative_sample_loss at step 237300: 0.055450
2023-03-17 04:54:29,590 INFO     Train loss at step 237300: 0.059489
2023-03-17 04:54:48,923 INFO     Train positive_sample_loss at step 237400: 0.063851
2023-03-17 04:54:48,923 INFO     Train negative_sample_loss at step 237400: 0.056331
2023-03-17 04:54:48,923 INFO     Train loss at step 237400: 0.060091
2023-03-17 04:55:08,253 INFO     Train positive_sample_loss at step 237500: 0.064130
2023-03-17 04:55:08,253 INFO     Train negative_sample_loss at step 237500: 0.056150
2023-03-17 04:55:08,253 INFO     Train loss at step 237500: 0.060140
2023-03-17 04:55:27,583 INFO     Train positive_sample_loss at step 237600: 0.064382
2023-03-17 04:55:27,583 INFO     Train negative_sample_loss at step 237600: 0.055868
2023-03-17 04:55:27,584 INFO     Train loss at step 237600: 0.060125
2023-03-17 04:55:46,919 INFO     Train positive_sample_loss at step 237700: 0.064544
2023-03-17 04:55:46,920 INFO     Train negative_sample_loss at step 237700: 0.055874
2023-03-17 04:55:46,920 INFO     Train loss at step 237700: 0.060209
2023-03-17 04:56:06,248 INFO     Train positive_sample_loss at step 237800: 0.064863
2023-03-17 04:56:06,248 INFO     Train negative_sample_loss at step 237800: 0.056743
2023-03-17 04:56:06,248 INFO     Train loss at step 237800: 0.060803
2023-03-17 04:56:25,583 INFO     Train positive_sample_loss at step 237900: 0.064967
2023-03-17 04:56:25,583 INFO     Train negative_sample_loss at step 237900: 0.056133
2023-03-17 04:56:25,583 INFO     Train loss at step 237900: 0.060550
2023-03-17 04:56:44,917 INFO     Train positive_sample_loss at step 238000: 0.065137
2023-03-17 04:56:44,917 INFO     Train negative_sample_loss at step 238000: 0.055613
2023-03-17 04:56:44,917 INFO     Train loss at step 238000: 0.060375
2023-03-17 04:57:04,249 INFO     Train positive_sample_loss at step 238100: 0.065223
2023-03-17 04:57:04,250 INFO     Train negative_sample_loss at step 238100: 0.055856
2023-03-17 04:57:04,250 INFO     Train loss at step 238100: 0.060539
2023-03-17 04:57:23,581 INFO     Train positive_sample_loss at step 238200: 0.065578
2023-03-17 04:57:23,581 INFO     Train negative_sample_loss at step 238200: 0.055976
2023-03-17 04:57:23,582 INFO     Train loss at step 238200: 0.060777
2023-03-17 04:57:42,928 INFO     Train positive_sample_loss at step 238300: 0.065447
2023-03-17 04:57:42,928 INFO     Train negative_sample_loss at step 238300: 0.056626
2023-03-17 04:57:42,928 INFO     Train loss at step 238300: 0.061037
2023-03-17 04:58:09,141 INFO     Train positive_sample_loss at step 238400: 0.065888
2023-03-17 04:58:09,141 INFO     Train negative_sample_loss at step 238400: 0.056217
2023-03-17 04:58:09,141 INFO     Train loss at step 238400: 0.061053
2023-03-17 04:58:28,488 INFO     Train positive_sample_loss at step 238500: 0.065678
2023-03-17 04:58:28,488 INFO     Train negative_sample_loss at step 238500: 0.056821
2023-03-17 04:58:28,488 INFO     Train loss at step 238500: 0.061250
2023-03-17 04:58:47,823 INFO     Train positive_sample_loss at step 238600: 0.065919
2023-03-17 04:58:47,823 INFO     Train negative_sample_loss at step 238600: 0.056907
2023-03-17 04:58:47,823 INFO     Train loss at step 238600: 0.061413
2023-03-17 04:59:07,152 INFO     Train positive_sample_loss at step 238700: 0.065929
2023-03-17 04:59:07,153 INFO     Train negative_sample_loss at step 238700: 0.056520
2023-03-17 04:59:07,153 INFO     Train loss at step 238700: 0.061225
2023-03-17 04:59:26,480 INFO     Train positive_sample_loss at step 238800: 0.065865
2023-03-17 04:59:26,480 INFO     Train negative_sample_loss at step 238800: 0.056203
2023-03-17 04:59:26,480 INFO     Train loss at step 238800: 0.061034
2023-03-17 04:59:45,816 INFO     Train positive_sample_loss at step 238900: 0.065935
2023-03-17 04:59:45,817 INFO     Train negative_sample_loss at step 238900: 0.056558
2023-03-17 04:59:45,817 INFO     Train loss at step 238900: 0.061246
2023-03-17 05:00:05,149 INFO     Train positive_sample_loss at step 239000: 0.066214
2023-03-17 05:00:05,150 INFO     Train negative_sample_loss at step 239000: 0.056787
2023-03-17 05:00:05,150 INFO     Train loss at step 239000: 0.061500
2023-03-17 05:00:24,501 INFO     Train positive_sample_loss at step 239100: 0.066264
2023-03-17 05:00:24,501 INFO     Train negative_sample_loss at step 239100: 0.056602
2023-03-17 05:00:24,501 INFO     Train loss at step 239100: 0.061433
2023-03-17 05:00:43,835 INFO     Train positive_sample_loss at step 239200: 0.065967
2023-03-17 05:00:43,835 INFO     Train negative_sample_loss at step 239200: 0.056351
2023-03-17 05:00:43,836 INFO     Train loss at step 239200: 0.061159
2023-03-17 05:01:03,161 INFO     Train positive_sample_loss at step 239300: 0.066339
2023-03-17 05:01:03,162 INFO     Train negative_sample_loss at step 239300: 0.056867
2023-03-17 05:01:03,162 INFO     Train loss at step 239300: 0.061603
2023-03-17 05:01:29,380 INFO     Train positive_sample_loss at step 239400: 0.066165
2023-03-17 05:01:29,380 INFO     Train negative_sample_loss at step 239400: 0.056502
2023-03-17 05:01:29,380 INFO     Train loss at step 239400: 0.061333
2023-03-17 05:01:48,706 INFO     Train positive_sample_loss at step 239500: 0.066189
2023-03-17 05:01:48,707 INFO     Train negative_sample_loss at step 239500: 0.056957
2023-03-17 05:01:48,707 INFO     Train loss at step 239500: 0.061573
2023-03-17 05:02:08,039 INFO     Train positive_sample_loss at step 239600: 0.066259
2023-03-17 05:02:08,039 INFO     Train negative_sample_loss at step 239600: 0.057010
2023-03-17 05:02:08,040 INFO     Train loss at step 239600: 0.061634
2023-03-17 05:02:27,370 INFO     Train positive_sample_loss at step 239700: 0.066253
2023-03-17 05:02:27,371 INFO     Train negative_sample_loss at step 239700: 0.057140
2023-03-17 05:02:27,371 INFO     Train loss at step 239700: 0.061697
2023-03-17 05:02:46,705 INFO     Train positive_sample_loss at step 239800: 0.066108
2023-03-17 05:02:46,706 INFO     Train negative_sample_loss at step 239800: 0.056656
2023-03-17 05:02:46,706 INFO     Train loss at step 239800: 0.061382
2023-03-17 05:03:06,038 INFO     Train positive_sample_loss at step 239900: 0.066155
2023-03-17 05:03:06,038 INFO     Train negative_sample_loss at step 239900: 0.056758
2023-03-17 05:03:06,038 INFO     Train loss at step 239900: 0.061456
2023-03-17 05:03:32,904 INFO     Train positive_sample_loss at step 240000: 0.063796
2023-03-17 05:03:32,904 INFO     Train negative_sample_loss at step 240000: 0.057656
2023-03-17 05:03:32,904 INFO     Train loss at step 240000: 0.060726
2023-03-17 05:03:32,905 INFO     Evaluating on Valid Dataset...
2023-03-17 05:03:33,947 INFO     Evaluating the model... (0/26842)
2023-03-17 05:03:35,210 INFO     Evaluating the model... (1000/26842)
2023-03-17 05:03:36,462 INFO     Evaluating the model... (2000/26842)
2023-03-17 05:03:37,707 INFO     Evaluating the model... (3000/26842)
2023-03-17 05:03:38,962 INFO     Evaluating the model... (4000/26842)
2023-03-17 05:03:40,209 INFO     Evaluating the model... (5000/26842)
2023-03-17 05:03:41,461 INFO     Evaluating the model... (6000/26842)
2023-03-17 05:03:42,705 INFO     Evaluating the model... (7000/26842)
2023-03-17 05:03:43,951 INFO     Evaluating the model... (8000/26842)
2023-03-17 05:03:45,203 INFO     Evaluating the model... (9000/26842)
2023-03-17 05:03:46,456 INFO     Evaluating the model... (10000/26842)
2023-03-17 05:03:47,710 INFO     Evaluating the model... (11000/26842)
2023-03-17 05:03:48,960 INFO     Evaluating the model... (12000/26842)
2023-03-17 05:03:50,205 INFO     Evaluating the model... (13000/26842)
2023-03-17 05:03:52,495 INFO     Evaluating the model... (14000/26842)
2023-03-17 05:03:53,991 INFO     Evaluating the model... (15000/26842)
2023-03-17 05:03:55,472 INFO     Evaluating the model... (16000/26842)
2023-03-17 05:03:56,955 INFO     Evaluating the model... (17000/26842)
2023-03-17 05:03:58,437 INFO     Evaluating the model... (18000/26842)
2023-03-17 05:03:59,920 INFO     Evaluating the model... (19000/26842)
2023-03-17 05:04:01,419 INFO     Evaluating the model... (20000/26842)
2023-03-17 05:04:02,889 INFO     Evaluating the model... (21000/26842)
2023-03-17 05:04:04,369 INFO     Evaluating the model... (22000/26842)
2023-03-17 05:04:05,854 INFO     Evaluating the model... (23000/26842)
2023-03-17 05:04:07,338 INFO     Evaluating the model... (24000/26842)
2023-03-17 05:04:08,825 INFO     Evaluating the model... (25000/26842)
2023-03-17 05:04:10,310 INFO     Evaluating the model... (26000/26842)
2023-03-17 05:04:11,902 INFO     Valid hits@1_list at step 240000: 0.655312
2023-03-17 05:04:11,902 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 05:04:11,902 INFO     Valid hits@3_list at step 240000: 0.745887
2023-03-17 05:04:11,902 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 05:04:11,902 INFO     Valid hits@10_list at step 240000: 0.834959
2023-03-17 05:04:11,903 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 05:04:11,903 INFO     Valid mrr_list at step 240000: 0.716619
2023-03-17 05:04:31,232 INFO     Train positive_sample_loss at step 240100: 0.057772
2023-03-17 05:04:31,233 INFO     Train negative_sample_loss at step 240100: 0.056326
2023-03-17 05:04:31,233 INFO     Train loss at step 240100: 0.057049
2023-03-17 05:04:58,531 INFO     Train positive_sample_loss at step 240200: 0.058626
2023-03-17 05:04:58,532 INFO     Train negative_sample_loss at step 240200: 0.056146
2023-03-17 05:04:58,532 INFO     Train loss at step 240200: 0.057386
2023-03-17 05:05:17,873 INFO     Train positive_sample_loss at step 240300: 0.059403
2023-03-17 05:05:17,873 INFO     Train negative_sample_loss at step 240300: 0.056021
2023-03-17 05:05:17,873 INFO     Train loss at step 240300: 0.057712
2023-03-17 05:05:37,205 INFO     Train positive_sample_loss at step 240400: 0.060084
2023-03-17 05:05:37,206 INFO     Train negative_sample_loss at step 240400: 0.055376
2023-03-17 05:05:37,206 INFO     Train loss at step 240400: 0.057730
2023-03-17 05:05:56,542 INFO     Train positive_sample_loss at step 240500: 0.060482
2023-03-17 05:05:56,543 INFO     Train negative_sample_loss at step 240500: 0.056014
2023-03-17 05:05:56,543 INFO     Train loss at step 240500: 0.058248
2023-03-17 05:06:15,876 INFO     Train positive_sample_loss at step 240600: 0.061094
2023-03-17 05:06:15,876 INFO     Train negative_sample_loss at step 240600: 0.055392
2023-03-17 05:06:15,876 INFO     Train loss at step 240600: 0.058243
2023-03-17 05:06:35,210 INFO     Train positive_sample_loss at step 240700: 0.061393
2023-03-17 05:06:35,210 INFO     Train negative_sample_loss at step 240700: 0.055429
2023-03-17 05:06:35,211 INFO     Train loss at step 240700: 0.058411
2023-03-17 05:06:54,544 INFO     Train positive_sample_loss at step 240800: 0.061942
2023-03-17 05:06:54,545 INFO     Train negative_sample_loss at step 240800: 0.055647
2023-03-17 05:06:54,545 INFO     Train loss at step 240800: 0.058795
2023-03-17 05:07:13,873 INFO     Train positive_sample_loss at step 240900: 0.062236
2023-03-17 05:07:13,873 INFO     Train negative_sample_loss at step 240900: 0.055336
2023-03-17 05:07:13,873 INFO     Train loss at step 240900: 0.058786
2023-03-17 05:07:33,211 INFO     Train positive_sample_loss at step 241000: 0.062499
2023-03-17 05:07:33,211 INFO     Train negative_sample_loss at step 241000: 0.055138
2023-03-17 05:07:33,211 INFO     Train loss at step 241000: 0.058818
2023-03-17 05:07:52,542 INFO     Train positive_sample_loss at step 241100: 0.063219
2023-03-17 05:07:52,542 INFO     Train negative_sample_loss at step 241100: 0.055449
2023-03-17 05:07:52,542 INFO     Train loss at step 241100: 0.059334
2023-03-17 05:08:18,909 INFO     Train positive_sample_loss at step 241200: 0.063294
2023-03-17 05:08:18,909 INFO     Train negative_sample_loss at step 241200: 0.055543
2023-03-17 05:08:18,909 INFO     Train loss at step 241200: 0.059418
2023-03-17 05:08:38,240 INFO     Train positive_sample_loss at step 241300: 0.063360
2023-03-17 05:08:38,240 INFO     Train negative_sample_loss at step 241300: 0.055364
2023-03-17 05:08:38,241 INFO     Train loss at step 241300: 0.059362
2023-03-17 05:08:57,574 INFO     Train positive_sample_loss at step 241400: 0.063875
2023-03-17 05:08:57,575 INFO     Train negative_sample_loss at step 241400: 0.055255
2023-03-17 05:08:57,575 INFO     Train loss at step 241400: 0.059565
2023-03-17 05:09:16,906 INFO     Train positive_sample_loss at step 241500: 0.064174
2023-03-17 05:09:16,906 INFO     Train negative_sample_loss at step 241500: 0.055447
2023-03-17 05:09:16,906 INFO     Train loss at step 241500: 0.059811
2023-03-17 05:09:36,241 INFO     Train positive_sample_loss at step 241600: 0.064471
2023-03-17 05:09:36,242 INFO     Train negative_sample_loss at step 241600: 0.055545
2023-03-17 05:09:36,242 INFO     Train loss at step 241600: 0.060008
2023-03-17 05:09:55,590 INFO     Train positive_sample_loss at step 241700: 0.064483
2023-03-17 05:09:55,590 INFO     Train negative_sample_loss at step 241700: 0.055946
2023-03-17 05:09:55,590 INFO     Train loss at step 241700: 0.060215
2023-03-17 05:10:14,922 INFO     Train positive_sample_loss at step 241800: 0.064850
2023-03-17 05:10:14,923 INFO     Train negative_sample_loss at step 241800: 0.055909
2023-03-17 05:10:14,923 INFO     Train loss at step 241800: 0.060379
2023-03-17 05:10:34,257 INFO     Train positive_sample_loss at step 241900: 0.064773
2023-03-17 05:10:34,257 INFO     Train negative_sample_loss at step 241900: 0.056204
2023-03-17 05:10:34,257 INFO     Train loss at step 241900: 0.060489
2023-03-17 05:10:53,590 INFO     Train positive_sample_loss at step 242000: 0.065033
2023-03-17 05:10:53,591 INFO     Train negative_sample_loss at step 242000: 0.055956
2023-03-17 05:10:53,591 INFO     Train loss at step 242000: 0.060494
2023-03-17 05:11:12,928 INFO     Train positive_sample_loss at step 242100: 0.065373
2023-03-17 05:11:12,929 INFO     Train negative_sample_loss at step 242100: 0.055771
2023-03-17 05:11:12,929 INFO     Train loss at step 242100: 0.060572
2023-03-17 05:11:32,265 INFO     Train positive_sample_loss at step 242200: 0.065160
2023-03-17 05:11:32,266 INFO     Train negative_sample_loss at step 242200: 0.055972
2023-03-17 05:11:32,266 INFO     Train loss at step 242200: 0.060566
2023-03-17 05:11:58,524 INFO     Train positive_sample_loss at step 242300: 0.065554
2023-03-17 05:11:58,524 INFO     Train negative_sample_loss at step 242300: 0.055972
2023-03-17 05:11:58,525 INFO     Train loss at step 242300: 0.060763
2023-03-17 05:12:17,866 INFO     Train positive_sample_loss at step 242400: 0.065803
2023-03-17 05:12:17,867 INFO     Train negative_sample_loss at step 242400: 0.056401
2023-03-17 05:12:17,867 INFO     Train loss at step 242400: 0.061102
2023-03-17 05:12:37,206 INFO     Train positive_sample_loss at step 242500: 0.065455
2023-03-17 05:12:37,206 INFO     Train negative_sample_loss at step 242500: 0.055843
2023-03-17 05:12:37,207 INFO     Train loss at step 242500: 0.060649
2023-03-17 05:12:56,544 INFO     Train positive_sample_loss at step 242600: 0.065557
2023-03-17 05:12:56,545 INFO     Train negative_sample_loss at step 242600: 0.056454
2023-03-17 05:12:56,545 INFO     Train loss at step 242600: 0.061005
2023-03-17 05:13:15,882 INFO     Train positive_sample_loss at step 242700: 0.065641
2023-03-17 05:13:15,883 INFO     Train negative_sample_loss at step 242700: 0.056755
2023-03-17 05:13:15,883 INFO     Train loss at step 242700: 0.061198
2023-03-17 05:13:35,222 INFO     Train positive_sample_loss at step 242800: 0.065614
2023-03-17 05:13:35,223 INFO     Train negative_sample_loss at step 242800: 0.056534
2023-03-17 05:13:35,223 INFO     Train loss at step 242800: 0.061074
2023-03-17 05:13:54,565 INFO     Train positive_sample_loss at step 242900: 0.065891
2023-03-17 05:13:54,566 INFO     Train negative_sample_loss at step 242900: 0.056435
2023-03-17 05:13:54,566 INFO     Train loss at step 242900: 0.061163
2023-03-17 05:14:13,896 INFO     Train positive_sample_loss at step 243000: 0.065863
2023-03-17 05:14:13,896 INFO     Train negative_sample_loss at step 243000: 0.056279
2023-03-17 05:14:13,896 INFO     Train loss at step 243000: 0.061071
2023-03-17 05:14:33,231 INFO     Train positive_sample_loss at step 243100: 0.065988
2023-03-17 05:14:33,232 INFO     Train negative_sample_loss at step 243100: 0.056317
2023-03-17 05:14:33,232 INFO     Train loss at step 243100: 0.061153
2023-03-17 05:14:52,564 INFO     Train positive_sample_loss at step 243200: 0.066038
2023-03-17 05:14:52,565 INFO     Train negative_sample_loss at step 243200: 0.056141
2023-03-17 05:14:52,565 INFO     Train loss at step 243200: 0.061090
2023-03-17 05:15:11,901 INFO     Train positive_sample_loss at step 243300: 0.066012
2023-03-17 05:15:11,901 INFO     Train negative_sample_loss at step 243300: 0.056659
2023-03-17 05:15:11,902 INFO     Train loss at step 243300: 0.061335
2023-03-17 05:15:38,208 INFO     Train positive_sample_loss at step 243400: 0.065788
2023-03-17 05:15:38,208 INFO     Train negative_sample_loss at step 243400: 0.056226
2023-03-17 05:15:38,209 INFO     Train loss at step 243400: 0.061007
2023-03-17 05:15:57,535 INFO     Train positive_sample_loss at step 243500: 0.066030
2023-03-17 05:15:57,535 INFO     Train negative_sample_loss at step 243500: 0.057021
2023-03-17 05:15:57,535 INFO     Train loss at step 243500: 0.061525
2023-03-17 05:16:16,867 INFO     Train positive_sample_loss at step 243600: 0.065989
2023-03-17 05:16:16,867 INFO     Train negative_sample_loss at step 243600: 0.056829
2023-03-17 05:16:16,867 INFO     Train loss at step 243600: 0.061409
2023-03-17 05:16:36,206 INFO     Train positive_sample_loss at step 243700: 0.066080
2023-03-17 05:16:36,207 INFO     Train negative_sample_loss at step 243700: 0.057195
2023-03-17 05:16:36,207 INFO     Train loss at step 243700: 0.061637
2023-03-17 05:16:55,551 INFO     Train positive_sample_loss at step 243800: 0.066111
2023-03-17 05:16:55,552 INFO     Train negative_sample_loss at step 243800: 0.056671
2023-03-17 05:16:55,552 INFO     Train loss at step 243800: 0.061391
2023-03-17 05:17:16,741 INFO     Train positive_sample_loss at step 243900: 0.066113
2023-03-17 05:17:16,741 INFO     Train negative_sample_loss at step 243900: 0.057097
2023-03-17 05:17:16,741 INFO     Train loss at step 243900: 0.061605
funtion time use:38804ms
2023-03-17 05:17:39,878 INFO     Train positive_sample_loss at step 244000: 0.058056
2023-03-17 05:17:39,879 INFO     Train negative_sample_loss at step 244000: 0.056177
2023-03-17 05:17:39,879 INFO     Train loss at step 244000: 0.057117
2023-03-17 05:18:07,093 INFO     Train positive_sample_loss at step 244100: 0.058381
2023-03-17 05:18:07,093 INFO     Train negative_sample_loss at step 244100: 0.056173
2023-03-17 05:18:07,093 INFO     Train loss at step 244100: 0.057277
2023-03-17 05:18:26,420 INFO     Train positive_sample_loss at step 244200: 0.059005
2023-03-17 05:18:26,421 INFO     Train negative_sample_loss at step 244200: 0.055913
2023-03-17 05:18:26,421 INFO     Train loss at step 244200: 0.057459
2023-03-17 05:18:45,748 INFO     Train positive_sample_loss at step 244300: 0.059623
2023-03-17 05:18:45,749 INFO     Train negative_sample_loss at step 244300: 0.056208
2023-03-17 05:18:45,749 INFO     Train loss at step 244300: 0.057916
2023-03-17 05:19:05,066 INFO     Train positive_sample_loss at step 244400: 0.060077
2023-03-17 05:19:05,066 INFO     Train negative_sample_loss at step 244400: 0.055102
2023-03-17 05:19:05,066 INFO     Train loss at step 244400: 0.057590
2023-03-17 05:19:24,391 INFO     Train positive_sample_loss at step 244500: 0.060895
2023-03-17 05:19:24,391 INFO     Train negative_sample_loss at step 244500: 0.055226
2023-03-17 05:19:24,392 INFO     Train loss at step 244500: 0.058061
2023-03-17 05:19:43,724 INFO     Train positive_sample_loss at step 244600: 0.061113
2023-03-17 05:19:43,724 INFO     Train negative_sample_loss at step 244600: 0.055446
2023-03-17 05:19:43,724 INFO     Train loss at step 244600: 0.058279
2023-03-17 05:20:03,053 INFO     Train positive_sample_loss at step 244700: 0.061653
2023-03-17 05:20:03,053 INFO     Train negative_sample_loss at step 244700: 0.054998
2023-03-17 05:20:03,053 INFO     Train loss at step 244700: 0.058326
2023-03-17 05:20:22,380 INFO     Train positive_sample_loss at step 244800: 0.062006
2023-03-17 05:20:22,380 INFO     Train negative_sample_loss at step 244800: 0.055182
2023-03-17 05:20:22,380 INFO     Train loss at step 244800: 0.058594
2023-03-17 05:20:41,715 INFO     Train positive_sample_loss at step 244900: 0.062557
2023-03-17 05:20:41,715 INFO     Train negative_sample_loss at step 244900: 0.055540
2023-03-17 05:20:41,715 INFO     Train loss at step 244900: 0.059049
2023-03-17 05:21:01,040 INFO     Train positive_sample_loss at step 245000: 0.062826
2023-03-17 05:21:01,041 INFO     Train negative_sample_loss at step 245000: 0.054717
2023-03-17 05:21:01,041 INFO     Train loss at step 245000: 0.058772
2023-03-17 05:21:27,226 INFO     Train positive_sample_loss at step 245100: 0.062927
2023-03-17 05:21:27,227 INFO     Train negative_sample_loss at step 245100: 0.055572
2023-03-17 05:21:27,227 INFO     Train loss at step 245100: 0.059250
2023-03-17 05:21:46,554 INFO     Train positive_sample_loss at step 245200: 0.063081
2023-03-17 05:21:46,554 INFO     Train negative_sample_loss at step 245200: 0.054720
2023-03-17 05:21:46,554 INFO     Train loss at step 245200: 0.058901
2023-03-17 05:22:05,879 INFO     Train positive_sample_loss at step 245300: 0.063628
2023-03-17 05:22:05,879 INFO     Train negative_sample_loss at step 245300: 0.055351
2023-03-17 05:22:05,879 INFO     Train loss at step 245300: 0.059489
2023-03-17 05:22:25,208 INFO     Train positive_sample_loss at step 245400: 0.063578
2023-03-17 05:22:25,208 INFO     Train negative_sample_loss at step 245400: 0.054836
2023-03-17 05:22:25,209 INFO     Train loss at step 245400: 0.059207
2023-03-17 05:22:44,528 INFO     Train positive_sample_loss at step 245500: 0.064089
2023-03-17 05:22:44,528 INFO     Train negative_sample_loss at step 245500: 0.055640
2023-03-17 05:22:44,528 INFO     Train loss at step 245500: 0.059865
2023-03-17 05:23:03,852 INFO     Train positive_sample_loss at step 245600: 0.064594
2023-03-17 05:23:03,853 INFO     Train negative_sample_loss at step 245600: 0.056010
2023-03-17 05:23:03,853 INFO     Train loss at step 245600: 0.060302
2023-03-17 05:23:23,176 INFO     Train positive_sample_loss at step 245700: 0.064535
2023-03-17 05:23:23,177 INFO     Train negative_sample_loss at step 245700: 0.055993
2023-03-17 05:23:23,177 INFO     Train loss at step 245700: 0.060264
2023-03-17 05:23:42,506 INFO     Train positive_sample_loss at step 245800: 0.064561
2023-03-17 05:23:42,506 INFO     Train negative_sample_loss at step 245800: 0.055796
2023-03-17 05:23:42,506 INFO     Train loss at step 245800: 0.060178
2023-03-17 05:24:01,829 INFO     Train positive_sample_loss at step 245900: 0.064871
2023-03-17 05:24:01,830 INFO     Train negative_sample_loss at step 245900: 0.056038
2023-03-17 05:24:01,830 INFO     Train loss at step 245900: 0.060455
2023-03-17 05:24:21,149 INFO     Train positive_sample_loss at step 246000: 0.064918
2023-03-17 05:24:21,149 INFO     Train negative_sample_loss at step 246000: 0.055418
2023-03-17 05:24:21,150 INFO     Train loss at step 246000: 0.060168
2023-03-17 05:24:40,479 INFO     Train positive_sample_loss at step 246100: 0.065220
2023-03-17 05:24:40,479 INFO     Train negative_sample_loss at step 246100: 0.056196
2023-03-17 05:24:40,479 INFO     Train loss at step 246100: 0.060708
2023-03-17 05:25:06,596 INFO     Train positive_sample_loss at step 246200: 0.065422
2023-03-17 05:25:06,596 INFO     Train negative_sample_loss at step 246200: 0.056272
2023-03-17 05:25:06,596 INFO     Train loss at step 246200: 0.060847
2023-03-17 05:25:25,929 INFO     Train positive_sample_loss at step 246300: 0.065256
2023-03-17 05:25:25,929 INFO     Train negative_sample_loss at step 246300: 0.056081
2023-03-17 05:25:25,929 INFO     Train loss at step 246300: 0.060669
2023-03-17 05:25:45,268 INFO     Train positive_sample_loss at step 246400: 0.065535
2023-03-17 05:25:45,269 INFO     Train negative_sample_loss at step 246400: 0.055993
2023-03-17 05:25:45,269 INFO     Train loss at step 246400: 0.060764
2023-03-17 05:26:04,596 INFO     Train positive_sample_loss at step 246500: 0.065378
2023-03-17 05:26:04,597 INFO     Train negative_sample_loss at step 246500: 0.055733
2023-03-17 05:26:04,597 INFO     Train loss at step 246500: 0.060555
2023-03-17 05:26:23,934 INFO     Train positive_sample_loss at step 246600: 0.065420
2023-03-17 05:26:23,935 INFO     Train negative_sample_loss at step 246600: 0.056245
2023-03-17 05:26:23,935 INFO     Train loss at step 246600: 0.060833
2023-03-17 05:26:43,266 INFO     Train positive_sample_loss at step 246700: 0.065561
2023-03-17 05:26:43,266 INFO     Train negative_sample_loss at step 246700: 0.055719
2023-03-17 05:26:43,267 INFO     Train loss at step 246700: 0.060640
2023-03-17 05:27:02,612 INFO     Train positive_sample_loss at step 246800: 0.065733
2023-03-17 05:27:02,612 INFO     Train negative_sample_loss at step 246800: 0.056211
2023-03-17 05:27:02,612 INFO     Train loss at step 246800: 0.060972
2023-03-17 05:27:21,954 INFO     Train positive_sample_loss at step 246900: 0.065822
2023-03-17 05:27:21,954 INFO     Train negative_sample_loss at step 246900: 0.056127
2023-03-17 05:27:21,954 INFO     Train loss at step 246900: 0.060975
2023-03-17 05:27:41,281 INFO     Train positive_sample_loss at step 247000: 0.065880
2023-03-17 05:27:41,282 INFO     Train negative_sample_loss at step 247000: 0.056467
2023-03-17 05:27:41,282 INFO     Train loss at step 247000: 0.061174
2023-03-17 05:28:00,609 INFO     Train positive_sample_loss at step 247100: 0.065868
2023-03-17 05:28:00,609 INFO     Train negative_sample_loss at step 247100: 0.056821
2023-03-17 05:28:00,609 INFO     Train loss at step 247100: 0.061344
2023-03-17 05:28:19,939 INFO     Train positive_sample_loss at step 247200: 0.065806
2023-03-17 05:28:19,940 INFO     Train negative_sample_loss at step 247200: 0.056250
2023-03-17 05:28:19,940 INFO     Train loss at step 247200: 0.061028
2023-03-17 05:28:46,202 INFO     Train positive_sample_loss at step 247300: 0.065905
2023-03-17 05:28:46,203 INFO     Train negative_sample_loss at step 247300: 0.055883
2023-03-17 05:28:46,203 INFO     Train loss at step 247300: 0.060894
2023-03-17 05:29:05,530 INFO     Train positive_sample_loss at step 247400: 0.065859
2023-03-17 05:29:05,531 INFO     Train negative_sample_loss at step 247400: 0.056212
2023-03-17 05:29:05,531 INFO     Train loss at step 247400: 0.061035
2023-03-17 05:29:24,857 INFO     Train positive_sample_loss at step 247500: 0.065763
2023-03-17 05:29:24,857 INFO     Train negative_sample_loss at step 247500: 0.056906
2023-03-17 05:29:24,857 INFO     Train loss at step 247500: 0.061334
2023-03-17 05:29:44,186 INFO     Train positive_sample_loss at step 247600: 0.065804
2023-03-17 05:29:44,187 INFO     Train negative_sample_loss at step 247600: 0.056815
2023-03-17 05:29:44,187 INFO     Train loss at step 247600: 0.061309
2023-03-17 05:30:03,522 INFO     Train positive_sample_loss at step 247700: 0.065790
2023-03-17 05:30:03,522 INFO     Train negative_sample_loss at step 247700: 0.055994
2023-03-17 05:30:03,522 INFO     Train loss at step 247700: 0.060892
2023-03-17 05:30:22,851 INFO     Train positive_sample_loss at step 247800: 0.065976
2023-03-17 05:30:22,851 INFO     Train negative_sample_loss at step 247800: 0.056712
2023-03-17 05:30:22,852 INFO     Train loss at step 247800: 0.061344
2023-03-17 05:30:47,830 INFO     Train positive_sample_loss at step 247900: 0.060641
2023-03-17 05:30:47,830 INFO     Train negative_sample_loss at step 247900: 0.056219
2023-03-17 05:30:47,830 INFO     Train loss at step 247900: 0.058430
2023-03-17 05:31:15,098 INFO     Train positive_sample_loss at step 248000: 0.057846
2023-03-17 05:31:15,098 INFO     Train negative_sample_loss at step 248000: 0.056177
2023-03-17 05:31:15,099 INFO     Train loss at step 248000: 0.057012
2023-03-17 05:31:34,423 INFO     Train positive_sample_loss at step 248100: 0.058598
2023-03-17 05:31:34,423 INFO     Train negative_sample_loss at step 248100: 0.055815
2023-03-17 05:31:34,423 INFO     Train loss at step 248100: 0.057207
2023-03-17 05:31:53,752 INFO     Train positive_sample_loss at step 248200: 0.059137
2023-03-17 05:31:53,752 INFO     Train negative_sample_loss at step 248200: 0.056046
2023-03-17 05:31:53,752 INFO     Train loss at step 248200: 0.057591
2023-03-17 05:32:13,088 INFO     Train positive_sample_loss at step 248300: 0.059782
2023-03-17 05:32:13,089 INFO     Train negative_sample_loss at step 248300: 0.055946
2023-03-17 05:32:13,089 INFO     Train loss at step 248300: 0.057864
2023-03-17 05:32:32,423 INFO     Train positive_sample_loss at step 248400: 0.060421
2023-03-17 05:32:32,424 INFO     Train negative_sample_loss at step 248400: 0.055140
2023-03-17 05:32:32,424 INFO     Train loss at step 248400: 0.057781
2023-03-17 05:32:51,757 INFO     Train positive_sample_loss at step 248500: 0.060760
2023-03-17 05:32:51,757 INFO     Train negative_sample_loss at step 248500: 0.055730
2023-03-17 05:32:51,757 INFO     Train loss at step 248500: 0.058245
2023-03-17 05:33:11,086 INFO     Train positive_sample_loss at step 248600: 0.061335
2023-03-17 05:33:11,086 INFO     Train negative_sample_loss at step 248600: 0.055627
2023-03-17 05:33:11,087 INFO     Train loss at step 248600: 0.058481
2023-03-17 05:33:30,421 INFO     Train positive_sample_loss at step 248700: 0.061833
2023-03-17 05:33:30,422 INFO     Train negative_sample_loss at step 248700: 0.055288
2023-03-17 05:33:30,422 INFO     Train loss at step 248700: 0.058561
2023-03-17 05:33:49,750 INFO     Train positive_sample_loss at step 248800: 0.062027
2023-03-17 05:33:49,751 INFO     Train negative_sample_loss at step 248800: 0.054827
2023-03-17 05:33:49,751 INFO     Train loss at step 248800: 0.058427
2023-03-17 05:34:09,079 INFO     Train positive_sample_loss at step 248900: 0.062450
2023-03-17 05:34:09,079 INFO     Train negative_sample_loss at step 248900: 0.055447
2023-03-17 05:34:09,080 INFO     Train loss at step 248900: 0.058948
2023-03-17 05:34:28,412 INFO     Train positive_sample_loss at step 249000: 0.062851
2023-03-17 05:34:28,412 INFO     Train negative_sample_loss at step 249000: 0.054887
2023-03-17 05:34:28,412 INFO     Train loss at step 249000: 0.058869
2023-03-17 05:34:54,650 INFO     Train positive_sample_loss at step 249100: 0.062982
2023-03-17 05:34:54,651 INFO     Train negative_sample_loss at step 249100: 0.055217
2023-03-17 05:34:54,651 INFO     Train loss at step 249100: 0.059100
2023-03-17 05:35:13,980 INFO     Train positive_sample_loss at step 249200: 0.063391
2023-03-17 05:35:13,980 INFO     Train negative_sample_loss at step 249200: 0.055406
2023-03-17 05:35:13,980 INFO     Train loss at step 249200: 0.059398
2023-03-17 05:35:33,306 INFO     Train positive_sample_loss at step 249300: 0.063776
2023-03-17 05:35:33,306 INFO     Train negative_sample_loss at step 249300: 0.055521
2023-03-17 05:35:33,306 INFO     Train loss at step 249300: 0.059648
2023-03-17 05:35:52,630 INFO     Train positive_sample_loss at step 249400: 0.063955
2023-03-17 05:35:52,631 INFO     Train negative_sample_loss at step 249400: 0.055385
2023-03-17 05:35:52,631 INFO     Train loss at step 249400: 0.059670
2023-03-17 05:36:11,958 INFO     Train positive_sample_loss at step 249500: 0.064210
2023-03-17 05:36:11,958 INFO     Train negative_sample_loss at step 249500: 0.055781
2023-03-17 05:36:11,958 INFO     Train loss at step 249500: 0.059996
2023-03-17 05:36:31,291 INFO     Train positive_sample_loss at step 249600: 0.064381
2023-03-17 05:36:31,291 INFO     Train negative_sample_loss at step 249600: 0.055423
2023-03-17 05:36:31,291 INFO     Train loss at step 249600: 0.059902
2023-03-17 05:36:50,634 INFO     Train positive_sample_loss at step 249700: 0.064551
2023-03-17 05:36:50,635 INFO     Train negative_sample_loss at step 249700: 0.055956
2023-03-17 05:36:50,635 INFO     Train loss at step 249700: 0.060253
2023-03-17 05:37:09,976 INFO     Train positive_sample_loss at step 249800: 0.064608
2023-03-17 05:37:09,976 INFO     Train negative_sample_loss at step 249800: 0.055735
2023-03-17 05:37:09,976 INFO     Train loss at step 249800: 0.060171
2023-03-17 05:37:29,299 INFO     Train positive_sample_loss at step 249900: 0.064803
2023-03-17 05:37:29,299 INFO     Train negative_sample_loss at step 249900: 0.055785
2023-03-17 05:37:29,299 INFO     Train loss at step 249900: 0.060294
2023-03-17 05:37:50,294 INFO     Train positive_sample_loss at step 250000: 0.064994
2023-03-17 05:37:50,294 INFO     Train negative_sample_loss at step 250000: 0.055874
2023-03-17 05:37:50,294 INFO     Train loss at step 250000: 0.060434
2023-03-17 05:37:50,294 INFO     Evaluating on Valid Dataset...
2023-03-17 05:37:51,291 INFO     Evaluating the model... (0/26842)
2023-03-17 05:37:52,964 INFO     Evaluating the model... (1000/26842)
2023-03-17 05:37:54,194 INFO     Evaluating the model... (2000/26842)
2023-03-17 05:37:55,427 INFO     Evaluating the model... (3000/26842)
2023-03-17 05:37:56,656 INFO     Evaluating the model... (4000/26842)
2023-03-17 05:37:57,887 INFO     Evaluating the model... (5000/26842)
2023-03-17 05:37:59,118 INFO     Evaluating the model... (6000/26842)
2023-03-17 05:38:00,351 INFO     Evaluating the model... (7000/26842)
2023-03-17 05:38:01,592 INFO     Evaluating the model... (8000/26842)
2023-03-17 05:38:02,827 INFO     Evaluating the model... (9000/26842)
2023-03-17 05:38:04,068 INFO     Evaluating the model... (10000/26842)
2023-03-17 05:38:05,304 INFO     Evaluating the model... (11000/26842)
2023-03-17 05:38:06,531 INFO     Evaluating the model... (12000/26842)
2023-03-17 05:38:07,759 INFO     Evaluating the model... (13000/26842)
2023-03-17 05:38:10,047 INFO     Evaluating the model... (14000/26842)
2023-03-17 05:38:11,533 INFO     Evaluating the model... (15000/26842)
2023-03-17 05:38:13,012 INFO     Evaluating the model... (16000/26842)
2023-03-17 05:38:14,490 INFO     Evaluating the model... (17000/26842)
2023-03-17 05:38:15,978 INFO     Evaluating the model... (18000/26842)
2023-03-17 05:38:17,480 INFO     Evaluating the model... (19000/26842)
2023-03-17 05:38:18,964 INFO     Evaluating the model... (20000/26842)
2023-03-17 05:38:20,448 INFO     Evaluating the model... (21000/26842)
2023-03-17 05:38:21,926 INFO     Evaluating the model... (22000/26842)
2023-03-17 05:38:23,398 INFO     Evaluating the model... (23000/26842)
2023-03-17 05:38:24,871 INFO     Evaluating the model... (24000/26842)
2023-03-17 05:38:26,343 INFO     Evaluating the model... (25000/26842)
2023-03-17 05:38:27,820 INFO     Evaluating the model... (26000/26842)
2023-03-17 05:38:29,378 INFO     Valid hits@1_list at step 250000: 0.655521
2023-03-17 05:38:29,379 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 05:38:29,379 INFO     Valid hits@3_list at step 250000: 0.745419
2023-03-17 05:38:29,379 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 05:38:29,379 INFO     Valid hits@10_list at step 250000: 0.834755
2023-03-17 05:38:29,379 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 05:38:29,379 INFO     Valid mrr_list at step 250000: 0.716589
2023-03-17 05:38:55,675 INFO     Train positive_sample_loss at step 250100: 0.065151
2023-03-17 05:38:55,675 INFO     Train negative_sample_loss at step 250100: 0.056011
2023-03-17 05:38:55,675 INFO     Train loss at step 250100: 0.060581
2023-03-17 05:39:15,021 INFO     Train positive_sample_loss at step 250200: 0.065105
2023-03-17 05:39:15,022 INFO     Train negative_sample_loss at step 250200: 0.056156
2023-03-17 05:39:15,022 INFO     Train loss at step 250200: 0.060630
2023-03-17 05:39:34,366 INFO     Train positive_sample_loss at step 250300: 0.065203
2023-03-17 05:39:34,367 INFO     Train negative_sample_loss at step 250300: 0.055548
2023-03-17 05:39:34,367 INFO     Train loss at step 250300: 0.060376
2023-03-17 05:39:53,717 INFO     Train positive_sample_loss at step 250400: 0.065528
2023-03-17 05:39:53,718 INFO     Train negative_sample_loss at step 250400: 0.055818
2023-03-17 05:39:53,718 INFO     Train loss at step 250400: 0.060673
2023-03-17 05:40:13,067 INFO     Train positive_sample_loss at step 250500: 0.065622
2023-03-17 05:40:13,067 INFO     Train negative_sample_loss at step 250500: 0.055803
2023-03-17 05:40:13,068 INFO     Train loss at step 250500: 0.060712
2023-03-17 05:40:32,410 INFO     Train positive_sample_loss at step 250600: 0.065340
2023-03-17 05:40:32,410 INFO     Train negative_sample_loss at step 250600: 0.055945
2023-03-17 05:40:32,411 INFO     Train loss at step 250600: 0.060642
2023-03-17 05:40:51,748 INFO     Train positive_sample_loss at step 250700: 0.065535
2023-03-17 05:40:51,749 INFO     Train negative_sample_loss at step 250700: 0.055717
2023-03-17 05:40:51,749 INFO     Train loss at step 250700: 0.060626
2023-03-17 05:41:11,088 INFO     Train positive_sample_loss at step 250800: 0.065593
2023-03-17 05:41:11,088 INFO     Train negative_sample_loss at step 250800: 0.055617
2023-03-17 05:41:11,088 INFO     Train loss at step 250800: 0.060605
2023-03-17 05:41:30,433 INFO     Train positive_sample_loss at step 250900: 0.065546
2023-03-17 05:41:30,433 INFO     Train negative_sample_loss at step 250900: 0.056116
2023-03-17 05:41:30,433 INFO     Train loss at step 250900: 0.060831
2023-03-17 05:41:49,781 INFO     Train positive_sample_loss at step 251000: 0.065566
2023-03-17 05:41:49,782 INFO     Train negative_sample_loss at step 251000: 0.056303
2023-03-17 05:41:49,782 INFO     Train loss at step 251000: 0.060935
2023-03-17 05:42:09,119 INFO     Train positive_sample_loss at step 251100: 0.065718
2023-03-17 05:42:09,120 INFO     Train negative_sample_loss at step 251100: 0.056700
2023-03-17 05:42:09,120 INFO     Train loss at step 251100: 0.061209
2023-03-17 05:42:35,562 INFO     Train positive_sample_loss at step 251200: 0.065525
2023-03-17 05:42:35,563 INFO     Train negative_sample_loss at step 251200: 0.056694
2023-03-17 05:42:35,563 INFO     Train loss at step 251200: 0.061109
2023-03-17 05:42:54,898 INFO     Train positive_sample_loss at step 251300: 0.065889
2023-03-17 05:42:54,898 INFO     Train negative_sample_loss at step 251300: 0.055947
2023-03-17 05:42:54,898 INFO     Train loss at step 251300: 0.060918
2023-03-17 05:43:14,232 INFO     Train positive_sample_loss at step 251400: 0.065542
2023-03-17 05:43:14,233 INFO     Train negative_sample_loss at step 251400: 0.055637
2023-03-17 05:43:14,233 INFO     Train loss at step 251400: 0.060590
2023-03-17 05:43:33,570 INFO     Train positive_sample_loss at step 251500: 0.065773
2023-03-17 05:43:33,571 INFO     Train negative_sample_loss at step 251500: 0.056361
2023-03-17 05:43:33,571 INFO     Train loss at step 251500: 0.061067
2023-03-17 05:43:52,914 INFO     Train positive_sample_loss at step 251600: 0.065850
2023-03-17 05:43:52,914 INFO     Train negative_sample_loss at step 251600: 0.056172
2023-03-17 05:43:52,914 INFO     Train loss at step 251600: 0.061011
2023-03-17 05:44:12,249 INFO     Train positive_sample_loss at step 251700: 0.065552
2023-03-17 05:44:12,250 INFO     Train negative_sample_loss at step 251700: 0.056379
2023-03-17 05:44:12,250 INFO     Train loss at step 251700: 0.060966
funtion time use:38907ms
2023-03-17 05:44:37,327 INFO     Train positive_sample_loss at step 251800: 0.063545
2023-03-17 05:44:37,328 INFO     Train negative_sample_loss at step 251800: 0.057100
2023-03-17 05:44:37,328 INFO     Train loss at step 251800: 0.060322
2023-03-17 05:45:04,759 INFO     Train positive_sample_loss at step 251900: 0.057139
2023-03-17 05:45:04,760 INFO     Train negative_sample_loss at step 251900: 0.055444
2023-03-17 05:45:04,760 INFO     Train loss at step 251900: 0.056291
2023-03-17 05:45:24,092 INFO     Train positive_sample_loss at step 252000: 0.058388
2023-03-17 05:45:24,093 INFO     Train negative_sample_loss at step 252000: 0.055957
2023-03-17 05:45:24,093 INFO     Train loss at step 252000: 0.057173
2023-03-17 05:45:43,412 INFO     Train positive_sample_loss at step 252100: 0.058997
2023-03-17 05:45:43,412 INFO     Train negative_sample_loss at step 252100: 0.055204
2023-03-17 05:45:43,413 INFO     Train loss at step 252100: 0.057101
2023-03-17 05:46:02,734 INFO     Train positive_sample_loss at step 252200: 0.059478
2023-03-17 05:46:02,734 INFO     Train negative_sample_loss at step 252200: 0.055510
2023-03-17 05:46:02,734 INFO     Train loss at step 252200: 0.057494
2023-03-17 05:46:22,071 INFO     Train positive_sample_loss at step 252300: 0.060113
2023-03-17 05:46:22,071 INFO     Train negative_sample_loss at step 252300: 0.054948
2023-03-17 05:46:22,071 INFO     Train loss at step 252300: 0.057530
2023-03-17 05:46:41,402 INFO     Train positive_sample_loss at step 252400: 0.060636
2023-03-17 05:46:41,403 INFO     Train negative_sample_loss at step 252400: 0.055151
2023-03-17 05:46:41,403 INFO     Train loss at step 252400: 0.057894
2023-03-17 05:47:00,735 INFO     Train positive_sample_loss at step 252500: 0.061035
2023-03-17 05:47:00,735 INFO     Train negative_sample_loss at step 252500: 0.055457
2023-03-17 05:47:00,735 INFO     Train loss at step 252500: 0.058246
2023-03-17 05:47:20,061 INFO     Train positive_sample_loss at step 252600: 0.061583
2023-03-17 05:47:20,061 INFO     Train negative_sample_loss at step 252600: 0.054962
2023-03-17 05:47:20,061 INFO     Train loss at step 252600: 0.058273
2023-03-17 05:47:39,385 INFO     Train positive_sample_loss at step 252700: 0.061851
2023-03-17 05:47:39,385 INFO     Train negative_sample_loss at step 252700: 0.054842
2023-03-17 05:47:39,385 INFO     Train loss at step 252700: 0.058346
2023-03-17 05:47:58,718 INFO     Train positive_sample_loss at step 252800: 0.062109
2023-03-17 05:47:58,719 INFO     Train negative_sample_loss at step 252800: 0.055906
2023-03-17 05:47:58,719 INFO     Train loss at step 252800: 0.059008
2023-03-17 05:48:18,050 INFO     Train positive_sample_loss at step 252900: 0.062453
2023-03-17 05:48:18,050 INFO     Train negative_sample_loss at step 252900: 0.054605
2023-03-17 05:48:18,050 INFO     Train loss at step 252900: 0.058529
2023-03-17 05:48:44,198 INFO     Train positive_sample_loss at step 253000: 0.062852
2023-03-17 05:48:44,199 INFO     Train negative_sample_loss at step 253000: 0.054842
2023-03-17 05:48:44,199 INFO     Train loss at step 253000: 0.058847
2023-03-17 05:49:03,522 INFO     Train positive_sample_loss at step 253100: 0.063192
2023-03-17 05:49:03,523 INFO     Train negative_sample_loss at step 253100: 0.055245
2023-03-17 05:49:03,523 INFO     Train loss at step 253100: 0.059219
2023-03-17 05:49:22,844 INFO     Train positive_sample_loss at step 253200: 0.063477
2023-03-17 05:49:22,845 INFO     Train negative_sample_loss at step 253200: 0.054671
2023-03-17 05:49:22,845 INFO     Train loss at step 253200: 0.059074
2023-03-17 05:49:42,172 INFO     Train positive_sample_loss at step 253300: 0.063581
2023-03-17 05:49:42,173 INFO     Train negative_sample_loss at step 253300: 0.055042
2023-03-17 05:49:42,173 INFO     Train loss at step 253300: 0.059312
2023-03-17 05:50:01,511 INFO     Train positive_sample_loss at step 253400: 0.064106
2023-03-17 05:50:01,512 INFO     Train negative_sample_loss at step 253400: 0.055681
2023-03-17 05:50:01,512 INFO     Train loss at step 253400: 0.059894
2023-03-17 05:50:20,841 INFO     Train positive_sample_loss at step 253500: 0.064491
2023-03-17 05:50:20,842 INFO     Train negative_sample_loss at step 253500: 0.055420
2023-03-17 05:50:20,842 INFO     Train loss at step 253500: 0.059955
2023-03-17 05:50:40,175 INFO     Train positive_sample_loss at step 253600: 0.064259
2023-03-17 05:50:40,176 INFO     Train negative_sample_loss at step 253600: 0.055216
2023-03-17 05:50:40,176 INFO     Train loss at step 253600: 0.059737
2023-03-17 05:50:59,496 INFO     Train positive_sample_loss at step 253700: 0.064368
2023-03-17 05:50:59,497 INFO     Train negative_sample_loss at step 253700: 0.055797
2023-03-17 05:50:59,497 INFO     Train loss at step 253700: 0.060082
2023-03-17 05:51:18,830 INFO     Train positive_sample_loss at step 253800: 0.064512
2023-03-17 05:51:18,830 INFO     Train negative_sample_loss at step 253800: 0.055678
2023-03-17 05:51:18,830 INFO     Train loss at step 253800: 0.060095
2023-03-17 05:51:38,163 INFO     Train positive_sample_loss at step 253900: 0.064753
2023-03-17 05:51:38,164 INFO     Train negative_sample_loss at step 253900: 0.055175
2023-03-17 05:51:38,164 INFO     Train loss at step 253900: 0.059964
2023-03-17 05:52:04,566 INFO     Train positive_sample_loss at step 254000: 0.064749
2023-03-17 05:52:04,567 INFO     Train negative_sample_loss at step 254000: 0.055750
2023-03-17 05:52:04,567 INFO     Train loss at step 254000: 0.060250
2023-03-17 05:52:23,891 INFO     Train positive_sample_loss at step 254100: 0.065029
2023-03-17 05:52:23,892 INFO     Train negative_sample_loss at step 254100: 0.056089
2023-03-17 05:52:23,892 INFO     Train loss at step 254100: 0.060559
2023-03-17 05:52:43,224 INFO     Train positive_sample_loss at step 254200: 0.064924
2023-03-17 05:52:43,224 INFO     Train negative_sample_loss at step 254200: 0.055357
2023-03-17 05:52:43,224 INFO     Train loss at step 254200: 0.060141
2023-03-17 05:53:02,551 INFO     Train positive_sample_loss at step 254300: 0.064833
2023-03-17 05:53:02,552 INFO     Train negative_sample_loss at step 254300: 0.055534
2023-03-17 05:53:02,552 INFO     Train loss at step 254300: 0.060183
2023-03-17 05:53:21,880 INFO     Train positive_sample_loss at step 254400: 0.065348
2023-03-17 05:53:21,881 INFO     Train negative_sample_loss at step 254400: 0.056019
2023-03-17 05:53:21,881 INFO     Train loss at step 254400: 0.060683
2023-03-17 05:53:41,208 INFO     Train positive_sample_loss at step 254500: 0.065242
2023-03-17 05:53:41,208 INFO     Train negative_sample_loss at step 254500: 0.056007
2023-03-17 05:53:41,208 INFO     Train loss at step 254500: 0.060624
2023-03-17 05:54:00,533 INFO     Train positive_sample_loss at step 254600: 0.065359
2023-03-17 05:54:00,533 INFO     Train negative_sample_loss at step 254600: 0.055521
2023-03-17 05:54:00,533 INFO     Train loss at step 254600: 0.060440
2023-03-17 05:54:19,859 INFO     Train positive_sample_loss at step 254700: 0.065214
2023-03-17 05:54:19,859 INFO     Train negative_sample_loss at step 254700: 0.055146
2023-03-17 05:54:19,859 INFO     Train loss at step 254700: 0.060180
2023-03-17 05:54:39,190 INFO     Train positive_sample_loss at step 254800: 0.065583
2023-03-17 05:54:39,190 INFO     Train negative_sample_loss at step 254800: 0.056037
2023-03-17 05:54:39,191 INFO     Train loss at step 254800: 0.060810
2023-03-17 05:54:58,523 INFO     Train positive_sample_loss at step 254900: 0.065222
2023-03-17 05:54:58,523 INFO     Train negative_sample_loss at step 254900: 0.055718
2023-03-17 05:54:58,523 INFO     Train loss at step 254900: 0.060470
2023-03-17 05:55:17,860 INFO     Train positive_sample_loss at step 255000: 0.065536
2023-03-17 05:55:17,861 INFO     Train negative_sample_loss at step 255000: 0.056123
2023-03-17 05:55:17,861 INFO     Train loss at step 255000: 0.060830
2023-03-17 05:55:46,969 INFO     Train positive_sample_loss at step 255100: 0.065593
2023-03-17 05:55:46,969 INFO     Train negative_sample_loss at step 255100: 0.055934
2023-03-17 05:55:46,970 INFO     Train loss at step 255100: 0.060763
2023-03-17 05:56:06,300 INFO     Train positive_sample_loss at step 255200: 0.065387
2023-03-17 05:56:06,300 INFO     Train negative_sample_loss at step 255200: 0.056023
2023-03-17 05:56:06,300 INFO     Train loss at step 255200: 0.060705
2023-03-17 05:56:25,629 INFO     Train positive_sample_loss at step 255300: 0.065526
2023-03-17 05:56:25,630 INFO     Train negative_sample_loss at step 255300: 0.056294
2023-03-17 05:56:25,630 INFO     Train loss at step 255300: 0.060910
2023-03-17 05:56:44,972 INFO     Train positive_sample_loss at step 255400: 0.065677
2023-03-17 05:56:44,973 INFO     Train negative_sample_loss at step 255400: 0.056766
2023-03-17 05:56:44,973 INFO     Train loss at step 255400: 0.061222
2023-03-17 05:57:04,307 INFO     Train positive_sample_loss at step 255500: 0.065632
2023-03-17 05:57:04,307 INFO     Train negative_sample_loss at step 255500: 0.056173
2023-03-17 05:57:04,307 INFO     Train loss at step 255500: 0.060903
2023-03-17 05:57:23,655 INFO     Train positive_sample_loss at step 255600: 0.065607
2023-03-17 05:57:23,655 INFO     Train negative_sample_loss at step 255600: 0.056930
2023-03-17 05:57:23,655 INFO     Train loss at step 255600: 0.061269
2023-03-17 05:57:44,847 INFO     Train positive_sample_loss at step 255700: 0.065508
2023-03-17 05:57:44,848 INFO     Train negative_sample_loss at step 255700: 0.056346
2023-03-17 05:57:44,848 INFO     Train loss at step 255700: 0.060927
2023-03-17 05:58:16,129 INFO     Train positive_sample_loss at step 255800: 0.057646
2023-03-17 05:58:16,129 INFO     Train negative_sample_loss at step 255800: 0.056374
2023-03-17 05:58:16,130 INFO     Train loss at step 255800: 0.057010
2023-03-17 05:58:35,459 INFO     Train positive_sample_loss at step 255900: 0.057877
2023-03-17 05:58:35,460 INFO     Train negative_sample_loss at step 255900: 0.055142
2023-03-17 05:58:35,460 INFO     Train loss at step 255900: 0.056509
2023-03-17 05:58:54,787 INFO     Train positive_sample_loss at step 256000: 0.058530
2023-03-17 05:58:54,788 INFO     Train negative_sample_loss at step 256000: 0.054781
2023-03-17 05:58:54,788 INFO     Train loss at step 256000: 0.056655
2023-03-17 05:59:14,114 INFO     Train positive_sample_loss at step 256100: 0.059319
2023-03-17 05:59:14,115 INFO     Train negative_sample_loss at step 256100: 0.055469
2023-03-17 05:59:14,115 INFO     Train loss at step 256100: 0.057394
2023-03-17 05:59:33,442 INFO     Train positive_sample_loss at step 256200: 0.059608
2023-03-17 05:59:33,443 INFO     Train negative_sample_loss at step 256200: 0.054674
2023-03-17 05:59:33,443 INFO     Train loss at step 256200: 0.057141
2023-03-17 05:59:52,776 INFO     Train positive_sample_loss at step 256300: 0.060187
2023-03-17 05:59:52,776 INFO     Train negative_sample_loss at step 256300: 0.054898
2023-03-17 05:59:52,776 INFO     Train loss at step 256300: 0.057542
2023-03-17 06:00:12,131 INFO     Train positive_sample_loss at step 256400: 0.060754
2023-03-17 06:00:12,132 INFO     Train negative_sample_loss at step 256400: 0.054638
2023-03-17 06:00:12,132 INFO     Train loss at step 256400: 0.057696
2023-03-17 06:00:31,461 INFO     Train positive_sample_loss at step 256500: 0.061420
2023-03-17 06:00:31,462 INFO     Train negative_sample_loss at step 256500: 0.054555
2023-03-17 06:00:31,462 INFO     Train loss at step 256500: 0.057987
2023-03-17 06:00:50,792 INFO     Train positive_sample_loss at step 256600: 0.061614
2023-03-17 06:00:50,793 INFO     Train negative_sample_loss at step 256600: 0.054797
2023-03-17 06:00:50,793 INFO     Train loss at step 256600: 0.058206
2023-03-17 06:01:10,116 INFO     Train positive_sample_loss at step 256700: 0.061918
2023-03-17 06:01:10,117 INFO     Train negative_sample_loss at step 256700: 0.054338
2023-03-17 06:01:10,117 INFO     Train loss at step 256700: 0.058128
2023-03-17 06:01:29,456 INFO     Train positive_sample_loss at step 256800: 0.062185
2023-03-17 06:01:29,456 INFO     Train negative_sample_loss at step 256800: 0.054371
2023-03-17 06:01:29,456 INFO     Train loss at step 256800: 0.058278
2023-03-17 06:01:55,835 INFO     Train positive_sample_loss at step 256900: 0.062573
2023-03-17 06:01:55,835 INFO     Train negative_sample_loss at step 256900: 0.054727
2023-03-17 06:01:55,835 INFO     Train loss at step 256900: 0.058650
2023-03-17 06:02:15,164 INFO     Train positive_sample_loss at step 257000: 0.062817
2023-03-17 06:02:15,165 INFO     Train negative_sample_loss at step 257000: 0.055302
2023-03-17 06:02:15,165 INFO     Train loss at step 257000: 0.059059
2023-03-17 06:02:34,496 INFO     Train positive_sample_loss at step 257100: 0.063077
2023-03-17 06:02:34,496 INFO     Train negative_sample_loss at step 257100: 0.054856
2023-03-17 06:02:34,496 INFO     Train loss at step 257100: 0.058966
2023-03-17 06:02:53,827 INFO     Train positive_sample_loss at step 257200: 0.063622
2023-03-17 06:02:53,828 INFO     Train negative_sample_loss at step 257200: 0.055337
2023-03-17 06:02:53,828 INFO     Train loss at step 257200: 0.059480
2023-03-17 06:03:13,156 INFO     Train positive_sample_loss at step 257300: 0.063596
2023-03-17 06:03:13,156 INFO     Train negative_sample_loss at step 257300: 0.055144
2023-03-17 06:03:13,156 INFO     Train loss at step 257300: 0.059370
2023-03-17 06:03:32,486 INFO     Train positive_sample_loss at step 257400: 0.063855
2023-03-17 06:03:32,486 INFO     Train negative_sample_loss at step 257400: 0.054833
2023-03-17 06:03:32,486 INFO     Train loss at step 257400: 0.059344
2023-03-17 06:03:51,817 INFO     Train positive_sample_loss at step 257500: 0.064004
2023-03-17 06:03:51,817 INFO     Train negative_sample_loss at step 257500: 0.054964
2023-03-17 06:03:51,817 INFO     Train loss at step 257500: 0.059484
2023-03-17 06:04:11,146 INFO     Train positive_sample_loss at step 257600: 0.064412
2023-03-17 06:04:11,147 INFO     Train negative_sample_loss at step 257600: 0.055405
2023-03-17 06:04:11,147 INFO     Train loss at step 257600: 0.059909
2023-03-17 06:04:30,481 INFO     Train positive_sample_loss at step 257700: 0.064296
2023-03-17 06:04:30,481 INFO     Train negative_sample_loss at step 257700: 0.055418
2023-03-17 06:04:30,481 INFO     Train loss at step 257700: 0.059857
2023-03-17 06:04:49,825 INFO     Train positive_sample_loss at step 257800: 0.064711
2023-03-17 06:04:49,825 INFO     Train negative_sample_loss at step 257800: 0.055268
2023-03-17 06:04:49,825 INFO     Train loss at step 257800: 0.059989
2023-03-17 06:05:09,152 INFO     Train positive_sample_loss at step 257900: 0.064479
2023-03-17 06:05:09,152 INFO     Train negative_sample_loss at step 257900: 0.054882
2023-03-17 06:05:09,152 INFO     Train loss at step 257900: 0.059681
2023-03-17 06:05:35,416 INFO     Train positive_sample_loss at step 258000: 0.064777
2023-03-17 06:05:35,417 INFO     Train negative_sample_loss at step 258000: 0.055937
2023-03-17 06:05:35,417 INFO     Train loss at step 258000: 0.060357
2023-03-17 06:05:54,751 INFO     Train positive_sample_loss at step 258100: 0.064683
2023-03-17 06:05:54,751 INFO     Train negative_sample_loss at step 258100: 0.054897
2023-03-17 06:05:54,751 INFO     Train loss at step 258100: 0.059790
2023-03-17 06:06:14,096 INFO     Train positive_sample_loss at step 258200: 0.064749
2023-03-17 06:06:14,096 INFO     Train negative_sample_loss at step 258200: 0.055803
2023-03-17 06:06:14,096 INFO     Train loss at step 258200: 0.060276
2023-03-17 06:06:33,445 INFO     Train positive_sample_loss at step 258300: 0.065034
2023-03-17 06:06:33,445 INFO     Train negative_sample_loss at step 258300: 0.055412
2023-03-17 06:06:33,446 INFO     Train loss at step 258300: 0.060223
2023-03-17 06:06:52,784 INFO     Train positive_sample_loss at step 258400: 0.065108
2023-03-17 06:06:52,784 INFO     Train negative_sample_loss at step 258400: 0.056072
2023-03-17 06:06:52,784 INFO     Train loss at step 258400: 0.060590
2023-03-17 06:07:12,117 INFO     Train positive_sample_loss at step 258500: 0.065504
2023-03-17 06:07:12,117 INFO     Train negative_sample_loss at step 258500: 0.056347
2023-03-17 06:07:12,117 INFO     Train loss at step 258500: 0.060926
2023-03-17 06:07:31,454 INFO     Train positive_sample_loss at step 258600: 0.065225
2023-03-17 06:07:31,454 INFO     Train negative_sample_loss at step 258600: 0.055610
2023-03-17 06:07:31,454 INFO     Train loss at step 258600: 0.060418
2023-03-17 06:07:50,786 INFO     Train positive_sample_loss at step 258700: 0.065243
2023-03-17 06:07:50,786 INFO     Train negative_sample_loss at step 258700: 0.055862
2023-03-17 06:07:50,786 INFO     Train loss at step 258700: 0.060552
2023-03-17 06:08:10,115 INFO     Train positive_sample_loss at step 258800: 0.065249
2023-03-17 06:08:10,115 INFO     Train negative_sample_loss at step 258800: 0.055786
2023-03-17 06:08:10,116 INFO     Train loss at step 258800: 0.060518
2023-03-17 06:08:29,441 INFO     Train positive_sample_loss at step 258900: 0.065300
2023-03-17 06:08:29,442 INFO     Train negative_sample_loss at step 258900: 0.055280
2023-03-17 06:08:29,442 INFO     Train loss at step 258900: 0.060290
2023-03-17 06:08:58,416 INFO     Train positive_sample_loss at step 259000: 0.065465
2023-03-17 06:08:58,417 INFO     Train negative_sample_loss at step 259000: 0.056274
2023-03-17 06:08:58,417 INFO     Train loss at step 259000: 0.060870
2023-03-17 06:09:17,733 INFO     Train positive_sample_loss at step 259100: 0.065559
2023-03-17 06:09:17,734 INFO     Train negative_sample_loss at step 259100: 0.055726
2023-03-17 06:09:17,734 INFO     Train loss at step 259100: 0.060643
2023-03-17 06:09:37,060 INFO     Train positive_sample_loss at step 259200: 0.065307
2023-03-17 06:09:37,060 INFO     Train negative_sample_loss at step 259200: 0.056168
2023-03-17 06:09:37,060 INFO     Train loss at step 259200: 0.060737
2023-03-17 06:09:56,389 INFO     Train positive_sample_loss at step 259300: 0.065506
2023-03-17 06:09:56,389 INFO     Train negative_sample_loss at step 259300: 0.055704
2023-03-17 06:09:56,389 INFO     Train loss at step 259300: 0.060605
2023-03-17 06:10:15,723 INFO     Train positive_sample_loss at step 259400: 0.065508
2023-03-17 06:10:15,723 INFO     Train negative_sample_loss at step 259400: 0.056043
2023-03-17 06:10:15,724 INFO     Train loss at step 259400: 0.060775
2023-03-17 06:10:35,052 INFO     Train positive_sample_loss at step 259500: 0.065381
2023-03-17 06:10:35,052 INFO     Train negative_sample_loss at step 259500: 0.055788
2023-03-17 06:10:35,052 INFO     Train loss at step 259500: 0.060585
2023-03-17 06:10:54,383 INFO     Train positive_sample_loss at step 259600: 0.065423
2023-03-17 06:10:54,383 INFO     Train negative_sample_loss at step 259600: 0.056547
2023-03-17 06:10:54,383 INFO     Train loss at step 259600: 0.060985
2023-03-17 06:11:19,280 INFO     Train positive_sample_loss at step 259700: 0.060497
2023-03-17 06:11:19,280 INFO     Train negative_sample_loss at step 259700: 0.056578
2023-03-17 06:11:19,280 INFO     Train loss at step 259700: 0.058537
2023-03-17 06:11:46,755 INFO     Train positive_sample_loss at step 259800: 0.057262
2023-03-17 06:11:46,756 INFO     Train negative_sample_loss at step 259800: 0.055569
2023-03-17 06:11:46,756 INFO     Train loss at step 259800: 0.056415
2023-03-17 06:12:06,084 INFO     Train positive_sample_loss at step 259900: 0.058144
2023-03-17 06:12:06,084 INFO     Train negative_sample_loss at step 259900: 0.055607
2023-03-17 06:12:06,085 INFO     Train loss at step 259900: 0.056876
2023-03-17 06:12:27,186 INFO     Train positive_sample_loss at step 260000: 0.058939
2023-03-17 06:12:27,186 INFO     Train negative_sample_loss at step 260000: 0.054477
2023-03-17 06:12:27,186 INFO     Train loss at step 260000: 0.056708
2023-03-17 06:12:27,186 INFO     Evaluating on Valid Dataset...
2023-03-17 06:12:28,201 INFO     Evaluating the model... (0/26842)
2023-03-17 06:12:29,779 INFO     Evaluating the model... (1000/26842)
2023-03-17 06:12:31,131 INFO     Evaluating the model... (2000/26842)
2023-03-17 06:12:32,361 INFO     Evaluating the model... (3000/26842)
2023-03-17 06:12:33,589 INFO     Evaluating the model... (4000/26842)
2023-03-17 06:12:34,819 INFO     Evaluating the model... (5000/26842)
2023-03-17 06:12:36,049 INFO     Evaluating the model... (6000/26842)
2023-03-17 06:12:37,284 INFO     Evaluating the model... (7000/26842)
2023-03-17 06:12:38,518 INFO     Evaluating the model... (8000/26842)
2023-03-17 06:12:39,758 INFO     Evaluating the model... (9000/26842)
2023-03-17 06:12:40,997 INFO     Evaluating the model... (10000/26842)
2023-03-17 06:12:42,235 INFO     Evaluating the model... (11000/26842)
2023-03-17 06:12:43,479 INFO     Evaluating the model... (12000/26842)
2023-03-17 06:12:44,712 INFO     Evaluating the model... (13000/26842)
2023-03-17 06:12:46,961 INFO     Evaluating the model... (14000/26842)
2023-03-17 06:12:48,457 INFO     Evaluating the model... (15000/26842)
2023-03-17 06:12:49,943 INFO     Evaluating the model... (16000/26842)
2023-03-17 06:12:51,425 INFO     Evaluating the model... (17000/26842)
2023-03-17 06:12:52,907 INFO     Evaluating the model... (18000/26842)
2023-03-17 06:12:54,394 INFO     Evaluating the model... (19000/26842)
2023-03-17 06:12:55,881 INFO     Evaluating the model... (20000/26842)
2023-03-17 06:12:57,364 INFO     Evaluating the model... (21000/26842)
2023-03-17 06:12:58,837 INFO     Evaluating the model... (22000/26842)
2023-03-17 06:13:00,307 INFO     Evaluating the model... (23000/26842)
2023-03-17 06:13:01,775 INFO     Evaluating the model... (24000/26842)
2023-03-17 06:13:03,255 INFO     Evaluating the model... (25000/26842)
2023-03-17 06:13:04,729 INFO     Evaluating the model... (26000/26842)
2023-03-17 06:13:06,279 INFO     Valid hits@1_list at step 260000: 0.655735
2023-03-17 06:13:06,279 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 06:13:06,280 INFO     Valid hits@3_list at step 260000: 0.745783
2023-03-17 06:13:06,280 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 06:13:06,280 INFO     Valid hits@10_list at step 260000: 0.834930
2023-03-17 06:13:06,280 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 06:13:06,280 INFO     Valid mrr_list at step 260000: 0.716886
2023-03-17 06:13:25,625 INFO     Train positive_sample_loss at step 260100: 0.059490
2023-03-17 06:13:25,626 INFO     Train negative_sample_loss at step 260100: 0.054683
2023-03-17 06:13:25,626 INFO     Train loss at step 260100: 0.057087
2023-03-17 06:13:44,978 INFO     Train positive_sample_loss at step 260200: 0.060057
2023-03-17 06:13:44,979 INFO     Train negative_sample_loss at step 260200: 0.055183
2023-03-17 06:13:44,979 INFO     Train loss at step 260200: 0.057620
2023-03-17 06:14:04,322 INFO     Train positive_sample_loss at step 260300: 0.060412
2023-03-17 06:14:04,322 INFO     Train negative_sample_loss at step 260300: 0.054503
2023-03-17 06:14:04,322 INFO     Train loss at step 260300: 0.057458
2023-03-17 06:14:23,660 INFO     Train positive_sample_loss at step 260400: 0.060951
2023-03-17 06:14:23,661 INFO     Train negative_sample_loss at step 260400: 0.055286
2023-03-17 06:14:23,661 INFO     Train loss at step 260400: 0.058118
2023-03-17 06:14:42,999 INFO     Train positive_sample_loss at step 260500: 0.061271
2023-03-17 06:14:42,999 INFO     Train negative_sample_loss at step 260500: 0.054320
2023-03-17 06:14:42,999 INFO     Train loss at step 260500: 0.057795
2023-03-17 06:15:02,343 INFO     Train positive_sample_loss at step 260600: 0.061826
2023-03-17 06:15:02,344 INFO     Train negative_sample_loss at step 260600: 0.054596
2023-03-17 06:15:02,344 INFO     Train loss at step 260600: 0.058211
2023-03-17 06:15:21,689 INFO     Train positive_sample_loss at step 260700: 0.062072
2023-03-17 06:15:21,689 INFO     Train negative_sample_loss at step 260700: 0.054507
2023-03-17 06:15:21,689 INFO     Train loss at step 260700: 0.058289
2023-03-17 06:15:48,117 INFO     Train positive_sample_loss at step 260800: 0.062596
2023-03-17 06:15:48,117 INFO     Train negative_sample_loss at step 260800: 0.055193
2023-03-17 06:15:48,117 INFO     Train loss at step 260800: 0.058895
2023-03-17 06:16:07,448 INFO     Train positive_sample_loss at step 260900: 0.062519
2023-03-17 06:16:07,449 INFO     Train negative_sample_loss at step 260900: 0.055049
2023-03-17 06:16:07,449 INFO     Train loss at step 260900: 0.058784
2023-03-17 06:16:26,793 INFO     Train positive_sample_loss at step 261000: 0.062958
2023-03-17 06:16:26,793 INFO     Train negative_sample_loss at step 261000: 0.055117
2023-03-17 06:16:26,793 INFO     Train loss at step 261000: 0.059038
2023-03-17 06:16:46,134 INFO     Train positive_sample_loss at step 261100: 0.063085
2023-03-17 06:16:46,134 INFO     Train negative_sample_loss at step 261100: 0.054547
2023-03-17 06:16:46,134 INFO     Train loss at step 261100: 0.058816
2023-03-17 06:17:05,464 INFO     Train positive_sample_loss at step 261200: 0.063439
2023-03-17 06:17:05,465 INFO     Train negative_sample_loss at step 261200: 0.055090
2023-03-17 06:17:05,465 INFO     Train loss at step 261200: 0.059264
2023-03-17 06:17:24,805 INFO     Train positive_sample_loss at step 261300: 0.063904
2023-03-17 06:17:24,805 INFO     Train negative_sample_loss at step 261300: 0.055213
2023-03-17 06:17:24,806 INFO     Train loss at step 261300: 0.059558
2023-03-17 06:17:44,144 INFO     Train positive_sample_loss at step 261400: 0.063773
2023-03-17 06:17:44,144 INFO     Train negative_sample_loss at step 261400: 0.054876
2023-03-17 06:17:44,144 INFO     Train loss at step 261400: 0.059325
2023-03-17 06:18:03,479 INFO     Train positive_sample_loss at step 261500: 0.063988
2023-03-17 06:18:03,479 INFO     Train negative_sample_loss at step 261500: 0.054981
2023-03-17 06:18:03,479 INFO     Train loss at step 261500: 0.059484
2023-03-17 06:18:22,810 INFO     Train positive_sample_loss at step 261600: 0.064179
2023-03-17 06:18:22,811 INFO     Train negative_sample_loss at step 261600: 0.054906
2023-03-17 06:18:22,811 INFO     Train loss at step 261600: 0.059542
2023-03-17 06:18:42,139 INFO     Train positive_sample_loss at step 261700: 0.064446
2023-03-17 06:18:42,139 INFO     Train negative_sample_loss at step 261700: 0.055489
2023-03-17 06:18:42,139 INFO     Train loss at step 261700: 0.059967
2023-03-17 06:19:01,469 INFO     Train positive_sample_loss at step 261800: 0.064494
2023-03-17 06:19:01,470 INFO     Train negative_sample_loss at step 261800: 0.055612
2023-03-17 06:19:01,470 INFO     Train loss at step 261800: 0.060053
2023-03-17 06:19:27,665 INFO     Train positive_sample_loss at step 261900: 0.064789
2023-03-17 06:19:27,666 INFO     Train negative_sample_loss at step 261900: 0.055604
2023-03-17 06:19:27,666 INFO     Train loss at step 261900: 0.060197
2023-03-17 06:19:47,005 INFO     Train positive_sample_loss at step 262000: 0.064757
2023-03-17 06:19:47,006 INFO     Train negative_sample_loss at step 262000: 0.055696
2023-03-17 06:19:47,006 INFO     Train loss at step 262000: 0.060226
2023-03-17 06:20:06,342 INFO     Train positive_sample_loss at step 262100: 0.064714
2023-03-17 06:20:06,342 INFO     Train negative_sample_loss at step 262100: 0.055555
2023-03-17 06:20:06,342 INFO     Train loss at step 262100: 0.060134
2023-03-17 06:20:25,684 INFO     Train positive_sample_loss at step 262200: 0.064903
2023-03-17 06:20:25,685 INFO     Train negative_sample_loss at step 262200: 0.055334
2023-03-17 06:20:25,685 INFO     Train loss at step 262200: 0.060119
2023-03-17 06:20:45,020 INFO     Train positive_sample_loss at step 262300: 0.064895
2023-03-17 06:20:45,020 INFO     Train negative_sample_loss at step 262300: 0.055494
2023-03-17 06:20:45,020 INFO     Train loss at step 262300: 0.060194
2023-03-17 06:21:04,352 INFO     Train positive_sample_loss at step 262400: 0.065028
2023-03-17 06:21:04,353 INFO     Train negative_sample_loss at step 262400: 0.055455
2023-03-17 06:21:04,353 INFO     Train loss at step 262400: 0.060242
2023-03-17 06:21:23,685 INFO     Train positive_sample_loss at step 262500: 0.064976
2023-03-17 06:21:23,686 INFO     Train negative_sample_loss at step 262500: 0.055547
2023-03-17 06:21:23,686 INFO     Train loss at step 262500: 0.060261
2023-03-17 06:21:43,016 INFO     Train positive_sample_loss at step 262600: 0.065214
2023-03-17 06:21:43,016 INFO     Train negative_sample_loss at step 262600: 0.056004
2023-03-17 06:21:43,016 INFO     Train loss at step 262600: 0.060609
2023-03-17 06:22:02,345 INFO     Train positive_sample_loss at step 262700: 0.065184
2023-03-17 06:22:02,346 INFO     Train negative_sample_loss at step 262700: 0.056187
2023-03-17 06:22:02,346 INFO     Train loss at step 262700: 0.060686
2023-03-17 06:22:21,674 INFO     Train positive_sample_loss at step 262800: 0.065215
2023-03-17 06:22:21,675 INFO     Train negative_sample_loss at step 262800: 0.056627
2023-03-17 06:22:21,675 INFO     Train loss at step 262800: 0.060921
2023-03-17 06:22:40,999 INFO     Train positive_sample_loss at step 262900: 0.065499
2023-03-17 06:22:40,999 INFO     Train negative_sample_loss at step 262900: 0.055293
2023-03-17 06:22:41,000 INFO     Train loss at step 262900: 0.060396
2023-03-17 06:23:10,328 INFO     Train positive_sample_loss at step 263000: 0.065339
2023-03-17 06:23:10,328 INFO     Train negative_sample_loss at step 263000: 0.055994
2023-03-17 06:23:10,329 INFO     Train loss at step 263000: 0.060666
2023-03-17 06:23:29,670 INFO     Train positive_sample_loss at step 263100: 0.065246
2023-03-17 06:23:29,671 INFO     Train negative_sample_loss at step 263100: 0.055854
2023-03-17 06:23:29,671 INFO     Train loss at step 263100: 0.060550
2023-03-17 06:23:49,012 INFO     Train positive_sample_loss at step 263200: 0.065224
2023-03-17 06:23:49,012 INFO     Train negative_sample_loss at step 263200: 0.056335
2023-03-17 06:23:49,012 INFO     Train loss at step 263200: 0.060779
2023-03-17 06:24:08,347 INFO     Train positive_sample_loss at step 263300: 0.065166
2023-03-17 06:24:08,348 INFO     Train negative_sample_loss at step 263300: 0.056019
2023-03-17 06:24:08,348 INFO     Train loss at step 263300: 0.060593
2023-03-17 06:24:27,673 INFO     Train positive_sample_loss at step 263400: 0.065078
2023-03-17 06:24:27,673 INFO     Train negative_sample_loss at step 263400: 0.056127
2023-03-17 06:24:27,673 INFO     Train loss at step 263400: 0.060602
2023-03-17 06:24:47,007 INFO     Train positive_sample_loss at step 263500: 0.065232
2023-03-17 06:24:47,007 INFO     Train negative_sample_loss at step 263500: 0.056415
2023-03-17 06:24:47,007 INFO     Train loss at step 263500: 0.060824
funtion time use:38916ms
2023-03-17 06:25:11,812 INFO     Train positive_sample_loss at step 263600: 0.063160
2023-03-17 06:25:11,812 INFO     Train negative_sample_loss at step 263600: 0.055860
2023-03-17 06:25:11,813 INFO     Train loss at step 263600: 0.059510
2023-03-17 06:25:39,142 INFO     Train positive_sample_loss at step 263700: 0.057107
2023-03-17 06:25:39,143 INFO     Train negative_sample_loss at step 263700: 0.055882
2023-03-17 06:25:39,143 INFO     Train loss at step 263700: 0.056495
2023-03-17 06:25:58,470 INFO     Train positive_sample_loss at step 263800: 0.057995
2023-03-17 06:25:58,470 INFO     Train negative_sample_loss at step 263800: 0.054879
2023-03-17 06:25:58,470 INFO     Train loss at step 263800: 0.056437
2023-03-17 06:26:17,796 INFO     Train positive_sample_loss at step 263900: 0.058531
2023-03-17 06:26:17,796 INFO     Train negative_sample_loss at step 263900: 0.054796
2023-03-17 06:26:17,796 INFO     Train loss at step 263900: 0.056663
2023-03-17 06:26:37,132 INFO     Train positive_sample_loss at step 264000: 0.059087
2023-03-17 06:26:37,133 INFO     Train negative_sample_loss at step 264000: 0.054737
2023-03-17 06:26:37,133 INFO     Train loss at step 264000: 0.056912
2023-03-17 06:26:56,465 INFO     Train positive_sample_loss at step 264100: 0.059760
2023-03-17 06:26:56,466 INFO     Train negative_sample_loss at step 264100: 0.054782
2023-03-17 06:26:56,466 INFO     Train loss at step 264100: 0.057271
2023-03-17 06:27:15,795 INFO     Train positive_sample_loss at step 264200: 0.060144
2023-03-17 06:27:15,795 INFO     Train negative_sample_loss at step 264200: 0.055240
2023-03-17 06:27:15,795 INFO     Train loss at step 264200: 0.057692
2023-03-17 06:27:35,119 INFO     Train positive_sample_loss at step 264300: 0.060940
2023-03-17 06:27:35,120 INFO     Train negative_sample_loss at step 264300: 0.054712
2023-03-17 06:27:35,120 INFO     Train loss at step 264300: 0.057826
2023-03-17 06:27:54,448 INFO     Train positive_sample_loss at step 264400: 0.061168
2023-03-17 06:27:54,448 INFO     Train negative_sample_loss at step 264400: 0.054872
2023-03-17 06:27:54,448 INFO     Train loss at step 264400: 0.058020
2023-03-17 06:28:13,786 INFO     Train positive_sample_loss at step 264500: 0.061499
2023-03-17 06:28:13,786 INFO     Train negative_sample_loss at step 264500: 0.054900
2023-03-17 06:28:13,786 INFO     Train loss at step 264500: 0.058200
2023-03-17 06:28:33,120 INFO     Train positive_sample_loss at step 264600: 0.061890
2023-03-17 06:28:33,120 INFO     Train negative_sample_loss at step 264600: 0.054710
2023-03-17 06:28:33,120 INFO     Train loss at step 264600: 0.058300
2023-03-17 06:28:59,571 INFO     Train positive_sample_loss at step 264700: 0.062150
2023-03-17 06:28:59,572 INFO     Train negative_sample_loss at step 264700: 0.054313
2023-03-17 06:28:59,572 INFO     Train loss at step 264700: 0.058231
2023-03-17 06:29:18,900 INFO     Train positive_sample_loss at step 264800: 0.062585
2023-03-17 06:29:18,901 INFO     Train negative_sample_loss at step 264800: 0.054808
2023-03-17 06:29:18,901 INFO     Train loss at step 264800: 0.058696
2023-03-17 06:29:38,234 INFO     Train positive_sample_loss at step 264900: 0.062624
2023-03-17 06:29:38,234 INFO     Train negative_sample_loss at step 264900: 0.055150
2023-03-17 06:29:38,235 INFO     Train loss at step 264900: 0.058887
2023-03-17 06:29:57,566 INFO     Train positive_sample_loss at step 265000: 0.062988
2023-03-17 06:29:57,567 INFO     Train negative_sample_loss at step 265000: 0.054389
2023-03-17 06:29:57,567 INFO     Train loss at step 265000: 0.058688
2023-03-17 06:30:16,908 INFO     Train positive_sample_loss at step 265100: 0.063410
2023-03-17 06:30:16,908 INFO     Train negative_sample_loss at step 265100: 0.054694
2023-03-17 06:30:16,908 INFO     Train loss at step 265100: 0.059052
2023-03-17 06:30:36,247 INFO     Train positive_sample_loss at step 265200: 0.063403
2023-03-17 06:30:36,247 INFO     Train negative_sample_loss at step 265200: 0.054842
2023-03-17 06:30:36,247 INFO     Train loss at step 265200: 0.059122
2023-03-17 06:30:55,575 INFO     Train positive_sample_loss at step 265300: 0.063699
2023-03-17 06:30:55,575 INFO     Train negative_sample_loss at step 265300: 0.055177
2023-03-17 06:30:55,575 INFO     Train loss at step 265300: 0.059438
2023-03-17 06:31:14,901 INFO     Train positive_sample_loss at step 265400: 0.063802
2023-03-17 06:31:14,901 INFO     Train negative_sample_loss at step 265400: 0.054919
2023-03-17 06:31:14,902 INFO     Train loss at step 265400: 0.059361
2023-03-17 06:31:34,231 INFO     Train positive_sample_loss at step 265500: 0.064167
2023-03-17 06:31:34,232 INFO     Train negative_sample_loss at step 265500: 0.055169
2023-03-17 06:31:34,232 INFO     Train loss at step 265500: 0.059668
2023-03-17 06:31:53,560 INFO     Train positive_sample_loss at step 265600: 0.064162
2023-03-17 06:31:53,561 INFO     Train negative_sample_loss at step 265600: 0.055191
2023-03-17 06:31:53,561 INFO     Train loss at step 265600: 0.059677
2023-03-17 06:32:12,893 INFO     Train positive_sample_loss at step 265700: 0.064212
2023-03-17 06:32:12,893 INFO     Train negative_sample_loss at step 265700: 0.055457
2023-03-17 06:32:12,893 INFO     Train loss at step 265700: 0.059835
2023-03-17 06:32:39,058 INFO     Train positive_sample_loss at step 265800: 0.064571
2023-03-17 06:32:39,058 INFO     Train negative_sample_loss at step 265800: 0.055308
2023-03-17 06:32:39,059 INFO     Train loss at step 265800: 0.059939
2023-03-17 06:32:58,386 INFO     Train positive_sample_loss at step 265900: 0.064445
2023-03-17 06:32:58,387 INFO     Train negative_sample_loss at step 265900: 0.054900
2023-03-17 06:32:58,387 INFO     Train loss at step 265900: 0.059672
2023-03-17 06:33:17,724 INFO     Train positive_sample_loss at step 266000: 0.064603
2023-03-17 06:33:17,724 INFO     Train negative_sample_loss at step 266000: 0.055558
2023-03-17 06:33:17,724 INFO     Train loss at step 266000: 0.060080
2023-03-17 06:33:37,051 INFO     Train positive_sample_loss at step 266100: 0.064855
2023-03-17 06:33:37,052 INFO     Train negative_sample_loss at step 266100: 0.055646
2023-03-17 06:33:37,052 INFO     Train loss at step 266100: 0.060251
2023-03-17 06:33:56,379 INFO     Train positive_sample_loss at step 266200: 0.064746
2023-03-17 06:33:56,379 INFO     Train negative_sample_loss at step 266200: 0.055155
2023-03-17 06:33:56,379 INFO     Train loss at step 266200: 0.059950
2023-03-17 06:34:15,701 INFO     Train positive_sample_loss at step 266300: 0.064835
2023-03-17 06:34:15,702 INFO     Train negative_sample_loss at step 266300: 0.054819
2023-03-17 06:34:15,702 INFO     Train loss at step 266300: 0.059827
2023-03-17 06:34:35,028 INFO     Train positive_sample_loss at step 266400: 0.065106
2023-03-17 06:34:35,029 INFO     Train negative_sample_loss at step 266400: 0.055834
2023-03-17 06:34:35,029 INFO     Train loss at step 266400: 0.060470
2023-03-17 06:34:54,365 INFO     Train positive_sample_loss at step 266500: 0.064836
2023-03-17 06:34:54,365 INFO     Train negative_sample_loss at step 266500: 0.055521
2023-03-17 06:34:54,365 INFO     Train loss at step 266500: 0.060178
2023-03-17 06:35:13,695 INFO     Train positive_sample_loss at step 266600: 0.065164
2023-03-17 06:35:13,695 INFO     Train negative_sample_loss at step 266600: 0.055260
2023-03-17 06:35:13,695 INFO     Train loss at step 266600: 0.060212
2023-03-17 06:35:33,025 INFO     Train positive_sample_loss at step 266700: 0.065165
2023-03-17 06:35:33,026 INFO     Train negative_sample_loss at step 266700: 0.055822
2023-03-17 06:35:33,026 INFO     Train loss at step 266700: 0.060494
2023-03-17 06:35:52,359 INFO     Train positive_sample_loss at step 266800: 0.064969
2023-03-17 06:35:52,360 INFO     Train negative_sample_loss at step 266800: 0.055875
2023-03-17 06:35:52,360 INFO     Train loss at step 266800: 0.060422
2023-03-17 06:36:20,888 INFO     Train positive_sample_loss at step 266900: 0.064986
2023-03-17 06:36:20,888 INFO     Train negative_sample_loss at step 266900: 0.055903
2023-03-17 06:36:20,889 INFO     Train loss at step 266900: 0.060445
2023-03-17 06:36:40,224 INFO     Train positive_sample_loss at step 267000: 0.065128
2023-03-17 06:36:40,224 INFO     Train negative_sample_loss at step 267000: 0.055952
2023-03-17 06:36:40,224 INFO     Train loss at step 267000: 0.060540
2023-03-17 06:36:59,556 INFO     Train positive_sample_loss at step 267100: 0.064989
2023-03-17 06:36:59,556 INFO     Train negative_sample_loss at step 267100: 0.056028
2023-03-17 06:36:59,557 INFO     Train loss at step 267100: 0.060508
2023-03-17 06:37:18,886 INFO     Train positive_sample_loss at step 267200: 0.065207
2023-03-17 06:37:18,886 INFO     Train negative_sample_loss at step 267200: 0.055874
2023-03-17 06:37:18,886 INFO     Train loss at step 267200: 0.060541
2023-03-17 06:37:38,211 INFO     Train positive_sample_loss at step 267300: 0.065133
2023-03-17 06:37:38,212 INFO     Train negative_sample_loss at step 267300: 0.055755
2023-03-17 06:37:38,212 INFO     Train loss at step 267300: 0.060444
2023-03-17 06:37:57,536 INFO     Train positive_sample_loss at step 267400: 0.065167
2023-03-17 06:37:57,537 INFO     Train negative_sample_loss at step 267400: 0.055439
2023-03-17 06:37:57,537 INFO     Train loss at step 267400: 0.060303
2023-03-17 06:38:18,674 INFO     Train positive_sample_loss at step 267500: 0.065204
2023-03-17 06:38:18,674 INFO     Train negative_sample_loss at step 267500: 0.055713
2023-03-17 06:38:18,674 INFO     Train loss at step 267500: 0.060458
2023-03-17 06:38:49,856 INFO     Train positive_sample_loss at step 267600: 0.057482
2023-03-17 06:38:49,856 INFO     Train negative_sample_loss at step 267600: 0.055628
2023-03-17 06:38:49,857 INFO     Train loss at step 267600: 0.056555
2023-03-17 06:39:09,177 INFO     Train positive_sample_loss at step 267700: 0.057613
2023-03-17 06:39:09,177 INFO     Train negative_sample_loss at step 267700: 0.055547
2023-03-17 06:39:09,177 INFO     Train loss at step 267700: 0.056580
2023-03-17 06:39:28,515 INFO     Train positive_sample_loss at step 267800: 0.058218
2023-03-17 06:39:28,515 INFO     Train negative_sample_loss at step 267800: 0.055047
2023-03-17 06:39:28,516 INFO     Train loss at step 267800: 0.056633
2023-03-17 06:39:47,842 INFO     Train positive_sample_loss at step 267900: 0.058937
2023-03-17 06:39:47,843 INFO     Train negative_sample_loss at step 267900: 0.055008
2023-03-17 06:39:47,843 INFO     Train loss at step 267900: 0.056973
2023-03-17 06:40:07,177 INFO     Train positive_sample_loss at step 268000: 0.059681
2023-03-17 06:40:07,178 INFO     Train negative_sample_loss at step 268000: 0.055223
2023-03-17 06:40:07,178 INFO     Train loss at step 268000: 0.057452
2023-03-17 06:40:26,510 INFO     Train positive_sample_loss at step 268100: 0.060171
2023-03-17 06:40:26,511 INFO     Train negative_sample_loss at step 268100: 0.054628
2023-03-17 06:40:26,511 INFO     Train loss at step 268100: 0.057400
2023-03-17 06:40:45,841 INFO     Train positive_sample_loss at step 268200: 0.060571
2023-03-17 06:40:45,841 INFO     Train negative_sample_loss at step 268200: 0.053954
2023-03-17 06:40:45,842 INFO     Train loss at step 268200: 0.057263
2023-03-17 06:41:05,167 INFO     Train positive_sample_loss at step 268300: 0.060891
2023-03-17 06:41:05,168 INFO     Train negative_sample_loss at step 268300: 0.054369
2023-03-17 06:41:05,168 INFO     Train loss at step 268300: 0.057630
2023-03-17 06:41:24,500 INFO     Train positive_sample_loss at step 268400: 0.061091
2023-03-17 06:41:24,500 INFO     Train negative_sample_loss at step 268400: 0.054497
2023-03-17 06:41:24,500 INFO     Train loss at step 268400: 0.057794
2023-03-17 06:41:43,831 INFO     Train positive_sample_loss at step 268500: 0.061429
2023-03-17 06:41:43,832 INFO     Train negative_sample_loss at step 268500: 0.054659
2023-03-17 06:41:43,832 INFO     Train loss at step 268500: 0.058044
2023-03-17 06:42:03,159 INFO     Train positive_sample_loss at step 268600: 0.062163
2023-03-17 06:42:03,160 INFO     Train negative_sample_loss at step 268600: 0.054685
2023-03-17 06:42:03,160 INFO     Train loss at step 268600: 0.058424
2023-03-17 06:42:29,436 INFO     Train positive_sample_loss at step 268700: 0.062302
2023-03-17 06:42:29,436 INFO     Train negative_sample_loss at step 268700: 0.054859
2023-03-17 06:42:29,436 INFO     Train loss at step 268700: 0.058580
2023-03-17 06:42:48,766 INFO     Train positive_sample_loss at step 268800: 0.062654
2023-03-17 06:42:48,766 INFO     Train negative_sample_loss at step 268800: 0.054632
2023-03-17 06:42:48,766 INFO     Train loss at step 268800: 0.058643
2023-03-17 06:43:08,094 INFO     Train positive_sample_loss at step 268900: 0.062715
2023-03-17 06:43:08,094 INFO     Train negative_sample_loss at step 268900: 0.054538
2023-03-17 06:43:08,094 INFO     Train loss at step 268900: 0.058627
2023-03-17 06:43:27,428 INFO     Train positive_sample_loss at step 269000: 0.063175
2023-03-17 06:43:27,428 INFO     Train negative_sample_loss at step 269000: 0.055141
2023-03-17 06:43:27,428 INFO     Train loss at step 269000: 0.059158
2023-03-17 06:43:46,759 INFO     Train positive_sample_loss at step 269100: 0.063208
2023-03-17 06:43:46,760 INFO     Train negative_sample_loss at step 269100: 0.054227
2023-03-17 06:43:46,760 INFO     Train loss at step 269100: 0.058717
2023-03-17 06:44:06,092 INFO     Train positive_sample_loss at step 269200: 0.063333
2023-03-17 06:44:06,092 INFO     Train negative_sample_loss at step 269200: 0.054908
2023-03-17 06:44:06,092 INFO     Train loss at step 269200: 0.059121
2023-03-17 06:44:25,423 INFO     Train positive_sample_loss at step 269300: 0.063659
2023-03-17 06:44:25,424 INFO     Train negative_sample_loss at step 269300: 0.054731
2023-03-17 06:44:25,424 INFO     Train loss at step 269300: 0.059195
2023-03-17 06:44:44,758 INFO     Train positive_sample_loss at step 269400: 0.063966
2023-03-17 06:44:44,758 INFO     Train negative_sample_loss at step 269400: 0.054867
2023-03-17 06:44:44,758 INFO     Train loss at step 269400: 0.059416
2023-03-17 06:45:04,101 INFO     Train positive_sample_loss at step 269500: 0.063721
2023-03-17 06:45:04,102 INFO     Train negative_sample_loss at step 269500: 0.054738
2023-03-17 06:45:04,102 INFO     Train loss at step 269500: 0.059229
2023-03-17 06:45:23,437 INFO     Train positive_sample_loss at step 269600: 0.064071
2023-03-17 06:45:23,438 INFO     Train negative_sample_loss at step 269600: 0.055187
2023-03-17 06:45:23,438 INFO     Train loss at step 269600: 0.059629
2023-03-17 06:45:49,773 INFO     Train positive_sample_loss at step 269700: 0.064443
2023-03-17 06:45:49,773 INFO     Train negative_sample_loss at step 269700: 0.055563
2023-03-17 06:45:49,773 INFO     Train loss at step 269700: 0.060003
2023-03-17 06:46:09,095 INFO     Train positive_sample_loss at step 269800: 0.064340
2023-03-17 06:46:09,096 INFO     Train negative_sample_loss at step 269800: 0.055869
2023-03-17 06:46:09,096 INFO     Train loss at step 269800: 0.060104
2023-03-17 06:46:28,426 INFO     Train positive_sample_loss at step 269900: 0.064434
2023-03-17 06:46:28,426 INFO     Train negative_sample_loss at step 269900: 0.055384
2023-03-17 06:46:28,427 INFO     Train loss at step 269900: 0.059909
2023-03-17 06:46:49,304 INFO     Train positive_sample_loss at step 270000: 0.064552
2023-03-17 06:46:49,304 INFO     Train negative_sample_loss at step 270000: 0.054543
2023-03-17 06:46:49,304 INFO     Train loss at step 270000: 0.059548
2023-03-17 06:46:49,305 INFO     Evaluating on Valid Dataset...
2023-03-17 06:46:50,285 INFO     Evaluating the model... (0/26842)
2023-03-17 06:46:51,812 INFO     Evaluating the model... (1000/26842)
2023-03-17 06:46:53,051 INFO     Evaluating the model... (2000/26842)
2023-03-17 06:46:54,298 INFO     Evaluating the model... (3000/26842)
2023-03-17 06:46:55,540 INFO     Evaluating the model... (4000/26842)
2023-03-17 06:46:56,777 INFO     Evaluating the model... (5000/26842)
2023-03-17 06:46:58,006 INFO     Evaluating the model... (6000/26842)
2023-03-17 06:46:59,232 INFO     Evaluating the model... (7000/26842)
2023-03-17 06:47:00,463 INFO     Evaluating the model... (8000/26842)
2023-03-17 06:47:01,688 INFO     Evaluating the model... (9000/26842)
2023-03-17 06:47:02,917 INFO     Evaluating the model... (10000/26842)
2023-03-17 06:47:04,144 INFO     Evaluating the model... (11000/26842)
2023-03-17 06:47:05,368 INFO     Evaluating the model... (12000/26842)
2023-03-17 06:47:06,597 INFO     Evaluating the model... (13000/26842)
2023-03-17 06:47:08,822 INFO     Evaluating the model... (14000/26842)
2023-03-17 06:47:10,317 INFO     Evaluating the model... (15000/26842)
2023-03-17 06:47:11,803 INFO     Evaluating the model... (16000/26842)
2023-03-17 06:47:13,288 INFO     Evaluating the model... (17000/26842)
2023-03-17 06:47:14,771 INFO     Evaluating the model... (18000/26842)
2023-03-17 06:47:16,254 INFO     Evaluating the model... (19000/26842)
2023-03-17 06:47:17,738 INFO     Evaluating the model... (20000/26842)
2023-03-17 06:47:19,218 INFO     Evaluating the model... (21000/26842)
2023-03-17 06:47:20,717 INFO     Evaluating the model... (22000/26842)
2023-03-17 06:47:22,202 INFO     Evaluating the model... (23000/26842)
2023-03-17 06:47:23,686 INFO     Evaluating the model... (24000/26842)
2023-03-17 06:47:25,181 INFO     Evaluating the model... (25000/26842)
2023-03-17 06:47:26,664 INFO     Evaluating the model... (26000/26842)
2023-03-17 06:47:28,223 INFO     Valid hits@1_list at step 270000: 0.655693
2023-03-17 06:47:28,223 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 06:47:28,224 INFO     Valid hits@3_list at step 270000: 0.745700
2023-03-17 06:47:28,224 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 06:47:28,224 INFO     Valid hits@10_list at step 270000: 0.834506
2023-03-17 06:47:28,224 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 06:47:28,224 INFO     Valid mrr_list at step 270000: 0.716653
2023-03-17 06:47:47,570 INFO     Train positive_sample_loss at step 270100: 0.064795
2023-03-17 06:47:47,570 INFO     Train negative_sample_loss at step 270100: 0.054630
2023-03-17 06:47:47,571 INFO     Train loss at step 270100: 0.059713
2023-03-17 06:48:06,922 INFO     Train positive_sample_loss at step 270200: 0.064567
2023-03-17 06:48:06,923 INFO     Train negative_sample_loss at step 270200: 0.055071
2023-03-17 06:48:06,923 INFO     Train loss at step 270200: 0.059819
2023-03-17 06:48:26,270 INFO     Train positive_sample_loss at step 270300: 0.064758
2023-03-17 06:48:26,270 INFO     Train negative_sample_loss at step 270300: 0.055339
2023-03-17 06:48:26,270 INFO     Train loss at step 270300: 0.060049
2023-03-17 06:48:45,615 INFO     Train positive_sample_loss at step 270400: 0.064911
2023-03-17 06:48:45,616 INFO     Train negative_sample_loss at step 270400: 0.055003
2023-03-17 06:48:45,616 INFO     Train loss at step 270400: 0.059957
2023-03-17 06:49:04,962 INFO     Train positive_sample_loss at step 270500: 0.064736
2023-03-17 06:49:04,962 INFO     Train negative_sample_loss at step 270500: 0.055181
2023-03-17 06:49:04,962 INFO     Train loss at step 270500: 0.059959
2023-03-17 06:49:24,309 INFO     Train positive_sample_loss at step 270600: 0.064801
2023-03-17 06:49:24,309 INFO     Train negative_sample_loss at step 270600: 0.055515
2023-03-17 06:49:24,309 INFO     Train loss at step 270600: 0.060158
2023-03-17 06:49:43,649 INFO     Train positive_sample_loss at step 270700: 0.065003
2023-03-17 06:49:43,649 INFO     Train negative_sample_loss at step 270700: 0.056058
2023-03-17 06:49:43,650 INFO     Train loss at step 270700: 0.060531
2023-03-17 06:50:12,553 INFO     Train positive_sample_loss at step 270800: 0.065060
2023-03-17 06:50:12,554 INFO     Train negative_sample_loss at step 270800: 0.055680
2023-03-17 06:50:12,554 INFO     Train loss at step 270800: 0.060370
2023-03-17 06:50:31,894 INFO     Train positive_sample_loss at step 270900: 0.065200
2023-03-17 06:50:31,894 INFO     Train negative_sample_loss at step 270900: 0.056097
2023-03-17 06:50:31,894 INFO     Train loss at step 270900: 0.060649
2023-03-17 06:50:51,242 INFO     Train positive_sample_loss at step 271000: 0.065053
2023-03-17 06:50:51,242 INFO     Train negative_sample_loss at step 271000: 0.055540
2023-03-17 06:50:51,242 INFO     Train loss at step 271000: 0.060296
2023-03-17 06:51:10,583 INFO     Train positive_sample_loss at step 271100: 0.064761
2023-03-17 06:51:10,583 INFO     Train negative_sample_loss at step 271100: 0.055584
2023-03-17 06:51:10,583 INFO     Train loss at step 271100: 0.060173
2023-03-17 06:51:29,922 INFO     Train positive_sample_loss at step 271200: 0.064988
2023-03-17 06:51:29,922 INFO     Train negative_sample_loss at step 271200: 0.055535
2023-03-17 06:51:29,923 INFO     Train loss at step 271200: 0.060262
2023-03-17 06:51:49,260 INFO     Train positive_sample_loss at step 271300: 0.065085
2023-03-17 06:51:49,261 INFO     Train negative_sample_loss at step 271300: 0.056467
2023-03-17 06:51:49,261 INFO     Train loss at step 271300: 0.060776
2023-03-17 06:52:08,600 INFO     Train positive_sample_loss at step 271400: 0.065201
2023-03-17 06:52:08,600 INFO     Train negative_sample_loss at step 271400: 0.055732
2023-03-17 06:52:08,600 INFO     Train loss at step 271400: 0.060466
funtion time use:38742ms
2023-03-17 06:52:41,556 INFO     Train positive_sample_loss at step 271500: 0.060150
2023-03-17 06:52:41,556 INFO     Train negative_sample_loss at step 271500: 0.055417
2023-03-17 06:52:41,557 INFO     Train loss at step 271500: 0.057783
2023-03-17 06:53:00,889 INFO     Train positive_sample_loss at step 271600: 0.057028
2023-03-17 06:53:00,890 INFO     Train negative_sample_loss at step 271600: 0.055288
2023-03-17 06:53:00,890 INFO     Train loss at step 271600: 0.056158
2023-03-17 06:53:20,224 INFO     Train positive_sample_loss at step 271700: 0.057899
2023-03-17 06:53:20,225 INFO     Train negative_sample_loss at step 271700: 0.055231
2023-03-17 06:53:20,225 INFO     Train loss at step 271700: 0.056565
2023-03-17 06:53:39,555 INFO     Train positive_sample_loss at step 271800: 0.058785
2023-03-17 06:53:39,556 INFO     Train negative_sample_loss at step 271800: 0.055328
2023-03-17 06:53:39,556 INFO     Train loss at step 271800: 0.057057
2023-03-17 06:53:58,883 INFO     Train positive_sample_loss at step 271900: 0.059291
2023-03-17 06:53:58,884 INFO     Train negative_sample_loss at step 271900: 0.054808
2023-03-17 06:53:58,884 INFO     Train loss at step 271900: 0.057050
2023-03-17 06:54:18,213 INFO     Train positive_sample_loss at step 272000: 0.059914
2023-03-17 06:54:18,213 INFO     Train negative_sample_loss at step 272000: 0.054224
2023-03-17 06:54:18,213 INFO     Train loss at step 272000: 0.057069
2023-03-17 06:54:37,553 INFO     Train positive_sample_loss at step 272100: 0.060185
2023-03-17 06:54:37,554 INFO     Train negative_sample_loss at step 272100: 0.054523
2023-03-17 06:54:37,554 INFO     Train loss at step 272100: 0.057354
2023-03-17 06:54:56,887 INFO     Train positive_sample_loss at step 272200: 0.060371
2023-03-17 06:54:56,888 INFO     Train negative_sample_loss at step 272200: 0.053945
2023-03-17 06:54:56,888 INFO     Train loss at step 272200: 0.057158
2023-03-17 06:55:16,220 INFO     Train positive_sample_loss at step 272300: 0.061224
2023-03-17 06:55:16,221 INFO     Train negative_sample_loss at step 272300: 0.054627
2023-03-17 06:55:16,221 INFO     Train loss at step 272300: 0.057926
2023-03-17 06:55:35,560 INFO     Train positive_sample_loss at step 272400: 0.061276
2023-03-17 06:55:35,560 INFO     Train negative_sample_loss at step 272400: 0.054194
2023-03-17 06:55:35,560 INFO     Train loss at step 272400: 0.057735
2023-03-17 06:55:54,884 INFO     Train positive_sample_loss at step 272500: 0.061610
2023-03-17 06:55:54,885 INFO     Train negative_sample_loss at step 272500: 0.054061
2023-03-17 06:55:54,885 INFO     Train loss at step 272500: 0.057836
2023-03-17 06:56:21,146 INFO     Train positive_sample_loss at step 272600: 0.062188
2023-03-17 06:56:21,146 INFO     Train negative_sample_loss at step 272600: 0.054386
2023-03-17 06:56:21,147 INFO     Train loss at step 272600: 0.058287
2023-03-17 06:56:40,479 INFO     Train positive_sample_loss at step 272700: 0.062322
2023-03-17 06:56:40,480 INFO     Train negative_sample_loss at step 272700: 0.054250
2023-03-17 06:56:40,480 INFO     Train loss at step 272700: 0.058286
2023-03-17 06:56:59,810 INFO     Train positive_sample_loss at step 272800: 0.062598
2023-03-17 06:56:59,811 INFO     Train negative_sample_loss at step 272800: 0.054596
2023-03-17 06:56:59,811 INFO     Train loss at step 272800: 0.058597
2023-03-17 06:57:19,136 INFO     Train positive_sample_loss at step 272900: 0.062760
2023-03-17 06:57:19,136 INFO     Train negative_sample_loss at step 272900: 0.054428
2023-03-17 06:57:19,136 INFO     Train loss at step 272900: 0.058594
2023-03-17 06:57:38,461 INFO     Train positive_sample_loss at step 273000: 0.063107
2023-03-17 06:57:38,461 INFO     Train negative_sample_loss at step 273000: 0.055051
2023-03-17 06:57:38,461 INFO     Train loss at step 273000: 0.059079
2023-03-17 06:57:57,790 INFO     Train positive_sample_loss at step 273100: 0.063136
2023-03-17 06:57:57,791 INFO     Train negative_sample_loss at step 273100: 0.054645
2023-03-17 06:57:57,791 INFO     Train loss at step 273100: 0.058891
2023-03-17 06:58:17,124 INFO     Train positive_sample_loss at step 273200: 0.063607
2023-03-17 06:58:17,125 INFO     Train negative_sample_loss at step 273200: 0.054890
2023-03-17 06:58:17,125 INFO     Train loss at step 273200: 0.059248
2023-03-17 06:58:36,457 INFO     Train positive_sample_loss at step 273300: 0.063673
2023-03-17 06:58:36,457 INFO     Train negative_sample_loss at step 273300: 0.054636
2023-03-17 06:58:36,457 INFO     Train loss at step 273300: 0.059155
2023-03-17 06:58:55,785 INFO     Train positive_sample_loss at step 273400: 0.063615
2023-03-17 06:58:55,785 INFO     Train negative_sample_loss at step 273400: 0.054979
2023-03-17 06:58:55,785 INFO     Train loss at step 273400: 0.059297
2023-03-17 06:59:15,122 INFO     Train positive_sample_loss at step 273500: 0.063857
2023-03-17 06:59:15,122 INFO     Train negative_sample_loss at step 273500: 0.054662
2023-03-17 06:59:15,122 INFO     Train loss at step 273500: 0.059259
2023-03-17 06:59:38,209 INFO     Train positive_sample_loss at step 273600: 0.064126
2023-03-17 06:59:38,210 INFO     Train negative_sample_loss at step 273600: 0.054800
2023-03-17 06:59:38,210 INFO     Train loss at step 273600: 0.059463
2023-03-17 07:00:03,266 INFO     Train positive_sample_loss at step 273700: 0.064179
2023-03-17 07:00:03,267 INFO     Train negative_sample_loss at step 273700: 0.055207
2023-03-17 07:00:03,267 INFO     Train loss at step 273700: 0.059693
2023-03-17 07:00:22,599 INFO     Train positive_sample_loss at step 273800: 0.064361
2023-03-17 07:00:22,599 INFO     Train negative_sample_loss at step 273800: 0.055037
2023-03-17 07:00:22,599 INFO     Train loss at step 273800: 0.059699
2023-03-17 07:00:41,927 INFO     Train positive_sample_loss at step 273900: 0.064635
2023-03-17 07:00:41,928 INFO     Train negative_sample_loss at step 273900: 0.055095
2023-03-17 07:00:41,928 INFO     Train loss at step 273900: 0.059865
2023-03-17 07:01:01,263 INFO     Train positive_sample_loss at step 274000: 0.064400
2023-03-17 07:01:01,264 INFO     Train negative_sample_loss at step 274000: 0.055182
2023-03-17 07:01:01,264 INFO     Train loss at step 274000: 0.059791
2023-03-17 07:01:20,591 INFO     Train positive_sample_loss at step 274100: 0.064697
2023-03-17 07:01:20,592 INFO     Train negative_sample_loss at step 274100: 0.054987
2023-03-17 07:01:20,592 INFO     Train loss at step 274100: 0.059842
2023-03-17 07:01:39,926 INFO     Train positive_sample_loss at step 274200: 0.064657
2023-03-17 07:01:39,927 INFO     Train negative_sample_loss at step 274200: 0.055064
2023-03-17 07:01:39,927 INFO     Train loss at step 274200: 0.059860
2023-03-17 07:01:59,260 INFO     Train positive_sample_loss at step 274300: 0.064814
2023-03-17 07:01:59,260 INFO     Train negative_sample_loss at step 274300: 0.055134
2023-03-17 07:01:59,260 INFO     Train loss at step 274300: 0.059974
2023-03-17 07:02:18,590 INFO     Train positive_sample_loss at step 274400: 0.064817
2023-03-17 07:02:18,590 INFO     Train negative_sample_loss at step 274400: 0.054901
2023-03-17 07:02:18,590 INFO     Train loss at step 274400: 0.059859
2023-03-17 07:02:37,931 INFO     Train positive_sample_loss at step 274500: 0.064941
2023-03-17 07:02:37,931 INFO     Train negative_sample_loss at step 274500: 0.055345
2023-03-17 07:02:37,931 INFO     Train loss at step 274500: 0.060143
2023-03-17 07:02:57,255 INFO     Train positive_sample_loss at step 274600: 0.064995
2023-03-17 07:02:57,256 INFO     Train negative_sample_loss at step 274600: 0.055494
2023-03-17 07:02:57,256 INFO     Train loss at step 274600: 0.060245
2023-03-17 07:03:23,450 INFO     Train positive_sample_loss at step 274700: 0.064713
2023-03-17 07:03:23,450 INFO     Train negative_sample_loss at step 274700: 0.055358
2023-03-17 07:03:23,450 INFO     Train loss at step 274700: 0.060035
2023-03-17 07:03:42,787 INFO     Train positive_sample_loss at step 274800: 0.064823
2023-03-17 07:03:42,788 INFO     Train negative_sample_loss at step 274800: 0.055308
2023-03-17 07:03:42,788 INFO     Train loss at step 274800: 0.060065
2023-03-17 07:04:02,115 INFO     Train positive_sample_loss at step 274900: 0.064871
2023-03-17 07:04:02,115 INFO     Train negative_sample_loss at step 274900: 0.055469
2023-03-17 07:04:02,115 INFO     Train loss at step 274900: 0.060170
2023-03-17 07:04:21,436 INFO     Train positive_sample_loss at step 275000: 0.064808
2023-03-17 07:04:21,437 INFO     Train negative_sample_loss at step 275000: 0.055749
2023-03-17 07:04:21,437 INFO     Train loss at step 275000: 0.060279
2023-03-17 07:04:40,761 INFO     Train positive_sample_loss at step 275100: 0.064848
2023-03-17 07:04:40,762 INFO     Train negative_sample_loss at step 275100: 0.056607
2023-03-17 07:04:40,762 INFO     Train loss at step 275100: 0.060728
2023-03-17 07:05:00,092 INFO     Train positive_sample_loss at step 275200: 0.065154
2023-03-17 07:05:00,093 INFO     Train negative_sample_loss at step 275200: 0.055891
2023-03-17 07:05:00,093 INFO     Train loss at step 275200: 0.060523
2023-03-17 07:05:19,422 INFO     Train positive_sample_loss at step 275300: 0.064955
2023-03-17 07:05:19,422 INFO     Train negative_sample_loss at step 275300: 0.055244
2023-03-17 07:05:19,422 INFO     Train loss at step 275300: 0.060099
2023-03-17 07:05:44,127 INFO     Train positive_sample_loss at step 275400: 0.062991
2023-03-17 07:05:44,128 INFO     Train negative_sample_loss at step 275400: 0.055655
2023-03-17 07:05:44,128 INFO     Train loss at step 275400: 0.059323
2023-03-17 07:06:11,438 INFO     Train positive_sample_loss at step 275500: 0.056725
2023-03-17 07:06:11,439 INFO     Train negative_sample_loss at step 275500: 0.055626
2023-03-17 07:06:11,439 INFO     Train loss at step 275500: 0.056175
2023-03-17 07:06:30,779 INFO     Train positive_sample_loss at step 275600: 0.057494
2023-03-17 07:06:30,779 INFO     Train negative_sample_loss at step 275600: 0.055384
2023-03-17 07:06:30,779 INFO     Train loss at step 275600: 0.056439
2023-03-17 07:06:50,114 INFO     Train positive_sample_loss at step 275700: 0.058340
2023-03-17 07:06:50,114 INFO     Train negative_sample_loss at step 275700: 0.054473
2023-03-17 07:06:50,115 INFO     Train loss at step 275700: 0.056406
2023-03-17 07:07:09,449 INFO     Train positive_sample_loss at step 275800: 0.058851
2023-03-17 07:07:09,449 INFO     Train negative_sample_loss at step 275800: 0.054389
2023-03-17 07:07:09,449 INFO     Train loss at step 275800: 0.056620
2023-03-17 07:07:28,786 INFO     Train positive_sample_loss at step 275900: 0.059546
2023-03-17 07:07:28,787 INFO     Train negative_sample_loss at step 275900: 0.054517
2023-03-17 07:07:28,787 INFO     Train loss at step 275900: 0.057031
2023-03-17 07:07:48,124 INFO     Train positive_sample_loss at step 276000: 0.060053
2023-03-17 07:07:48,125 INFO     Train negative_sample_loss at step 276000: 0.054780
2023-03-17 07:07:48,125 INFO     Train loss at step 276000: 0.057417
2023-03-17 07:08:07,475 INFO     Train positive_sample_loss at step 276100: 0.060236
2023-03-17 07:08:07,476 INFO     Train negative_sample_loss at step 276100: 0.054088
2023-03-17 07:08:07,476 INFO     Train loss at step 276100: 0.057162
2023-03-17 07:08:26,810 INFO     Train positive_sample_loss at step 276200: 0.060879
2023-03-17 07:08:26,811 INFO     Train negative_sample_loss at step 276200: 0.054904
2023-03-17 07:08:26,811 INFO     Train loss at step 276200: 0.057891
2023-03-17 07:08:46,145 INFO     Train positive_sample_loss at step 276300: 0.061114
2023-03-17 07:08:46,146 INFO     Train negative_sample_loss at step 276300: 0.053957
2023-03-17 07:08:46,146 INFO     Train loss at step 276300: 0.057536
2023-03-17 07:09:05,479 INFO     Train positive_sample_loss at step 276400: 0.061338
2023-03-17 07:09:05,480 INFO     Train negative_sample_loss at step 276400: 0.053944
2023-03-17 07:09:05,480 INFO     Train loss at step 276400: 0.057641
2023-03-17 07:09:31,750 INFO     Train positive_sample_loss at step 276500: 0.061876
2023-03-17 07:09:31,751 INFO     Train negative_sample_loss at step 276500: 0.054201
2023-03-17 07:09:31,751 INFO     Train loss at step 276500: 0.058038
2023-03-17 07:09:51,092 INFO     Train positive_sample_loss at step 276600: 0.062297
2023-03-17 07:09:51,093 INFO     Train negative_sample_loss at step 276600: 0.054353
2023-03-17 07:09:51,093 INFO     Train loss at step 276600: 0.058325
2023-03-17 07:10:10,437 INFO     Train positive_sample_loss at step 276700: 0.062695
2023-03-17 07:10:10,437 INFO     Train negative_sample_loss at step 276700: 0.054117
2023-03-17 07:10:10,437 INFO     Train loss at step 276700: 0.058406
2023-03-17 07:10:29,780 INFO     Train positive_sample_loss at step 276800: 0.062778
2023-03-17 07:10:29,780 INFO     Train negative_sample_loss at step 276800: 0.054789
2023-03-17 07:10:29,780 INFO     Train loss at step 276800: 0.058784
2023-03-17 07:10:49,117 INFO     Train positive_sample_loss at step 276900: 0.063124
2023-03-17 07:10:49,117 INFO     Train negative_sample_loss at step 276900: 0.054840
2023-03-17 07:10:49,118 INFO     Train loss at step 276900: 0.058982
2023-03-17 07:11:08,449 INFO     Train positive_sample_loss at step 277000: 0.063100
2023-03-17 07:11:08,450 INFO     Train negative_sample_loss at step 277000: 0.054481
2023-03-17 07:11:08,450 INFO     Train loss at step 277000: 0.058791
2023-03-17 07:11:27,791 INFO     Train positive_sample_loss at step 277100: 0.063231
2023-03-17 07:11:27,792 INFO     Train negative_sample_loss at step 277100: 0.054599
2023-03-17 07:11:27,792 INFO     Train loss at step 277100: 0.058915
2023-03-17 07:11:47,133 INFO     Train positive_sample_loss at step 277200: 0.063413
2023-03-17 07:11:47,133 INFO     Train negative_sample_loss at step 277200: 0.054561
2023-03-17 07:11:47,134 INFO     Train loss at step 277200: 0.058987
2023-03-17 07:12:06,468 INFO     Train positive_sample_loss at step 277300: 0.063590
2023-03-17 07:12:06,469 INFO     Train negative_sample_loss at step 277300: 0.054611
2023-03-17 07:12:06,469 INFO     Train loss at step 277300: 0.059101
2023-03-17 07:12:25,804 INFO     Train positive_sample_loss at step 277400: 0.063860
2023-03-17 07:12:25,805 INFO     Train negative_sample_loss at step 277400: 0.054156
2023-03-17 07:12:25,805 INFO     Train loss at step 277400: 0.059008
2023-03-17 07:12:45,140 INFO     Train positive_sample_loss at step 277500: 0.063835
2023-03-17 07:12:45,141 INFO     Train negative_sample_loss at step 277500: 0.055082
2023-03-17 07:12:45,141 INFO     Train loss at step 277500: 0.059458
2023-03-17 07:13:14,046 INFO     Train positive_sample_loss at step 277600: 0.063981
2023-03-17 07:13:14,046 INFO     Train negative_sample_loss at step 277600: 0.054281
2023-03-17 07:13:14,046 INFO     Train loss at step 277600: 0.059131
2023-03-17 07:13:33,379 INFO     Train positive_sample_loss at step 277700: 0.064086
2023-03-17 07:13:33,379 INFO     Train negative_sample_loss at step 277700: 0.054704
2023-03-17 07:13:33,379 INFO     Train loss at step 277700: 0.059395
2023-03-17 07:13:52,707 INFO     Train positive_sample_loss at step 277800: 0.064337
2023-03-17 07:13:52,708 INFO     Train negative_sample_loss at step 277800: 0.054893
2023-03-17 07:13:52,708 INFO     Train loss at step 277800: 0.059615
2023-03-17 07:14:12,041 INFO     Train positive_sample_loss at step 277900: 0.064273
2023-03-17 07:14:12,042 INFO     Train negative_sample_loss at step 277900: 0.055079
2023-03-17 07:14:12,042 INFO     Train loss at step 277900: 0.059676
2023-03-17 07:14:31,367 INFO     Train positive_sample_loss at step 278000: 0.064476
2023-03-17 07:14:31,367 INFO     Train negative_sample_loss at step 278000: 0.054424
2023-03-17 07:14:31,367 INFO     Train loss at step 278000: 0.059450
2023-03-17 07:14:50,709 INFO     Train positive_sample_loss at step 278100: 0.064367
2023-03-17 07:14:50,709 INFO     Train negative_sample_loss at step 278100: 0.054776
2023-03-17 07:14:50,709 INFO     Train loss at step 278100: 0.059571
2023-03-17 07:15:10,045 INFO     Train positive_sample_loss at step 278200: 0.064720
2023-03-17 07:15:10,045 INFO     Train negative_sample_loss at step 278200: 0.055382
2023-03-17 07:15:10,045 INFO     Train loss at step 278200: 0.060051
2023-03-17 07:15:29,383 INFO     Train positive_sample_loss at step 278300: 0.064594
2023-03-17 07:15:29,383 INFO     Train negative_sample_loss at step 278300: 0.055099
2023-03-17 07:15:29,383 INFO     Train loss at step 278300: 0.059846
2023-03-17 07:15:48,716 INFO     Train positive_sample_loss at step 278400: 0.064716
2023-03-17 07:15:48,717 INFO     Train negative_sample_loss at step 278400: 0.054845
2023-03-17 07:15:48,717 INFO     Train loss at step 278400: 0.059781
2023-03-17 07:16:08,048 INFO     Train positive_sample_loss at step 278500: 0.064710
2023-03-17 07:16:08,048 INFO     Train negative_sample_loss at step 278500: 0.055826
2023-03-17 07:16:08,048 INFO     Train loss at step 278500: 0.060268
2023-03-17 07:16:27,379 INFO     Train positive_sample_loss at step 278600: 0.064800
2023-03-17 07:16:27,380 INFO     Train negative_sample_loss at step 278600: 0.055262
2023-03-17 07:16:27,380 INFO     Train loss at step 278600: 0.060031
2023-03-17 07:16:53,644 INFO     Train positive_sample_loss at step 278700: 0.064626
2023-03-17 07:16:53,644 INFO     Train negative_sample_loss at step 278700: 0.055269
2023-03-17 07:16:53,645 INFO     Train loss at step 278700: 0.059947
2023-03-17 07:17:12,991 INFO     Train positive_sample_loss at step 278800: 0.064737
2023-03-17 07:17:12,991 INFO     Train negative_sample_loss at step 278800: 0.055226
2023-03-17 07:17:12,991 INFO     Train loss at step 278800: 0.059982
2023-03-17 07:17:32,327 INFO     Train positive_sample_loss at step 278900: 0.064734
2023-03-17 07:17:32,328 INFO     Train negative_sample_loss at step 278900: 0.055428
2023-03-17 07:17:32,328 INFO     Train loss at step 278900: 0.060081
2023-03-17 07:17:51,660 INFO     Train positive_sample_loss at step 279000: 0.064656
2023-03-17 07:17:51,661 INFO     Train negative_sample_loss at step 279000: 0.055740
2023-03-17 07:17:51,661 INFO     Train loss at step 279000: 0.060198
2023-03-17 07:18:10,997 INFO     Train positive_sample_loss at step 279100: 0.065061
2023-03-17 07:18:10,998 INFO     Train negative_sample_loss at step 279100: 0.055730
2023-03-17 07:18:10,998 INFO     Train loss at step 279100: 0.060396
2023-03-17 07:18:30,340 INFO     Train positive_sample_loss at step 279200: 0.064755
2023-03-17 07:18:30,341 INFO     Train negative_sample_loss at step 279200: 0.056628
2023-03-17 07:18:30,341 INFO     Train loss at step 279200: 0.060691
2023-03-17 07:18:51,470 INFO     Train positive_sample_loss at step 279300: 0.064907
2023-03-17 07:18:51,471 INFO     Train negative_sample_loss at step 279300: 0.055724
2023-03-17 07:18:51,471 INFO     Train loss at step 279300: 0.060315
2023-03-17 07:19:22,817 INFO     Train positive_sample_loss at step 279400: 0.057238
2023-03-17 07:19:22,818 INFO     Train negative_sample_loss at step 279400: 0.055753
2023-03-17 07:19:22,818 INFO     Train loss at step 279400: 0.056496
2023-03-17 07:19:42,154 INFO     Train positive_sample_loss at step 279500: 0.057146
2023-03-17 07:19:42,154 INFO     Train negative_sample_loss at step 279500: 0.055167
2023-03-17 07:19:42,154 INFO     Train loss at step 279500: 0.056157
2023-03-17 07:20:01,492 INFO     Train positive_sample_loss at step 279600: 0.057865
2023-03-17 07:20:01,493 INFO     Train negative_sample_loss at step 279600: 0.055026
2023-03-17 07:20:01,493 INFO     Train loss at step 279600: 0.056446
2023-03-17 07:20:20,837 INFO     Train positive_sample_loss at step 279700: 0.058598
2023-03-17 07:20:20,838 INFO     Train negative_sample_loss at step 279700: 0.054432
2023-03-17 07:20:20,838 INFO     Train loss at step 279700: 0.056515
2023-03-17 07:20:40,172 INFO     Train positive_sample_loss at step 279800: 0.059224
2023-03-17 07:20:40,173 INFO     Train negative_sample_loss at step 279800: 0.054808
2023-03-17 07:20:40,173 INFO     Train loss at step 279800: 0.057016
2023-03-17 07:20:59,511 INFO     Train positive_sample_loss at step 279900: 0.059621
2023-03-17 07:20:59,511 INFO     Train negative_sample_loss at step 279900: 0.054178
2023-03-17 07:20:59,511 INFO     Train loss at step 279900: 0.056899
2023-03-17 07:21:20,423 INFO     Train positive_sample_loss at step 280000: 0.060184
2023-03-17 07:21:20,423 INFO     Train negative_sample_loss at step 280000: 0.054234
2023-03-17 07:21:20,423 INFO     Train loss at step 280000: 0.057209
2023-03-17 07:21:20,423 INFO     Evaluating on Valid Dataset...
2023-03-17 07:21:21,428 INFO     Evaluating the model... (0/26842)
2023-03-17 07:21:23,100 INFO     Evaluating the model... (1000/26842)
2023-03-17 07:21:24,334 INFO     Evaluating the model... (2000/26842)
2023-03-17 07:21:25,564 INFO     Evaluating the model... (3000/26842)
2023-03-17 07:21:26,789 INFO     Evaluating the model... (4000/26842)
2023-03-17 07:21:28,019 INFO     Evaluating the model... (5000/26842)
2023-03-17 07:21:29,245 INFO     Evaluating the model... (6000/26842)
2023-03-17 07:21:30,455 INFO     Evaluating the model... (7000/26842)
2023-03-17 07:21:31,681 INFO     Evaluating the model... (8000/26842)
2023-03-17 07:21:32,916 INFO     Evaluating the model... (9000/26842)
2023-03-17 07:21:34,152 INFO     Evaluating the model... (10000/26842)
2023-03-17 07:21:35,390 INFO     Evaluating the model... (11000/26842)
2023-03-17 07:21:36,633 INFO     Evaluating the model... (12000/26842)
2023-03-17 07:21:37,885 INFO     Evaluating the model... (13000/26842)
2023-03-17 07:21:40,117 INFO     Evaluating the model... (14000/26842)
2023-03-17 07:21:41,606 INFO     Evaluating the model... (15000/26842)
2023-03-17 07:21:43,084 INFO     Evaluating the model... (16000/26842)
2023-03-17 07:21:44,570 INFO     Evaluating the model... (17000/26842)
2023-03-17 07:21:46,056 INFO     Evaluating the model... (18000/26842)
2023-03-17 07:21:47,540 INFO     Evaluating the model... (19000/26842)
2023-03-17 07:21:49,026 INFO     Evaluating the model... (20000/26842)
2023-03-17 07:21:50,521 INFO     Evaluating the model... (21000/26842)
2023-03-17 07:21:52,011 INFO     Evaluating the model... (22000/26842)
2023-03-17 07:21:53,490 INFO     Evaluating the model... (23000/26842)
2023-03-17 07:21:54,977 INFO     Evaluating the model... (24000/26842)
2023-03-17 07:21:56,456 INFO     Evaluating the model... (25000/26842)
2023-03-17 07:21:57,921 INFO     Evaluating the model... (26000/26842)
2023-03-17 07:21:59,477 INFO     Valid hits@1_list at step 280000: 0.655836
2023-03-17 07:21:59,477 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 07:21:59,477 INFO     Valid hits@3_list at step 280000: 0.745929
2023-03-17 07:21:59,477 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 07:21:59,477 INFO     Valid hits@10_list at step 280000: 0.835051
2023-03-17 07:21:59,477 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 07:21:59,477 INFO     Valid mrr_list at step 280000: 0.716958
2023-03-17 07:22:18,830 INFO     Train positive_sample_loss at step 280100: 0.060624
2023-03-17 07:22:18,831 INFO     Train negative_sample_loss at step 280100: 0.054114
2023-03-17 07:22:18,831 INFO     Train loss at step 280100: 0.057369
2023-03-17 07:22:38,180 INFO     Train positive_sample_loss at step 280200: 0.060914
2023-03-17 07:22:38,180 INFO     Train negative_sample_loss at step 280200: 0.054509
2023-03-17 07:22:38,180 INFO     Train loss at step 280200: 0.057712
2023-03-17 07:22:57,527 INFO     Train positive_sample_loss at step 280300: 0.061319
2023-03-17 07:22:57,527 INFO     Train negative_sample_loss at step 280300: 0.054585
2023-03-17 07:22:57,527 INFO     Train loss at step 280300: 0.057952
2023-03-17 07:23:16,883 INFO     Train positive_sample_loss at step 280400: 0.061696
2023-03-17 07:23:16,884 INFO     Train negative_sample_loss at step 280400: 0.053948
2023-03-17 07:23:16,884 INFO     Train loss at step 280400: 0.057822
2023-03-17 07:23:43,256 INFO     Train positive_sample_loss at step 280500: 0.062057
2023-03-17 07:23:43,256 INFO     Train negative_sample_loss at step 280500: 0.053780
2023-03-17 07:23:43,256 INFO     Train loss at step 280500: 0.057919
2023-03-17 07:24:02,603 INFO     Train positive_sample_loss at step 280600: 0.062102
2023-03-17 07:24:02,603 INFO     Train negative_sample_loss at step 280600: 0.054286
2023-03-17 07:24:02,604 INFO     Train loss at step 280600: 0.058194
2023-03-17 07:24:21,955 INFO     Train positive_sample_loss at step 280700: 0.062436
2023-03-17 07:24:21,955 INFO     Train negative_sample_loss at step 280700: 0.054323
2023-03-17 07:24:21,955 INFO     Train loss at step 280700: 0.058379
2023-03-17 07:24:41,302 INFO     Train positive_sample_loss at step 280800: 0.062892
2023-03-17 07:24:41,302 INFO     Train negative_sample_loss at step 280800: 0.055008
2023-03-17 07:24:41,303 INFO     Train loss at step 280800: 0.058950
2023-03-17 07:25:00,649 INFO     Train positive_sample_loss at step 280900: 0.063045
2023-03-17 07:25:00,649 INFO     Train negative_sample_loss at step 280900: 0.054189
2023-03-17 07:25:00,649 INFO     Train loss at step 280900: 0.058617
2023-03-17 07:25:20,005 INFO     Train positive_sample_loss at step 281000: 0.063329
2023-03-17 07:25:20,006 INFO     Train negative_sample_loss at step 281000: 0.054262
2023-03-17 07:25:20,006 INFO     Train loss at step 281000: 0.058796
2023-03-17 07:25:39,348 INFO     Train positive_sample_loss at step 281100: 0.063313
2023-03-17 07:25:39,348 INFO     Train negative_sample_loss at step 281100: 0.054655
2023-03-17 07:25:39,348 INFO     Train loss at step 281100: 0.058984
2023-03-17 07:25:58,692 INFO     Train positive_sample_loss at step 281200: 0.063596
2023-03-17 07:25:58,693 INFO     Train negative_sample_loss at step 281200: 0.054536
2023-03-17 07:25:58,693 INFO     Train loss at step 281200: 0.059066
2023-03-17 07:26:18,035 INFO     Train positive_sample_loss at step 281300: 0.063626
2023-03-17 07:26:18,035 INFO     Train negative_sample_loss at step 281300: 0.054527
2023-03-17 07:26:18,035 INFO     Train loss at step 281300: 0.059077
2023-03-17 07:26:37,377 INFO     Train positive_sample_loss at step 281400: 0.063868
2023-03-17 07:26:37,378 INFO     Train negative_sample_loss at step 281400: 0.054772
2023-03-17 07:26:37,378 INFO     Train loss at step 281400: 0.059320
2023-03-17 07:27:06,184 INFO     Train positive_sample_loss at step 281500: 0.064142
2023-03-17 07:27:06,184 INFO     Train negative_sample_loss at step 281500: 0.055001
2023-03-17 07:27:06,184 INFO     Train loss at step 281500: 0.059572
2023-03-17 07:27:25,521 INFO     Train positive_sample_loss at step 281600: 0.063919
2023-03-17 07:27:25,522 INFO     Train negative_sample_loss at step 281600: 0.054286
2023-03-17 07:27:25,522 INFO     Train loss at step 281600: 0.059103
2023-03-17 07:27:44,865 INFO     Train positive_sample_loss at step 281700: 0.064136
2023-03-17 07:27:44,865 INFO     Train negative_sample_loss at step 281700: 0.055138
2023-03-17 07:27:44,865 INFO     Train loss at step 281700: 0.059637
2023-03-17 07:28:04,212 INFO     Train positive_sample_loss at step 281800: 0.064170
2023-03-17 07:28:04,213 INFO     Train negative_sample_loss at step 281800: 0.054773
2023-03-17 07:28:04,213 INFO     Train loss at step 281800: 0.059472
2023-03-17 07:28:23,551 INFO     Train positive_sample_loss at step 281900: 0.064346
2023-03-17 07:28:23,551 INFO     Train negative_sample_loss at step 281900: 0.054982
2023-03-17 07:28:23,551 INFO     Train loss at step 281900: 0.059664
2023-03-17 07:28:42,889 INFO     Train positive_sample_loss at step 282000: 0.064280
2023-03-17 07:28:42,890 INFO     Train negative_sample_loss at step 282000: 0.054660
2023-03-17 07:28:42,890 INFO     Train loss at step 282000: 0.059470
2023-03-17 07:29:02,232 INFO     Train positive_sample_loss at step 282100: 0.064647
2023-03-17 07:29:02,232 INFO     Train negative_sample_loss at step 282100: 0.055236
2023-03-17 07:29:02,232 INFO     Train loss at step 282100: 0.059942
2023-03-17 07:29:21,561 INFO     Train positive_sample_loss at step 282200: 0.064470
2023-03-17 07:29:21,561 INFO     Train negative_sample_loss at step 282200: 0.055126
2023-03-17 07:29:21,561 INFO     Train loss at step 282200: 0.059798
2023-03-17 07:29:40,891 INFO     Train positive_sample_loss at step 282300: 0.064658
2023-03-17 07:29:40,891 INFO     Train negative_sample_loss at step 282300: 0.055393
2023-03-17 07:29:40,892 INFO     Train loss at step 282300: 0.060025
2023-03-17 07:30:00,229 INFO     Train positive_sample_loss at step 282400: 0.064657
2023-03-17 07:30:00,229 INFO     Train negative_sample_loss at step 282400: 0.055198
2023-03-17 07:30:00,229 INFO     Train loss at step 282400: 0.059928
2023-03-17 07:30:19,564 INFO     Train positive_sample_loss at step 282500: 0.064607
2023-03-17 07:30:19,564 INFO     Train negative_sample_loss at step 282500: 0.054946
2023-03-17 07:30:19,564 INFO     Train loss at step 282500: 0.059776
2023-03-17 07:30:45,878 INFO     Train positive_sample_loss at step 282600: 0.064754
2023-03-17 07:30:45,878 INFO     Train negative_sample_loss at step 282600: 0.055071
2023-03-17 07:30:45,878 INFO     Train loss at step 282600: 0.059913
2023-03-17 07:31:05,222 INFO     Train positive_sample_loss at step 282700: 0.064888
2023-03-17 07:31:05,223 INFO     Train negative_sample_loss at step 282700: 0.055549
2023-03-17 07:31:05,223 INFO     Train loss at step 282700: 0.060218
2023-03-17 07:31:24,556 INFO     Train positive_sample_loss at step 282800: 0.064825
2023-03-17 07:31:24,557 INFO     Train negative_sample_loss at step 282800: 0.055274
2023-03-17 07:31:24,557 INFO     Train loss at step 282800: 0.060050
2023-03-17 07:31:43,895 INFO     Train positive_sample_loss at step 282900: 0.064594
2023-03-17 07:31:43,895 INFO     Train negative_sample_loss at step 282900: 0.055630
2023-03-17 07:31:43,895 INFO     Train loss at step 282900: 0.060112
2023-03-17 07:32:03,247 INFO     Train positive_sample_loss at step 283000: 0.064737
2023-03-17 07:32:03,248 INFO     Train negative_sample_loss at step 283000: 0.055367
2023-03-17 07:32:03,248 INFO     Train loss at step 283000: 0.060052
2023-03-17 07:32:22,588 INFO     Train positive_sample_loss at step 283100: 0.064688
2023-03-17 07:32:22,588 INFO     Train negative_sample_loss at step 283100: 0.055612
2023-03-17 07:32:22,588 INFO     Train loss at step 283100: 0.060150
2023-03-17 07:32:41,923 INFO     Train positive_sample_loss at step 283200: 0.064655
2023-03-17 07:32:41,923 INFO     Train negative_sample_loss at step 283200: 0.055930
2023-03-17 07:32:41,923 INFO     Train loss at step 283200: 0.060292
funtion time use:38875ms
2023-03-17 07:33:20,293 INFO     Train positive_sample_loss at step 283300: 0.059892
2023-03-17 07:33:20,294 INFO     Train negative_sample_loss at step 283300: 0.054820
2023-03-17 07:33:20,294 INFO     Train loss at step 283300: 0.057356
2023-03-17 07:33:39,613 INFO     Train positive_sample_loss at step 283400: 0.056770
2023-03-17 07:33:39,613 INFO     Train negative_sample_loss at step 283400: 0.055238
2023-03-17 07:33:39,613 INFO     Train loss at step 283400: 0.056004
2023-03-17 07:33:58,934 INFO     Train positive_sample_loss at step 283500: 0.057606
2023-03-17 07:33:58,935 INFO     Train negative_sample_loss at step 283500: 0.054965
2023-03-17 07:33:58,935 INFO     Train loss at step 283500: 0.056285
2023-03-17 07:34:18,264 INFO     Train positive_sample_loss at step 283600: 0.058212
2023-03-17 07:34:18,264 INFO     Train negative_sample_loss at step 283600: 0.054467
2023-03-17 07:34:18,264 INFO     Train loss at step 283600: 0.056339
2023-03-17 07:34:37,586 INFO     Train positive_sample_loss at step 283700: 0.058702
2023-03-17 07:34:37,587 INFO     Train negative_sample_loss at step 283700: 0.054434
2023-03-17 07:34:37,587 INFO     Train loss at step 283700: 0.056568
2023-03-17 07:34:56,907 INFO     Train positive_sample_loss at step 283800: 0.059435
2023-03-17 07:34:56,908 INFO     Train negative_sample_loss at step 283800: 0.054113
2023-03-17 07:34:56,908 INFO     Train loss at step 283800: 0.056774
2023-03-17 07:35:16,238 INFO     Train positive_sample_loss at step 283900: 0.059888
2023-03-17 07:35:16,239 INFO     Train negative_sample_loss at step 283900: 0.054822
2023-03-17 07:35:16,239 INFO     Train loss at step 283900: 0.057355
2023-03-17 07:35:35,564 INFO     Train positive_sample_loss at step 284000: 0.060392
2023-03-17 07:35:35,564 INFO     Train negative_sample_loss at step 284000: 0.054863
2023-03-17 07:35:35,564 INFO     Train loss at step 284000: 0.057628
2023-03-17 07:35:54,891 INFO     Train positive_sample_loss at step 284100: 0.060841
2023-03-17 07:35:54,892 INFO     Train negative_sample_loss at step 284100: 0.054464
2023-03-17 07:35:54,892 INFO     Train loss at step 284100: 0.057652
2023-03-17 07:36:14,214 INFO     Train positive_sample_loss at step 284200: 0.061284
2023-03-17 07:36:14,215 INFO     Train negative_sample_loss at step 284200: 0.054289
2023-03-17 07:36:14,215 INFO     Train loss at step 284200: 0.057787
2023-03-17 07:36:33,556 INFO     Train positive_sample_loss at step 284300: 0.061642
2023-03-17 07:36:33,556 INFO     Train negative_sample_loss at step 284300: 0.053771
2023-03-17 07:36:33,557 INFO     Train loss at step 284300: 0.057707
2023-03-17 07:36:59,809 INFO     Train positive_sample_loss at step 284400: 0.061787
2023-03-17 07:36:59,810 INFO     Train negative_sample_loss at step 284400: 0.053765
2023-03-17 07:36:59,810 INFO     Train loss at step 284400: 0.057776
2023-03-17 07:37:19,142 INFO     Train positive_sample_loss at step 284500: 0.061942
2023-03-17 07:37:19,143 INFO     Train negative_sample_loss at step 284500: 0.054204
2023-03-17 07:37:19,143 INFO     Train loss at step 284500: 0.058073
2023-03-17 07:37:38,475 INFO     Train positive_sample_loss at step 284600: 0.062503
2023-03-17 07:37:38,476 INFO     Train negative_sample_loss at step 284600: 0.054902
2023-03-17 07:37:38,476 INFO     Train loss at step 284600: 0.058703
2023-03-17 07:37:57,803 INFO     Train positive_sample_loss at step 284700: 0.062555
2023-03-17 07:37:57,803 INFO     Train negative_sample_loss at step 284700: 0.054788
2023-03-17 07:37:57,803 INFO     Train loss at step 284700: 0.058671
2023-03-17 07:38:17,143 INFO     Train positive_sample_loss at step 284800: 0.062990
2023-03-17 07:38:17,143 INFO     Train negative_sample_loss at step 284800: 0.054182
2023-03-17 07:38:17,143 INFO     Train loss at step 284800: 0.058586
2023-03-17 07:38:36,480 INFO     Train positive_sample_loss at step 284900: 0.063071
2023-03-17 07:38:36,480 INFO     Train negative_sample_loss at step 284900: 0.054480
2023-03-17 07:38:36,480 INFO     Train loss at step 284900: 0.058775
2023-03-17 07:38:55,806 INFO     Train positive_sample_loss at step 285000: 0.063232
2023-03-17 07:38:55,806 INFO     Train negative_sample_loss at step 285000: 0.054077
2023-03-17 07:38:55,806 INFO     Train loss at step 285000: 0.058654
2023-03-17 07:39:15,136 INFO     Train positive_sample_loss at step 285100: 0.063255
2023-03-17 07:39:15,137 INFO     Train negative_sample_loss at step 285100: 0.054391
2023-03-17 07:39:15,137 INFO     Train loss at step 285100: 0.058823
2023-03-17 07:39:34,463 INFO     Train positive_sample_loss at step 285200: 0.063768
2023-03-17 07:39:34,464 INFO     Train negative_sample_loss at step 285200: 0.055019
2023-03-17 07:39:34,464 INFO     Train loss at step 285200: 0.059394
2023-03-17 07:39:53,798 INFO     Train positive_sample_loss at step 285300: 0.063511
2023-03-17 07:39:53,799 INFO     Train negative_sample_loss at step 285300: 0.053991
2023-03-17 07:39:53,799 INFO     Train loss at step 285300: 0.058751
2023-03-17 07:40:20,123 INFO     Train positive_sample_loss at step 285400: 0.063800
2023-03-17 07:40:20,124 INFO     Train negative_sample_loss at step 285400: 0.055221
2023-03-17 07:40:20,124 INFO     Train loss at step 285400: 0.059510
2023-03-17 07:40:39,458 INFO     Train positive_sample_loss at step 285500: 0.064135
2023-03-17 07:40:39,459 INFO     Train negative_sample_loss at step 285500: 0.055331
2023-03-17 07:40:39,459 INFO     Train loss at step 285500: 0.059733
2023-03-17 07:40:58,782 INFO     Train positive_sample_loss at step 285600: 0.064018
2023-03-17 07:40:58,783 INFO     Train negative_sample_loss at step 285600: 0.054538
2023-03-17 07:40:58,783 INFO     Train loss at step 285600: 0.059278
2023-03-17 07:41:18,123 INFO     Train positive_sample_loss at step 285700: 0.064140
2023-03-17 07:41:18,123 INFO     Train negative_sample_loss at step 285700: 0.054924
2023-03-17 07:41:18,123 INFO     Train loss at step 285700: 0.059532
2023-03-17 07:41:37,452 INFO     Train positive_sample_loss at step 285800: 0.064197
2023-03-17 07:41:37,452 INFO     Train negative_sample_loss at step 285800: 0.055103
2023-03-17 07:41:37,452 INFO     Train loss at step 285800: 0.059650
2023-03-17 07:41:56,786 INFO     Train positive_sample_loss at step 285900: 0.064226
2023-03-17 07:41:56,787 INFO     Train negative_sample_loss at step 285900: 0.054950
2023-03-17 07:41:56,787 INFO     Train loss at step 285900: 0.059588
2023-03-17 07:42:16,120 INFO     Train positive_sample_loss at step 286000: 0.064426
2023-03-17 07:42:16,121 INFO     Train negative_sample_loss at step 286000: 0.055255
2023-03-17 07:42:16,121 INFO     Train loss at step 286000: 0.059841
2023-03-17 07:42:35,451 INFO     Train positive_sample_loss at step 286100: 0.064417
2023-03-17 07:42:35,452 INFO     Train negative_sample_loss at step 286100: 0.055194
2023-03-17 07:42:35,452 INFO     Train loss at step 286100: 0.059805
2023-03-17 07:42:54,776 INFO     Train positive_sample_loss at step 286200: 0.064521
2023-03-17 07:42:54,777 INFO     Train negative_sample_loss at step 286200: 0.055371
2023-03-17 07:42:54,777 INFO     Train loss at step 286200: 0.059946
2023-03-17 07:43:14,110 INFO     Train positive_sample_loss at step 286300: 0.064541
2023-03-17 07:43:14,111 INFO     Train negative_sample_loss at step 286300: 0.054689
2023-03-17 07:43:14,111 INFO     Train loss at step 286300: 0.059615
2023-03-17 07:43:33,444 INFO     Train positive_sample_loss at step 286400: 0.064456
2023-03-17 07:43:33,444 INFO     Train negative_sample_loss at step 286400: 0.054973
2023-03-17 07:43:33,444 INFO     Train loss at step 286400: 0.059714
2023-03-17 07:43:59,632 INFO     Train positive_sample_loss at step 286500: 0.064495
2023-03-17 07:43:59,632 INFO     Train negative_sample_loss at step 286500: 0.055415
2023-03-17 07:43:59,632 INFO     Train loss at step 286500: 0.059955
2023-03-17 07:44:18,961 INFO     Train positive_sample_loss at step 286600: 0.064531
2023-03-17 07:44:18,962 INFO     Train negative_sample_loss at step 286600: 0.055538
2023-03-17 07:44:18,962 INFO     Train loss at step 286600: 0.060034
2023-03-17 07:44:38,295 INFO     Train positive_sample_loss at step 286700: 0.064659
2023-03-17 07:44:38,295 INFO     Train negative_sample_loss at step 286700: 0.054977
2023-03-17 07:44:38,295 INFO     Train loss at step 286700: 0.059818
2023-03-17 07:44:57,627 INFO     Train positive_sample_loss at step 286800: 0.064560
2023-03-17 07:44:57,627 INFO     Train negative_sample_loss at step 286800: 0.055191
2023-03-17 07:44:57,627 INFO     Train loss at step 286800: 0.059876
2023-03-17 07:45:16,958 INFO     Train positive_sample_loss at step 286900: 0.064573
2023-03-17 07:45:16,959 INFO     Train negative_sample_loss at step 286900: 0.055247
2023-03-17 07:45:16,959 INFO     Train loss at step 286900: 0.059910
2023-03-17 07:45:36,288 INFO     Train positive_sample_loss at step 287000: 0.064603
2023-03-17 07:45:36,289 INFO     Train negative_sample_loss at step 287000: 0.055061
2023-03-17 07:45:36,289 INFO     Train loss at step 287000: 0.059832
2023-03-17 07:45:55,616 INFO     Train positive_sample_loss at step 287100: 0.064513
2023-03-17 07:45:55,616 INFO     Train negative_sample_loss at step 287100: 0.055171
2023-03-17 07:45:55,616 INFO     Train loss at step 287100: 0.059842
2023-03-17 07:46:33,599 INFO     Train positive_sample_loss at step 287200: 0.062909
2023-03-17 07:46:33,600 INFO     Train negative_sample_loss at step 287200: 0.055816
2023-03-17 07:46:33,600 INFO     Train loss at step 287200: 0.059362
2023-03-17 07:46:52,926 INFO     Train positive_sample_loss at step 287300: 0.056433
2023-03-17 07:46:52,927 INFO     Train negative_sample_loss at step 287300: 0.055353
2023-03-17 07:46:52,927 INFO     Train loss at step 287300: 0.055893
2023-03-17 07:47:12,249 INFO     Train positive_sample_loss at step 287400: 0.057249
2023-03-17 07:47:12,249 INFO     Train negative_sample_loss at step 287400: 0.054477
2023-03-17 07:47:12,249 INFO     Train loss at step 287400: 0.055863
2023-03-17 07:47:31,575 INFO     Train positive_sample_loss at step 287500: 0.057903
2023-03-17 07:47:31,575 INFO     Train negative_sample_loss at step 287500: 0.054535
2023-03-17 07:47:31,575 INFO     Train loss at step 287500: 0.056219
2023-03-17 07:47:50,898 INFO     Train positive_sample_loss at step 287600: 0.058443
2023-03-17 07:47:50,899 INFO     Train negative_sample_loss at step 287600: 0.054510
2023-03-17 07:47:50,899 INFO     Train loss at step 287600: 0.056476
2023-03-17 07:48:10,224 INFO     Train positive_sample_loss at step 287700: 0.058969
2023-03-17 07:48:10,224 INFO     Train negative_sample_loss at step 287700: 0.054431
2023-03-17 07:48:10,225 INFO     Train loss at step 287700: 0.056700
2023-03-17 07:48:29,551 INFO     Train positive_sample_loss at step 287800: 0.059691
2023-03-17 07:48:29,552 INFO     Train negative_sample_loss at step 287800: 0.054236
2023-03-17 07:48:29,552 INFO     Train loss at step 287800: 0.056964
2023-03-17 07:48:48,885 INFO     Train positive_sample_loss at step 287900: 0.060121
2023-03-17 07:48:48,885 INFO     Train negative_sample_loss at step 287900: 0.053529
2023-03-17 07:48:48,886 INFO     Train loss at step 287900: 0.056825
2023-03-17 07:49:08,218 INFO     Train positive_sample_loss at step 288000: 0.060564
2023-03-17 07:49:08,219 INFO     Train negative_sample_loss at step 288000: 0.054597
2023-03-17 07:49:08,219 INFO     Train loss at step 288000: 0.057580
2023-03-17 07:49:27,554 INFO     Train positive_sample_loss at step 288100: 0.060918
2023-03-17 07:49:27,554 INFO     Train negative_sample_loss at step 288100: 0.054023
2023-03-17 07:49:27,554 INFO     Train loss at step 288100: 0.057471
2023-03-17 07:49:46,887 INFO     Train positive_sample_loss at step 288200: 0.061132
2023-03-17 07:49:46,888 INFO     Train negative_sample_loss at step 288200: 0.054208
2023-03-17 07:49:46,888 INFO     Train loss at step 288200: 0.057670
2023-03-17 07:50:13,232 INFO     Train positive_sample_loss at step 288300: 0.061616
2023-03-17 07:50:13,232 INFO     Train negative_sample_loss at step 288300: 0.054057
2023-03-17 07:50:13,232 INFO     Train loss at step 288300: 0.057836
2023-03-17 07:50:32,564 INFO     Train positive_sample_loss at step 288400: 0.061942
2023-03-17 07:50:32,564 INFO     Train negative_sample_loss at step 288400: 0.053926
2023-03-17 07:50:32,564 INFO     Train loss at step 288400: 0.057934
2023-03-17 07:50:51,897 INFO     Train positive_sample_loss at step 288500: 0.062164
2023-03-17 07:50:51,897 INFO     Train negative_sample_loss at step 288500: 0.054145
2023-03-17 07:50:51,898 INFO     Train loss at step 288500: 0.058155
2023-03-17 07:51:11,224 INFO     Train positive_sample_loss at step 288600: 0.062406
2023-03-17 07:51:11,224 INFO     Train negative_sample_loss at step 288600: 0.053946
2023-03-17 07:51:11,225 INFO     Train loss at step 288600: 0.058176
2023-03-17 07:51:30,557 INFO     Train positive_sample_loss at step 288700: 0.062931
2023-03-17 07:51:30,558 INFO     Train negative_sample_loss at step 288700: 0.054321
2023-03-17 07:51:30,558 INFO     Train loss at step 288700: 0.058626
2023-03-17 07:51:49,901 INFO     Train positive_sample_loss at step 288800: 0.062970
2023-03-17 07:51:49,901 INFO     Train negative_sample_loss at step 288800: 0.054303
2023-03-17 07:51:49,902 INFO     Train loss at step 288800: 0.058637
2023-03-17 07:52:09,246 INFO     Train positive_sample_loss at step 288900: 0.062903
2023-03-17 07:52:09,247 INFO     Train negative_sample_loss at step 288900: 0.053904
2023-03-17 07:52:09,247 INFO     Train loss at step 288900: 0.058404
2023-03-17 07:52:28,582 INFO     Train positive_sample_loss at step 289000: 0.063218
2023-03-17 07:52:28,582 INFO     Train negative_sample_loss at step 289000: 0.054670
2023-03-17 07:52:28,582 INFO     Train loss at step 289000: 0.058944
2023-03-17 07:52:47,912 INFO     Train positive_sample_loss at step 289100: 0.063387
2023-03-17 07:52:47,913 INFO     Train negative_sample_loss at step 289100: 0.054648
2023-03-17 07:52:47,913 INFO     Train loss at step 289100: 0.059018
2023-03-17 07:53:07,244 INFO     Train positive_sample_loss at step 289200: 0.063296
2023-03-17 07:53:07,245 INFO     Train negative_sample_loss at step 289200: 0.054800
2023-03-17 07:53:07,245 INFO     Train loss at step 289200: 0.059048
2023-03-17 07:53:26,591 INFO     Train positive_sample_loss at step 289300: 0.063770
2023-03-17 07:53:26,592 INFO     Train negative_sample_loss at step 289300: 0.054912
2023-03-17 07:53:26,593 INFO     Train loss at step 289300: 0.059341
2023-03-17 07:53:52,845 INFO     Train positive_sample_loss at step 289400: 0.063758
2023-03-17 07:53:52,846 INFO     Train negative_sample_loss at step 289400: 0.054282
2023-03-17 07:53:52,846 INFO     Train loss at step 289400: 0.059020
2023-03-17 07:54:12,187 INFO     Train positive_sample_loss at step 289500: 0.064002
2023-03-17 07:54:12,187 INFO     Train negative_sample_loss at step 289500: 0.054645
2023-03-17 07:54:12,187 INFO     Train loss at step 289500: 0.059324
2023-03-17 07:54:31,518 INFO     Train positive_sample_loss at step 289600: 0.064144
2023-03-17 07:54:31,519 INFO     Train negative_sample_loss at step 289600: 0.054770
2023-03-17 07:54:31,519 INFO     Train loss at step 289600: 0.059457
2023-03-17 07:54:50,865 INFO     Train positive_sample_loss at step 289700: 0.063874
2023-03-17 07:54:50,865 INFO     Train negative_sample_loss at step 289700: 0.054497
2023-03-17 07:54:50,865 INFO     Train loss at step 289700: 0.059186
2023-03-17 07:55:10,203 INFO     Train positive_sample_loss at step 289800: 0.064159
2023-03-17 07:55:10,203 INFO     Train negative_sample_loss at step 289800: 0.054719
2023-03-17 07:55:10,203 INFO     Train loss at step 289800: 0.059439
2023-03-17 07:55:29,541 INFO     Train positive_sample_loss at step 289900: 0.064124
2023-03-17 07:55:29,542 INFO     Train negative_sample_loss at step 289900: 0.054717
2023-03-17 07:55:29,542 INFO     Train loss at step 289900: 0.059421
2023-03-17 07:55:50,415 INFO     Train positive_sample_loss at step 290000: 0.064559
2023-03-17 07:55:50,416 INFO     Train negative_sample_loss at step 290000: 0.055205
2023-03-17 07:55:50,416 INFO     Train loss at step 290000: 0.059882
2023-03-17 07:55:50,416 INFO     Evaluating on Valid Dataset...
2023-03-17 07:55:51,356 INFO     Evaluating the model... (0/26842)
2023-03-17 07:55:52,880 INFO     Evaluating the model... (1000/26842)
2023-03-17 07:55:54,231 INFO     Evaluating the model... (2000/26842)
2023-03-17 07:55:55,470 INFO     Evaluating the model... (3000/26842)
2023-03-17 07:56:01,965 INFO     Evaluating the model... (4000/26842)
2023-03-17 07:56:03,180 INFO     Evaluating the model... (5000/26842)
2023-03-17 07:56:04,394 INFO     Evaluating the model... (6000/26842)
2023-03-17 07:56:05,613 INFO     Evaluating the model... (7000/26842)
2023-03-17 07:56:06,840 INFO     Evaluating the model... (8000/26842)
2023-03-17 07:56:08,068 INFO     Evaluating the model... (9000/26842)
2023-03-17 07:56:09,293 INFO     Evaluating the model... (10000/26842)
2023-03-17 07:56:10,539 INFO     Evaluating the model... (11000/26842)
2023-03-17 07:56:11,763 INFO     Evaluating the model... (12000/26842)
2023-03-17 07:56:12,984 INFO     Evaluating the model... (13000/26842)
2023-03-17 07:56:15,339 INFO     Evaluating the model... (14000/26842)
2023-03-17 07:56:16,826 INFO     Evaluating the model... (15000/26842)
2023-03-17 07:56:18,311 INFO     Evaluating the model... (16000/26842)
2023-03-17 07:56:19,794 INFO     Evaluating the model... (17000/26842)
2023-03-17 07:56:21,288 INFO     Evaluating the model... (18000/26842)
2023-03-17 07:56:22,781 INFO     Evaluating the model... (19000/26842)
2023-03-17 07:56:24,268 INFO     Evaluating the model... (20000/26842)
2023-03-17 07:56:25,753 INFO     Evaluating the model... (21000/26842)
2023-03-17 07:56:27,229 INFO     Evaluating the model... (22000/26842)
2023-03-17 07:56:28,703 INFO     Evaluating the model... (23000/26842)
2023-03-17 07:56:30,182 INFO     Evaluating the model... (24000/26842)
2023-03-17 07:56:31,667 INFO     Evaluating the model... (25000/26842)
2023-03-17 07:56:33,153 INFO     Evaluating the model... (26000/26842)
2023-03-17 07:56:34,737 INFO     Valid hits@1_list at step 290000: 0.656354
2023-03-17 07:56:34,737 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 07:56:34,737 INFO     Valid hits@3_list at step 290000: 0.745967
2023-03-17 07:56:34,737 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 07:56:34,737 INFO     Valid hits@10_list at step 290000: 0.834364
2023-03-17 07:56:34,737 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 07:56:34,737 INFO     Valid mrr_list at step 290000: 0.717168
2023-03-17 07:56:54,127 INFO     Train positive_sample_loss at step 290100: 0.064320
2023-03-17 07:56:54,127 INFO     Train negative_sample_loss at step 290100: 0.055757
2023-03-17 07:56:54,127 INFO     Train loss at step 290100: 0.060039
2023-03-17 07:57:13,528 INFO     Train positive_sample_loss at step 290200: 0.064468
2023-03-17 07:57:13,528 INFO     Train negative_sample_loss at step 290200: 0.055116
2023-03-17 07:57:13,529 INFO     Train loss at step 290200: 0.059792
2023-03-17 07:57:32,927 INFO     Train positive_sample_loss at step 290300: 0.064446
2023-03-17 07:57:32,928 INFO     Train negative_sample_loss at step 290300: 0.055738
2023-03-17 07:57:32,928 INFO     Train loss at step 290300: 0.060092
2023-03-17 07:57:59,080 INFO     Train positive_sample_loss at step 290400: 0.064373
2023-03-17 07:57:59,081 INFO     Train negative_sample_loss at step 290400: 0.055209
2023-03-17 07:57:59,081 INFO     Train loss at step 290400: 0.059791
2023-03-17 07:58:18,489 INFO     Train positive_sample_loss at step 290500: 0.064503
2023-03-17 07:58:18,489 INFO     Train negative_sample_loss at step 290500: 0.055507
2023-03-17 07:58:18,489 INFO     Train loss at step 290500: 0.060005
2023-03-17 07:58:37,886 INFO     Train positive_sample_loss at step 290600: 0.064728
2023-03-17 07:58:37,886 INFO     Train negative_sample_loss at step 290600: 0.055379
2023-03-17 07:58:37,886 INFO     Train loss at step 290600: 0.060054
2023-03-17 07:58:57,288 INFO     Train positive_sample_loss at step 290700: 0.064391
2023-03-17 07:58:57,288 INFO     Train negative_sample_loss at step 290700: 0.055572
2023-03-17 07:58:57,288 INFO     Train loss at step 290700: 0.059981
2023-03-17 07:59:16,688 INFO     Train positive_sample_loss at step 290800: 0.064448
2023-03-17 07:59:16,689 INFO     Train negative_sample_loss at step 290800: 0.054399
2023-03-17 07:59:16,689 INFO     Train loss at step 290800: 0.059423
2023-03-17 07:59:36,086 INFO     Train positive_sample_loss at step 290900: 0.064584
2023-03-17 07:59:36,087 INFO     Train negative_sample_loss at step 290900: 0.055493
2023-03-17 07:59:36,087 INFO     Train loss at step 290900: 0.060039
2023-03-17 07:59:55,483 INFO     Train positive_sample_loss at step 291000: 0.064437
2023-03-17 07:59:55,484 INFO     Train negative_sample_loss at step 291000: 0.054682
2023-03-17 07:59:55,484 INFO     Train loss at step 291000: 0.059560
2023-03-17 08:00:16,825 INFO     Train positive_sample_loss at step 291100: 0.064462
2023-03-17 08:00:16,825 INFO     Train negative_sample_loss at step 291100: 0.055223
2023-03-17 08:00:16,826 INFO     Train loss at step 291100: 0.059842
funtion time use:44144ms
2023-03-17 08:00:39,806 INFO     Train positive_sample_loss at step 291200: 0.057309
2023-03-17 08:00:39,806 INFO     Train negative_sample_loss at step 291200: 0.054554
2023-03-17 08:00:39,807 INFO     Train loss at step 291200: 0.055932
2023-03-17 08:00:59,123 INFO     Train positive_sample_loss at step 291300: 0.056805
2023-03-17 08:00:59,123 INFO     Train negative_sample_loss at step 291300: 0.054927
2023-03-17 08:00:59,123 INFO     Train loss at step 291300: 0.055866
2023-03-17 08:01:18,441 INFO     Train positive_sample_loss at step 291400: 0.057664
2023-03-17 08:01:18,441 INFO     Train negative_sample_loss at step 291400: 0.054581
2023-03-17 08:01:18,441 INFO     Train loss at step 291400: 0.056123
2023-03-17 08:01:37,747 INFO     Train positive_sample_loss at step 291500: 0.058297
2023-03-17 08:01:37,747 INFO     Train negative_sample_loss at step 291500: 0.054744
2023-03-17 08:01:37,748 INFO     Train loss at step 291500: 0.056521
2023-03-17 08:01:57,054 INFO     Train positive_sample_loss at step 291600: 0.058691
2023-03-17 08:01:57,055 INFO     Train negative_sample_loss at step 291600: 0.054534
2023-03-17 08:01:57,055 INFO     Train loss at step 291600: 0.056613
2023-03-17 08:02:16,363 INFO     Train positive_sample_loss at step 291700: 0.059493
2023-03-17 08:02:16,363 INFO     Train negative_sample_loss at step 291700: 0.054588
2023-03-17 08:02:16,364 INFO     Train loss at step 291700: 0.057040
2023-03-17 08:02:35,676 INFO     Train positive_sample_loss at step 291800: 0.059683
2023-03-17 08:02:35,676 INFO     Train negative_sample_loss at step 291800: 0.053837
2023-03-17 08:02:35,676 INFO     Train loss at step 291800: 0.056760
2023-03-17 08:02:54,994 INFO     Train positive_sample_loss at step 291900: 0.060404
2023-03-17 08:02:54,995 INFO     Train negative_sample_loss at step 291900: 0.053735
2023-03-17 08:02:54,995 INFO     Train loss at step 291900: 0.057069
2023-03-17 08:03:14,314 INFO     Train positive_sample_loss at step 292000: 0.060646
2023-03-17 08:03:14,315 INFO     Train negative_sample_loss at step 292000: 0.053781
2023-03-17 08:03:14,315 INFO     Train loss at step 292000: 0.057213
2023-03-17 08:03:33,634 INFO     Train positive_sample_loss at step 292100: 0.061054
2023-03-17 08:03:33,634 INFO     Train negative_sample_loss at step 292100: 0.054259
2023-03-17 08:03:33,634 INFO     Train loss at step 292100: 0.057656
2023-03-17 08:04:00,213 INFO     Train positive_sample_loss at step 292200: 0.061497
2023-03-17 08:04:00,213 INFO     Train negative_sample_loss at step 292200: 0.054055
2023-03-17 08:04:00,213 INFO     Train loss at step 292200: 0.057776
2023-03-17 08:04:19,530 INFO     Train positive_sample_loss at step 292300: 0.061715
2023-03-17 08:04:19,530 INFO     Train negative_sample_loss at step 292300: 0.053693
2023-03-17 08:04:19,530 INFO     Train loss at step 292300: 0.057704
2023-03-17 08:04:38,845 INFO     Train positive_sample_loss at step 292400: 0.061917
2023-03-17 08:04:38,845 INFO     Train negative_sample_loss at step 292400: 0.054344
2023-03-17 08:04:38,845 INFO     Train loss at step 292400: 0.058130
2023-03-17 08:04:58,166 INFO     Train positive_sample_loss at step 292500: 0.062176
2023-03-17 08:04:58,167 INFO     Train negative_sample_loss at step 292500: 0.054297
2023-03-17 08:04:58,167 INFO     Train loss at step 292500: 0.058237
2023-03-17 08:05:17,491 INFO     Train positive_sample_loss at step 292600: 0.062520
2023-03-17 08:05:17,491 INFO     Train negative_sample_loss at step 292600: 0.054006
2023-03-17 08:05:17,491 INFO     Train loss at step 292600: 0.058263
2023-03-17 08:05:36,813 INFO     Train positive_sample_loss at step 292700: 0.062697
2023-03-17 08:05:36,814 INFO     Train negative_sample_loss at step 292700: 0.054191
2023-03-17 08:05:36,814 INFO     Train loss at step 292700: 0.058444
2023-03-17 08:05:56,145 INFO     Train positive_sample_loss at step 292800: 0.062963
2023-03-17 08:05:56,146 INFO     Train negative_sample_loss at step 292800: 0.053961
2023-03-17 08:05:56,146 INFO     Train loss at step 292800: 0.058462
2023-03-17 08:06:15,468 INFO     Train positive_sample_loss at step 292900: 0.063139
2023-03-17 08:06:15,468 INFO     Train negative_sample_loss at step 292900: 0.054118
2023-03-17 08:06:15,468 INFO     Train loss at step 292900: 0.058629
2023-03-17 08:06:34,789 INFO     Train positive_sample_loss at step 293000: 0.063004
2023-03-17 08:06:34,790 INFO     Train negative_sample_loss at step 293000: 0.054302
2023-03-17 08:06:34,790 INFO     Train loss at step 293000: 0.058653
2023-03-17 08:06:54,126 INFO     Train positive_sample_loss at step 293100: 0.063359
2023-03-17 08:06:54,126 INFO     Train negative_sample_loss at step 293100: 0.054182
2023-03-17 08:06:54,126 INFO     Train loss at step 293100: 0.058770
2023-03-17 08:07:13,453 INFO     Train positive_sample_loss at step 293200: 0.063552
2023-03-17 08:07:13,454 INFO     Train negative_sample_loss at step 293200: 0.054315
2023-03-17 08:07:13,454 INFO     Train loss at step 293200: 0.058934
2023-03-17 08:07:39,604 INFO     Train positive_sample_loss at step 293300: 0.063652
2023-03-17 08:07:39,604 INFO     Train negative_sample_loss at step 293300: 0.054617
2023-03-17 08:07:39,605 INFO     Train loss at step 293300: 0.059135
2023-03-17 08:07:58,923 INFO     Train positive_sample_loss at step 293400: 0.063819
2023-03-17 08:07:58,923 INFO     Train negative_sample_loss at step 293400: 0.054361
2023-03-17 08:07:58,923 INFO     Train loss at step 293400: 0.059090
2023-03-17 08:08:18,262 INFO     Train positive_sample_loss at step 293500: 0.063906
2023-03-17 08:08:18,262 INFO     Train negative_sample_loss at step 293500: 0.054713
2023-03-17 08:08:18,262 INFO     Train loss at step 293500: 0.059309
2023-03-17 08:08:37,584 INFO     Train positive_sample_loss at step 293600: 0.064082
2023-03-17 08:08:37,584 INFO     Train negative_sample_loss at step 293600: 0.055267
2023-03-17 08:08:37,584 INFO     Train loss at step 293600: 0.059675
2023-03-17 08:08:56,904 INFO     Train positive_sample_loss at step 293700: 0.063899
2023-03-17 08:08:56,905 INFO     Train negative_sample_loss at step 293700: 0.054869
2023-03-17 08:08:56,905 INFO     Train loss at step 293700: 0.059384
2023-03-17 08:09:16,224 INFO     Train positive_sample_loss at step 293800: 0.064024
2023-03-17 08:09:16,225 INFO     Train negative_sample_loss at step 293800: 0.055179
2023-03-17 08:09:16,225 INFO     Train loss at step 293800: 0.059602
2023-03-17 08:09:35,545 INFO     Train positive_sample_loss at step 293900: 0.064379
2023-03-17 08:09:35,546 INFO     Train negative_sample_loss at step 293900: 0.054743
2023-03-17 08:09:35,546 INFO     Train loss at step 293900: 0.059561
2023-03-17 08:09:54,875 INFO     Train positive_sample_loss at step 294000: 0.064216
2023-03-17 08:09:54,875 INFO     Train negative_sample_loss at step 294000: 0.054576
2023-03-17 08:09:54,875 INFO     Train loss at step 294000: 0.059396
2023-03-17 08:10:14,204 INFO     Train positive_sample_loss at step 294100: 0.064633
2023-03-17 08:10:14,205 INFO     Train negative_sample_loss at step 294100: 0.054910
2023-03-17 08:10:14,205 INFO     Train loss at step 294100: 0.059772
2023-03-17 08:10:33,535 INFO     Train positive_sample_loss at step 294200: 0.064560
2023-03-17 08:10:33,536 INFO     Train negative_sample_loss at step 294200: 0.055288
2023-03-17 08:10:33,536 INFO     Train loss at step 294200: 0.059924
2023-03-17 08:10:59,736 INFO     Train positive_sample_loss at step 294300: 0.064351
2023-03-17 08:10:59,737 INFO     Train negative_sample_loss at step 294300: 0.054752
2023-03-17 08:10:59,737 INFO     Train loss at step 294300: 0.059552
2023-03-17 08:11:19,063 INFO     Train positive_sample_loss at step 294400: 0.064215
2023-03-17 08:11:19,063 INFO     Train negative_sample_loss at step 294400: 0.055265
2023-03-17 08:11:19,063 INFO     Train loss at step 294400: 0.059740
2023-03-17 08:11:38,394 INFO     Train positive_sample_loss at step 294500: 0.064484
2023-03-17 08:11:38,395 INFO     Train negative_sample_loss at step 294500: 0.055477
2023-03-17 08:11:38,395 INFO     Train loss at step 294500: 0.059981
2023-03-17 08:11:57,720 INFO     Train positive_sample_loss at step 294600: 0.064597
2023-03-17 08:11:57,721 INFO     Train negative_sample_loss at step 294600: 0.055923
2023-03-17 08:11:57,721 INFO     Train loss at step 294600: 0.060260
2023-03-17 08:12:17,053 INFO     Train positive_sample_loss at step 294700: 0.064416
2023-03-17 08:12:17,054 INFO     Train negative_sample_loss at step 294700: 0.055394
2023-03-17 08:12:17,054 INFO     Train loss at step 294700: 0.059905
2023-03-17 08:12:36,390 INFO     Train positive_sample_loss at step 294800: 0.064502
2023-03-17 08:12:36,390 INFO     Train negative_sample_loss at step 294800: 0.056129
2023-03-17 08:12:36,390 INFO     Train loss at step 294800: 0.060315
2023-03-17 08:12:55,716 INFO     Train positive_sample_loss at step 294900: 0.064307
2023-03-17 08:12:55,716 INFO     Train negative_sample_loss at step 294900: 0.055713
2023-03-17 08:12:55,716 INFO     Train loss at step 294900: 0.060010
2023-03-17 08:13:15,050 INFO     Train positive_sample_loss at step 295000: 0.064373
2023-03-17 08:13:15,050 INFO     Train negative_sample_loss at step 295000: 0.055346
2023-03-17 08:13:15,050 INFO     Train loss at step 295000: 0.059860
2023-03-17 08:13:40,374 INFO     Train positive_sample_loss at step 295100: 0.060208
2023-03-17 08:13:40,374 INFO     Train negative_sample_loss at step 295100: 0.055663
2023-03-17 08:13:40,375 INFO     Train loss at step 295100: 0.057935
2023-03-17 08:13:59,702 INFO     Train positive_sample_loss at step 295200: 0.056667
2023-03-17 08:13:59,702 INFO     Train negative_sample_loss at step 295200: 0.055071
2023-03-17 08:13:59,703 INFO     Train loss at step 295200: 0.055869
2023-03-17 08:14:19,015 INFO     Train positive_sample_loss at step 295300: 0.057289
2023-03-17 08:14:19,015 INFO     Train negative_sample_loss at step 295300: 0.054956
2023-03-17 08:14:19,015 INFO     Train loss at step 295300: 0.056123
2023-03-17 08:14:38,323 INFO     Train positive_sample_loss at step 295400: 0.057864
2023-03-17 08:14:38,323 INFO     Train negative_sample_loss at step 295400: 0.054327
2023-03-17 08:14:38,323 INFO     Train loss at step 295400: 0.056096
2023-03-17 08:14:57,636 INFO     Train positive_sample_loss at step 295500: 0.058535
2023-03-17 08:14:57,636 INFO     Train negative_sample_loss at step 295500: 0.054178
2023-03-17 08:14:57,637 INFO     Train loss at step 295500: 0.056357
2023-03-17 08:15:16,945 INFO     Train positive_sample_loss at step 295600: 0.059168
2023-03-17 08:15:16,946 INFO     Train negative_sample_loss at step 295600: 0.053916
2023-03-17 08:15:16,946 INFO     Train loss at step 295600: 0.056542
2023-03-17 08:15:36,261 INFO     Train positive_sample_loss at step 295700: 0.059777
2023-03-17 08:15:36,261 INFO     Train negative_sample_loss at step 295700: 0.054097
2023-03-17 08:15:36,261 INFO     Train loss at step 295700: 0.056937
2023-03-17 08:15:55,589 INFO     Train positive_sample_loss at step 295800: 0.060070
2023-03-17 08:15:55,590 INFO     Train negative_sample_loss at step 295800: 0.053745
2023-03-17 08:15:55,590 INFO     Train loss at step 295800: 0.056908
2023-03-17 08:16:14,914 INFO     Train positive_sample_loss at step 295900: 0.060652
2023-03-17 08:16:14,914 INFO     Train negative_sample_loss at step 295900: 0.054662
2023-03-17 08:16:14,914 INFO     Train loss at step 295900: 0.057657
2023-03-17 08:16:34,242 INFO     Train positive_sample_loss at step 296000: 0.061000
2023-03-17 08:16:34,242 INFO     Train negative_sample_loss at step 296000: 0.053975
2023-03-17 08:16:34,243 INFO     Train loss at step 296000: 0.057487
2023-03-17 08:17:00,770 INFO     Train positive_sample_loss at step 296100: 0.061319
2023-03-17 08:17:00,771 INFO     Train negative_sample_loss at step 296100: 0.053672
2023-03-17 08:17:00,771 INFO     Train loss at step 296100: 0.057496
2023-03-17 08:17:20,096 INFO     Train positive_sample_loss at step 296200: 0.061525
2023-03-17 08:17:20,097 INFO     Train negative_sample_loss at step 296200: 0.053805
2023-03-17 08:17:20,097 INFO     Train loss at step 296200: 0.057665
2023-03-17 08:17:39,421 INFO     Train positive_sample_loss at step 296300: 0.061689
2023-03-17 08:17:39,422 INFO     Train negative_sample_loss at step 296300: 0.053427
2023-03-17 08:17:39,422 INFO     Train loss at step 296300: 0.057558
2023-03-17 08:17:58,742 INFO     Train positive_sample_loss at step 296400: 0.061878
2023-03-17 08:17:58,743 INFO     Train negative_sample_loss at step 296400: 0.054101
2023-03-17 08:17:58,743 INFO     Train loss at step 296400: 0.057989
2023-03-17 08:18:18,078 INFO     Train positive_sample_loss at step 296500: 0.062298
2023-03-17 08:18:18,078 INFO     Train negative_sample_loss at step 296500: 0.053740
2023-03-17 08:18:18,078 INFO     Train loss at step 296500: 0.058019
2023-03-17 08:18:37,405 INFO     Train positive_sample_loss at step 296600: 0.062425
2023-03-17 08:18:37,406 INFO     Train negative_sample_loss at step 296600: 0.053830
2023-03-17 08:18:37,406 INFO     Train loss at step 296600: 0.058128
2023-03-17 08:18:56,745 INFO     Train positive_sample_loss at step 296700: 0.062672
2023-03-17 08:18:56,746 INFO     Train negative_sample_loss at step 296700: 0.054428
2023-03-17 08:18:56,746 INFO     Train loss at step 296700: 0.058550
2023-03-17 08:19:16,075 INFO     Train positive_sample_loss at step 296800: 0.062814
2023-03-17 08:19:16,076 INFO     Train negative_sample_loss at step 296800: 0.053865
2023-03-17 08:19:16,076 INFO     Train loss at step 296800: 0.058340
2023-03-17 08:19:35,396 INFO     Train positive_sample_loss at step 296900: 0.063026
2023-03-17 08:19:35,397 INFO     Train negative_sample_loss at step 296900: 0.054193
2023-03-17 08:19:35,397 INFO     Train loss at step 296900: 0.058609
2023-03-17 08:19:54,733 INFO     Train positive_sample_loss at step 297000: 0.063110
2023-03-17 08:19:54,733 INFO     Train negative_sample_loss at step 297000: 0.054416
2023-03-17 08:19:54,734 INFO     Train loss at step 297000: 0.058763
2023-03-17 08:20:14,064 INFO     Train positive_sample_loss at step 297100: 0.063408
2023-03-17 08:20:14,065 INFO     Train negative_sample_loss at step 297100: 0.054353
2023-03-17 08:20:14,065 INFO     Train loss at step 297100: 0.058880
2023-03-17 08:20:40,394 INFO     Train positive_sample_loss at step 297200: 0.063388
2023-03-17 08:20:40,395 INFO     Train negative_sample_loss at step 297200: 0.054675
2023-03-17 08:20:40,395 INFO     Train loss at step 297200: 0.059031
2023-03-17 08:20:59,729 INFO     Train positive_sample_loss at step 297300: 0.063694
2023-03-17 08:20:59,729 INFO     Train negative_sample_loss at step 297300: 0.054221
2023-03-17 08:20:59,729 INFO     Train loss at step 297300: 0.058957
2023-03-17 08:21:19,077 INFO     Train positive_sample_loss at step 297400: 0.063777
2023-03-17 08:21:19,078 INFO     Train negative_sample_loss at step 297400: 0.054424
2023-03-17 08:21:19,078 INFO     Train loss at step 297400: 0.059100
2023-03-17 08:21:38,413 INFO     Train positive_sample_loss at step 297500: 0.063788
2023-03-17 08:21:38,414 INFO     Train negative_sample_loss at step 297500: 0.054108
2023-03-17 08:21:38,414 INFO     Train loss at step 297500: 0.058948
2023-03-17 08:21:57,753 INFO     Train positive_sample_loss at step 297600: 0.064025
2023-03-17 08:21:57,754 INFO     Train negative_sample_loss at step 297600: 0.055366
2023-03-17 08:21:57,754 INFO     Train loss at step 297600: 0.059696
2023-03-17 08:22:17,090 INFO     Train positive_sample_loss at step 297700: 0.064023
2023-03-17 08:22:17,091 INFO     Train negative_sample_loss at step 297700: 0.054570
2023-03-17 08:22:17,091 INFO     Train loss at step 297700: 0.059297
2023-03-17 08:22:36,424 INFO     Train positive_sample_loss at step 297800: 0.064383
2023-03-17 08:22:36,425 INFO     Train negative_sample_loss at step 297800: 0.055140
2023-03-17 08:22:36,425 INFO     Train loss at step 297800: 0.059762
2023-03-17 08:22:55,748 INFO     Train positive_sample_loss at step 297900: 0.064077
2023-03-17 08:22:55,749 INFO     Train negative_sample_loss at step 297900: 0.054586
2023-03-17 08:22:55,749 INFO     Train loss at step 297900: 0.059331
2023-03-17 08:23:15,070 INFO     Train positive_sample_loss at step 298000: 0.064444
2023-03-17 08:23:15,071 INFO     Train negative_sample_loss at step 298000: 0.054982
2023-03-17 08:23:15,071 INFO     Train loss at step 298000: 0.059713
2023-03-17 08:23:34,397 INFO     Train positive_sample_loss at step 298100: 0.064190
2023-03-17 08:23:34,397 INFO     Train negative_sample_loss at step 298100: 0.054760
2023-03-17 08:23:34,397 INFO     Train loss at step 298100: 0.059475
2023-03-17 08:23:53,727 INFO     Train positive_sample_loss at step 298200: 0.064258
2023-03-17 08:23:53,727 INFO     Train negative_sample_loss at step 298200: 0.054841
2023-03-17 08:23:53,727 INFO     Train loss at step 298200: 0.059549
2023-03-17 08:24:19,911 INFO     Train positive_sample_loss at step 298300: 0.064320
2023-03-17 08:24:19,911 INFO     Train negative_sample_loss at step 298300: 0.054931
2023-03-17 08:24:19,911 INFO     Train loss at step 298300: 0.059626
2023-03-17 08:24:39,236 INFO     Train positive_sample_loss at step 298400: 0.064335
2023-03-17 08:24:39,237 INFO     Train negative_sample_loss at step 298400: 0.055178
2023-03-17 08:24:39,237 INFO     Train loss at step 298400: 0.059757
2023-03-17 08:24:58,579 INFO     Train positive_sample_loss at step 298500: 0.064393
2023-03-17 08:24:58,580 INFO     Train negative_sample_loss at step 298500: 0.054910
2023-03-17 08:24:58,580 INFO     Train loss at step 298500: 0.059652
2023-03-17 08:25:17,918 INFO     Train positive_sample_loss at step 298600: 0.064389
2023-03-17 08:25:17,919 INFO     Train negative_sample_loss at step 298600: 0.054884
2023-03-17 08:25:17,919 INFO     Train loss at step 298600: 0.059637
2023-03-17 08:25:37,256 INFO     Train positive_sample_loss at step 298700: 0.064283
2023-03-17 08:25:37,256 INFO     Train negative_sample_loss at step 298700: 0.055110
2023-03-17 08:25:37,256 INFO     Train loss at step 298700: 0.059697
2023-03-17 08:25:56,579 INFO     Train positive_sample_loss at step 298800: 0.064314
2023-03-17 08:25:56,580 INFO     Train negative_sample_loss at step 298800: 0.055759
2023-03-17 08:25:56,580 INFO     Train loss at step 298800: 0.060037
2023-03-17 08:26:15,898 INFO     Train positive_sample_loss at step 298900: 0.064179
2023-03-17 08:26:15,898 INFO     Train negative_sample_loss at step 298900: 0.055168
2023-03-17 08:26:15,899 INFO     Train loss at step 298900: 0.059673
2023-03-17 08:26:41,153 INFO     Train positive_sample_loss at step 299000: 0.062788
2023-03-17 08:26:41,154 INFO     Train negative_sample_loss at step 299000: 0.055307
2023-03-17 08:26:41,154 INFO     Train loss at step 299000: 0.059048
2023-03-17 08:27:00,496 INFO     Train positive_sample_loss at step 299100: 0.056022
2023-03-17 08:27:00,496 INFO     Train negative_sample_loss at step 299100: 0.055097
2023-03-17 08:27:00,497 INFO     Train loss at step 299100: 0.055560
2023-03-17 08:27:19,827 INFO     Train positive_sample_loss at step 299200: 0.056880
2023-03-17 08:27:19,828 INFO     Train negative_sample_loss at step 299200: 0.054440
2023-03-17 08:27:19,828 INFO     Train loss at step 299200: 0.055660
2023-03-17 08:27:39,145 INFO     Train positive_sample_loss at step 299300: 0.057692
2023-03-17 08:27:39,145 INFO     Train negative_sample_loss at step 299300: 0.054739
2023-03-17 08:27:39,145 INFO     Train loss at step 299300: 0.056215
2023-03-17 08:27:58,468 INFO     Train positive_sample_loss at step 299400: 0.058348
2023-03-17 08:27:58,468 INFO     Train negative_sample_loss at step 299400: 0.054357
2023-03-17 08:27:58,469 INFO     Train loss at step 299400: 0.056353
2023-03-17 08:28:17,781 INFO     Train positive_sample_loss at step 299500: 0.058957
2023-03-17 08:28:17,782 INFO     Train negative_sample_loss at step 299500: 0.054160
2023-03-17 08:28:17,782 INFO     Train loss at step 299500: 0.056559
2023-03-17 08:28:37,101 INFO     Train positive_sample_loss at step 299600: 0.059247
2023-03-17 08:28:37,101 INFO     Train negative_sample_loss at step 299600: 0.054334
2023-03-17 08:28:37,102 INFO     Train loss at step 299600: 0.056791
2023-03-17 08:28:56,420 INFO     Train positive_sample_loss at step 299700: 0.059949
2023-03-17 08:28:56,421 INFO     Train negative_sample_loss at step 299700: 0.054293
2023-03-17 08:28:56,421 INFO     Train loss at step 299700: 0.057121
2023-03-17 08:29:15,758 INFO     Train positive_sample_loss at step 299800: 0.060186
2023-03-17 08:29:15,758 INFO     Train negative_sample_loss at step 299800: 0.053908
2023-03-17 08:29:15,758 INFO     Train loss at step 299800: 0.057047
2023-03-17 08:29:35,079 INFO     Train positive_sample_loss at step 299900: 0.060710
2023-03-17 08:29:35,080 INFO     Train negative_sample_loss at step 299900: 0.054008
2023-03-17 08:29:35,080 INFO     Train loss at step 299900: 0.057359
2023-03-17 08:29:55,681 INFO     Evaluating on Valid Dataset...
2023-03-17 08:29:56,685 INFO     Evaluating the model... (0/26842)
2023-03-17 08:29:58,240 INFO     Evaluating the model... (1000/26842)
2023-03-17 08:29:59,480 INFO     Evaluating the model... (2000/26842)
2023-03-17 08:30:00,718 INFO     Evaluating the model... (3000/26842)
2023-03-17 08:30:01,962 INFO     Evaluating the model... (4000/26842)
2023-03-17 08:30:03,198 INFO     Evaluating the model... (5000/26842)
2023-03-17 08:30:04,444 INFO     Evaluating the model... (6000/26842)
2023-03-17 08:30:05,690 INFO     Evaluating the model... (7000/26842)
2023-03-17 08:30:06,935 INFO     Evaluating the model... (8000/26842)
2023-03-17 08:30:08,186 INFO     Evaluating the model... (9000/26842)
2023-03-17 08:30:09,421 INFO     Evaluating the model... (10000/26842)
2023-03-17 08:30:10,653 INFO     Evaluating the model... (11000/26842)
2023-03-17 08:30:11,884 INFO     Evaluating the model... (12000/26842)
2023-03-17 08:30:13,124 INFO     Evaluating the model... (13000/26842)
2023-03-17 08:30:15,421 INFO     Evaluating the model... (14000/26842)
2023-03-17 08:30:16,902 INFO     Evaluating the model... (15000/26842)
2023-03-17 08:30:18,366 INFO     Evaluating the model... (16000/26842)
2023-03-17 08:30:19,837 INFO     Evaluating the model... (17000/26842)
2023-03-17 08:30:21,310 INFO     Evaluating the model... (18000/26842)
2023-03-17 08:30:22,790 INFO     Evaluating the model... (19000/26842)
2023-03-17 08:30:24,265 INFO     Evaluating the model... (20000/26842)
2023-03-17 08:30:25,745 INFO     Evaluating the model... (21000/26842)
2023-03-17 08:30:27,219 INFO     Evaluating the model... (22000/26842)
2023-03-17 08:30:28,706 INFO     Evaluating the model... (23000/26842)
2023-03-17 08:30:30,187 INFO     Evaluating the model... (24000/26842)
2023-03-17 08:30:31,661 INFO     Evaluating the model... (25000/26842)
2023-03-17 08:30:33,136 INFO     Evaluating the model... (26000/26842)
2023-03-17 08:30:34,718 INFO     Valid hits@1_list at step 299999: 0.656572
2023-03-17 08:30:34,718 INFO     Summary name Valid_hits@1_list is illegal; using Valid_hits_1_list instead.
2023-03-17 08:30:34,718 INFO     Valid hits@3_list at step 299999: 0.746200
2023-03-17 08:30:34,718 INFO     Summary name Valid_hits@3_list is illegal; using Valid_hits_3_list instead.
2023-03-17 08:30:34,719 INFO     Valid hits@10_list at step 299999: 0.835088
2023-03-17 08:30:34,719 INFO     Summary name Valid_hits@10_list is illegal; using Valid_hits_10_list instead.
2023-03-17 08:30:34,719 INFO     Valid mrr_list at step 299999: 0.717513
2023-03-17 08:30:34,719 INFO     Evaluating on Test Dataset...
funtion time use:38858ms
2023-03-17 08:30:35,347 INFO     Evaluating the model... (0/37410)
2023-03-17 08:30:36,606 INFO     Evaluating the model... (1000/37410)
2023-03-17 08:30:37,807 INFO     Evaluating the model... (2000/37410)
2023-03-17 08:30:39,013 INFO     Evaluating the model... (3000/37410)
2023-03-17 08:30:40,215 INFO     Evaluating the model... (4000/37410)
2023-03-17 08:30:41,425 INFO     Evaluating the model... (5000/37410)
2023-03-17 08:30:42,650 INFO     Evaluating the model... (6000/37410)
2023-03-17 08:30:43,886 INFO     Evaluating the model... (7000/37410)
2023-03-17 08:30:45,128 INFO     Evaluating the model... (8000/37410)
2023-03-17 08:30:46,377 INFO     Evaluating the model... (9000/37410)
2023-03-17 08:30:47,623 INFO     Evaluating the model... (10000/37410)
2023-03-17 08:30:48,872 INFO     Evaluating the model... (11000/37410)
2023-03-17 08:30:50,124 INFO     Evaluating the model... (12000/37410)
2023-03-17 08:30:51,362 INFO     Evaluating the model... (13000/37410)
2023-03-17 08:30:52,595 INFO     Evaluating the model... (14000/37410)
2023-03-17 08:30:53,835 INFO     Evaluating the model... (15000/37410)
2023-03-17 08:30:55,070 INFO     Evaluating the model... (16000/37410)
2023-03-17 08:30:56,296 INFO     Evaluating the model... (17000/37410)
2023-03-17 08:30:57,516 INFO     Evaluating the model... (18000/37410)
2023-03-17 08:30:59,667 INFO     Evaluating the model... (19000/37410)
2023-03-17 08:31:01,151 INFO     Evaluating the model... (20000/37410)
2023-03-17 08:31:02,629 INFO     Evaluating the model... (21000/37410)
2023-03-17 08:31:04,110 INFO     Evaluating the model... (22000/37410)
2023-03-17 08:31:05,586 INFO     Evaluating the model... (23000/37410)
2023-03-17 08:31:07,066 INFO     Evaluating the model... (24000/37410)
2023-03-17 08:31:08,565 INFO     Evaluating the model... (25000/37410)
2023-03-17 08:31:10,049 INFO     Evaluating the model... (26000/37410)
2023-03-17 08:31:11,526 INFO     Evaluating the model... (27000/37410)
2023-03-17 08:31:13,005 INFO     Evaluating the model... (28000/37410)
2023-03-17 08:31:14,486 INFO     Evaluating the model... (29000/37410)
2023-03-17 08:31:15,964 INFO     Evaluating the model... (30000/37410)
2023-03-17 08:31:17,436 INFO     Evaluating the model... (31000/37410)
2023-03-17 08:31:18,909 INFO     Evaluating the model... (32000/37410)
2023-03-17 08:31:20,395 INFO     Evaluating the model... (33000/37410)
2023-03-17 08:31:21,877 INFO     Evaluating the model... (34000/37410)
2023-03-17 08:31:23,352 INFO     Evaluating the model... (35000/37410)
2023-03-17 08:31:24,818 INFO     Evaluating the model... (36000/37410)
2023-03-17 08:31:26,290 INFO     Evaluating the model... (37000/37410)
2023-03-17 08:31:27,313 INFO     Test hits@1_list at step 299999: 0.632289
2023-03-17 08:31:27,314 INFO     Summary name Test_hits@1_list is illegal; using Test_hits_1_list instead.
2023-03-17 08:31:27,314 INFO     Test hits@3_list at step 299999: 0.731299
2023-03-17 08:31:27,314 INFO     Summary name Test_hits@3_list is illegal; using Test_hits_3_list instead.
2023-03-17 08:31:27,314 INFO     Test hits@10_list at step 299999: 0.837925
2023-03-17 08:31:27,314 INFO     Summary name Test_hits@10_list is illegal; using Test_hits_10_list instead.
2023-03-17 08:31:27,314 INFO     Test mrr_list at step 299999: 0.700613
2023-03-17 08:31:27,314 INFO     Evaluating on Training Dataset...
funtion time use:52332ms
{'hits@1_list': 0.6322886943817139, 'hits@3_list': 0.7312991619110107, 'hits@10_list': 0.8379247188568115, 'mrr_list': 0.7006131410598755}
2023-03-17 08:31:28,374 INFO     Evaluating the model... (0/12500)
2023-03-17 08:31:29,712 INFO     Evaluating the model... (1000/12500)
2023-03-17 08:31:30,949 INFO     Evaluating the model... (2000/12500)
2023-03-17 08:31:32,184 INFO     Evaluating the model... (3000/12500)
2023-03-17 08:31:33,433 INFO     Evaluating the model... (4000/12500)
2023-03-17 08:31:34,681 INFO     Evaluating the model... (5000/12500)
2023-03-17 08:31:35,930 INFO     Evaluating the model... (6000/12500)
2023-03-17 08:31:38,284 INFO     Evaluating the model... (7000/12500)
2023-03-17 08:31:39,750 INFO     Evaluating the model... (8000/12500)
2023-03-17 08:31:41,217 INFO     Evaluating the model... (9000/12500)
2023-03-17 08:31:42,682 INFO     Evaluating the model... (10000/12500)
2023-03-17 08:31:44,146 INFO     Evaluating the model... (11000/12500)
2023-03-17 08:31:45,616 INFO     Evaluating the model... (12000/12500)
2023-03-17 08:31:46,582 INFO     Train hits@1_list at step 299999: 0.770700
2023-03-17 08:31:46,582 INFO     Summary name Train_hits@1_list is illegal; using Train_hits_1_list instead.
2023-03-17 08:31:46,583 INFO     Train hits@3_list at step 299999: 0.827807
2023-03-17 08:31:46,583 INFO     Summary name Train_hits@3_list is illegal; using Train_hits_3_list instead.
2023-03-17 08:31:46,583 INFO     Train hits@10_list at step 299999: 0.874787
2023-03-17 08:31:46,583 INFO     Summary name Train_hits@10_list is illegal; using Train_hits_10_list instead.
2023-03-17 08:31:46,583 INFO     Train mrr_list at step 299999: 0.807462
funtion time use:18703ms
